I20250120 12:15:39 3554128 dinov2 config.py:59] git:
  sha: 3ded4e34eb54a7264c5d718f22ec7b24d73ba04c, status: has uncommitted changes, branch: main

I20250120 12:15:39 3554128 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: CelebA_pixelated_B/config.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
pretrained_weights: CelebA_pixelated_B/eval/training_124999/teacher_checkpoint.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: CelebAPixelatedTrain
val_class_mapping_fpath: None
val_dataset_str: CelebAPixelatedVal
val_metric_type: mean_accuracy
I20250120 12:15:39 3554128 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250120 12:15:39 3554128 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAPixelatedABTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
  a_b_training: B
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250120 12:15:39 3554128 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250120 12:15:58 3554128 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250120 12:15:58 3554128 dinov2 utils.py:33] Pretrained weights found at CelebA_pixelated_B/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250120 12:15:58 3554128 dinov2 loaders.py:116] using dataset: "CelebAPixelatedTrain"
I20250120 12:16:00 3554128 dinov2 loaders.py:121] # of dataset samples: 162,127
I20250120 12:16:01 3554128 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 12:16:01 3554128 dinov2 loaders.py:154] sampler: sharded infinite
I20250120 12:16:01 3554128 dinov2 loaders.py:238] using PyTorch data loader
W20250120 12:16:01 3554128 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 12:16:01 3554128 dinov2 loaders.py:253] infinite data loader
I20250120 12:16:01 3554128 dinov2 loaders.py:116] using dataset: "CelebAPixelatedVal"
I20250120 12:16:01 3554128 dinov2 loaders.py:121] # of dataset samples: 19,792
I20250120 12:16:01 3554128 dinov2 loaders.py:179] sampler: distributed
I20250120 12:16:01 3554128 dinov2 loaders.py:238] using PyTorch data loader
W20250120 12:16:01 3554128 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 12:16:01 3554128 dinov2 loaders.py:251] # of batches: 155
I20250120 12:16:01 3554128 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 12:16:01 3554128 dinov2 linear.py:338] Starting training from iteration 0
I20250120 12:16:05 3554128 dinov2 helpers.py:102] Training  [    0/12500]  eta: 13:55:23  loss: 35.1254 (35.1254)  lr: 0.0000 (0.0000)  time: 4.009846  data: 3.463225  max mem: 2706
I20250120 12:16:05 3554128 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20250120 12:16:07 3554128 dinov2 helpers.py:102] Training  [   10/12500]  eta: 1:51:49  loss: 30.5704 (32.8479)  lr: 0.0000 (0.0000)  time: 0.537172  data: 0.315274  max mem: 3115
I20250120 12:16:09 3554128 dinov2 helpers.py:102] Training  [   20/12500]  eta: 1:17:06  loss: 31.5609 (32.4189)  lr: 0.0000 (0.0000)  time: 0.188735  data: 0.000487  max mem: 3115
I20250120 12:16:11 3554128 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:04:47  loss: 31.5609 (33.9640)  lr: 0.0000 (0.0000)  time: 0.187756  data: 0.000417  max mem: 3115
I20250120 12:16:13 3554128 dinov2 helpers.py:102] Training  [   40/12500]  eta: 0:58:29  loss: 35.1254 (34.2392)  lr: 0.0000 (0.0000)  time: 0.188156  data: 0.000389  max mem: 3115
I20250120 12:16:15 3554128 dinov2 helpers.py:102] Training  [   50/12500]  eta: 0:54:41  loss: 34.6860 (34.3137)  lr: 0.0000 (0.0000)  time: 0.188855  data: 0.000430  max mem: 3115
I20250120 12:16:17 3554128 dinov2 helpers.py:102] Training  [   60/12500]  eta: 0:52:07  loss: 35.1254 (34.4522)  lr: 0.0000 (0.0000)  time: 0.189462  data: 0.000375  max mem: 3115
I20250120 12:16:18 3554128 dinov2 helpers.py:102] Training  [   70/12500]  eta: 0:50:17  loss: 35.1254 (35.2748)  lr: 0.0000 (0.0000)  time: 0.189781  data: 0.000395  max mem: 3115
I20250120 12:16:20 3554128 dinov2 helpers.py:102] Training  [   80/12500]  eta: 0:48:54  loss: 35.2837 (35.9694)  lr: 0.0000 (0.0000)  time: 0.190122  data: 0.000473  max mem: 3115
I20250120 12:16:22 3554128 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:47:50  loss: 35.1254 (35.8720)  lr: 0.0000 (0.0000)  time: 0.190697  data: 0.000427  max mem: 3115
I20250120 12:16:24 3554128 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:46:59  loss: 35.1254 (35.6085)  lr: 0.0000 (0.0000)  time: 0.191128  data: 0.000415  max mem: 3115
I20250120 12:16:26 3554128 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:46:16  loss: 34.9946 (35.3740)  lr: 0.0000 (0.0000)  time: 0.191263  data: 0.000409  max mem: 3115
I20250120 12:16:28 3554128 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:45:41  loss: 34.9946 (34.8533)  lr: 0.0000 (0.0000)  time: 0.191654  data: 0.000375  max mem: 3115
I20250120 12:16:30 3554128 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:45:11  loss: 34.6860 (34.8076)  lr: 0.0000 (0.0000)  time: 0.191905  data: 0.000396  max mem: 3115
I20250120 12:16:32 3554128 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:44:45  loss: 34.9946 (35.1143)  lr: 0.0000 (0.0000)  time: 0.192167  data: 0.000409  max mem: 3115
I20250120 12:16:34 3554128 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:44:23  loss: 34.6860 (34.9843)  lr: 0.0000 (0.0000)  time: 0.192525  data: 0.000410  max mem: 3115
I20250120 12:16:36 3554128 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:44:03  loss: 34.6860 (34.7360)  lr: 0.0000 (0.0000)  time: 0.192689  data: 0.000416  max mem: 3115
I20250120 12:16:38 3554128 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:43:46  loss: 34.2136 (34.6167)  lr: 0.0000 (0.0000)  time: 0.193057  data: 0.000423  max mem: 3115
I20250120 12:16:40 3554128 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:43:31  loss: 34.6860 (34.7714)  lr: 0.0000 (0.0000)  time: 0.193381  data: 0.000425  max mem: 3115
I20250120 12:16:41 3554128 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:43:17  loss: 34.2136 (34.6018)  lr: 0.0000 (0.0000)  time: 0.193672  data: 0.000457  max mem: 3115
I20250120 12:16:43 3554128 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:43:05  loss: 33.7863 (34.5630)  lr: 0.0000 (0.0000)  time: 0.194209  data: 0.000477  max mem: 3115
I20250120 12:16:45 3554128 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:42:53  loss: 33.7863 (34.3945)  lr: 0.0000 (0.0000)  time: 0.194443  data: 0.000442  max mem: 3115
I20250120 12:16:47 3554128 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:42:43  loss: 34.2136 (34.4580)  lr: 0.0000 (0.0000)  time: 0.194459  data: 0.000407  max mem: 3115
I20250120 12:16:49 3554128 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:42:33  loss: 33.7863 (34.4036)  lr: 0.0000 (0.0000)  time: 0.194557  data: 0.000428  max mem: 3115
I20250120 12:16:51 3554128 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:42:24  loss: 33.7863 (34.5978)  lr: 0.0000 (0.0000)  time: 0.194717  data: 0.000446  max mem: 3115
I20250120 12:16:53 3554128 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:42:16  loss: 33.1525 (34.4025)  lr: 0.0000 (0.0000)  time: 0.194926  data: 0.000433  max mem: 3115
I20250120 12:16:55 3554128 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:42:09  loss: 33.1525 (34.3999)  lr: 0.0000 (0.0000)  time: 0.195178  data: 0.000370  max mem: 3115
I20250120 12:16:57 3554128 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:42:01  loss: 33.0350 (34.3495)  lr: 0.0000 (0.0000)  time: 0.195268  data: 0.000374  max mem: 3115
I20250120 12:16:59 3554128 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:41:55  loss: 33.0350 (34.3387)  lr: 0.0000 (0.0000)  time: 0.195307  data: 0.000382  max mem: 3115
I20250120 12:17:01 3554128 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:41:48  loss: 32.9900 (34.2661)  lr: 0.0000 (0.0000)  time: 0.195566  data: 0.000367  max mem: 3115
I20250120 12:17:03 3554128 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:41:42  loss: 32.9900 (34.1171)  lr: 0.0000 (0.0000)  time: 0.195642  data: 0.000381  max mem: 3115
I20250120 12:17:05 3554128 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:41:37  loss: 33.0350 (34.1054)  lr: 0.0000 (0.0000)  time: 0.195838  data: 0.000362  max mem: 3115
I20250120 12:17:07 3554128 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:41:31  loss: 33.0350 (33.9219)  lr: 0.0000 (0.0000)  time: 0.196251  data: 0.000355  max mem: 3115
I20250120 12:17:09 3554128 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:41:26  loss: 33.0350 (33.9270)  lr: 0.0000 (0.0000)  time: 0.196460  data: 0.000365  max mem: 3115
I20250120 12:17:11 3554128 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:41:22  loss: 33.0350 (33.9835)  lr: 0.0000 (0.0000)  time: 0.196452  data: 0.000410  max mem: 3115
I20250120 12:17:13 3554128 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:41:17  loss: 32.9900 (33.8639)  lr: 0.0000 (0.0000)  time: 0.196510  data: 0.000403  max mem: 3115
I20250120 12:17:15 3554128 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:41:12  loss: 33.1525 (33.9562)  lr: 0.0000 (0.0000)  time: 0.196604  data: 0.000395  max mem: 3115
I20250120 12:17:17 3554128 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:41:08  loss: 33.1525 (33.8800)  lr: 0.0000 (0.0000)  time: 0.196655  data: 0.000420  max mem: 3115
I20250120 12:17:19 3554128 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:41:04  loss: 32.9900 (33.8431)  lr: 0.0000 (0.0000)  time: 0.196690  data: 0.000388  max mem: 3115
I20250120 12:17:21 3554128 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:41:00  loss: 33.1525 (33.9751)  lr: 0.0000 (0.0000)  time: 0.196920  data: 0.000363  max mem: 3115
I20250120 12:17:23 3554128 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:40:56  loss: 32.9900 (33.9473)  lr: 0.0000 (0.0000)  time: 0.197038  data: 0.000371  max mem: 3115
I20250120 12:17:25 3554128 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:40:52  loss: 33.1525 (34.0140)  lr: 0.0000 (0.0000)  time: 0.197049  data: 0.000391  max mem: 3115
I20250120 12:17:27 3554128 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:40:49  loss: 32.9900 (33.9622)  lr: 0.0000 (0.0000)  time: 0.197278  data: 0.000421  max mem: 3115
I20250120 12:17:29 3554128 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:40:45  loss: 32.9753 (33.9398)  lr: 0.0000 (0.0000)  time: 0.197230  data: 0.000435  max mem: 3115
I20250120 12:17:30 3554128 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:40:42  loss: 32.9753 (34.0321)  lr: 0.0000 (0.0000)  time: 0.197313  data: 0.000427  max mem: 3115
I20250120 12:17:32 3554128 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:40:38  loss: 32.9753 (33.9684)  lr: 0.0000 (0.0000)  time: 0.197539  data: 0.000416  max mem: 3115
I20250120 12:17:34 3554128 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:40:35  loss: 32.8343 (33.9232)  lr: 0.0000 (0.0000)  time: 0.197710  data: 0.000410  max mem: 3115
I20250120 12:17:36 3554128 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:40:32  loss: 32.8343 (33.9047)  lr: 0.0000 (0.0000)  time: 0.197920  data: 0.000399  max mem: 3115
I20250120 12:17:38 3554128 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:40:29  loss: 32.4394 (33.7796)  lr: 0.0000 (0.0000)  time: 0.197875  data: 0.000385  max mem: 3115
I20250120 12:17:40 3554128 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:40:26  loss: 32.8343 (33.8238)  lr: 0.0000 (0.0000)  time: 0.197818  data: 0.000393  max mem: 3115
I20250120 12:17:42 3554128 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:40:23  loss: 32.8343 (33.7519)  lr: 0.0000 (0.0000)  time: 0.197888  data: 0.000390  max mem: 3115
I20250120 12:17:44 3554128 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:40:20  loss: 32.4394 (33.6710)  lr: 0.0000 (0.0000)  time: 0.197816  data: 0.000370  max mem: 3115
I20250120 12:17:46 3554128 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:40:17  loss: 32.4394 (33.6179)  lr: 0.0000 (0.0000)  time: 0.197824  data: 0.000409  max mem: 3115
I20250120 12:17:48 3554128 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:40:14  loss: 32.4394 (33.6324)  lr: 0.0000 (0.0000)  time: 0.198029  data: 0.000423  max mem: 3115
I20250120 12:17:50 3554128 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:40:11  loss: 32.4394 (33.6652)  lr: 0.0000 (0.0000)  time: 0.198083  data: 0.000384  max mem: 3115
I20250120 12:17:52 3554128 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:40:08  loss: 32.8343 (33.6823)  lr: 0.0000 (0.0000)  time: 0.198128  data: 0.000404  max mem: 3115
I20250120 12:17:54 3554128 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:40:06  loss: 32.8343 (33.6938)  lr: 0.0000 (0.0000)  time: 0.198184  data: 0.000418  max mem: 3115
I20250120 12:17:56 3554128 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:40:03  loss: 32.9753 (33.7986)  lr: 0.0000 (0.0000)  time: 0.198252  data: 0.000409  max mem: 3115
I20250120 12:17:58 3554128 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:40:00  loss: 33.0330 (33.8416)  lr: 0.0000 (0.0000)  time: 0.198214  data: 0.000382  max mem: 3115
I20250120 12:18:00 3554128 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:39:58  loss: 32.9753 (33.7422)  lr: 0.0000 (0.0000)  time: 0.197943  data: 0.000391  max mem: 3115
I20250120 12:18:02 3554128 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:39:55  loss: 33.0330 (33.7726)  lr: 0.0000 (0.0000)  time: 0.197875  data: 0.000417  max mem: 3115
I20250120 12:18:04 3554128 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:39:52  loss: 33.0330 (33.7687)  lr: 0.0000 (0.0000)  time: 0.198018  data: 0.000376  max mem: 3115
I20250120 12:18:06 3554128 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:39:50  loss: 33.0330 (33.7266)  lr: 0.0000 (0.0000)  time: 0.198102  data: 0.000394  max mem: 3115
I20250120 12:18:08 3554128 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:39:47  loss: 33.0330 (33.6510)  lr: 0.0000 (0.0000)  time: 0.198066  data: 0.000442  max mem: 3115
I20250120 12:18:10 3554128 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:39:44  loss: 33.0330 (33.6948)  lr: 0.0000 (0.0000)  time: 0.197960  data: 0.000421  max mem: 3115
I20250120 12:18:12 3554128 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:39:42  loss: 33.0330 (33.6830)  lr: 0.0000 (0.0000)  time: 0.198072  data: 0.000425  max mem: 3115
I20250120 12:18:14 3554128 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:39:39  loss: 33.0330 (33.6110)  lr: 0.0000 (0.0000)  time: 0.198076  data: 0.000453  max mem: 3115
I20250120 12:18:16 3554128 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:39:37  loss: 33.0007 (33.6020)  lr: 0.0000 (0.0000)  time: 0.198137  data: 0.000438  max mem: 3115
I20250120 12:18:18 3554128 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:39:34  loss: 33.0007 (33.4521)  lr: 0.0000 (0.0000)  time: 0.198406  data: 0.000435  max mem: 3115
I20250120 12:18:20 3554128 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:39:32  loss: 32.9154 (33.4045)  lr: 0.0000 (0.0000)  time: 0.198351  data: 0.000405  max mem: 3115
I20250120 12:18:22 3554128 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:39:29  loss: 32.9154 (33.3613)  lr: 0.0000 (0.0000)  time: 0.198047  data: 0.000404  max mem: 3115
I20250120 12:18:24 3554128 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:39:27  loss: 32.9154 (33.2888)  lr: 0.0000 (0.0000)  time: 0.198032  data: 0.000400  max mem: 3115
I20250120 12:18:26 3554128 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:39:25  loss: 32.9154 (33.2342)  lr: 0.0000 (0.0000)  time: 0.198340  data: 0.000377  max mem: 3115
I20250120 12:18:28 3554128 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:39:22  loss: 32.9154 (33.2571)  lr: 0.0000 (0.0000)  time: 0.198460  data: 0.000391  max mem: 3115
I20250120 12:18:30 3554128 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:39:20  loss: 31.4380 (33.2328)  lr: 0.0000 (0.0000)  time: 0.198439  data: 0.000403  max mem: 3115
I20250120 12:18:32 3554128 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:39:17  loss: 31.1133 (33.1638)  lr: 0.0000 (0.0000)  time: 0.198383  data: 0.000430  max mem: 3115
I20250120 12:18:34 3554128 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:39:15  loss: 31.1133 (33.1549)  lr: 0.0000 (0.0000)  time: 0.198567  data: 0.000409  max mem: 3115
I20250120 12:18:36 3554128 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:39:13  loss: 31.1133 (33.1573)  lr: 0.0000 (0.0000)  time: 0.198615  data: 0.000362  max mem: 3115
I20250120 12:18:38 3554128 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:39:10  loss: 31.1133 (33.2519)  lr: 0.0000 (0.0000)  time: 0.198439  data: 0.000380  max mem: 3115
I20250120 12:18:40 3554128 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:39:08  loss: 31.4380 (33.2803)  lr: 0.0000 (0.0000)  time: 0.198317  data: 0.000418  max mem: 3115
I20250120 12:18:42 3554128 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:39:06  loss: 31.4380 (33.2683)  lr: 0.0000 (0.0000)  time: 0.198400  data: 0.000398  max mem: 3115
I20250120 12:18:44 3554128 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:39:03  loss: 31.4380 (33.3458)  lr: 0.0000 (0.0000)  time: 0.198422  data: 0.000398  max mem: 3115
I20250120 12:18:46 3554128 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:39:01  loss: 31.4380 (33.3010)  lr: 0.0000 (0.0000)  time: 0.198239  data: 0.000429  max mem: 3115
I20250120 12:18:48 3554128 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:38:59  loss: 31.4380 (33.2519)  lr: 0.0000 (0.0000)  time: 0.198177  data: 0.000416  max mem: 3115
I20250120 12:18:50 3554128 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:38:57  loss: 31.4380 (33.3460)  lr: 0.0000 (0.0000)  time: 0.198306  data: 0.000388  max mem: 3115
I20250120 12:18:52 3554128 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:38:54  loss: 30.5284 (33.3132)  lr: 0.0000 (0.0000)  time: 0.198476  data: 0.000384  max mem: 3115
I20250120 12:18:54 3554128 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:38:52  loss: 31.4380 (33.3184)  lr: 0.0000 (0.0000)  time: 0.198379  data: 0.000404  max mem: 3115
I20250120 12:18:56 3554128 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:38:50  loss: 31.4380 (33.3087)  lr: 0.0000 (0.0000)  time: 0.198507  data: 0.000448  max mem: 3115
I20250120 12:18:58 3554128 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:38:47  loss: 31.4380 (33.2756)  lr: 0.0000 (0.0000)  time: 0.198561  data: 0.000421  max mem: 3115
I20250120 12:19:00 3554128 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:38:45  loss: 31.4380 (33.2463)  lr: 0.0000 (0.0000)  time: 0.198360  data: 0.000380  max mem: 3115
I20250120 12:19:02 3554128 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:38:43  loss: 32.3132 (33.2700)  lr: 0.0000 (0.0000)  time: 0.198333  data: 0.000400  max mem: 3115
I20250120 12:19:04 3554128 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:38:41  loss: 32.4677 (33.2987)  lr: 0.0000 (0.0000)  time: 0.198396  data: 0.000381  max mem: 3115
I20250120 12:19:06 3554128 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:38:38  loss: 32.4677 (33.2250)  lr: 0.0000 (0.0000)  time: 0.198508  data: 0.000403  max mem: 3115
I20250120 12:19:08 3554128 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:38:36  loss: 32.3132 (33.1731)  lr: 0.0000 (0.0000)  time: 0.198464  data: 0.000434  max mem: 3115
I20250120 12:19:10 3554128 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:38:34  loss: 32.3132 (33.1319)  lr: 0.0000 (0.0000)  time: 0.198485  data: 0.000418  max mem: 3115
I20250120 12:19:12 3554128 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:38:32  loss: 32.4677 (33.1482)  lr: 0.0000 (0.0000)  time: 0.198724  data: 0.000404  max mem: 3115
I20250120 12:19:14 3554128 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:38:30  loss: 32.3132 (33.1317)  lr: 0.0000 (0.0000)  time: 0.198783  data: 0.000430  max mem: 3115
I20250120 12:19:16 3554128 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:38:28  loss: 32.3132 (33.1947)  lr: 0.0000 (0.0000)  time: 0.198817  data: 0.000449  max mem: 3115
I20250120 12:19:18 3554128 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:38:25  loss: 31.5463 (33.1467)  lr: 0.0000 (0.0000)  time: 0.198909  data: 0.000461  max mem: 3115
I20250120 12:19:20 3554128 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:38:23  loss: 30.6370 (33.1151)  lr: 0.0000 (0.0000)  time: 0.198788  data: 0.000441  max mem: 3115
I20250120 12:19:22 3554128 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:38:21  loss: 30.5284 (33.0831)  lr: 0.0000 (0.0000)  time: 0.198631  data: 0.000390  max mem: 3115
I20250120 12:19:24 3554128 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:38:19  loss: 30.5284 (33.0631)  lr: 0.0000 (0.0000)  time: 0.198815  data: 0.000387  max mem: 3115
I20250120 12:19:26 3554128 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:38:17  loss: 30.5284 (33.0187)  lr: 0.0000 (0.0000)  time: 0.198706  data: 0.000396  max mem: 3115
I20250120 12:19:28 3554128 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:38:15  loss: 30.5284 (32.9944)  lr: 0.0000 (0.0000)  time: 0.198424  data: 0.000400  max mem: 3115
I20250120 12:19:30 3554128 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:38:12  loss: 30.4921 (32.9604)  lr: 0.0000 (0.0000)  time: 0.198657  data: 0.000453  max mem: 3115
I20250120 12:19:31 3554128 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:38:10  loss: 30.4921 (32.9597)  lr: 0.0000 (0.0000)  time: 0.198725  data: 0.000448  max mem: 3115
I20250120 12:19:33 3554128 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:38:08  loss: 30.3641 (32.8721)  lr: 0.0000 (0.0000)  time: 0.198843  data: 0.000413  max mem: 3115
I20250120 12:19:35 3554128 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:38:06  loss: 29.9901 (32.8436)  lr: 0.0000 (0.0000)  time: 0.198821  data: 0.000435  max mem: 3115
I20250120 12:19:37 3554128 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:38:04  loss: 29.8818 (32.7957)  lr: 0.0000 (0.0000)  time: 0.198791  data: 0.000362  max mem: 3115
I20250120 12:19:39 3554128 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:38:02  loss: 29.8818 (32.8150)  lr: 0.0000 (0.0000)  time: 0.198665  data: 0.000364  max mem: 3115
I20250120 12:19:41 3554128 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:38:00  loss: 29.8818 (32.8163)  lr: 0.0000 (0.0000)  time: 0.198447  data: 0.000417  max mem: 3115
I20250120 12:19:43 3554128 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:37:57  loss: 29.8818 (32.8364)  lr: 0.0000 (0.0000)  time: 0.198725  data: 0.000411  max mem: 3115
I20250120 12:19:45 3554128 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:37:55  loss: 29.9901 (32.8171)  lr: 0.0000 (0.0000)  time: 0.198801  data: 0.000421  max mem: 3115
I20250120 12:19:47 3554128 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:37:53  loss: 29.9901 (32.7879)  lr: 0.0000 (0.0000)  time: 0.198815  data: 0.000407  max mem: 3115
I20250120 12:19:49 3554128 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:37:51  loss: 30.4921 (32.7729)  lr: 0.0000 (0.0000)  time: 0.198719  data: 0.000446  max mem: 3115
I20250120 12:19:51 3554128 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:37:49  loss: 30.4921 (32.7553)  lr: 0.0000 (0.0000)  time: 0.198780  data: 0.000454  max mem: 3115
I20250120 12:19:53 3554128 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:37:47  loss: 30.4921 (32.7723)  lr: 0.0000 (0.0000)  time: 0.198807  data: 0.000398  max mem: 3115
I20250120 12:19:55 3554128 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:37:45  loss: 30.4921 (32.7531)  lr: 0.0000 (0.0000)  time: 0.198556  data: 0.000381  max mem: 3115
I20250120 12:19:57 3554128 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:37:43  loss: 30.5143 (32.7426)  lr: 0.0000 (0.0000)  time: 0.198618  data: 0.000403  max mem: 3115
I20250120 12:19:59 3554128 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:37:40  loss: 30.6538 (32.7453)  lr: 0.0000 (0.0000)  time: 0.198701  data: 0.000408  max mem: 3115
I20250120 12:20:01 3554128 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:37:38  loss: 30.6538 (32.7172)  lr: 0.0000 (0.0000)  time: 0.198814  data: 0.000372  max mem: 3115
I20250120 12:20:03 3554128 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:37:36  loss: 30.6538 (32.7294)  lr: 0.0000 (0.0000)  time: 0.198778  data: 0.000357  max mem: 3115
I20250120 12:20:05 3554128 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:37:34  loss: 30.6538 (32.7093)  lr: 0.0000 (0.0000)  time: 0.198871  data: 0.000383  max mem: 3115
I20250120 12:20:07 3554128 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:37:32  loss: 30.7367 (32.7175)  lr: 0.0000 (0.0000)  time: 0.198987  data: 0.000406  max mem: 3115
I20250120 12:20:09 3554128 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:37:30  loss: 31.0629 (32.7226)  lr: 0.0000 (0.0000)  time: 0.198986  data: 0.000381  max mem: 3115
I20250120 12:20:11 3554128 dinov2 linear.py:272] running validation !
I20250120 12:20:13 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:05:12    time: 2.013348  data: 1.779961  max mem: 3190
I20250120 12:20:15 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:56    time: 0.392011  data: 0.162665  max mem: 3586
I20250120 12:20:17 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:40    time: 0.214356  data: 0.000618  max mem: 3586
I20250120 12:20:19 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:33    time: 0.199092  data: 0.000290  max mem: 3586
I20250120 12:20:21 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.199695  data: 0.000276  max mem: 3586
I20250120 12:20:23 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.199821  data: 0.000271  max mem: 3586
I20250120 12:20:25 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.199898  data: 0.000264  max mem: 3586
I20250120 12:20:27 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.200040  data: 0.000275  max mem: 3586
I20250120 12:20:29 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199800  data: 0.000274  max mem: 3586
I20250120 12:20:31 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.199881  data: 0.000251  max mem: 3586
I20250120 12:20:33 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.199941  data: 0.000220  max mem: 3586
I20250120 12:20:35 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199927  data: 0.000247  max mem: 3586
I20250120 12:20:37 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199876  data: 0.000262  max mem: 3586
I20250120 12:20:39 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199679  data: 0.000262  max mem: 3586
I20250120 12:20:41 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199749  data: 0.000275  max mem: 3586
I20250120 12:20:43 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199755  data: 0.000191  max mem: 3586
I20250120 12:20:44 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.200494  data: 0.000176  max mem: 3586
I20250120 12:20:44 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.214419 s / it)
I20250120 12:20:44 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:20:44 3554128 dinov2 linear.py:287] 
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7280, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7693, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7846, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7967, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8060, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8124, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8143, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8163, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8091, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8011, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7860, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7778, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7146, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7708, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7922, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8024, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8114, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8136, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8141, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8119, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8101, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8146, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7912, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7852, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7853, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7921, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8082, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8140, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8149, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8134, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8120, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8072, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7986, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7774, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7683, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7663, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7859, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7978, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8074, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8138, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8147, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8129, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8105, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8081, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7897, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7916, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7690, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7437, device='cuda:0')}
I20250120 12:20:44 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_False_lr_0_00250', 'accuracy': 0.816339910030365}
I20250120 12:20:45 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:20:45 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:20:45 3554128 dinov2 helpers.py:102] Training  [ 1250/12500]  eta: 0:42:33  loss: 31.0629 (32.7259)  lr: 0.0000 (0.0000)  time: 1.892926  data: 0.027579  max mem: 3586
I20250120 12:20:47 3554128 dinov2 helpers.py:102] Training  [ 1260/12500]  eta: 0:42:28  loss: 31.0629 (32.7074)  lr: 0.0000 (0.0000)  time: 1.891194  data: 0.027579  max mem: 3586
I20250120 12:20:49 3554128 dinov2 helpers.py:102] Training  [ 1270/12500]  eta: 0:42:23  loss: 31.5054 (32.7138)  lr: 0.0000 (0.0000)  time: 0.196547  data: 0.000420  max mem: 3586
I20250120 12:20:51 3554128 dinov2 helpers.py:102] Training  [ 1280/12500]  eta: 0:42:18  loss: 31.6193 (32.7053)  lr: 0.0000 (0.0000)  time: 0.197520  data: 0.000448  max mem: 3586
I20250120 12:20:53 3554128 dinov2 helpers.py:102] Training  [ 1290/12500]  eta: 0:42:13  loss: 31.5054 (32.6587)  lr: 0.0000 (0.0000)  time: 0.197695  data: 0.000437  max mem: 3586
I20250120 12:20:55 3554128 dinov2 helpers.py:102] Training  [ 1300/12500]  eta: 0:42:08  loss: 31.0629 (32.6427)  lr: 0.0000 (0.0000)  time: 0.197756  data: 0.000459  max mem: 3586
I20250120 12:20:57 3554128 dinov2 helpers.py:102] Training  [ 1310/12500]  eta: 0:42:04  loss: 30.7367 (32.6011)  lr: 0.0000 (0.0000)  time: 0.197804  data: 0.000455  max mem: 3586
I20250120 12:20:59 3554128 dinov2 helpers.py:102] Training  [ 1320/12500]  eta: 0:41:59  loss: 31.0629 (32.6210)  lr: 0.0000 (0.0000)  time: 0.197826  data: 0.000417  max mem: 3586
I20250120 12:21:01 3554128 dinov2 helpers.py:102] Training  [ 1330/12500]  eta: 0:41:55  loss: 31.0629 (32.5729)  lr: 0.0000 (0.0000)  time: 0.197861  data: 0.000402  max mem: 3586
I20250120 12:21:03 3554128 dinov2 helpers.py:102] Training  [ 1340/12500]  eta: 0:41:50  loss: 30.7367 (32.5250)  lr: 0.0000 (0.0000)  time: 0.197958  data: 0.000433  max mem: 3586
I20250120 12:21:05 3554128 dinov2 helpers.py:102] Training  [ 1350/12500]  eta: 0:41:46  loss: 31.5054 (32.5279)  lr: 0.0000 (0.0000)  time: 0.197925  data: 0.000447  max mem: 3586
I20250120 12:21:07 3554128 dinov2 helpers.py:102] Training  [ 1360/12500]  eta: 0:41:41  loss: 30.5693 (32.5012)  lr: 0.0000 (0.0000)  time: 0.197915  data: 0.000455  max mem: 3586
I20250120 12:21:09 3554128 dinov2 helpers.py:102] Training  [ 1370/12500]  eta: 0:41:37  loss: 30.5693 (32.4824)  lr: 0.0000 (0.0000)  time: 0.198110  data: 0.000454  max mem: 3586
I20250120 12:21:11 3554128 dinov2 helpers.py:102] Training  [ 1380/12500]  eta: 0:41:32  loss: 30.3761 (32.4445)  lr: 0.0000 (0.0000)  time: 0.198367  data: 0.000424  max mem: 3586
I20250120 12:21:13 3554128 dinov2 helpers.py:102] Training  [ 1390/12500]  eta: 0:41:28  loss: 30.3761 (32.4496)  lr: 0.0000 (0.0000)  time: 0.198426  data: 0.000465  max mem: 3586
I20250120 12:21:15 3554128 dinov2 helpers.py:102] Training  [ 1400/12500]  eta: 0:41:24  loss: 30.3761 (32.4244)  lr: 0.0000 (0.0000)  time: 0.198398  data: 0.000464  max mem: 3586
I20250120 12:21:17 3554128 dinov2 helpers.py:102] Training  [ 1410/12500]  eta: 0:41:20  loss: 30.3761 (32.4180)  lr: 0.0000 (0.0000)  time: 0.198252  data: 0.000461  max mem: 3586
I20250120 12:21:19 3554128 dinov2 helpers.py:102] Training  [ 1420/12500]  eta: 0:41:15  loss: 30.5693 (32.4383)  lr: 0.0000 (0.0000)  time: 0.198278  data: 0.000483  max mem: 3586
I20250120 12:21:21 3554128 dinov2 helpers.py:102] Training  [ 1430/12500]  eta: 0:41:11  loss: 30.5693 (32.4514)  lr: 0.0000 (0.0000)  time: 0.198382  data: 0.000464  max mem: 3586
I20250120 12:21:23 3554128 dinov2 helpers.py:102] Training  [ 1440/12500]  eta: 0:41:07  loss: 30.3761 (32.4239)  lr: 0.0000 (0.0000)  time: 0.198352  data: 0.000506  max mem: 3586
I20250120 12:21:25 3554128 dinov2 helpers.py:102] Training  [ 1450/12500]  eta: 0:41:03  loss: 29.8983 (32.3635)  lr: 0.0000 (0.0000)  time: 0.198593  data: 0.000506  max mem: 3586
I20250120 12:21:27 3554128 dinov2 helpers.py:102] Training  [ 1460/12500]  eta: 0:40:59  loss: 29.8983 (32.3978)  lr: 0.0000 (0.0000)  time: 0.198675  data: 0.000485  max mem: 3586
I20250120 12:21:29 3554128 dinov2 helpers.py:102] Training  [ 1470/12500]  eta: 0:40:55  loss: 28.8979 (32.3524)  lr: 0.0000 (0.0000)  time: 0.198667  data: 0.000487  max mem: 3586
I20250120 12:21:31 3554128 dinov2 helpers.py:102] Training  [ 1480/12500]  eta: 0:40:51  loss: 28.8979 (32.3323)  lr: 0.0000 (0.0000)  time: 0.198872  data: 0.000455  max mem: 3586
I20250120 12:21:33 3554128 dinov2 helpers.py:102] Training  [ 1490/12500]  eta: 0:40:47  loss: 28.8979 (32.2861)  lr: 0.0000 (0.0000)  time: 0.198781  data: 0.000436  max mem: 3586
I20250120 12:21:35 3554128 dinov2 helpers.py:102] Training  [ 1500/12500]  eta: 0:40:43  loss: 28.8979 (32.2983)  lr: 0.0000 (0.0000)  time: 0.198804  data: 0.000444  max mem: 3586
I20250120 12:21:37 3554128 dinov2 helpers.py:102] Training  [ 1510/12500]  eta: 0:40:39  loss: 29.3566 (32.2803)  lr: 0.0000 (0.0000)  time: 0.198894  data: 0.000475  max mem: 3586
I20250120 12:21:39 3554128 dinov2 helpers.py:102] Training  [ 1520/12500]  eta: 0:40:35  loss: 29.3566 (32.2623)  lr: 0.0000 (0.0000)  time: 0.198912  data: 0.000473  max mem: 3586
I20250120 12:21:41 3554128 dinov2 helpers.py:102] Training  [ 1530/12500]  eta: 0:40:31  loss: 29.3566 (32.2348)  lr: 0.0000 (0.0000)  time: 0.198938  data: 0.000450  max mem: 3586
I20250120 12:21:43 3554128 dinov2 helpers.py:102] Training  [ 1540/12500]  eta: 0:40:28  loss: 29.5393 (32.2221)  lr: 0.0000 (0.0000)  time: 0.198798  data: 0.000471  max mem: 3586
I20250120 12:21:45 3554128 dinov2 helpers.py:102] Training  [ 1550/12500]  eta: 0:40:24  loss: 29.5393 (32.2451)  lr: 0.0000 (0.0000)  time: 0.198721  data: 0.000459  max mem: 3586
I20250120 12:21:47 3554128 dinov2 helpers.py:102] Training  [ 1560/12500]  eta: 0:40:20  loss: 29.5393 (32.2187)  lr: 0.0000 (0.0000)  time: 0.198768  data: 0.000454  max mem: 3586
I20250120 12:21:49 3554128 dinov2 helpers.py:102] Training  [ 1570/12500]  eta: 0:40:16  loss: 29.5393 (32.2477)  lr: 0.0000 (0.0000)  time: 0.198600  data: 0.000473  max mem: 3586
I20250120 12:21:51 3554128 dinov2 helpers.py:102] Training  [ 1580/12500]  eta: 0:40:12  loss: 29.5545 (32.2801)  lr: 0.0000 (0.0000)  time: 0.198450  data: 0.000456  max mem: 3586
I20250120 12:21:53 3554128 dinov2 helpers.py:102] Training  [ 1590/12500]  eta: 0:40:09  loss: 29.5393 (32.2506)  lr: 0.0000 (0.0000)  time: 0.198755  data: 0.000452  max mem: 3586
I20250120 12:21:55 3554128 dinov2 helpers.py:102] Training  [ 1600/12500]  eta: 0:40:05  loss: 29.5393 (32.2195)  lr: 0.0000 (0.0000)  time: 0.198811  data: 0.000472  max mem: 3586
I20250120 12:21:57 3554128 dinov2 helpers.py:102] Training  [ 1610/12500]  eta: 0:40:01  loss: 29.3566 (32.1702)  lr: 0.0000 (0.0000)  time: 0.198776  data: 0.000488  max mem: 3586
I20250120 12:21:59 3554128 dinov2 helpers.py:102] Training  [ 1620/12500]  eta: 0:39:58  loss: 28.4695 (32.1457)  lr: 0.0000 (0.0000)  time: 0.198818  data: 0.000490  max mem: 3586
I20250120 12:22:01 3554128 dinov2 helpers.py:102] Training  [ 1630/12500]  eta: 0:39:54  loss: 28.4695 (32.1312)  lr: 0.0000 (0.0000)  time: 0.198943  data: 0.000489  max mem: 3586
I20250120 12:22:03 3554128 dinov2 helpers.py:102] Training  [ 1640/12500]  eta: 0:39:50  loss: 29.1575 (32.1132)  lr: 0.0000 (0.0000)  time: 0.198890  data: 0.000455  max mem: 3586
I20250120 12:22:05 3554128 dinov2 helpers.py:102] Training  [ 1650/12500]  eta: 0:39:47  loss: 29.3566 (32.1055)  lr: 0.0000 (0.0000)  time: 0.198685  data: 0.000454  max mem: 3586
I20250120 12:22:07 3554128 dinov2 helpers.py:102] Training  [ 1660/12500]  eta: 0:39:43  loss: 29.3566 (32.1660)  lr: 0.0000 (0.0000)  time: 0.198649  data: 0.000492  max mem: 3586
I20250120 12:22:08 3554128 dinov2 helpers.py:102] Training  [ 1670/12500]  eta: 0:39:40  loss: 29.5393 (32.1699)  lr: 0.0000 (0.0000)  time: 0.198641  data: 0.000467  max mem: 3586
I20250120 12:22:10 3554128 dinov2 helpers.py:102] Training  [ 1680/12500]  eta: 0:39:36  loss: 29.5545 (32.1822)  lr: 0.0000 (0.0000)  time: 0.198781  data: 0.000425  max mem: 3586
I20250120 12:22:12 3554128 dinov2 helpers.py:102] Training  [ 1690/12500]  eta: 0:39:32  loss: 29.7614 (32.2076)  lr: 0.0000 (0.0000)  time: 0.198886  data: 0.000435  max mem: 3586
I20250120 12:22:14 3554128 dinov2 helpers.py:102] Training  [ 1700/12500]  eta: 0:39:29  loss: 29.7614 (32.2189)  lr: 0.0000 (0.0000)  time: 0.198839  data: 0.000434  max mem: 3586
I20250120 12:22:16 3554128 dinov2 helpers.py:102] Training  [ 1710/12500]  eta: 0:39:25  loss: 29.7614 (32.1951)  lr: 0.0000 (0.0000)  time: 0.198767  data: 0.000401  max mem: 3586
I20250120 12:22:18 3554128 dinov2 helpers.py:102] Training  [ 1720/12500]  eta: 0:39:22  loss: 30.2624 (32.1903)  lr: 0.0000 (0.0000)  time: 0.198946  data: 0.000398  max mem: 3586
I20250120 12:22:20 3554128 dinov2 helpers.py:102] Training  [ 1730/12500]  eta: 0:39:19  loss: 30.2624 (32.1581)  lr: 0.0000 (0.0000)  time: 0.199001  data: 0.000398  max mem: 3586
I20250120 12:22:22 3554128 dinov2 helpers.py:102] Training  [ 1740/12500]  eta: 0:39:15  loss: 29.7614 (32.1172)  lr: 0.0000 (0.0000)  time: 0.198971  data: 0.000421  max mem: 3586
I20250120 12:22:24 3554128 dinov2 helpers.py:102] Training  [ 1750/12500]  eta: 0:39:12  loss: 29.7614 (32.1076)  lr: 0.0000 (0.0000)  time: 0.198991  data: 0.000459  max mem: 3586
I20250120 12:22:26 3554128 dinov2 helpers.py:102] Training  [ 1760/12500]  eta: 0:39:08  loss: 30.4256 (32.1279)  lr: 0.0000 (0.0000)  time: 0.198800  data: 0.000477  max mem: 3586
I20250120 12:22:28 3554128 dinov2 helpers.py:102] Training  [ 1770/12500]  eta: 0:39:05  loss: 30.4256 (32.1698)  lr: 0.0000 (0.0000)  time: 0.198725  data: 0.000428  max mem: 3586
I20250120 12:22:30 3554128 dinov2 helpers.py:102] Training  [ 1780/12500]  eta: 0:39:02  loss: 29.7614 (32.1330)  lr: 0.0000 (0.0000)  time: 0.198696  data: 0.000412  max mem: 3586
I20250120 12:22:32 3554128 dinov2 helpers.py:102] Training  [ 1790/12500]  eta: 0:38:58  loss: 30.4256 (32.1436)  lr: 0.0000 (0.0000)  time: 0.198529  data: 0.000475  max mem: 3586
I20250120 12:22:34 3554128 dinov2 helpers.py:102] Training  [ 1800/12500]  eta: 0:38:55  loss: 30.8366 (32.1432)  lr: 0.0000 (0.0000)  time: 0.198678  data: 0.000446  max mem: 3586
I20250120 12:22:36 3554128 dinov2 helpers.py:102] Training  [ 1810/12500]  eta: 0:38:51  loss: 30.8366 (32.1218)  lr: 0.0000 (0.0000)  time: 0.198936  data: 0.000456  max mem: 3586
I20250120 12:22:38 3554128 dinov2 helpers.py:102] Training  [ 1820/12500]  eta: 0:38:48  loss: 30.8366 (32.0662)  lr: 0.0000 (0.0000)  time: 0.199007  data: 0.000487  max mem: 3586
I20250120 12:22:40 3554128 dinov2 helpers.py:102] Training  [ 1830/12500]  eta: 0:38:45  loss: 30.8366 (32.0515)  lr: 0.0000 (0.0000)  time: 0.198814  data: 0.000453  max mem: 3586
I20250120 12:22:42 3554128 dinov2 helpers.py:102] Training  [ 1840/12500]  eta: 0:38:42  loss: 31.3574 (32.0533)  lr: 0.0000 (0.0000)  time: 0.198793  data: 0.000461  max mem: 3586
I20250120 12:22:44 3554128 dinov2 helpers.py:102] Training  [ 1850/12500]  eta: 0:38:38  loss: 31.3574 (32.0491)  lr: 0.0000 (0.0000)  time: 0.198758  data: 0.000470  max mem: 3586
I20250120 12:22:46 3554128 dinov2 helpers.py:102] Training  [ 1860/12500]  eta: 0:38:35  loss: 31.2633 (32.0387)  lr: 0.0000 (0.0000)  time: 0.198683  data: 0.000469  max mem: 3586
I20250120 12:22:48 3554128 dinov2 helpers.py:102] Training  [ 1870/12500]  eta: 0:38:32  loss: 30.4256 (32.0235)  lr: 0.0000 (0.0000)  time: 0.198801  data: 0.000467  max mem: 3586
I20250120 12:22:50 3554128 dinov2 helpers.py:102] Training  [ 1880/12500]  eta: 0:38:29  loss: 30.1067 (32.0110)  lr: 0.0000 (0.0000)  time: 0.198904  data: 0.000458  max mem: 3586
I20250120 12:22:52 3554128 dinov2 helpers.py:102] Training  [ 1890/12500]  eta: 0:38:25  loss: 29.6506 (31.9948)  lr: 0.0000 (0.0000)  time: 0.198762  data: 0.000458  max mem: 3586
I20250120 12:22:54 3554128 dinov2 helpers.py:102] Training  [ 1900/12500]  eta: 0:38:22  loss: 29.6506 (31.9979)  lr: 0.0000 (0.0000)  time: 0.198601  data: 0.000466  max mem: 3586
I20250120 12:22:56 3554128 dinov2 helpers.py:102] Training  [ 1910/12500]  eta: 0:38:19  loss: 30.1067 (32.0035)  lr: 0.0000 (0.0000)  time: 0.198718  data: 0.000449  max mem: 3586
I20250120 12:22:58 3554128 dinov2 helpers.py:102] Training  [ 1920/12500]  eta: 0:38:16  loss: 30.1067 (32.0199)  lr: 0.0000 (0.0000)  time: 0.198808  data: 0.000432  max mem: 3586
I20250120 12:23:00 3554128 dinov2 helpers.py:102] Training  [ 1930/12500]  eta: 0:38:13  loss: 30.1067 (32.0027)  lr: 0.0000 (0.0000)  time: 0.199101  data: 0.000452  max mem: 3586
I20250120 12:23:02 3554128 dinov2 helpers.py:102] Training  [ 1940/12500]  eta: 0:38:09  loss: 30.1067 (31.9872)  lr: 0.0000 (0.0000)  time: 0.198997  data: 0.000435  max mem: 3586
I20250120 12:23:04 3554128 dinov2 helpers.py:102] Training  [ 1950/12500]  eta: 0:38:06  loss: 30.1067 (31.9880)  lr: 0.0000 (0.0000)  time: 0.198703  data: 0.000400  max mem: 3586
I20250120 12:23:06 3554128 dinov2 helpers.py:102] Training  [ 1960/12500]  eta: 0:38:03  loss: 30.1067 (31.9989)  lr: 0.0000 (0.0000)  time: 0.198713  data: 0.000393  max mem: 3586
I20250120 12:23:08 3554128 dinov2 helpers.py:102] Training  [ 1970/12500]  eta: 0:38:00  loss: 30.1067 (32.0269)  lr: 0.0000 (0.0000)  time: 0.198786  data: 0.000423  max mem: 3586
I20250120 12:23:10 3554128 dinov2 helpers.py:102] Training  [ 1980/12500]  eta: 0:37:57  loss: 31.2633 (32.0284)  lr: 0.0000 (0.0000)  time: 0.198779  data: 0.000462  max mem: 3586
I20250120 12:23:12 3554128 dinov2 helpers.py:102] Training  [ 1990/12500]  eta: 0:37:54  loss: 30.1067 (32.0111)  lr: 0.0000 (0.0000)  time: 0.198749  data: 0.000444  max mem: 3586
I20250120 12:23:14 3554128 dinov2 helpers.py:102] Training  [ 2000/12500]  eta: 0:37:51  loss: 29.6506 (31.9724)  lr: 0.0000 (0.0000)  time: 0.198677  data: 0.000423  max mem: 3586
I20250120 12:23:16 3554128 dinov2 helpers.py:102] Training  [ 2010/12500]  eta: 0:37:48  loss: 30.1067 (31.9964)  lr: 0.0000 (0.0000)  time: 0.198830  data: 0.000447  max mem: 3586
I20250120 12:23:18 3554128 dinov2 helpers.py:102] Training  [ 2020/12500]  eta: 0:37:45  loss: 31.2633 (32.0231)  lr: 0.0000 (0.0000)  time: 0.198875  data: 0.000473  max mem: 3586
I20250120 12:23:20 3554128 dinov2 helpers.py:102] Training  [ 2030/12500]  eta: 0:37:42  loss: 31.2633 (32.0156)  lr: 0.0000 (0.0000)  time: 0.198759  data: 0.000483  max mem: 3586
I20250120 12:23:22 3554128 dinov2 helpers.py:102] Training  [ 2040/12500]  eta: 0:37:38  loss: 30.4897 (32.0012)  lr: 0.0000 (0.0000)  time: 0.198845  data: 0.000518  max mem: 3586
I20250120 12:23:24 3554128 dinov2 helpers.py:102] Training  [ 2050/12500]  eta: 0:37:35  loss: 30.2912 (31.9929)  lr: 0.0000 (0.0000)  time: 0.198863  data: 0.000453  max mem: 3586
I20250120 12:23:26 3554128 dinov2 helpers.py:102] Training  [ 2060/12500]  eta: 0:37:32  loss: 30.2912 (31.9652)  lr: 0.0000 (0.0000)  time: 0.198896  data: 0.000369  max mem: 3586
I20250120 12:23:28 3554128 dinov2 helpers.py:102] Training  [ 2070/12500]  eta: 0:37:29  loss: 30.4897 (31.9708)  lr: 0.0000 (0.0000)  time: 0.199208  data: 0.000420  max mem: 3586
I20250120 12:23:30 3554128 dinov2 helpers.py:102] Training  [ 2080/12500]  eta: 0:37:26  loss: 32.0193 (31.9710)  lr: 0.0000 (0.0000)  time: 0.199262  data: 0.000477  max mem: 3586
I20250120 12:23:32 3554128 dinov2 helpers.py:102] Training  [ 2090/12500]  eta: 0:37:23  loss: 32.0193 (31.9474)  lr: 0.0000 (0.0000)  time: 0.199034  data: 0.000476  max mem: 3586
I20250120 12:23:34 3554128 dinov2 helpers.py:102] Training  [ 2100/12500]  eta: 0:37:21  loss: 30.4897 (31.9296)  lr: 0.0000 (0.0000)  time: 0.199395  data: 0.000458  max mem: 3586
I20250120 12:23:36 3554128 dinov2 helpers.py:102] Training  [ 2110/12500]  eta: 0:37:18  loss: 30.4897 (31.9467)  lr: 0.0000 (0.0000)  time: 0.199675  data: 0.000434  max mem: 3586
I20250120 12:23:38 3554128 dinov2 helpers.py:102] Training  [ 2120/12500]  eta: 0:37:15  loss: 30.2912 (31.9191)  lr: 0.0000 (0.0000)  time: 0.199297  data: 0.000447  max mem: 3586
I20250120 12:23:40 3554128 dinov2 helpers.py:102] Training  [ 2130/12500]  eta: 0:37:12  loss: 30.4897 (31.9424)  lr: 0.0000 (0.0000)  time: 0.199199  data: 0.000478  max mem: 3586
I20250120 12:23:42 3554128 dinov2 helpers.py:102] Training  [ 2140/12500]  eta: 0:37:09  loss: 32.0193 (31.9584)  lr: 0.0000 (0.0000)  time: 0.199408  data: 0.000467  max mem: 3586
I20250120 12:23:44 3554128 dinov2 helpers.py:102] Training  [ 2150/12500]  eta: 0:37:06  loss: 32.0193 (31.9809)  lr: 0.0000 (0.0000)  time: 0.199456  data: 0.000466  max mem: 3586
I20250120 12:23:46 3554128 dinov2 helpers.py:102] Training  [ 2160/12500]  eta: 0:37:03  loss: 32.0193 (31.9978)  lr: 0.0000 (0.0000)  time: 0.199310  data: 0.000472  max mem: 3586
I20250120 12:23:48 3554128 dinov2 helpers.py:102] Training  [ 2170/12500]  eta: 0:37:00  loss: 32.0193 (32.0115)  lr: 0.0000 (0.0000)  time: 0.199170  data: 0.000407  max mem: 3586
I20250120 12:23:50 3554128 dinov2 helpers.py:102] Training  [ 2180/12500]  eta: 0:36:57  loss: 30.4897 (31.9967)  lr: 0.0000 (0.0000)  time: 0.199317  data: 0.000387  max mem: 3586
I20250120 12:23:52 3554128 dinov2 helpers.py:102] Training  [ 2190/12500]  eta: 0:36:54  loss: 30.8371 (31.9915)  lr: 0.0000 (0.0000)  time: 0.199160  data: 0.000439  max mem: 3586
I20250120 12:23:54 3554128 dinov2 helpers.py:102] Training  [ 2200/12500]  eta: 0:36:51  loss: 30.8371 (31.9710)  lr: 0.0000 (0.0000)  time: 0.198978  data: 0.000438  max mem: 3586
I20250120 12:23:56 3554128 dinov2 helpers.py:102] Training  [ 2210/12500]  eta: 0:36:49  loss: 30.4897 (31.9535)  lr: 0.0000 (0.0000)  time: 0.199237  data: 0.000434  max mem: 3586
I20250120 12:23:58 3554128 dinov2 helpers.py:102] Training  [ 2220/12500]  eta: 0:36:46  loss: 30.2912 (31.9250)  lr: 0.0000 (0.0000)  time: 0.199029  data: 0.000454  max mem: 3586
I20250120 12:24:00 3554128 dinov2 helpers.py:102] Training  [ 2230/12500]  eta: 0:36:43  loss: 30.2912 (31.9277)  lr: 0.0000 (0.0000)  time: 0.198837  data: 0.000458  max mem: 3586
I20250120 12:24:02 3554128 dinov2 helpers.py:102] Training  [ 2240/12500]  eta: 0:36:40  loss: 30.8371 (31.9257)  lr: 0.0000 (0.0000)  time: 0.198968  data: 0.000445  max mem: 3586
I20250120 12:24:08 3554128 dinov2 helpers.py:102] Training  [ 2250/12500]  eta: 0:36:56  loss: 31.4740 (31.9303)  lr: 0.0000 (0.0000)  time: 0.402060  data: 0.214722  max mem: 3586
I20250120 12:24:10 3554128 dinov2 helpers.py:102] Training  [ 2260/12500]  eta: 0:36:54  loss: 31.4740 (31.9276)  lr: 0.0000 (0.0000)  time: 0.416478  data: 0.234550  max mem: 3586
I20250120 12:24:12 3554128 dinov2 helpers.py:102] Training  [ 2270/12500]  eta: 0:36:51  loss: 31.4740 (31.9305)  lr: 0.0000 (0.0000)  time: 0.211826  data: 0.020694  max mem: 3586
I20250120 12:24:14 3554128 dinov2 helpers.py:102] Training  [ 2280/12500]  eta: 0:36:48  loss: 31.4740 (31.9307)  lr: 0.0000 (0.0000)  time: 0.196378  data: 0.000861  max mem: 3586
I20250120 12:24:16 3554128 dinov2 helpers.py:102] Training  [ 2290/12500]  eta: 0:36:45  loss: 31.4740 (31.9236)  lr: 0.0000 (0.0000)  time: 0.196730  data: 0.000468  max mem: 3586
I20250120 12:24:18 3554128 dinov2 helpers.py:102] Training  [ 2300/12500]  eta: 0:36:42  loss: 31.4740 (31.9210)  lr: 0.0000 (0.0000)  time: 0.196786  data: 0.000484  max mem: 3586
I20250120 12:24:20 3554128 dinov2 helpers.py:102] Training  [ 2310/12500]  eta: 0:36:39  loss: 31.4740 (31.9200)  lr: 0.0000 (0.0000)  time: 0.196954  data: 0.000432  max mem: 3586
I20250120 12:24:22 3554128 dinov2 helpers.py:102] Training  [ 2320/12500]  eta: 0:36:36  loss: 31.6899 (31.9457)  lr: 0.0000 (0.0000)  time: 0.197328  data: 0.000392  max mem: 3586
I20250120 12:24:24 3554128 dinov2 helpers.py:102] Training  [ 2330/12500]  eta: 0:36:33  loss: 31.4740 (31.9421)  lr: 0.0000 (0.0000)  time: 0.197651  data: 0.000396  max mem: 3586
I20250120 12:24:26 3554128 dinov2 helpers.py:102] Training  [ 2340/12500]  eta: 0:36:30  loss: 31.3270 (31.9136)  lr: 0.0000 (0.0000)  time: 0.197675  data: 0.000436  max mem: 3586
I20250120 12:24:28 3554128 dinov2 helpers.py:102] Training  [ 2350/12500]  eta: 0:36:27  loss: 31.3264 (31.8936)  lr: 0.0000 (0.0000)  time: 0.197808  data: 0.000463  max mem: 3586
I20250120 12:24:30 3554128 dinov2 helpers.py:102] Training  [ 2360/12500]  eta: 0:36:24  loss: 31.0972 (31.8869)  lr: 0.0000 (0.0000)  time: 0.197877  data: 0.000446  max mem: 3586
I20250120 12:24:32 3554128 dinov2 helpers.py:102] Training  [ 2370/12500]  eta: 0:36:21  loss: 30.8371 (31.8782)  lr: 0.0000 (0.0000)  time: 0.197866  data: 0.000453  max mem: 3586
I20250120 12:24:34 3554128 dinov2 helpers.py:102] Training  [ 2380/12500]  eta: 0:36:18  loss: 30.8371 (31.8479)  lr: 0.0000 (0.0000)  time: 0.197918  data: 0.000454  max mem: 3586
I20250120 12:24:36 3554128 dinov2 helpers.py:102] Training  [ 2390/12500]  eta: 0:36:15  loss: 30.2888 (31.8328)  lr: 0.0000 (0.0000)  time: 0.197941  data: 0.000442  max mem: 3586
I20250120 12:24:38 3554128 dinov2 helpers.py:102] Training  [ 2400/12500]  eta: 0:36:13  loss: 31.0972 (31.8360)  lr: 0.0000 (0.0000)  time: 0.198004  data: 0.000470  max mem: 3586
I20250120 12:24:40 3554128 dinov2 helpers.py:102] Training  [ 2410/12500]  eta: 0:36:10  loss: 31.0972 (31.8322)  lr: 0.0000 (0.0000)  time: 0.198244  data: 0.000492  max mem: 3586
I20250120 12:24:42 3554128 dinov2 helpers.py:102] Training  [ 2420/12500]  eta: 0:36:07  loss: 31.3264 (31.8387)  lr: 0.0000 (0.0000)  time: 0.198397  data: 0.000473  max mem: 3586
I20250120 12:24:44 3554128 dinov2 helpers.py:102] Training  [ 2430/12500]  eta: 0:36:04  loss: 31.3264 (31.8653)  lr: 0.0000 (0.0000)  time: 0.198273  data: 0.000464  max mem: 3586
I20250120 12:24:46 3554128 dinov2 helpers.py:102] Training  [ 2440/12500]  eta: 0:36:01  loss: 31.0972 (31.8475)  lr: 0.0000 (0.0000)  time: 0.198258  data: 0.000437  max mem: 3586
I20250120 12:24:48 3554128 dinov2 helpers.py:102] Training  [ 2450/12500]  eta: 0:35:58  loss: 30.9202 (31.8295)  lr: 0.0000 (0.0000)  time: 0.198430  data: 0.000417  max mem: 3586
I20250120 12:24:50 3554128 dinov2 helpers.py:102] Training  [ 2460/12500]  eta: 0:35:56  loss: 30.2888 (31.8201)  lr: 0.0000 (0.0000)  time: 0.198542  data: 0.000464  max mem: 3586
I20250120 12:24:52 3554128 dinov2 helpers.py:102] Training  [ 2470/12500]  eta: 0:35:53  loss: 30.2888 (31.8269)  lr: 0.0000 (0.0000)  time: 0.198587  data: 0.000513  max mem: 3586
I20250120 12:24:54 3554128 dinov2 helpers.py:102] Training  [ 2480/12500]  eta: 0:35:50  loss: 30.2888 (31.8253)  lr: 0.0000 (0.0000)  time: 0.198590  data: 0.000449  max mem: 3586
I20250120 12:24:56 3554128 dinov2 helpers.py:102] Training  [ 2490/12500]  eta: 0:35:47  loss: 30.2879 (31.8074)  lr: 0.0000 (0.0000)  time: 0.198652  data: 0.000385  max mem: 3586
I20250120 12:24:58 3554128 dinov2 linear.py:272] running validation !
I20250120 12:24:59 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:03    time: 1.572969  data: 1.380023  max mem: 3586
I20250120 12:25:01 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.326663  data: 0.125805  max mem: 3586
I20250120 12:25:03 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.202021  data: 0.000578  max mem: 3586
I20250120 12:25:05 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.201485  data: 0.000484  max mem: 3586
I20250120 12:25:07 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.200737  data: 0.000226  max mem: 3586
I20250120 12:25:09 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.200880  data: 0.000263  max mem: 3586
I20250120 12:25:11 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.200433  data: 0.000229  max mem: 3586
I20250120 12:25:13 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199867  data: 0.000181  max mem: 3586
I20250120 12:25:15 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.200024  data: 0.000202  max mem: 3586
I20250120 12:25:17 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.200021  data: 0.000240  max mem: 3586
I20250120 12:25:19 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.200721  data: 0.000249  max mem: 3586
I20250120 12:25:21 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.200773  data: 0.000256  max mem: 3586
I20250120 12:25:23 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.200383  data: 0.000238  max mem: 3586
I20250120 12:25:25 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.201081  data: 0.000253  max mem: 3586
I20250120 12:25:27 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.201267  data: 0.000267  max mem: 3586
I20250120 12:25:29 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.200383  data: 0.000181  max mem: 3586
I20250120 12:25:30 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.196398  data: 0.000163  max mem: 3586
I20250120 12:25:30 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.210023 s / it)
I20250120 12:25:30 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:25:30 3554128 dinov2 linear.py:287] 
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7608, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7883, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7991, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8056, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8118, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8155, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8160, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8170, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8165, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8131, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8042, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7796, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7590, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7903, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8023, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8084, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8140, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8163, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8212, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8250, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8240, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8225, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8063, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8006, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7972, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8042, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8130, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8171, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8181, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8203, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8214, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8142, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8020, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7729, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7707, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7987, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8053, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8133, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8164, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8220, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8274, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8178, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7886, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7896, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7805, device='cuda:0')}
I20250120 12:25:30 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.8274050354957581}
I20250120 12:25:30 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:25:30 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:25:30 3554128 dinov2 helpers.py:102] Training  [ 2500/12500]  eta: 0:37:55  loss: 30.2879 (31.8118)  lr: 0.0000 (0.0000)  time: 1.830392  data: 0.000430  max mem: 3586
I20250120 12:25:32 3554128 dinov2 helpers.py:102] Training  [ 2510/12500]  eta: 0:37:51  loss: 29.8340 (31.7982)  lr: 0.0000 (0.0000)  time: 1.829509  data: 0.000405  max mem: 3586
I20250120 12:25:35 3554128 dinov2 helpers.py:102] Training  [ 2520/12500]  eta: 0:37:50  loss: 29.8340 (31.8057)  lr: 0.0000 (0.0000)  time: 0.221475  data: 0.027932  max mem: 3586
I20250120 12:25:37 3554128 dinov2 helpers.py:102] Training  [ 2530/12500]  eta: 0:37:46  loss: 29.8340 (31.8010)  lr: 0.0000 (0.0000)  time: 0.222213  data: 0.027993  max mem: 3586
I20250120 12:25:39 3554128 dinov2 helpers.py:102] Training  [ 2540/12500]  eta: 0:37:43  loss: 30.2879 (31.7976)  lr: 0.0000 (0.0000)  time: 0.198266  data: 0.000476  max mem: 3586
I20250120 12:25:41 3554128 dinov2 helpers.py:102] Training  [ 2550/12500]  eta: 0:37:40  loss: 30.2879 (31.7810)  lr: 0.0000 (0.0000)  time: 0.198330  data: 0.000450  max mem: 3586
I20250120 12:25:43 3554128 dinov2 helpers.py:102] Training  [ 2560/12500]  eta: 0:37:36  loss: 29.8340 (31.7707)  lr: 0.0000 (0.0000)  time: 0.198491  data: 0.000444  max mem: 3586
I20250120 12:25:45 3554128 dinov2 helpers.py:102] Training  [ 2570/12500]  eta: 0:37:33  loss: 29.5012 (31.7453)  lr: 0.0000 (0.0000)  time: 0.198347  data: 0.000485  max mem: 3586
I20250120 12:25:47 3554128 dinov2 helpers.py:102] Training  [ 2580/12500]  eta: 0:37:29  loss: 29.5012 (31.7271)  lr: 0.0000 (0.0000)  time: 0.198457  data: 0.000476  max mem: 3586
I20250120 12:25:49 3554128 dinov2 helpers.py:102] Training  [ 2590/12500]  eta: 0:37:26  loss: 29.5012 (31.7148)  lr: 0.0000 (0.0000)  time: 0.198512  data: 0.000467  max mem: 3586
I20250120 12:25:51 3554128 dinov2 helpers.py:102] Training  [ 2600/12500]  eta: 0:37:23  loss: 29.1262 (31.6930)  lr: 0.0000 (0.0000)  time: 0.198337  data: 0.000422  max mem: 3586
I20250120 12:25:53 3554128 dinov2 helpers.py:102] Training  [ 2610/12500]  eta: 0:37:19  loss: 29.1262 (31.6879)  lr: 0.0000 (0.0000)  time: 0.198406  data: 0.000396  max mem: 3586
I20250120 12:25:55 3554128 dinov2 helpers.py:102] Training  [ 2620/12500]  eta: 0:37:16  loss: 28.5185 (31.6706)  lr: 0.0000 (0.0000)  time: 0.198583  data: 0.000445  max mem: 3586
I20250120 12:25:57 3554128 dinov2 helpers.py:102] Training  [ 2630/12500]  eta: 0:37:13  loss: 28.3845 (31.6509)  lr: 0.0000 (0.0000)  time: 0.198599  data: 0.000449  max mem: 3586
I20250120 12:25:59 3554128 dinov2 helpers.py:102] Training  [ 2640/12500]  eta: 0:37:10  loss: 28.3845 (31.6280)  lr: 0.0000 (0.0000)  time: 0.198853  data: 0.000462  max mem: 3586
I20250120 12:26:01 3554128 dinov2 helpers.py:102] Training  [ 2650/12500]  eta: 0:37:06  loss: 28.5185 (31.6189)  lr: 0.0000 (0.0000)  time: 0.198958  data: 0.000473  max mem: 3586
I20250120 12:26:03 3554128 dinov2 helpers.py:102] Training  [ 2660/12500]  eta: 0:37:03  loss: 28.5185 (31.6181)  lr: 0.0000 (0.0000)  time: 0.198947  data: 0.000459  max mem: 3586
I20250120 12:26:05 3554128 dinov2 helpers.py:102] Training  [ 2670/12500]  eta: 0:37:00  loss: 28.5185 (31.6241)  lr: 0.0000 (0.0000)  time: 0.198855  data: 0.000434  max mem: 3586
I20250120 12:26:07 3554128 dinov2 helpers.py:102] Training  [ 2680/12500]  eta: 0:36:57  loss: 28.4412 (31.6123)  lr: 0.0000 (0.0000)  time: 0.198827  data: 0.000402  max mem: 3586
I20250120 12:26:09 3554128 dinov2 helpers.py:102] Training  [ 2690/12500]  eta: 0:36:53  loss: 28.5185 (31.6098)  lr: 0.0000 (0.0000)  time: 0.199114  data: 0.000431  max mem: 3586
I20250120 12:26:11 3554128 dinov2 helpers.py:102] Training  [ 2700/12500]  eta: 0:36:50  loss: 28.4412 (31.5942)  lr: 0.0000 (0.0000)  time: 0.199076  data: 0.000441  max mem: 3586
I20250120 12:26:13 3554128 dinov2 helpers.py:102] Training  [ 2710/12500]  eta: 0:36:47  loss: 28.5185 (31.5836)  lr: 0.0000 (0.0000)  time: 0.198900  data: 0.000443  max mem: 3586
I20250120 12:26:15 3554128 dinov2 helpers.py:102] Training  [ 2720/12500]  eta: 0:36:44  loss: 28.4412 (31.5534)  lr: 0.0000 (0.0000)  time: 0.198835  data: 0.000476  max mem: 3586
I20250120 12:26:17 3554128 dinov2 helpers.py:102] Training  [ 2730/12500]  eta: 0:36:40  loss: 28.4412 (31.5422)  lr: 0.0000 (0.0000)  time: 0.198720  data: 0.000458  max mem: 3586
I20250120 12:26:19 3554128 dinov2 helpers.py:102] Training  [ 2740/12500]  eta: 0:36:37  loss: 28.4412 (31.5826)  lr: 0.0000 (0.0000)  time: 0.198662  data: 0.000416  max mem: 3586
I20250120 12:26:21 3554128 dinov2 helpers.py:102] Training  [ 2750/12500]  eta: 0:36:34  loss: 28.4412 (31.5643)  lr: 0.0000 (0.0000)  time: 0.198786  data: 0.000423  max mem: 3586
I20250120 12:26:23 3554128 dinov2 helpers.py:102] Training  [ 2760/12500]  eta: 0:36:31  loss: 28.4412 (31.5545)  lr: 0.0000 (0.0000)  time: 0.199053  data: 0.000444  max mem: 3586
I20250120 12:26:25 3554128 dinov2 helpers.py:102] Training  [ 2770/12500]  eta: 0:36:28  loss: 28.4412 (31.5405)  lr: 0.0000 (0.0000)  time: 0.199115  data: 0.000428  max mem: 3586
I20250120 12:26:27 3554128 dinov2 helpers.py:102] Training  [ 2780/12500]  eta: 0:36:25  loss: 28.4774 (31.5416)  lr: 0.0000 (0.0000)  time: 0.198841  data: 0.000442  max mem: 3586
I20250120 12:26:29 3554128 dinov2 helpers.py:102] Training  [ 2790/12500]  eta: 0:36:21  loss: 28.4774 (31.5426)  lr: 0.0000 (0.0000)  time: 0.198755  data: 0.000474  max mem: 3586
I20250120 12:26:30 3554128 dinov2 helpers.py:102] Training  [ 2800/12500]  eta: 0:36:18  loss: 28.4774 (31.5271)  lr: 0.0000 (0.0000)  time: 0.198780  data: 0.000504  max mem: 3586
I20250120 12:26:32 3554128 dinov2 helpers.py:102] Training  [ 2810/12500]  eta: 0:36:15  loss: 28.4412 (31.5130)  lr: 0.0000 (0.0000)  time: 0.198744  data: 0.000501  max mem: 3586
I20250120 12:26:34 3554128 dinov2 helpers.py:102] Training  [ 2820/12500]  eta: 0:36:12  loss: 28.4774 (31.5217)  lr: 0.0000 (0.0000)  time: 0.198801  data: 0.000464  max mem: 3586
I20250120 12:26:36 3554128 dinov2 helpers.py:102] Training  [ 2830/12500]  eta: 0:36:09  loss: 28.4774 (31.4960)  lr: 0.0000 (0.0000)  time: 0.198715  data: 0.000427  max mem: 3586
I20250120 12:26:38 3554128 dinov2 helpers.py:102] Training  [ 2840/12500]  eta: 0:36:06  loss: 28.7140 (31.4872)  lr: 0.0000 (0.0000)  time: 0.198673  data: 0.000419  max mem: 3586
I20250120 12:26:40 3554128 dinov2 helpers.py:102] Training  [ 2850/12500]  eta: 0:36:03  loss: 28.7140 (31.4961)  lr: 0.0000 (0.0000)  time: 0.198579  data: 0.000390  max mem: 3586
I20250120 12:26:42 3554128 dinov2 helpers.py:102] Training  [ 2860/12500]  eta: 0:36:00  loss: 28.4774 (31.4751)  lr: 0.0000 (0.0000)  time: 0.198249  data: 0.000438  max mem: 3586
I20250120 12:26:44 3554128 dinov2 helpers.py:102] Training  [ 2870/12500]  eta: 0:35:56  loss: 28.4412 (31.4544)  lr: 0.0000 (0.0000)  time: 0.198406  data: 0.000487  max mem: 3586
I20250120 12:26:46 3554128 dinov2 helpers.py:102] Training  [ 2880/12500]  eta: 0:35:53  loss: 27.6658 (31.4386)  lr: 0.0000 (0.0000)  time: 0.198636  data: 0.000484  max mem: 3586
I20250120 12:26:48 3554128 dinov2 helpers.py:102] Training  [ 2890/12500]  eta: 0:35:50  loss: 27.5483 (31.4241)  lr: 0.0000 (0.0000)  time: 0.198583  data: 0.000465  max mem: 3586
I20250120 12:26:50 3554128 dinov2 helpers.py:102] Training  [ 2900/12500]  eta: 0:35:47  loss: 27.6658 (31.4160)  lr: 0.0000 (0.0000)  time: 0.198659  data: 0.000435  max mem: 3586
I20250120 12:26:52 3554128 dinov2 helpers.py:102] Training  [ 2910/12500]  eta: 0:35:44  loss: 27.6658 (31.4261)  lr: 0.0000 (0.0000)  time: 0.198559  data: 0.000424  max mem: 3586
I20250120 12:26:54 3554128 dinov2 helpers.py:102] Training  [ 2920/12500]  eta: 0:35:41  loss: 27.6658 (31.4093)  lr: 0.0000 (0.0000)  time: 0.198281  data: 0.000427  max mem: 3586
I20250120 12:26:56 3554128 dinov2 helpers.py:102] Training  [ 2930/12500]  eta: 0:35:38  loss: 27.6658 (31.4305)  lr: 0.0000 (0.0000)  time: 0.198277  data: 0.000463  max mem: 3586
I20250120 12:26:58 3554128 dinov2 helpers.py:102] Training  [ 2940/12500]  eta: 0:35:35  loss: 27.6658 (31.4206)  lr: 0.0000 (0.0000)  time: 0.198474  data: 0.000460  max mem: 3586
I20250120 12:27:00 3554128 dinov2 helpers.py:102] Training  [ 2950/12500]  eta: 0:35:32  loss: 28.5117 (31.4118)  lr: 0.0000 (0.0000)  time: 0.198513  data: 0.000441  max mem: 3586
I20250120 12:27:02 3554128 dinov2 helpers.py:102] Training  [ 2960/12500]  eta: 0:35:29  loss: 27.6658 (31.3884)  lr: 0.0000 (0.0000)  time: 0.198297  data: 0.000460  max mem: 3586
I20250120 12:27:04 3554128 dinov2 helpers.py:102] Training  [ 2970/12500]  eta: 0:35:26  loss: 27.6662 (31.3759)  lr: 0.0000 (0.0000)  time: 0.198316  data: 0.000476  max mem: 3586
I20250120 12:27:06 3554128 dinov2 helpers.py:102] Training  [ 2980/12500]  eta: 0:35:23  loss: 27.6662 (31.3876)  lr: 0.0000 (0.0000)  time: 0.198569  data: 0.000436  max mem: 3586
I20250120 12:27:08 3554128 dinov2 helpers.py:102] Training  [ 2990/12500]  eta: 0:35:20  loss: 27.6662 (31.3780)  lr: 0.0000 (0.0000)  time: 0.198568  data: 0.000426  max mem: 3586
I20250120 12:27:10 3554128 dinov2 helpers.py:102] Training  [ 3000/12500]  eta: 0:35:17  loss: 27.6662 (31.3652)  lr: 0.0000 (0.0000)  time: 0.198408  data: 0.000410  max mem: 3586
I20250120 12:27:12 3554128 dinov2 helpers.py:102] Training  [ 3010/12500]  eta: 0:35:14  loss: 27.6662 (31.3522)  lr: 0.0000 (0.0000)  time: 0.198430  data: 0.000416  max mem: 3586
I20250120 12:27:14 3554128 dinov2 helpers.py:102] Training  [ 3020/12500]  eta: 0:35:11  loss: 27.6662 (31.3580)  lr: 0.0000 (0.0000)  time: 0.198465  data: 0.000460  max mem: 3586
I20250120 12:27:16 3554128 dinov2 helpers.py:102] Training  [ 3030/12500]  eta: 0:35:08  loss: 27.6662 (31.3396)  lr: 0.0000 (0.0000)  time: 0.198415  data: 0.000463  max mem: 3586
I20250120 12:27:18 3554128 dinov2 helpers.py:102] Training  [ 3040/12500]  eta: 0:35:05  loss: 27.6662 (31.3336)  lr: 0.0000 (0.0000)  time: 0.198354  data: 0.000480  max mem: 3586
I20250120 12:27:20 3554128 dinov2 helpers.py:102] Training  [ 3050/12500]  eta: 0:35:02  loss: 27.6662 (31.3473)  lr: 0.0000 (0.0000)  time: 0.198341  data: 0.000460  max mem: 3586
I20250120 12:27:22 3554128 dinov2 helpers.py:102] Training  [ 3060/12500]  eta: 0:34:59  loss: 28.5117 (31.3536)  lr: 0.0000 (0.0000)  time: 0.198415  data: 0.000440  max mem: 3586
I20250120 12:27:24 3554128 dinov2 helpers.py:102] Training  [ 3070/12500]  eta: 0:34:56  loss: 28.5217 (31.3743)  lr: 0.0000 (0.0000)  time: 0.198260  data: 0.000465  max mem: 3586
I20250120 12:27:26 3554128 dinov2 helpers.py:102] Training  [ 3080/12500]  eta: 0:34:53  loss: 28.8209 (31.3760)  lr: 0.0000 (0.0000)  time: 0.198095  data: 0.000457  max mem: 3586
I20250120 12:27:28 3554128 dinov2 helpers.py:102] Training  [ 3090/12500]  eta: 0:34:50  loss: 28.8209 (31.3612)  lr: 0.0000 (0.0000)  time: 0.198225  data: 0.000448  max mem: 3586
I20250120 12:27:30 3554128 dinov2 helpers.py:102] Training  [ 3100/12500]  eta: 0:34:47  loss: 28.5217 (31.3488)  lr: 0.0000 (0.0000)  time: 0.198319  data: 0.000459  max mem: 3586
I20250120 12:27:32 3554128 dinov2 helpers.py:102] Training  [ 3110/12500]  eta: 0:34:44  loss: 28.5117 (31.3347)  lr: 0.0000 (0.0000)  time: 0.198398  data: 0.000461  max mem: 3586
I20250120 12:27:34 3554128 dinov2 helpers.py:102] Training  [ 3120/12500]  eta: 0:34:41  loss: 28.5117 (31.3211)  lr: 0.0000 (0.0000)  time: 0.198404  data: 0.000472  max mem: 3586
I20250120 12:27:36 3554128 dinov2 helpers.py:102] Training  [ 3130/12500]  eta: 0:34:38  loss: 27.6662 (31.3059)  lr: 0.0000 (0.0000)  time: 0.198335  data: 0.000506  max mem: 3586
I20250120 12:27:38 3554128 dinov2 helpers.py:102] Training  [ 3140/12500]  eta: 0:34:35  loss: 27.6662 (31.3202)  lr: 0.0000 (0.0000)  time: 0.198304  data: 0.000498  max mem: 3586
I20250120 12:27:40 3554128 dinov2 helpers.py:102] Training  [ 3150/12500]  eta: 0:34:32  loss: 27.5052 (31.3014)  lr: 0.0000 (0.0000)  time: 0.198426  data: 0.000455  max mem: 3586
I20250120 12:27:42 3554128 dinov2 helpers.py:102] Training  [ 3160/12500]  eta: 0:34:30  loss: 27.6662 (31.2924)  lr: 0.0000 (0.0000)  time: 0.198346  data: 0.000418  max mem: 3586
I20250120 12:27:44 3554128 dinov2 helpers.py:102] Training  [ 3170/12500]  eta: 0:34:27  loss: 28.4656 (31.2958)  lr: 0.0000 (0.0000)  time: 0.198174  data: 0.000400  max mem: 3586
I20250120 12:27:46 3554128 dinov2 helpers.py:102] Training  [ 3180/12500]  eta: 0:34:24  loss: 28.4656 (31.2918)  lr: 0.0000 (0.0000)  time: 0.198290  data: 0.000402  max mem: 3586
I20250120 12:27:48 3554128 dinov2 helpers.py:102] Training  [ 3190/12500]  eta: 0:34:21  loss: 28.4656 (31.2846)  lr: 0.0000 (0.0000)  time: 0.198300  data: 0.000444  max mem: 3586
I20250120 12:27:50 3554128 dinov2 helpers.py:102] Training  [ 3200/12500]  eta: 0:34:18  loss: 28.9794 (31.2804)  lr: 0.0000 (0.0000)  time: 0.198073  data: 0.000451  max mem: 3586
I20250120 12:27:52 3554128 dinov2 helpers.py:102] Training  [ 3210/12500]  eta: 0:34:15  loss: 29.5154 (31.2834)  lr: 0.0000 (0.0000)  time: 0.198105  data: 0.000470  max mem: 3586
I20250120 12:27:54 3554128 dinov2 helpers.py:102] Training  [ 3220/12500]  eta: 0:34:12  loss: 29.5154 (31.2827)  lr: 0.0000 (0.0000)  time: 0.198205  data: 0.000482  max mem: 3586
I20250120 12:27:56 3554128 dinov2 helpers.py:102] Training  [ 3230/12500]  eta: 0:34:09  loss: 29.5154 (31.2746)  lr: 0.0000 (0.0000)  time: 0.198257  data: 0.000430  max mem: 3586
I20250120 12:27:58 3554128 dinov2 helpers.py:102] Training  [ 3240/12500]  eta: 0:34:06  loss: 28.9794 (31.2673)  lr: 0.0000 (0.0000)  time: 0.198172  data: 0.000455  max mem: 3586
I20250120 12:28:00 3554128 dinov2 helpers.py:102] Training  [ 3250/12500]  eta: 0:34:04  loss: 28.9794 (31.2748)  lr: 0.0000 (0.0000)  time: 0.197900  data: 0.000452  max mem: 3586
I20250120 12:28:02 3554128 dinov2 helpers.py:102] Training  [ 3260/12500]  eta: 0:34:01  loss: 28.9794 (31.2689)  lr: 0.0000 (0.0000)  time: 0.198048  data: 0.000429  max mem: 3586
I20250120 12:28:04 3554128 dinov2 helpers.py:102] Training  [ 3270/12500]  eta: 0:33:58  loss: 28.8835 (31.2586)  lr: 0.0000 (0.0000)  time: 0.198144  data: 0.000444  max mem: 3586
I20250120 12:28:06 3554128 dinov2 helpers.py:102] Training  [ 3280/12500]  eta: 0:33:55  loss: 28.6513 (31.2503)  lr: 0.0000 (0.0000)  time: 0.198030  data: 0.000480  max mem: 3586
I20250120 12:28:08 3554128 dinov2 helpers.py:102] Training  [ 3290/12500]  eta: 0:33:52  loss: 28.8835 (31.2454)  lr: 0.0000 (0.0000)  time: 0.197994  data: 0.000516  max mem: 3586
I20250120 12:28:10 3554128 dinov2 helpers.py:102] Training  [ 3300/12500]  eta: 0:33:49  loss: 28.8835 (31.2274)  lr: 0.0000 (0.0000)  time: 0.197944  data: 0.000462  max mem: 3586
I20250120 12:28:12 3554128 dinov2 helpers.py:102] Training  [ 3310/12500]  eta: 0:33:46  loss: 28.8835 (31.2083)  lr: 0.0000 (0.0000)  time: 0.197908  data: 0.000425  max mem: 3586
I20250120 12:28:14 3554128 dinov2 helpers.py:102] Training  [ 3320/12500]  eta: 0:33:44  loss: 28.8835 (31.1882)  lr: 0.0000 (0.0000)  time: 0.197989  data: 0.000446  max mem: 3586
I20250120 12:28:16 3554128 dinov2 helpers.py:102] Training  [ 3330/12500]  eta: 0:33:41  loss: 28.8835 (31.1812)  lr: 0.0000 (0.0000)  time: 0.197933  data: 0.000452  max mem: 3586
I20250120 12:28:18 3554128 dinov2 helpers.py:102] Training  [ 3340/12500]  eta: 0:33:38  loss: 28.8835 (31.1859)  lr: 0.0000 (0.0000)  time: 0.197754  data: 0.000456  max mem: 3586
I20250120 12:28:20 3554128 dinov2 helpers.py:102] Training  [ 3350/12500]  eta: 0:33:35  loss: 28.9794 (31.1824)  lr: 0.0000 (0.0000)  time: 0.197751  data: 0.000469  max mem: 3586
I20250120 12:28:22 3554128 dinov2 helpers.py:102] Training  [ 3360/12500]  eta: 0:33:32  loss: 29.3555 (31.1897)  lr: 0.0000 (0.0000)  time: 0.197966  data: 0.000459  max mem: 3586
I20250120 12:28:24 3554128 dinov2 helpers.py:102] Training  [ 3370/12500]  eta: 0:33:30  loss: 28.9794 (31.1808)  lr: 0.0000 (0.0000)  time: 0.197997  data: 0.000460  max mem: 3586
I20250120 12:28:26 3554128 dinov2 helpers.py:102] Training  [ 3380/12500]  eta: 0:33:27  loss: 28.9794 (31.1785)  lr: 0.0000 (0.0000)  time: 0.197759  data: 0.000476  max mem: 3586
I20250120 12:28:28 3554128 dinov2 helpers.py:102] Training  [ 3390/12500]  eta: 0:33:24  loss: 28.8835 (31.1606)  lr: 0.0000 (0.0000)  time: 0.197672  data: 0.000441  max mem: 3586
I20250120 12:28:29 3554128 dinov2 helpers.py:102] Training  [ 3400/12500]  eta: 0:33:21  loss: 28.8658 (31.1474)  lr: 0.0000 (0.0000)  time: 0.197844  data: 0.000441  max mem: 3586
I20250120 12:28:31 3554128 dinov2 helpers.py:102] Training  [ 3410/12500]  eta: 0:33:18  loss: 28.8658 (31.1586)  lr: 0.0000 (0.0000)  time: 0.197848  data: 0.000445  max mem: 3586
I20250120 12:28:33 3554128 dinov2 helpers.py:102] Training  [ 3420/12500]  eta: 0:33:16  loss: 28.8658 (31.1569)  lr: 0.0000 (0.0000)  time: 0.197739  data: 0.000473  max mem: 3586
I20250120 12:28:35 3554128 dinov2 helpers.py:102] Training  [ 3430/12500]  eta: 0:33:13  loss: 28.8658 (31.1458)  lr: 0.0000 (0.0000)  time: 0.197870  data: 0.000450  max mem: 3586
I20250120 12:28:37 3554128 dinov2 helpers.py:102] Training  [ 3440/12500]  eta: 0:33:10  loss: 28.8658 (31.1539)  lr: 0.0000 (0.0000)  time: 0.197997  data: 0.000387  max mem: 3586
I20250120 12:28:39 3554128 dinov2 helpers.py:102] Training  [ 3450/12500]  eta: 0:33:07  loss: 28.5431 (31.1441)  lr: 0.0000 (0.0000)  time: 0.197980  data: 0.000427  max mem: 3586
I20250120 12:28:41 3554128 dinov2 helpers.py:102] Training  [ 3460/12500]  eta: 0:33:05  loss: 28.5431 (31.1381)  lr: 0.0000 (0.0000)  time: 0.197804  data: 0.000483  max mem: 3586
I20250120 12:28:43 3554128 dinov2 helpers.py:102] Training  [ 3470/12500]  eta: 0:33:02  loss: 28.8658 (31.1333)  lr: 0.0000 (0.0000)  time: 0.197707  data: 0.000455  max mem: 3586
I20250120 12:28:45 3554128 dinov2 helpers.py:102] Training  [ 3480/12500]  eta: 0:32:59  loss: 28.8658 (31.1199)  lr: 0.0000 (0.0000)  time: 0.197640  data: 0.000407  max mem: 3586
I20250120 12:28:47 3554128 dinov2 helpers.py:102] Training  [ 3490/12500]  eta: 0:32:56  loss: 28.1848 (31.1079)  lr: 0.0000 (0.0000)  time: 0.197688  data: 0.000454  max mem: 3586
I20250120 12:28:49 3554128 dinov2 helpers.py:102] Training  [ 3500/12500]  eta: 0:32:53  loss: 28.1848 (31.0938)  lr: 0.0000 (0.0000)  time: 0.197816  data: 0.000491  max mem: 3586
I20250120 12:28:51 3554128 dinov2 helpers.py:102] Training  [ 3510/12500]  eta: 0:32:51  loss: 28.8658 (31.1051)  lr: 0.0000 (0.0000)  time: 0.197728  data: 0.000461  max mem: 3586
I20250120 12:28:53 3554128 dinov2 helpers.py:102] Training  [ 3520/12500]  eta: 0:32:48  loss: 28.8658 (31.0911)  lr: 0.0000 (0.0000)  time: 0.197643  data: 0.000397  max mem: 3586
I20250120 12:28:55 3554128 dinov2 helpers.py:102] Training  [ 3530/12500]  eta: 0:32:45  loss: 29.0716 (31.1037)  lr: 0.0000 (0.0000)  time: 0.197768  data: 0.000384  max mem: 3586
I20250120 12:28:57 3554128 dinov2 helpers.py:102] Training  [ 3540/12500]  eta: 0:32:43  loss: 28.1848 (31.0864)  lr: 0.0000 (0.0000)  time: 0.197813  data: 0.000426  max mem: 3586
I20250120 12:28:59 3554128 dinov2 helpers.py:102] Training  [ 3550/12500]  eta: 0:32:40  loss: 27.7388 (31.0765)  lr: 0.0000 (0.0000)  time: 0.197682  data: 0.000441  max mem: 3586
I20250120 12:29:01 3554128 dinov2 helpers.py:102] Training  [ 3560/12500]  eta: 0:32:37  loss: 27.7388 (31.0682)  lr: 0.0000 (0.0000)  time: 0.197641  data: 0.000440  max mem: 3586
I20250120 12:29:03 3554128 dinov2 helpers.py:102] Training  [ 3570/12500]  eta: 0:32:34  loss: 27.5338 (31.0525)  lr: 0.0000 (0.0000)  time: 0.197694  data: 0.000421  max mem: 3586
I20250120 12:29:05 3554128 dinov2 helpers.py:102] Training  [ 3580/12500]  eta: 0:32:32  loss: 27.3383 (31.0391)  lr: 0.0000 (0.0000)  time: 0.197726  data: 0.000445  max mem: 3586
I20250120 12:29:07 3554128 dinov2 helpers.py:102] Training  [ 3590/12500]  eta: 0:32:29  loss: 27.5338 (31.0331)  lr: 0.0000 (0.0000)  time: 0.197578  data: 0.000468  max mem: 3586
I20250120 12:29:09 3554128 dinov2 helpers.py:102] Training  [ 3600/12500]  eta: 0:32:26  loss: 27.5748 (31.0235)  lr: 0.0000 (0.0000)  time: 0.197309  data: 0.000411  max mem: 3586
I20250120 12:29:11 3554128 dinov2 helpers.py:102] Training  [ 3610/12500]  eta: 0:32:23  loss: 27.5748 (31.0160)  lr: 0.0000 (0.0000)  time: 0.197223  data: 0.000429  max mem: 3586
I20250120 12:29:13 3554128 dinov2 helpers.py:102] Training  [ 3620/12500]  eta: 0:32:21  loss: 27.5338 (31.0022)  lr: 0.0000 (0.0000)  time: 0.197369  data: 0.000485  max mem: 3586
I20250120 12:29:15 3554128 dinov2 helpers.py:102] Training  [ 3630/12500]  eta: 0:32:18  loss: 27.5748 (30.9944)  lr: 0.0000 (0.0000)  time: 0.197496  data: 0.000465  max mem: 3586
I20250120 12:29:17 3554128 dinov2 helpers.py:102] Training  [ 3640/12500]  eta: 0:32:15  loss: 27.5748 (30.9923)  lr: 0.0000 (0.0000)  time: 0.197516  data: 0.000421  max mem: 3586
I20250120 12:29:19 3554128 dinov2 helpers.py:102] Training  [ 3650/12500]  eta: 0:32:13  loss: 27.5338 (30.9732)  lr: 0.0000 (0.0000)  time: 0.197367  data: 0.000456  max mem: 3586
I20250120 12:29:25 3554128 dinov2 helpers.py:102] Training  [ 3660/12500]  eta: 0:32:21  loss: 26.9000 (30.9593)  lr: 0.0000 (0.0000)  time: 0.422503  data: 0.236613  max mem: 3586
I20250120 12:29:28 3554128 dinov2 helpers.py:102] Training  [ 3670/12500]  eta: 0:32:19  loss: 26.9000 (30.9666)  lr: 0.0000 (0.0000)  time: 0.431724  data: 0.248069  max mem: 3586
I20250120 12:29:30 3554128 dinov2 helpers.py:102] Training  [ 3680/12500]  eta: 0:32:16  loss: 26.9000 (30.9428)  lr: 0.0000 (0.0000)  time: 0.205356  data: 0.011944  max mem: 3586
I20250120 12:29:31 3554128 dinov2 helpers.py:102] Training  [ 3690/12500]  eta: 0:32:13  loss: 27.5338 (30.9499)  lr: 0.0000 (0.0000)  time: 0.195144  data: 0.000451  max mem: 3586
I20250120 12:29:33 3554128 dinov2 helpers.py:102] Training  [ 3700/12500]  eta: 0:32:10  loss: 27.5748 (30.9443)  lr: 0.0000 (0.0000)  time: 0.195386  data: 0.000461  max mem: 3586
I20250120 12:29:35 3554128 dinov2 helpers.py:102] Training  [ 3710/12500]  eta: 0:32:07  loss: 27.5748 (30.9514)  lr: 0.0000 (0.0000)  time: 0.195708  data: 0.000453  max mem: 3586
I20250120 12:29:37 3554128 dinov2 helpers.py:102] Training  [ 3720/12500]  eta: 0:32:05  loss: 27.5748 (30.9253)  lr: 0.0000 (0.0000)  time: 0.195958  data: 0.000419  max mem: 3586
I20250120 12:29:39 3554128 dinov2 helpers.py:102] Training  [ 3730/12500]  eta: 0:32:02  loss: 27.5748 (30.9234)  lr: 0.0000 (0.0000)  time: 0.196134  data: 0.000461  max mem: 3586
I20250120 12:29:41 3554128 dinov2 helpers.py:102] Training  [ 3740/12500]  eta: 0:31:59  loss: 27.5748 (30.9113)  lr: 0.0000 (0.0000)  time: 0.196383  data: 0.000493  max mem: 3586
I20250120 12:29:43 3554128 dinov2 linear.py:272] running validation !
I20250120 12:29:44 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:39    time: 1.413742  data: 1.215544  max mem: 3586
I20250120 12:29:47 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:45    time: 0.314215  data: 0.111474  max mem: 3586
I20250120 12:29:49 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:35    time: 0.203232  data: 0.001375  max mem: 3586
I20250120 12:29:51 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.201109  data: 0.000959  max mem: 3586
I20250120 12:29:53 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199965  data: 0.000244  max mem: 3586
I20250120 12:29:55 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.199860  data: 0.000257  max mem: 3586
I20250120 12:29:57 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:20    time: 0.199773  data: 0.000256  max mem: 3586
I20250120 12:29:59 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199757  data: 0.000280  max mem: 3586
I20250120 12:30:01 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.200044  data: 0.000311  max mem: 3586
I20250120 12:30:03 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.200047  data: 0.000262  max mem: 3586
I20250120 12:30:05 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199889  data: 0.000229  max mem: 3586
I20250120 12:30:07 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.200019  data: 0.000288  max mem: 3586
I20250120 12:30:09 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199930  data: 0.000275  max mem: 3586
I20250120 12:30:11 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199685  data: 0.000255  max mem: 3586
I20250120 12:30:13 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199701  data: 0.000286  max mem: 3586
I20250120 12:30:15 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199778  data: 0.000205  max mem: 3586
I20250120 12:30:15 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195804  data: 0.000186  max mem: 3586
I20250120 12:30:15 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208579 s / it)
I20250120 12:30:15 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:30:15 3554128 dinov2 linear.py:287] 
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7758, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7973, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8034, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8099, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8158, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8223, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8210, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8206, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8199, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8061, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7784, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7764, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7973, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8073, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8110, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8182, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8223, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8271, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8273, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8263, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8136, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8099, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8003, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8050, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8114, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8166, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8208, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8226, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8212, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8193, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7945, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7669, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7559, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8042, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8095, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8183, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8221, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8277, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8270, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8197, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8278, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7996, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7800, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7805, device='cuda:0')}
I20250120 12:30:15 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.82780921459198}
I20250120 12:30:16 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:30:16 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:30:16 3554128 dinov2 helpers.py:102] Training  [ 3750/12500]  eta: 0:33:12  loss: 27.5748 (30.8864)  lr: 0.0000 (0.0000)  time: 1.817549  data: 0.000459  max mem: 3586
I20250120 12:30:18 3554128 dinov2 helpers.py:102] Training  [ 3760/12500]  eta: 0:33:09  loss: 27.5748 (30.9102)  lr: 0.0000 (0.0000)  time: 1.817106  data: 0.000406  max mem: 3586
I20250120 12:30:20 3554128 dinov2 helpers.py:102] Training  [ 3770/12500]  eta: 0:33:06  loss: 27.5748 (30.8924)  lr: 0.0000 (0.0000)  time: 0.196299  data: 0.000413  max mem: 3586
I20250120 12:30:22 3554128 dinov2 helpers.py:102] Training  [ 3780/12500]  eta: 0:33:03  loss: 27.6627 (30.8839)  lr: 0.0000 (0.0000)  time: 0.197075  data: 0.000411  max mem: 3586
I20250120 12:30:24 3554128 dinov2 helpers.py:102] Training  [ 3790/12500]  eta: 0:33:01  loss: 27.6627 (30.8804)  lr: 0.0000 (0.0000)  time: 0.221085  data: 0.027732  max mem: 3586
I20250120 12:30:26 3554128 dinov2 helpers.py:102] Training  [ 3800/12500]  eta: 0:32:58  loss: 27.6627 (30.8690)  lr: 0.0000 (0.0000)  time: 0.221214  data: 0.027764  max mem: 3586
I20250120 12:30:28 3554128 dinov2 helpers.py:102] Training  [ 3810/12500]  eta: 0:32:55  loss: 26.5545 (30.8542)  lr: 0.0000 (0.0000)  time: 0.197394  data: 0.000435  max mem: 3586
I20250120 12:30:30 3554128 dinov2 helpers.py:102] Training  [ 3820/12500]  eta: 0:32:52  loss: 26.5545 (30.8399)  lr: 0.0000 (0.0000)  time: 0.197098  data: 0.000463  max mem: 3586
I20250120 12:30:32 3554128 dinov2 helpers.py:102] Training  [ 3830/12500]  eta: 0:32:49  loss: 26.3745 (30.8272)  lr: 0.0000 (0.0000)  time: 0.197025  data: 0.000447  max mem: 3586
I20250120 12:30:34 3554128 dinov2 helpers.py:102] Training  [ 3840/12500]  eta: 0:32:47  loss: 26.3745 (30.8319)  lr: 0.0000 (0.0000)  time: 0.197236  data: 0.000440  max mem: 3586
I20250120 12:30:36 3554128 dinov2 helpers.py:102] Training  [ 3850/12500]  eta: 0:32:44  loss: 26.5545 (30.8391)  lr: 0.0000 (0.0000)  time: 0.197362  data: 0.000477  max mem: 3586
I20250120 12:30:38 3554128 dinov2 helpers.py:102] Training  [ 3860/12500]  eta: 0:32:41  loss: 27.6627 (30.8372)  lr: 0.0000 (0.0000)  time: 0.197280  data: 0.000454  max mem: 3586
I20250120 12:30:40 3554128 dinov2 helpers.py:102] Training  [ 3870/12500]  eta: 0:32:38  loss: 27.6627 (30.8429)  lr: 0.0000 (0.0000)  time: 0.197298  data: 0.000427  max mem: 3586
I20250120 12:30:42 3554128 dinov2 helpers.py:102] Training  [ 3880/12500]  eta: 0:32:35  loss: 27.6627 (30.8221)  lr: 0.0000 (0.0000)  time: 0.197603  data: 0.000436  max mem: 3586
I20250120 12:30:44 3554128 dinov2 helpers.py:102] Training  [ 3890/12500]  eta: 0:32:32  loss: 27.4911 (30.8135)  lr: 0.0000 (0.0000)  time: 0.197647  data: 0.000416  max mem: 3586
I20250120 12:30:46 3554128 dinov2 helpers.py:102] Training  [ 3900/12500]  eta: 0:32:29  loss: 27.4911 (30.8101)  lr: 0.0000 (0.0000)  time: 0.197345  data: 0.000415  max mem: 3586
I20250120 12:30:48 3554128 dinov2 helpers.py:102] Training  [ 3910/12500]  eta: 0:32:26  loss: 26.5545 (30.7956)  lr: 0.0000 (0.0000)  time: 0.197321  data: 0.000463  max mem: 3586
I20250120 12:30:50 3554128 dinov2 helpers.py:102] Training  [ 3920/12500]  eta: 0:32:23  loss: 27.4911 (30.7975)  lr: 0.0000 (0.0000)  time: 0.197366  data: 0.000467  max mem: 3586
I20250120 12:30:52 3554128 dinov2 helpers.py:102] Training  [ 3930/12500]  eta: 0:32:20  loss: 27.4911 (30.8044)  lr: 0.0000 (0.0000)  time: 0.197327  data: 0.000442  max mem: 3586
I20250120 12:30:54 3554128 dinov2 helpers.py:102] Training  [ 3940/12500]  eta: 0:32:17  loss: 27.6627 (30.7983)  lr: 0.0000 (0.0000)  time: 0.197480  data: 0.000459  max mem: 3586
I20250120 12:30:56 3554128 dinov2 helpers.py:102] Training  [ 3950/12500]  eta: 0:32:14  loss: 28.3834 (30.8006)  lr: 0.0000 (0.0000)  time: 0.197705  data: 0.000483  max mem: 3586
I20250120 12:30:58 3554128 dinov2 helpers.py:102] Training  [ 3960/12500]  eta: 0:32:12  loss: 28.3834 (30.7945)  lr: 0.0000 (0.0000)  time: 0.197951  data: 0.000478  max mem: 3586
I20250120 12:31:00 3554128 dinov2 helpers.py:102] Training  [ 3970/12500]  eta: 0:32:09  loss: 28.3948 (30.7892)  lr: 0.0000 (0.0000)  time: 0.198046  data: 0.000394  max mem: 3586
I20250120 12:31:02 3554128 dinov2 helpers.py:102] Training  [ 3980/12500]  eta: 0:32:06  loss: 28.3948 (30.7830)  lr: 0.0000 (0.0000)  time: 0.197898  data: 0.000366  max mem: 3586
I20250120 12:31:04 3554128 dinov2 helpers.py:102] Training  [ 3990/12500]  eta: 0:32:03  loss: 28.3834 (30.7713)  lr: 0.0000 (0.0000)  time: 0.197692  data: 0.000435  max mem: 3586
I20250120 12:31:06 3554128 dinov2 helpers.py:102] Training  [ 4000/12500]  eta: 0:32:00  loss: 28.3948 (30.7703)  lr: 0.0000 (0.0000)  time: 0.197792  data: 0.000421  max mem: 3586
I20250120 12:31:07 3554128 dinov2 helpers.py:102] Training  [ 4010/12500]  eta: 0:31:57  loss: 28.6646 (30.7687)  lr: 0.0000 (0.0000)  time: 0.197927  data: 0.000397  max mem: 3586
I20250120 12:31:09 3554128 dinov2 helpers.py:102] Training  [ 4020/12500]  eta: 0:31:54  loss: 28.6646 (30.7635)  lr: 0.0000 (0.0000)  time: 0.197864  data: 0.000405  max mem: 3586
I20250120 12:31:11 3554128 dinov2 helpers.py:102] Training  [ 4030/12500]  eta: 0:31:52  loss: 28.6646 (30.7520)  lr: 0.0000 (0.0000)  time: 0.197830  data: 0.000397  max mem: 3586
I20250120 12:31:13 3554128 dinov2 helpers.py:102] Training  [ 4040/12500]  eta: 0:31:49  loss: 28.6637 (30.7457)  lr: 0.0000 (0.0000)  time: 0.197736  data: 0.000430  max mem: 3586
I20250120 12:31:15 3554128 dinov2 helpers.py:102] Training  [ 4050/12500]  eta: 0:31:46  loss: 28.3948 (30.7367)  lr: 0.0000 (0.0000)  time: 0.197619  data: 0.000421  max mem: 3586
I20250120 12:31:17 3554128 dinov2 helpers.py:102] Training  [ 4060/12500]  eta: 0:31:43  loss: 28.3834 (30.7278)  lr: 0.0000 (0.0000)  time: 0.197639  data: 0.000388  max mem: 3586
I20250120 12:31:19 3554128 dinov2 helpers.py:102] Training  [ 4070/12500]  eta: 0:31:40  loss: 28.3834 (30.7307)  lr: 0.0000 (0.0000)  time: 0.197846  data: 0.000447  max mem: 3586
I20250120 12:31:21 3554128 dinov2 helpers.py:102] Training  [ 4080/12500]  eta: 0:31:37  loss: 28.3834 (30.7130)  lr: 0.0000 (0.0000)  time: 0.197922  data: 0.000471  max mem: 3586
I20250120 12:31:23 3554128 dinov2 helpers.py:102] Training  [ 4090/12500]  eta: 0:31:35  loss: 28.3948 (30.7099)  lr: 0.0000 (0.0000)  time: 0.197913  data: 0.000420  max mem: 3586
I20250120 12:31:25 3554128 dinov2 helpers.py:102] Training  [ 4100/12500]  eta: 0:31:32  loss: 28.3948 (30.7163)  lr: 0.0000 (0.0000)  time: 0.198084  data: 0.000399  max mem: 3586
I20250120 12:31:27 3554128 dinov2 helpers.py:102] Training  [ 4110/12500]  eta: 0:31:29  loss: 28.6637 (30.7192)  lr: 0.0000 (0.0000)  time: 0.198129  data: 0.000421  max mem: 3586
I20250120 12:31:29 3554128 dinov2 helpers.py:102] Training  [ 4120/12500]  eta: 0:31:26  loss: 28.6637 (30.7232)  lr: 0.0000 (0.0000)  time: 0.198312  data: 0.000468  max mem: 3586
I20250120 12:31:31 3554128 dinov2 helpers.py:102] Training  [ 4130/12500]  eta: 0:31:23  loss: 28.6637 (30.7202)  lr: 0.0000 (0.0000)  time: 0.198263  data: 0.000490  max mem: 3586
I20250120 12:31:33 3554128 dinov2 helpers.py:102] Training  [ 4140/12500]  eta: 0:31:21  loss: 28.6646 (30.7308)  lr: 0.0000 (0.0000)  time: 0.198010  data: 0.000430  max mem: 3586
I20250120 12:31:35 3554128 dinov2 helpers.py:102] Training  [ 4150/12500]  eta: 0:31:18  loss: 28.6646 (30.7306)  lr: 0.0000 (0.0000)  time: 0.198008  data: 0.000398  max mem: 3586
I20250120 12:31:37 3554128 dinov2 helpers.py:102] Training  [ 4160/12500]  eta: 0:31:15  loss: 29.4292 (30.7451)  lr: 0.0000 (0.0000)  time: 0.198031  data: 0.000423  max mem: 3586
I20250120 12:31:39 3554128 dinov2 helpers.py:102] Training  [ 4170/12500]  eta: 0:31:12  loss: 29.4740 (30.7422)  lr: 0.0000 (0.0000)  time: 0.198195  data: 0.000470  max mem: 3586
I20250120 12:31:41 3554128 dinov2 helpers.py:102] Training  [ 4180/12500]  eta: 0:31:09  loss: 29.4740 (30.7248)  lr: 0.0000 (0.0000)  time: 0.198346  data: 0.000476  max mem: 3586
I20250120 12:31:43 3554128 dinov2 helpers.py:102] Training  [ 4190/12500]  eta: 0:31:07  loss: 29.5117 (30.7266)  lr: 0.0000 (0.0000)  time: 0.198260  data: 0.000474  max mem: 3586
I20250120 12:31:45 3554128 dinov2 helpers.py:102] Training  [ 4200/12500]  eta: 0:31:04  loss: 29.4740 (30.7218)  lr: 0.0000 (0.0000)  time: 0.198247  data: 0.000472  max mem: 3586
I20250120 12:31:47 3554128 dinov2 helpers.py:102] Training  [ 4210/12500]  eta: 0:31:01  loss: 29.4740 (30.7315)  lr: 0.0000 (0.0000)  time: 0.198231  data: 0.000459  max mem: 3586
I20250120 12:31:49 3554128 dinov2 helpers.py:102] Training  [ 4220/12500]  eta: 0:30:58  loss: 29.4740 (30.7211)  lr: 0.0000 (0.0000)  time: 0.198201  data: 0.000471  max mem: 3586
I20250120 12:31:51 3554128 dinov2 helpers.py:102] Training  [ 4230/12500]  eta: 0:30:56  loss: 29.4740 (30.7172)  lr: 0.0000 (0.0000)  time: 0.198351  data: 0.000455  max mem: 3586
I20250120 12:31:53 3554128 dinov2 helpers.py:102] Training  [ 4240/12500]  eta: 0:30:53  loss: 29.4740 (30.7030)  lr: 0.0000 (0.0000)  time: 0.198365  data: 0.000427  max mem: 3586
I20250120 12:31:55 3554128 dinov2 helpers.py:102] Training  [ 4250/12500]  eta: 0:30:50  loss: 29.4740 (30.6991)  lr: 0.0000 (0.0000)  time: 0.198237  data: 0.000449  max mem: 3586
I20250120 12:31:57 3554128 dinov2 helpers.py:102] Training  [ 4260/12500]  eta: 0:30:47  loss: 29.5117 (30.7026)  lr: 0.0000 (0.0000)  time: 0.198344  data: 0.000439  max mem: 3586
I20250120 12:31:59 3554128 dinov2 helpers.py:102] Training  [ 4270/12500]  eta: 0:30:45  loss: 29.5117 (30.7036)  lr: 0.0000 (0.0000)  time: 0.198357  data: 0.000438  max mem: 3586
I20250120 12:32:01 3554128 dinov2 helpers.py:102] Training  [ 4280/12500]  eta: 0:30:42  loss: 29.5117 (30.6919)  lr: 0.0000 (0.0000)  time: 0.198166  data: 0.000478  max mem: 3586
I20250120 12:32:03 3554128 dinov2 helpers.py:102] Training  [ 4290/12500]  eta: 0:30:39  loss: 29.5117 (30.6829)  lr: 0.0000 (0.0000)  time: 0.198085  data: 0.000474  max mem: 3586
I20250120 12:32:05 3554128 dinov2 helpers.py:102] Training  [ 4300/12500]  eta: 0:30:36  loss: 29.5117 (30.6922)  lr: 0.0000 (0.0000)  time: 0.198186  data: 0.000466  max mem: 3586
I20250120 12:32:07 3554128 dinov2 helpers.py:102] Training  [ 4310/12500]  eta: 0:30:34  loss: 29.5117 (30.6924)  lr: 0.0000 (0.0000)  time: 0.198149  data: 0.000429  max mem: 3586
I20250120 12:32:09 3554128 dinov2 helpers.py:102] Training  [ 4320/12500]  eta: 0:30:31  loss: 29.4740 (30.6873)  lr: 0.0000 (0.0000)  time: 0.198012  data: 0.000448  max mem: 3586
I20250120 12:32:11 3554128 dinov2 helpers.py:102] Training  [ 4330/12500]  eta: 0:30:28  loss: 29.5117 (30.6920)  lr: 0.0000 (0.0000)  time: 0.198025  data: 0.000496  max mem: 3586
I20250120 12:32:13 3554128 dinov2 helpers.py:102] Training  [ 4340/12500]  eta: 0:30:26  loss: 29.5117 (30.6998)  lr: 0.0000 (0.0000)  time: 0.197917  data: 0.000448  max mem: 3586
I20250120 12:32:15 3554128 dinov2 helpers.py:102] Training  [ 4350/12500]  eta: 0:30:23  loss: 29.0595 (30.6832)  lr: 0.0000 (0.0000)  time: 0.197895  data: 0.000447  max mem: 3586
I20250120 12:32:17 3554128 dinov2 helpers.py:102] Training  [ 4360/12500]  eta: 0:30:20  loss: 29.0595 (30.6812)  lr: 0.0000 (0.0000)  time: 0.197949  data: 0.000467  max mem: 3586
I20250120 12:32:19 3554128 dinov2 helpers.py:102] Training  [ 4370/12500]  eta: 0:30:17  loss: 29.0595 (30.6817)  lr: 0.0000 (0.0000)  time: 0.197856  data: 0.000468  max mem: 3586
I20250120 12:32:21 3554128 dinov2 helpers.py:102] Training  [ 4380/12500]  eta: 0:30:15  loss: 29.0595 (30.6765)  lr: 0.0000 (0.0000)  time: 0.197950  data: 0.000445  max mem: 3586
I20250120 12:32:23 3554128 dinov2 helpers.py:102] Training  [ 4390/12500]  eta: 0:30:12  loss: 29.0447 (30.6649)  lr: 0.0000 (0.0000)  time: 0.197912  data: 0.000432  max mem: 3586
I20250120 12:32:25 3554128 dinov2 helpers.py:102] Training  [ 4400/12500]  eta: 0:30:09  loss: 29.0447 (30.6593)  lr: 0.0000 (0.0000)  time: 0.197889  data: 0.000434  max mem: 3586
I20250120 12:32:27 3554128 dinov2 helpers.py:102] Training  [ 4410/12500]  eta: 0:30:07  loss: 28.4939 (30.6521)  lr: 0.0000 (0.0000)  time: 0.198101  data: 0.000455  max mem: 3586
I20250120 12:32:29 3554128 dinov2 helpers.py:102] Training  [ 4420/12500]  eta: 0:30:04  loss: 28.6686 (30.6476)  lr: 0.0000 (0.0000)  time: 0.197979  data: 0.000468  max mem: 3586
I20250120 12:32:31 3554128 dinov2 helpers.py:102] Training  [ 4430/12500]  eta: 0:30:01  loss: 28.4939 (30.6386)  lr: 0.0000 (0.0000)  time: 0.197911  data: 0.000418  max mem: 3586
I20250120 12:32:33 3554128 dinov2 helpers.py:102] Training  [ 4440/12500]  eta: 0:29:58  loss: 28.4939 (30.6308)  lr: 0.0000 (0.0000)  time: 0.197950  data: 0.000420  max mem: 3586
I20250120 12:32:35 3554128 dinov2 helpers.py:102] Training  [ 4450/12500]  eta: 0:29:56  loss: 28.4096 (30.6229)  lr: 0.0000 (0.0000)  time: 0.197807  data: 0.000464  max mem: 3586
I20250120 12:32:37 3554128 dinov2 helpers.py:102] Training  [ 4460/12500]  eta: 0:29:53  loss: 28.4096 (30.6188)  lr: 0.0000 (0.0000)  time: 0.197790  data: 0.000470  max mem: 3586
I20250120 12:32:39 3554128 dinov2 helpers.py:102] Training  [ 4470/12500]  eta: 0:29:50  loss: 28.2036 (30.6125)  lr: 0.0000 (0.0000)  time: 0.197901  data: 0.000460  max mem: 3586
I20250120 12:32:41 3554128 dinov2 helpers.py:102] Training  [ 4480/12500]  eta: 0:29:48  loss: 28.2036 (30.6069)  lr: 0.0000 (0.0000)  time: 0.197822  data: 0.000440  max mem: 3586
I20250120 12:32:43 3554128 dinov2 helpers.py:102] Training  [ 4490/12500]  eta: 0:29:45  loss: 28.2036 (30.5958)  lr: 0.0000 (0.0000)  time: 0.197780  data: 0.000403  max mem: 3586
I20250120 12:32:45 3554128 dinov2 helpers.py:102] Training  [ 4500/12500]  eta: 0:29:42  loss: 28.2036 (30.5941)  lr: 0.0000 (0.0000)  time: 0.197904  data: 0.000424  max mem: 3586
I20250120 12:32:47 3554128 dinov2 helpers.py:102] Training  [ 4510/12500]  eta: 0:29:40  loss: 28.2036 (30.5954)  lr: 0.0000 (0.0000)  time: 0.197902  data: 0.000412  max mem: 3586
I20250120 12:32:49 3554128 dinov2 helpers.py:102] Training  [ 4520/12500]  eta: 0:29:37  loss: 28.1042 (30.5896)  lr: 0.0000 (0.0000)  time: 0.197965  data: 0.000432  max mem: 3586
I20250120 12:32:50 3554128 dinov2 helpers.py:102] Training  [ 4530/12500]  eta: 0:29:34  loss: 28.1042 (30.5857)  lr: 0.0000 (0.0000)  time: 0.197932  data: 0.000477  max mem: 3586
I20250120 12:32:52 3554128 dinov2 helpers.py:102] Training  [ 4540/12500]  eta: 0:29:32  loss: 28.1042 (30.5893)  lr: 0.0000 (0.0000)  time: 0.197884  data: 0.000477  max mem: 3586
I20250120 12:32:54 3554128 dinov2 helpers.py:102] Training  [ 4550/12500]  eta: 0:29:29  loss: 28.1042 (30.5838)  lr: 0.0000 (0.0000)  time: 0.198008  data: 0.000461  max mem: 3586
I20250120 12:32:56 3554128 dinov2 helpers.py:102] Training  [ 4560/12500]  eta: 0:29:26  loss: 28.1042 (30.5788)  lr: 0.0000 (0.0000)  time: 0.198139  data: 0.000393  max mem: 3586
I20250120 12:32:58 3554128 dinov2 helpers.py:102] Training  [ 4570/12500]  eta: 0:29:24  loss: 28.0996 (30.5725)  lr: 0.0000 (0.0000)  time: 0.198214  data: 0.000356  max mem: 3586
I20250120 12:33:00 3554128 dinov2 helpers.py:102] Training  [ 4580/12500]  eta: 0:29:21  loss: 28.0996 (30.5673)  lr: 0.0000 (0.0000)  time: 0.197961  data: 0.000408  max mem: 3586
I20250120 12:33:02 3554128 dinov2 helpers.py:102] Training  [ 4590/12500]  eta: 0:29:18  loss: 28.1042 (30.5652)  lr: 0.0000 (0.0000)  time: 0.197905  data: 0.000473  max mem: 3586
I20250120 12:33:04 3554128 dinov2 helpers.py:102] Training  [ 4600/12500]  eta: 0:29:16  loss: 28.1042 (30.5652)  lr: 0.0000 (0.0000)  time: 0.198031  data: 0.000489  max mem: 3586
I20250120 12:33:06 3554128 dinov2 helpers.py:102] Training  [ 4610/12500]  eta: 0:29:13  loss: 28.1569 (30.5624)  lr: 0.0000 (0.0000)  time: 0.198119  data: 0.000437  max mem: 3586
I20250120 12:33:08 3554128 dinov2 helpers.py:102] Training  [ 4620/12500]  eta: 0:29:11  loss: 28.1042 (30.5520)  lr: 0.0000 (0.0000)  time: 0.198206  data: 0.000404  max mem: 3586
I20250120 12:33:10 3554128 dinov2 helpers.py:102] Training  [ 4630/12500]  eta: 0:29:08  loss: 28.1569 (30.5535)  lr: 0.0000 (0.0000)  time: 0.198001  data: 0.000430  max mem: 3586
I20250120 12:33:12 3554128 dinov2 helpers.py:102] Training  [ 4640/12500]  eta: 0:29:05  loss: 28.1569 (30.5475)  lr: 0.0000 (0.0000)  time: 0.197980  data: 0.000457  max mem: 3586
I20250120 12:33:14 3554128 dinov2 helpers.py:102] Training  [ 4650/12500]  eta: 0:29:03  loss: 28.1569 (30.5339)  lr: 0.0000 (0.0000)  time: 0.198225  data: 0.000473  max mem: 3586
I20250120 12:33:16 3554128 dinov2 helpers.py:102] Training  [ 4660/12500]  eta: 0:29:00  loss: 28.1042 (30.5281)  lr: 0.0000 (0.0000)  time: 0.198112  data: 0.000415  max mem: 3586
I20250120 12:33:18 3554128 dinov2 helpers.py:102] Training  [ 4670/12500]  eta: 0:28:57  loss: 28.1042 (30.5138)  lr: 0.0000 (0.0000)  time: 0.197972  data: 0.000364  max mem: 3586
I20250120 12:33:20 3554128 dinov2 helpers.py:102] Training  [ 4680/12500]  eta: 0:28:55  loss: 28.0996 (30.5061)  lr: 0.0000 (0.0000)  time: 0.197988  data: 0.000387  max mem: 3586
I20250120 12:33:22 3554128 dinov2 helpers.py:102] Training  [ 4690/12500]  eta: 0:28:52  loss: 28.1569 (30.5098)  lr: 0.0000 (0.0000)  time: 0.197918  data: 0.000445  max mem: 3586
I20250120 12:33:24 3554128 dinov2 helpers.py:102] Training  [ 4700/12500]  eta: 0:28:50  loss: 28.0996 (30.4967)  lr: 0.0000 (0.0000)  time: 0.197836  data: 0.000451  max mem: 3586
I20250120 12:33:26 3554128 dinov2 helpers.py:102] Training  [ 4710/12500]  eta: 0:28:47  loss: 28.0996 (30.4933)  lr: 0.0000 (0.0000)  time: 0.197705  data: 0.000463  max mem: 3586
I20250120 12:33:28 3554128 dinov2 helpers.py:102] Training  [ 4720/12500]  eta: 0:28:44  loss: 28.0996 (30.4845)  lr: 0.0000 (0.0000)  time: 0.197709  data: 0.000466  max mem: 3586
I20250120 12:33:30 3554128 dinov2 helpers.py:102] Training  [ 4730/12500]  eta: 0:28:42  loss: 27.7931 (30.4749)  lr: 0.0000 (0.0000)  time: 0.197729  data: 0.000423  max mem: 3586
I20250120 12:33:32 3554128 dinov2 helpers.py:102] Training  [ 4740/12500]  eta: 0:28:39  loss: 27.7931 (30.4732)  lr: 0.0000 (0.0000)  time: 0.197602  data: 0.000431  max mem: 3586
I20250120 12:33:34 3554128 dinov2 helpers.py:102] Training  [ 4750/12500]  eta: 0:28:36  loss: 27.7459 (30.4612)  lr: 0.0000 (0.0000)  time: 0.197608  data: 0.000479  max mem: 3586
I20250120 12:33:36 3554128 dinov2 helpers.py:102] Training  [ 4760/12500]  eta: 0:28:34  loss: 27.7459 (30.4556)  lr: 0.0000 (0.0000)  time: 0.197803  data: 0.000490  max mem: 3586
I20250120 12:33:38 3554128 dinov2 helpers.py:102] Training  [ 4770/12500]  eta: 0:28:31  loss: 27.7931 (30.4519)  lr: 0.0000 (0.0000)  time: 0.197870  data: 0.000419  max mem: 3586
I20250120 12:33:40 3554128 dinov2 helpers.py:102] Training  [ 4780/12500]  eta: 0:28:29  loss: 27.7931 (30.4482)  lr: 0.0000 (0.0000)  time: 0.197908  data: 0.000429  max mem: 3586
I20250120 12:33:42 3554128 dinov2 helpers.py:102] Training  [ 4790/12500]  eta: 0:28:26  loss: 27.7931 (30.4442)  lr: 0.0000 (0.0000)  time: 0.197811  data: 0.000462  max mem: 3586
I20250120 12:33:44 3554128 dinov2 helpers.py:102] Training  [ 4800/12500]  eta: 0:28:23  loss: 27.7931 (30.4450)  lr: 0.0000 (0.0000)  time: 0.197746  data: 0.000446  max mem: 3586
I20250120 12:33:46 3554128 dinov2 helpers.py:102] Training  [ 4810/12500]  eta: 0:28:21  loss: 27.7459 (30.4333)  lr: 0.0000 (0.0000)  time: 0.197819  data: 0.000446  max mem: 3586
I20250120 12:33:48 3554128 dinov2 helpers.py:102] Training  [ 4820/12500]  eta: 0:28:18  loss: 27.7459 (30.4166)  lr: 0.0000 (0.0000)  time: 0.197731  data: 0.000463  max mem: 3586
I20250120 12:33:50 3554128 dinov2 helpers.py:102] Training  [ 4830/12500]  eta: 0:28:16  loss: 26.9374 (30.4088)  lr: 0.0000 (0.0000)  time: 0.197724  data: 0.000455  max mem: 3586
I20250120 12:33:52 3554128 dinov2 helpers.py:102] Training  [ 4840/12500]  eta: 0:28:13  loss: 26.6452 (30.4002)  lr: 0.0000 (0.0000)  time: 0.197819  data: 0.000456  max mem: 3586
I20250120 12:33:54 3554128 dinov2 helpers.py:102] Training  [ 4850/12500]  eta: 0:28:11  loss: 26.6452 (30.3882)  lr: 0.0000 (0.0000)  time: 0.197780  data: 0.000460  max mem: 3586
I20250120 12:33:56 3554128 dinov2 helpers.py:102] Training  [ 4860/12500]  eta: 0:28:08  loss: 26.6452 (30.3902)  lr: 0.0000 (0.0000)  time: 0.197852  data: 0.000441  max mem: 3586
I20250120 12:33:58 3554128 dinov2 helpers.py:102] Training  [ 4870/12500]  eta: 0:28:05  loss: 26.6548 (30.3826)  lr: 0.0000 (0.0000)  time: 0.197971  data: 0.000405  max mem: 3586
I20250120 12:34:00 3554128 dinov2 helpers.py:102] Training  [ 4880/12500]  eta: 0:28:03  loss: 26.6452 (30.3745)  lr: 0.0000 (0.0000)  time: 0.197886  data: 0.000421  max mem: 3586
I20250120 12:34:02 3554128 dinov2 helpers.py:102] Training  [ 4890/12500]  eta: 0:28:00  loss: 26.6452 (30.3850)  lr: 0.0000 (0.0000)  time: 0.197802  data: 0.000510  max mem: 3586
I20250120 12:34:04 3554128 dinov2 helpers.py:102] Training  [ 4900/12500]  eta: 0:27:58  loss: 26.6452 (30.3720)  lr: 0.0000 (0.0000)  time: 0.197723  data: 0.000462  max mem: 3586
I20250120 12:34:06 3554128 dinov2 helpers.py:102] Training  [ 4910/12500]  eta: 0:27:55  loss: 26.4461 (30.3609)  lr: 0.0000 (0.0000)  time: 0.197751  data: 0.000446  max mem: 3586
I20250120 12:34:08 3554128 dinov2 helpers.py:102] Training  [ 4920/12500]  eta: 0:27:53  loss: 26.4461 (30.3513)  lr: 0.0000 (0.0000)  time: 0.197903  data: 0.000454  max mem: 3586
I20250120 12:34:10 3554128 dinov2 helpers.py:102] Training  [ 4930/12500]  eta: 0:27:50  loss: 26.6452 (30.3442)  lr: 0.0000 (0.0000)  time: 0.197791  data: 0.000435  max mem: 3586
I20250120 12:34:12 3554128 dinov2 helpers.py:102] Training  [ 4940/12500]  eta: 0:27:47  loss: 26.4461 (30.3342)  lr: 0.0000 (0.0000)  time: 0.197643  data: 0.000476  max mem: 3586
I20250120 12:34:14 3554128 dinov2 helpers.py:102] Training  [ 4950/12500]  eta: 0:27:45  loss: 26.6452 (30.3351)  lr: 0.0000 (0.0000)  time: 0.197751  data: 0.000434  max mem: 3586
I20250120 12:34:16 3554128 dinov2 helpers.py:102] Training  [ 4960/12500]  eta: 0:27:42  loss: 26.6452 (30.3453)  lr: 0.0000 (0.0000)  time: 0.197904  data: 0.000385  max mem: 3586
I20250120 12:34:18 3554128 dinov2 helpers.py:102] Training  [ 4970/12500]  eta: 0:27:40  loss: 26.6452 (30.3440)  lr: 0.0000 (0.0000)  time: 0.197979  data: 0.000440  max mem: 3586
I20250120 12:34:20 3554128 dinov2 helpers.py:102] Training  [ 4980/12500]  eta: 0:27:37  loss: 26.4461 (30.3356)  lr: 0.0000 (0.0000)  time: 0.197921  data: 0.000422  max mem: 3586
I20250120 12:34:22 3554128 dinov2 helpers.py:102] Training  [ 4990/12500]  eta: 0:27:35  loss: 26.4461 (30.3427)  lr: 0.0000 (0.0000)  time: 0.197827  data: 0.000359  max mem: 3586
I20250120 12:34:27 3554128 dinov2 linear.py:272] running validation !
I20250120 12:34:30 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:07:33    time: 2.924225  data: 2.728392  max mem: 3586
I20250120 12:34:32 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:01:05    time: 0.452410  data: 0.249964  max mem: 3586
I20250120 12:34:34 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:44    time: 0.202598  data: 0.001487  max mem: 3586
I20250120 12:34:36 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:36    time: 0.199374  data: 0.000563  max mem: 3586
I20250120 12:34:38 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:30    time: 0.198633  data: 0.000262  max mem: 3586
I20250120 12:34:40 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:26    time: 0.198603  data: 0.000261  max mem: 3586
I20250120 12:34:42 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:23    time: 0.198967  data: 0.000297  max mem: 3586
I20250120 12:34:44 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:20    time: 0.199654  data: 0.000284  max mem: 3586
I20250120 12:34:46 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.199945  data: 0.000237  max mem: 3586
I20250120 12:34:48 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.199975  data: 0.000230  max mem: 3586
I20250120 12:34:50 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.199861  data: 0.000264  max mem: 3586
I20250120 12:34:52 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.199776  data: 0.000244  max mem: 3586
I20250120 12:34:54 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.200016  data: 0.000188  max mem: 3586
I20250120 12:34:56 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.200027  data: 0.000222  max mem: 3586
I20250120 12:34:58 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199728  data: 0.000240  max mem: 3586
I20250120 12:35:00 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.198821  data: 0.000170  max mem: 3586
I20250120 12:35:01 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.194920  data: 0.000141  max mem: 3586
I20250120 12:35:01 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.217779 s / it)
I20250120 12:35:01 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:35:01 3554128 dinov2 linear.py:287] 
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7831, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8006, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8062, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8110, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8175, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8204, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8216, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8202, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8160, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8025, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7749, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7840, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8026, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8097, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8131, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8204, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8238, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8275, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8314, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8351, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8249, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8141, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8088, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8076, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8139, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8212, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8224, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8236, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8246, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8151, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7945, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7477, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7190, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8075, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8121, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8205, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8223, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8235, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8275, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8327, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8306, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8274, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7896, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7661, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7301, device='cuda:0')}
I20250120 12:35:01 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8351354002952576}
I20250120 12:35:01 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:35:01 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:35:01 3554128 dinov2 helpers.py:102] Training  [ 5000/12500]  eta: 0:28:29  loss: 26.2352 (30.3302)  lr: 0.0000 (0.0000)  time: 2.092309  data: 0.206355  max mem: 3586
I20250120 12:35:03 3554128 dinov2 helpers.py:102] Training  [ 5010/12500]  eta: 0:28:26  loss: 26.4461 (30.3244)  lr: 0.0000 (0.0000)  time: 2.090932  data: 0.206349  max mem: 3586
I20250120 12:35:05 3554128 dinov2 helpers.py:102] Training  [ 5020/12500]  eta: 0:28:23  loss: 26.6452 (30.3176)  lr: 0.0000 (0.0000)  time: 0.195692  data: 0.000406  max mem: 3586
I20250120 12:35:07 3554128 dinov2 helpers.py:102] Training  [ 5030/12500]  eta: 0:28:21  loss: 26.6548 (30.3163)  lr: 0.0000 (0.0000)  time: 0.196495  data: 0.000473  max mem: 3586
I20250120 12:35:09 3554128 dinov2 helpers.py:102] Training  [ 5040/12500]  eta: 0:28:18  loss: 26.8450 (30.3134)  lr: 0.0000 (0.0000)  time: 0.196694  data: 0.000465  max mem: 3586
I20250120 12:35:12 3554128 dinov2 helpers.py:102] Training  [ 5050/12500]  eta: 0:28:16  loss: 26.8821 (30.3185)  lr: 0.0000 (0.0000)  time: 0.221386  data: 0.028430  max mem: 3586
I20250120 12:35:14 3554128 dinov2 helpers.py:102] Training  [ 5060/12500]  eta: 0:28:13  loss: 26.8821 (30.3131)  lr: 0.0000 (0.0000)  time: 0.221171  data: 0.028425  max mem: 3586
I20250120 12:35:16 3554128 dinov2 helpers.py:102] Training  [ 5070/12500]  eta: 0:28:11  loss: 27.4031 (30.3206)  lr: 0.0000 (0.0000)  time: 0.196377  data: 0.000438  max mem: 3586
I20250120 12:35:18 3554128 dinov2 helpers.py:102] Training  [ 5080/12500]  eta: 0:28:08  loss: 27.4031 (30.3037)  lr: 0.0000 (0.0000)  time: 0.196392  data: 0.000449  max mem: 3586
I20250120 12:35:20 3554128 dinov2 helpers.py:102] Training  [ 5090/12500]  eta: 0:28:05  loss: 26.8821 (30.2956)  lr: 0.0000 (0.0000)  time: 0.196352  data: 0.000415  max mem: 3586
I20250120 12:35:22 3554128 dinov2 helpers.py:102] Training  [ 5100/12500]  eta: 0:28:02  loss: 26.8821 (30.2851)  lr: 0.0000 (0.0000)  time: 0.196310  data: 0.000409  max mem: 3586
I20250120 12:35:24 3554128 dinov2 helpers.py:102] Training  [ 5110/12500]  eta: 0:28:00  loss: 26.8821 (30.2780)  lr: 0.0000 (0.0000)  time: 0.196531  data: 0.000438  max mem: 3586
I20250120 12:35:25 3554128 dinov2 helpers.py:102] Training  [ 5120/12500]  eta: 0:27:57  loss: 26.8821 (30.2649)  lr: 0.0000 (0.0000)  time: 0.196740  data: 0.000443  max mem: 3586
I20250120 12:35:27 3554128 dinov2 helpers.py:102] Training  [ 5130/12500]  eta: 0:27:54  loss: 26.9141 (30.2584)  lr: 0.0000 (0.0000)  time: 0.196646  data: 0.000425  max mem: 3586
I20250120 12:35:29 3554128 dinov2 helpers.py:102] Training  [ 5140/12500]  eta: 0:27:51  loss: 26.9141 (30.2469)  lr: 0.0000 (0.0000)  time: 0.196827  data: 0.000388  max mem: 3586
I20250120 12:35:31 3554128 dinov2 helpers.py:102] Training  [ 5150/12500]  eta: 0:27:49  loss: 26.9141 (30.2447)  lr: 0.0000 (0.0000)  time: 0.197031  data: 0.000375  max mem: 3586
I20250120 12:35:33 3554128 dinov2 helpers.py:102] Training  [ 5160/12500]  eta: 0:27:46  loss: 26.8821 (30.2362)  lr: 0.0000 (0.0000)  time: 0.197116  data: 0.000410  max mem: 3586
I20250120 12:35:35 3554128 dinov2 helpers.py:102] Training  [ 5170/12500]  eta: 0:27:43  loss: 26.6182 (30.2242)  lr: 0.0000 (0.0000)  time: 0.197018  data: 0.000430  max mem: 3586
I20250120 12:35:37 3554128 dinov2 helpers.py:102] Training  [ 5180/12500]  eta: 0:27:41  loss: 26.8821 (30.2190)  lr: 0.0000 (0.0000)  time: 0.196927  data: 0.000412  max mem: 3586
I20250120 12:35:39 3554128 dinov2 helpers.py:102] Training  [ 5190/12500]  eta: 0:27:38  loss: 26.8821 (30.2157)  lr: 0.0000 (0.0000)  time: 0.197073  data: 0.000445  max mem: 3586
I20250120 12:35:41 3554128 dinov2 helpers.py:102] Training  [ 5200/12500]  eta: 0:27:35  loss: 26.9141 (30.2174)  lr: 0.0000 (0.0000)  time: 0.197074  data: 0.000484  max mem: 3586
I20250120 12:35:43 3554128 dinov2 helpers.py:102] Training  [ 5210/12500]  eta: 0:27:33  loss: 26.8821 (30.2051)  lr: 0.0000 (0.0000)  time: 0.197174  data: 0.000443  max mem: 3586
I20250120 12:35:45 3554128 dinov2 helpers.py:102] Training  [ 5220/12500]  eta: 0:27:30  loss: 26.9141 (30.2058)  lr: 0.0000 (0.0000)  time: 0.197256  data: 0.000371  max mem: 3586
I20250120 12:35:47 3554128 dinov2 helpers.py:102] Training  [ 5230/12500]  eta: 0:27:27  loss: 26.6182 (30.1945)  lr: 0.0000 (0.0000)  time: 0.197210  data: 0.000399  max mem: 3586
I20250120 12:35:49 3554128 dinov2 helpers.py:102] Training  [ 5240/12500]  eta: 0:27:25  loss: 26.6182 (30.1883)  lr: 0.0000 (0.0000)  time: 0.197056  data: 0.000446  max mem: 3586
I20250120 12:35:51 3554128 dinov2 helpers.py:102] Training  [ 5250/12500]  eta: 0:27:22  loss: 26.1991 (30.1781)  lr: 0.0000 (0.0000)  time: 0.197161  data: 0.000418  max mem: 3586
I20250120 12:35:53 3554128 dinov2 helpers.py:102] Training  [ 5260/12500]  eta: 0:27:19  loss: 25.8537 (30.1669)  lr: 0.0000 (0.0000)  time: 0.197323  data: 0.000393  max mem: 3586
I20250120 12:35:55 3554128 dinov2 helpers.py:102] Training  [ 5270/12500]  eta: 0:27:17  loss: 24.9359 (30.1527)  lr: 0.0000 (0.0000)  time: 0.197271  data: 0.000421  max mem: 3586
I20250120 12:35:57 3554128 dinov2 helpers.py:102] Training  [ 5280/12500]  eta: 0:27:14  loss: 25.8537 (30.1493)  lr: 0.0000 (0.0000)  time: 0.197411  data: 0.000383  max mem: 3586
I20250120 12:35:59 3554128 dinov2 helpers.py:102] Training  [ 5290/12500]  eta: 0:27:11  loss: 25.8537 (30.1492)  lr: 0.0000 (0.0000)  time: 0.197545  data: 0.000379  max mem: 3586
I20250120 12:36:01 3554128 dinov2 helpers.py:102] Training  [ 5300/12500]  eta: 0:27:09  loss: 26.6182 (30.1450)  lr: 0.0000 (0.0000)  time: 0.197357  data: 0.000457  max mem: 3586
I20250120 12:36:03 3554128 dinov2 helpers.py:102] Training  [ 5310/12500]  eta: 0:27:06  loss: 26.9141 (30.1421)  lr: 0.0000 (0.0000)  time: 0.197188  data: 0.000452  max mem: 3586
I20250120 12:36:05 3554128 dinov2 helpers.py:102] Training  [ 5320/12500]  eta: 0:27:03  loss: 26.9273 (30.1433)  lr: 0.0000 (0.0000)  time: 0.197447  data: 0.000412  max mem: 3586
I20250120 12:36:07 3554128 dinov2 helpers.py:102] Training  [ 5330/12500]  eta: 0:27:01  loss: 27.5500 (30.1395)  lr: 0.0000 (0.0000)  time: 0.197626  data: 0.000381  max mem: 3586
I20250120 12:36:09 3554128 dinov2 helpers.py:102] Training  [ 5340/12500]  eta: 0:26:58  loss: 27.5500 (30.1229)  lr: 0.0000 (0.0000)  time: 0.197747  data: 0.000442  max mem: 3586
I20250120 12:36:11 3554128 dinov2 helpers.py:102] Training  [ 5350/12500]  eta: 0:26:55  loss: 27.5500 (30.1285)  lr: 0.0000 (0.0000)  time: 0.197735  data: 0.000432  max mem: 3586
I20250120 12:36:13 3554128 dinov2 helpers.py:102] Training  [ 5360/12500]  eta: 0:26:53  loss: 27.9179 (30.1349)  lr: 0.0000 (0.0000)  time: 0.197650  data: 0.000379  max mem: 3586
I20250120 12:36:15 3554128 dinov2 helpers.py:102] Training  [ 5370/12500]  eta: 0:26:50  loss: 28.1326 (30.1370)  lr: 0.0000 (0.0000)  time: 0.197745  data: 0.000400  max mem: 3586
I20250120 12:36:17 3554128 dinov2 helpers.py:102] Training  [ 5380/12500]  eta: 0:26:48  loss: 28.3575 (30.1359)  lr: 0.0000 (0.0000)  time: 0.197671  data: 0.000451  max mem: 3586
I20250120 12:36:19 3554128 dinov2 helpers.py:102] Training  [ 5390/12500]  eta: 0:26:45  loss: 28.3575 (30.1345)  lr: 0.0000 (0.0000)  time: 0.197779  data: 0.000467  max mem: 3586
I20250120 12:36:21 3554128 dinov2 helpers.py:102] Training  [ 5400/12500]  eta: 0:26:42  loss: 28.3575 (30.1351)  lr: 0.0000 (0.0000)  time: 0.197876  data: 0.000443  max mem: 3586
I20250120 12:36:23 3554128 dinov2 helpers.py:102] Training  [ 5410/12500]  eta: 0:26:40  loss: 28.3575 (30.1251)  lr: 0.0000 (0.0000)  time: 0.197655  data: 0.000452  max mem: 3586
I20250120 12:36:25 3554128 dinov2 helpers.py:102] Training  [ 5420/12500]  eta: 0:26:37  loss: 28.3051 (30.1217)  lr: 0.0000 (0.0000)  time: 0.197571  data: 0.000488  max mem: 3586
I20250120 12:36:27 3554128 dinov2 helpers.py:102] Training  [ 5430/12500]  eta: 0:26:34  loss: 28.3051 (30.1086)  lr: 0.0000 (0.0000)  time: 0.197629  data: 0.000471  max mem: 3586
I20250120 12:36:29 3554128 dinov2 helpers.py:102] Training  [ 5440/12500]  eta: 0:26:32  loss: 28.3051 (30.0969)  lr: 0.0000 (0.0000)  time: 0.197645  data: 0.000422  max mem: 3586
I20250120 12:36:31 3554128 dinov2 helpers.py:102] Training  [ 5450/12500]  eta: 0:26:29  loss: 28.3575 (30.0952)  lr: 0.0000 (0.0000)  time: 0.197605  data: 0.000425  max mem: 3586
I20250120 12:36:33 3554128 dinov2 helpers.py:102] Training  [ 5460/12500]  eta: 0:26:27  loss: 28.3575 (30.0821)  lr: 0.0000 (0.0000)  time: 0.197654  data: 0.000439  max mem: 3586
I20250120 12:36:35 3554128 dinov2 helpers.py:102] Training  [ 5470/12500]  eta: 0:26:24  loss: 28.6202 (30.0882)  lr: 0.0000 (0.0000)  time: 0.197878  data: 0.000475  max mem: 3586
I20250120 12:36:37 3554128 dinov2 helpers.py:102] Training  [ 5480/12500]  eta: 0:26:21  loss: 28.6202 (30.0808)  lr: 0.0000 (0.0000)  time: 0.197920  data: 0.000457  max mem: 3586
I20250120 12:36:39 3554128 dinov2 helpers.py:102] Training  [ 5490/12500]  eta: 0:26:19  loss: 28.3051 (30.0698)  lr: 0.0000 (0.0000)  time: 0.197864  data: 0.000445  max mem: 3586
I20250120 12:36:41 3554128 dinov2 helpers.py:102] Training  [ 5500/12500]  eta: 0:26:16  loss: 28.4680 (30.0669)  lr: 0.0000 (0.0000)  time: 0.197937  data: 0.000458  max mem: 3586
I20250120 12:36:43 3554128 dinov2 helpers.py:102] Training  [ 5510/12500]  eta: 0:26:14  loss: 28.3051 (30.0529)  lr: 0.0000 (0.0000)  time: 0.197947  data: 0.000443  max mem: 3586
I20250120 12:36:45 3554128 dinov2 helpers.py:102] Training  [ 5520/12500]  eta: 0:26:11  loss: 28.1326 (30.0445)  lr: 0.0000 (0.0000)  time: 0.197991  data: 0.000430  max mem: 3586
I20250120 12:36:46 3554128 dinov2 helpers.py:102] Training  [ 5530/12500]  eta: 0:26:08  loss: 27.0193 (30.0391)  lr: 0.0000 (0.0000)  time: 0.198015  data: 0.000454  max mem: 3586
I20250120 12:36:48 3554128 dinov2 helpers.py:102] Training  [ 5540/12500]  eta: 0:26:06  loss: 28.3051 (30.0373)  lr: 0.0000 (0.0000)  time: 0.197921  data: 0.000453  max mem: 3586
I20250120 12:36:50 3554128 dinov2 helpers.py:102] Training  [ 5550/12500]  eta: 0:26:03  loss: 28.3051 (30.0405)  lr: 0.0000 (0.0000)  time: 0.197899  data: 0.000433  max mem: 3586
I20250120 12:36:52 3554128 dinov2 helpers.py:102] Training  [ 5560/12500]  eta: 0:26:01  loss: 27.0193 (30.0317)  lr: 0.0000 (0.0000)  time: 0.197956  data: 0.000449  max mem: 3586
I20250120 12:36:54 3554128 dinov2 helpers.py:102] Training  [ 5570/12500]  eta: 0:25:58  loss: 27.0193 (30.0342)  lr: 0.0000 (0.0000)  time: 0.197929  data: 0.000453  max mem: 3586
I20250120 12:36:56 3554128 dinov2 helpers.py:102] Training  [ 5580/12500]  eta: 0:25:55  loss: 27.0193 (30.0317)  lr: 0.0000 (0.0000)  time: 0.197954  data: 0.000468  max mem: 3586
I20250120 12:36:58 3554128 dinov2 helpers.py:102] Training  [ 5590/12500]  eta: 0:25:53  loss: 26.5828 (30.0255)  lr: 0.0000 (0.0000)  time: 0.197991  data: 0.000464  max mem: 3586
I20250120 12:37:00 3554128 dinov2 helpers.py:102] Training  [ 5600/12500]  eta: 0:25:50  loss: 26.5828 (30.0255)  lr: 0.0000 (0.0000)  time: 0.197880  data: 0.000421  max mem: 3586
I20250120 12:37:02 3554128 dinov2 helpers.py:102] Training  [ 5610/12500]  eta: 0:25:48  loss: 27.0193 (30.0223)  lr: 0.0000 (0.0000)  time: 0.197872  data: 0.000403  max mem: 3586
I20250120 12:37:04 3554128 dinov2 helpers.py:102] Training  [ 5620/12500]  eta: 0:25:45  loss: 26.5828 (30.0135)  lr: 0.0000 (0.0000)  time: 0.197764  data: 0.000391  max mem: 3586
I20250120 12:37:06 3554128 dinov2 helpers.py:102] Training  [ 5630/12500]  eta: 0:25:43  loss: 26.5828 (30.0059)  lr: 0.0000 (0.0000)  time: 0.197810  data: 0.000395  max mem: 3586
I20250120 12:37:08 3554128 dinov2 helpers.py:102] Training  [ 5640/12500]  eta: 0:25:40  loss: 26.5828 (29.9970)  lr: 0.0000 (0.0000)  time: 0.198123  data: 0.000463  max mem: 3586
I20250120 12:37:10 3554128 dinov2 helpers.py:102] Training  [ 5650/12500]  eta: 0:25:37  loss: 26.3940 (29.9906)  lr: 0.0000 (0.0000)  time: 0.198139  data: 0.000456  max mem: 3586
I20250120 12:37:12 3554128 dinov2 helpers.py:102] Training  [ 5660/12500]  eta: 0:25:35  loss: 26.5828 (29.9863)  lr: 0.0000 (0.0000)  time: 0.198095  data: 0.000412  max mem: 3586
I20250120 12:37:14 3554128 dinov2 helpers.py:102] Training  [ 5670/12500]  eta: 0:25:32  loss: 26.3940 (29.9663)  lr: 0.0000 (0.0000)  time: 0.198148  data: 0.000402  max mem: 3586
I20250120 12:37:16 3554128 dinov2 helpers.py:102] Training  [ 5680/12500]  eta: 0:25:30  loss: 26.5828 (29.9618)  lr: 0.0000 (0.0000)  time: 0.198125  data: 0.000416  max mem: 3586
I20250120 12:37:18 3554128 dinov2 helpers.py:102] Training  [ 5690/12500]  eta: 0:25:27  loss: 26.5828 (29.9545)  lr: 0.0000 (0.0000)  time: 0.198117  data: 0.000445  max mem: 3586
I20250120 12:37:20 3554128 dinov2 helpers.py:102] Training  [ 5700/12500]  eta: 0:25:25  loss: 26.5828 (29.9522)  lr: 0.0000 (0.0000)  time: 0.198069  data: 0.000461  max mem: 3586
I20250120 12:37:22 3554128 dinov2 helpers.py:102] Training  [ 5710/12500]  eta: 0:25:22  loss: 27.0193 (29.9492)  lr: 0.0000 (0.0000)  time: 0.197927  data: 0.000411  max mem: 3586
I20250120 12:37:24 3554128 dinov2 helpers.py:102] Training  [ 5720/12500]  eta: 0:25:19  loss: 27.0193 (29.9440)  lr: 0.0000 (0.0000)  time: 0.197946  data: 0.000398  max mem: 3586
I20250120 12:37:26 3554128 dinov2 helpers.py:102] Training  [ 5730/12500]  eta: 0:25:17  loss: 27.3906 (29.9424)  lr: 0.0000 (0.0000)  time: 0.198129  data: 0.000457  max mem: 3586
I20250120 12:37:28 3554128 dinov2 helpers.py:102] Training  [ 5740/12500]  eta: 0:25:14  loss: 26.9820 (29.9356)  lr: 0.0000 (0.0000)  time: 0.198321  data: 0.000451  max mem: 3586
I20250120 12:37:30 3554128 dinov2 helpers.py:102] Training  [ 5750/12500]  eta: 0:25:12  loss: 26.9820 (29.9343)  lr: 0.0000 (0.0000)  time: 0.198379  data: 0.000396  max mem: 3586
I20250120 12:37:32 3554128 dinov2 helpers.py:102] Training  [ 5760/12500]  eta: 0:25:09  loss: 27.3906 (29.9375)  lr: 0.0000 (0.0000)  time: 0.198355  data: 0.000416  max mem: 3586
I20250120 12:37:34 3554128 dinov2 helpers.py:102] Training  [ 5770/12500]  eta: 0:25:07  loss: 26.9820 (29.9297)  lr: 0.0000 (0.0000)  time: 0.198132  data: 0.000474  max mem: 3586
I20250120 12:37:36 3554128 dinov2 helpers.py:102] Training  [ 5780/12500]  eta: 0:25:04  loss: 26.5828 (29.9236)  lr: 0.0000 (0.0000)  time: 0.198067  data: 0.000487  max mem: 3586
I20250120 12:37:38 3554128 dinov2 helpers.py:102] Training  [ 5790/12500]  eta: 0:25:02  loss: 26.3940 (29.9123)  lr: 0.0000 (0.0000)  time: 0.198296  data: 0.000493  max mem: 3586
I20250120 12:37:40 3554128 dinov2 helpers.py:102] Training  [ 5800/12500]  eta: 0:24:59  loss: 26.3940 (29.9131)  lr: 0.0000 (0.0000)  time: 0.198427  data: 0.000455  max mem: 3586
I20250120 12:37:42 3554128 dinov2 helpers.py:102] Training  [ 5810/12500]  eta: 0:24:57  loss: 26.3940 (29.9101)  lr: 0.0000 (0.0000)  time: 0.198412  data: 0.000428  max mem: 3586
I20250120 12:37:44 3554128 dinov2 helpers.py:102] Training  [ 5820/12500]  eta: 0:24:54  loss: 26.3940 (29.8956)  lr: 0.0000 (0.0000)  time: 0.198281  data: 0.000452  max mem: 3586
I20250120 12:37:46 3554128 dinov2 helpers.py:102] Training  [ 5830/12500]  eta: 0:24:52  loss: 26.3940 (29.8819)  lr: 0.0000 (0.0000)  time: 0.198324  data: 0.000438  max mem: 3586
I20250120 12:37:48 3554128 dinov2 helpers.py:102] Training  [ 5840/12500]  eta: 0:24:49  loss: 26.3940 (29.8755)  lr: 0.0000 (0.0000)  time: 0.198433  data: 0.000447  max mem: 3586
I20250120 12:37:50 3554128 dinov2 helpers.py:102] Training  [ 5850/12500]  eta: 0:24:46  loss: 26.3913 (29.8690)  lr: 0.0000 (0.0000)  time: 0.198401  data: 0.000457  max mem: 3586
I20250120 12:37:52 3554128 dinov2 helpers.py:102] Training  [ 5860/12500]  eta: 0:24:44  loss: 26.1518 (29.8574)  lr: 0.0000 (0.0000)  time: 0.198359  data: 0.000453  max mem: 3586
I20250120 12:37:54 3554128 dinov2 helpers.py:102] Training  [ 5870/12500]  eta: 0:24:41  loss: 26.3913 (29.8533)  lr: 0.0000 (0.0000)  time: 0.198453  data: 0.000448  max mem: 3586
I20250120 12:37:56 3554128 dinov2 helpers.py:102] Training  [ 5880/12500]  eta: 0:24:39  loss: 26.3913 (29.8545)  lr: 0.0000 (0.0000)  time: 0.198436  data: 0.000440  max mem: 3586
I20250120 12:37:58 3554128 dinov2 helpers.py:102] Training  [ 5890/12500]  eta: 0:24:36  loss: 26.3913 (29.8477)  lr: 0.0000 (0.0000)  time: 0.198335  data: 0.000509  max mem: 3586
I20250120 12:38:00 3554128 dinov2 helpers.py:102] Training  [ 5900/12500]  eta: 0:24:34  loss: 26.3913 (29.8470)  lr: 0.0000 (0.0000)  time: 0.198413  data: 0.000499  max mem: 3586
I20250120 12:38:02 3554128 dinov2 helpers.py:102] Training  [ 5910/12500]  eta: 0:24:31  loss: 26.1518 (29.8382)  lr: 0.0000 (0.0000)  time: 0.198465  data: 0.000435  max mem: 3586
I20250120 12:38:04 3554128 dinov2 helpers.py:102] Training  [ 5920/12500]  eta: 0:24:29  loss: 26.0430 (29.8228)  lr: 0.0000 (0.0000)  time: 0.198415  data: 0.000403  max mem: 3586
I20250120 12:38:06 3554128 dinov2 helpers.py:102] Training  [ 5930/12500]  eta: 0:24:26  loss: 26.0410 (29.8132)  lr: 0.0000 (0.0000)  time: 0.198296  data: 0.000421  max mem: 3586
I20250120 12:38:08 3554128 dinov2 helpers.py:102] Training  [ 5940/12500]  eta: 0:24:24  loss: 25.8438 (29.8038)  lr: 0.0000 (0.0000)  time: 0.198293  data: 0.000441  max mem: 3586
I20250120 12:38:10 3554128 dinov2 helpers.py:102] Training  [ 5950/12500]  eta: 0:24:21  loss: 25.4057 (29.7937)  lr: 0.0000 (0.0000)  time: 0.198218  data: 0.000434  max mem: 3586
I20250120 12:38:12 3554128 dinov2 helpers.py:102] Training  [ 5960/12500]  eta: 0:24:19  loss: 24.9119 (29.7855)  lr: 0.0000 (0.0000)  time: 0.198031  data: 0.000422  max mem: 3586
I20250120 12:38:14 3554128 dinov2 helpers.py:102] Training  [ 5970/12500]  eta: 0:24:16  loss: 24.6252 (29.7725)  lr: 0.0000 (0.0000)  time: 0.198047  data: 0.000456  max mem: 3586
I20250120 12:38:16 3554128 dinov2 helpers.py:102] Training  [ 5980/12500]  eta: 0:24:14  loss: 24.6252 (29.7769)  lr: 0.0000 (0.0000)  time: 0.198120  data: 0.000488  max mem: 3586
I20250120 12:38:18 3554128 dinov2 helpers.py:102] Training  [ 5990/12500]  eta: 0:24:11  loss: 24.9119 (29.7736)  lr: 0.0000 (0.0000)  time: 0.198067  data: 0.000490  max mem: 3586
I20250120 12:38:20 3554128 dinov2 helpers.py:102] Training  [ 6000/12500]  eta: 0:24:09  loss: 24.6252 (29.7627)  lr: 0.0000 (0.0000)  time: 0.197898  data: 0.000434  max mem: 3586
I20250120 12:38:22 3554128 dinov2 helpers.py:102] Training  [ 6010/12500]  eta: 0:24:06  loss: 24.6252 (29.7569)  lr: 0.0000 (0.0000)  time: 0.197921  data: 0.000408  max mem: 3586
I20250120 12:38:24 3554128 dinov2 helpers.py:102] Training  [ 6020/12500]  eta: 0:24:04  loss: 24.9119 (29.7499)  lr: 0.0000 (0.0000)  time: 0.197984  data: 0.000423  max mem: 3586
I20250120 12:38:26 3554128 dinov2 helpers.py:102] Training  [ 6030/12500]  eta: 0:24:01  loss: 25.5429 (29.7498)  lr: 0.0000 (0.0000)  time: 0.197918  data: 0.000407  max mem: 3586
I20250120 12:38:28 3554128 dinov2 helpers.py:102] Training  [ 6040/12500]  eta: 0:23:59  loss: 25.2287 (29.7424)  lr: 0.0000 (0.0000)  time: 0.198005  data: 0.000462  max mem: 3586
I20250120 12:38:30 3554128 dinov2 helpers.py:102] Training  [ 6050/12500]  eta: 0:23:56  loss: 25.2287 (29.7397)  lr: 0.0000 (0.0000)  time: 0.198180  data: 0.000487  max mem: 3586
I20250120 12:38:32 3554128 dinov2 helpers.py:102] Training  [ 6060/12500]  eta: 0:23:54  loss: 25.5166 (29.7328)  lr: 0.0000 (0.0000)  time: 0.198389  data: 0.000454  max mem: 3586
I20250120 12:38:34 3554128 dinov2 helpers.py:102] Training  [ 6070/12500]  eta: 0:23:51  loss: 25.2287 (29.7247)  lr: 0.0000 (0.0000)  time: 0.198538  data: 0.000419  max mem: 3586
I20250120 12:38:36 3554128 dinov2 helpers.py:102] Training  [ 6080/12500]  eta: 0:23:49  loss: 24.9119 (29.7125)  lr: 0.0000 (0.0000)  time: 0.198363  data: 0.000455  max mem: 3586
I20250120 12:38:37 3554128 dinov2 helpers.py:102] Training  [ 6090/12500]  eta: 0:23:46  loss: 24.9119 (29.7065)  lr: 0.0000 (0.0000)  time: 0.198218  data: 0.000510  max mem: 3586
I20250120 12:38:39 3554128 dinov2 helpers.py:102] Training  [ 6100/12500]  eta: 0:23:44  loss: 24.9119 (29.7032)  lr: 0.0000 (0.0000)  time: 0.198247  data: 0.000487  max mem: 3586
I20250120 12:38:41 3554128 dinov2 helpers.py:102] Training  [ 6110/12500]  eta: 0:23:41  loss: 24.9119 (29.6925)  lr: 0.0000 (0.0000)  time: 0.198226  data: 0.000454  max mem: 3586
I20250120 12:38:43 3554128 dinov2 helpers.py:102] Training  [ 6120/12500]  eta: 0:23:39  loss: 24.9119 (29.6810)  lr: 0.0000 (0.0000)  time: 0.198177  data: 0.000434  max mem: 3586
I20250120 12:38:45 3554128 dinov2 helpers.py:102] Training  [ 6130/12500]  eta: 0:23:36  loss: 25.2287 (29.6762)  lr: 0.0000 (0.0000)  time: 0.198192  data: 0.000431  max mem: 3586
I20250120 12:38:47 3554128 dinov2 helpers.py:102] Training  [ 6140/12500]  eta: 0:23:34  loss: 25.5166 (29.6725)  lr: 0.0000 (0.0000)  time: 0.198239  data: 0.000457  max mem: 3586
I20250120 12:38:49 3554128 dinov2 helpers.py:102] Training  [ 6150/12500]  eta: 0:23:32  loss: 25.5429 (29.6661)  lr: 0.0000 (0.0000)  time: 0.198272  data: 0.000468  max mem: 3586
I20250120 12:38:51 3554128 dinov2 helpers.py:102] Training  [ 6160/12500]  eta: 0:23:29  loss: 25.7311 (29.6642)  lr: 0.0000 (0.0000)  time: 0.198255  data: 0.000428  max mem: 3586
I20250120 12:38:53 3554128 dinov2 helpers.py:102] Training  [ 6170/12500]  eta: 0:23:27  loss: 25.7311 (29.6546)  lr: 0.0000 (0.0000)  time: 0.198284  data: 0.000432  max mem: 3586
I20250120 12:38:55 3554128 dinov2 helpers.py:102] Training  [ 6180/12500]  eta: 0:23:24  loss: 25.7311 (29.6521)  lr: 0.0000 (0.0000)  time: 0.198268  data: 0.000472  max mem: 3586
I20250120 12:38:57 3554128 dinov2 helpers.py:102] Training  [ 6190/12500]  eta: 0:23:22  loss: 25.5429 (29.6420)  lr: 0.0000 (0.0000)  time: 0.198109  data: 0.000491  max mem: 3586
I20250120 12:38:59 3554128 dinov2 helpers.py:102] Training  [ 6200/12500]  eta: 0:23:19  loss: 25.7311 (29.6365)  lr: 0.0000 (0.0000)  time: 0.198025  data: 0.000512  max mem: 3586
I20250120 12:39:01 3554128 dinov2 helpers.py:102] Training  [ 6210/12500]  eta: 0:23:17  loss: 25.7311 (29.6316)  lr: 0.0000 (0.0000)  time: 0.198247  data: 0.000460  max mem: 3586
I20250120 12:39:03 3554128 dinov2 helpers.py:102] Training  [ 6220/12500]  eta: 0:23:14  loss: 25.7311 (29.6230)  lr: 0.0000 (0.0000)  time: 0.198223  data: 0.000421  max mem: 3586
I20250120 12:39:05 3554128 dinov2 helpers.py:102] Training  [ 6230/12500]  eta: 0:23:12  loss: 25.5166 (29.6145)  lr: 0.0000 (0.0000)  time: 0.197789  data: 0.000474  max mem: 3586
I20250120 12:39:07 3554128 dinov2 helpers.py:102] Training  [ 6240/12500]  eta: 0:23:09  loss: 25.5166 (29.6067)  lr: 0.0000 (0.0000)  time: 0.197778  data: 0.000523  max mem: 3586
I20250120 12:39:09 3554128 dinov2 linear.py:272] running validation !
I20250120 12:39:11 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:04    time: 1.576700  data: 1.381821  max mem: 3586
I20250120 12:39:13 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.330474  data: 0.126319  max mem: 3586
I20250120 12:39:15 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.203692  data: 0.000956  max mem: 3586
I20250120 12:39:17 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.200710  data: 0.000678  max mem: 3586
I20250120 12:39:19 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.200063  data: 0.000201  max mem: 3586
I20250120 12:39:21 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.200094  data: 0.000210  max mem: 3586
I20250120 12:39:23 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.199950  data: 0.000248  max mem: 3586
I20250120 12:39:25 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199695  data: 0.000243  max mem: 3586
I20250120 12:39:27 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199820  data: 0.000234  max mem: 3586
I20250120 12:39:29 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.200154  data: 0.000247  max mem: 3586
I20250120 12:39:31 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199915  data: 0.000228  max mem: 3586
I20250120 12:39:33 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199588  data: 0.000253  max mem: 3586
I20250120 12:39:35 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199916  data: 0.000298  max mem: 3586
I20250120 12:39:37 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.200059  data: 0.000340  max mem: 3586
I20250120 12:39:39 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199676  data: 0.000327  max mem: 3586
I20250120 12:39:41 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199686  data: 0.000201  max mem: 3586
I20250120 12:39:41 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195839  data: 0.000178  max mem: 3586
I20250120 12:39:42 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.209622 s / it)
I20250120 12:39:42 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:39:42 3554128 dinov2 linear.py:287] 
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7868, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8023, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8080, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8119, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8169, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8205, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8221, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8238, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8215, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8189, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8026, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8061, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7890, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8052, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8104, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8146, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8216, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8243, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8252, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8271, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8232, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8328, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8211, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7970, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8097, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8151, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8191, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8222, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8249, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8249, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8189, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8226, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8080, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7749, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7554, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8086, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8135, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8220, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8238, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8275, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8280, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8275, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8310, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8194, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7868, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7592, device='cuda:0')}
I20250120 12:39:42 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_01000', 'accuracy': 0.8328112363815308}
I20250120 12:39:42 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:39:42 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:39:42 3554128 dinov2 helpers.py:102] Training  [ 6250/12500]  eta: 0:23:39  loss: 25.5166 (29.6021)  lr: 0.0000 (0.0000)  time: 1.827024  data: 0.000482  max mem: 3586
I20250120 12:39:44 3554128 dinov2 helpers.py:102] Training  [ 6260/12500]  eta: 0:23:37  loss: 25.0106 (29.5948)  lr: 0.0000 (0.0000)  time: 1.826082  data: 0.000400  max mem: 3586
I20250120 12:39:46 3554128 dinov2 helpers.py:102] Training  [ 6270/12500]  eta: 0:23:34  loss: 25.7311 (29.5935)  lr: 0.0000 (0.0000)  time: 0.196817  data: 0.000431  max mem: 3586
I20250120 12:39:48 3554128 dinov2 helpers.py:102] Training  [ 6280/12500]  eta: 0:23:32  loss: 26.0453 (29.5934)  lr: 0.0000 (0.0000)  time: 0.197649  data: 0.000485  max mem: 3586
I20250120 12:39:50 3554128 dinov2 helpers.py:102] Training  [ 6290/12500]  eta: 0:23:29  loss: 25.7311 (29.5858)  lr: 0.0000 (0.0000)  time: 0.197712  data: 0.000469  max mem: 3586
I20250120 12:39:52 3554128 dinov2 helpers.py:102] Training  [ 6300/12500]  eta: 0:23:27  loss: 25.0106 (29.5764)  lr: 0.0000 (0.0000)  time: 0.197583  data: 0.000472  max mem: 3586
I20250120 12:39:54 3554128 dinov2 helpers.py:102] Training  [ 6310/12500]  eta: 0:23:24  loss: 25.7311 (29.5704)  lr: 0.0000 (0.0000)  time: 0.197436  data: 0.000460  max mem: 3586
I20250120 12:39:56 3554128 dinov2 helpers.py:102] Training  [ 6320/12500]  eta: 0:23:22  loss: 25.7643 (29.5683)  lr: 0.0000 (0.0000)  time: 0.221474  data: 0.028425  max mem: 3586
I20250120 12:39:58 3554128 dinov2 helpers.py:102] Training  [ 6330/12500]  eta: 0:23:19  loss: 25.7311 (29.5600)  lr: 0.0000 (0.0000)  time: 0.221528  data: 0.028437  max mem: 3586
I20250120 12:40:00 3554128 dinov2 helpers.py:102] Training  [ 6340/12500]  eta: 0:23:17  loss: 25.7311 (29.5555)  lr: 0.0000 (0.0000)  time: 0.197562  data: 0.000461  max mem: 3586
I20250120 12:40:02 3554128 dinov2 helpers.py:102] Training  [ 6350/12500]  eta: 0:23:14  loss: 25.4555 (29.5490)  lr: 0.0000 (0.0000)  time: 0.197527  data: 0.000477  max mem: 3586
I20250120 12:40:04 3554128 dinov2 helpers.py:102] Training  [ 6360/12500]  eta: 0:23:12  loss: 25.0106 (29.5411)  lr: 0.0000 (0.0000)  time: 0.197398  data: 0.000490  max mem: 3586
I20250120 12:40:06 3554128 dinov2 helpers.py:102] Training  [ 6370/12500]  eta: 0:23:09  loss: 25.4555 (29.5386)  lr: 0.0000 (0.0000)  time: 0.197496  data: 0.000463  max mem: 3586
I20250120 12:40:08 3554128 dinov2 helpers.py:102] Training  [ 6380/12500]  eta: 0:23:07  loss: 25.4555 (29.5345)  lr: 0.0000 (0.0000)  time: 0.197796  data: 0.000474  max mem: 3586
I20250120 12:40:10 3554128 dinov2 helpers.py:102] Training  [ 6390/12500]  eta: 0:23:04  loss: 25.7643 (29.5324)  lr: 0.0000 (0.0000)  time: 0.197845  data: 0.000487  max mem: 3586
I20250120 12:40:12 3554128 dinov2 helpers.py:102] Training  [ 6400/12500]  eta: 0:23:02  loss: 25.7643 (29.5282)  lr: 0.0000 (0.0000)  time: 0.197857  data: 0.000447  max mem: 3586
I20250120 12:40:14 3554128 dinov2 helpers.py:102] Training  [ 6410/12500]  eta: 0:22:59  loss: 25.7643 (29.5332)  lr: 0.0000 (0.0000)  time: 0.197798  data: 0.000450  max mem: 3586
I20250120 12:40:16 3554128 dinov2 helpers.py:102] Training  [ 6420/12500]  eta: 0:22:57  loss: 26.6942 (29.5335)  lr: 0.0000 (0.0000)  time: 0.197574  data: 0.000489  max mem: 3586
I20250120 12:40:18 3554128 dinov2 helpers.py:102] Training  [ 6430/12500]  eta: 0:22:54  loss: 26.6942 (29.5283)  lr: 0.0000 (0.0000)  time: 0.197570  data: 0.000430  max mem: 3586
I20250120 12:40:20 3554128 dinov2 helpers.py:102] Training  [ 6440/12500]  eta: 0:22:51  loss: 26.7659 (29.5273)  lr: 0.0000 (0.0000)  time: 0.197818  data: 0.000427  max mem: 3586
I20250120 12:40:22 3554128 dinov2 helpers.py:102] Training  [ 6450/12500]  eta: 0:22:49  loss: 26.6956 (29.5229)  lr: 0.0000 (0.0000)  time: 0.197967  data: 0.000457  max mem: 3586
I20250120 12:40:24 3554128 dinov2 helpers.py:102] Training  [ 6460/12500]  eta: 0:22:46  loss: 26.6956 (29.5159)  lr: 0.0000 (0.0000)  time: 0.197927  data: 0.000456  max mem: 3586
I20250120 12:40:26 3554128 dinov2 helpers.py:102] Training  [ 6470/12500]  eta: 0:22:44  loss: 26.6942 (29.5058)  lr: 0.0000 (0.0000)  time: 0.197908  data: 0.000477  max mem: 3586
I20250120 12:40:28 3554128 dinov2 helpers.py:102] Training  [ 6480/12500]  eta: 0:22:41  loss: 26.2120 (29.4940)  lr: 0.0000 (0.0000)  time: 0.197884  data: 0.000446  max mem: 3586
I20250120 12:40:30 3554128 dinov2 helpers.py:102] Training  [ 6490/12500]  eta: 0:22:39  loss: 26.2120 (29.4867)  lr: 0.0000 (0.0000)  time: 0.198048  data: 0.000457  max mem: 3586
I20250120 12:40:32 3554128 dinov2 helpers.py:102] Training  [ 6500/12500]  eta: 0:22:36  loss: 26.2120 (29.4804)  lr: 0.0000 (0.0000)  time: 0.198063  data: 0.000475  max mem: 3586
I20250120 12:40:34 3554128 dinov2 helpers.py:102] Training  [ 6510/12500]  eta: 0:22:34  loss: 26.6942 (29.4766)  lr: 0.0000 (0.0000)  time: 0.197935  data: 0.000457  max mem: 3586
I20250120 12:40:36 3554128 dinov2 helpers.py:102] Training  [ 6520/12500]  eta: 0:22:31  loss: 26.3400 (29.4718)  lr: 0.0000 (0.0000)  time: 0.197998  data: 0.000430  max mem: 3586
I20250120 12:40:38 3554128 dinov2 helpers.py:102] Training  [ 6530/12500]  eta: 0:22:29  loss: 26.6942 (29.4694)  lr: 0.0000 (0.0000)  time: 0.197977  data: 0.000455  max mem: 3586
I20250120 12:40:40 3554128 dinov2 helpers.py:102] Training  [ 6540/12500]  eta: 0:22:26  loss: 26.3445 (29.4646)  lr: 0.0000 (0.0000)  time: 0.197816  data: 0.000453  max mem: 3586
I20250120 12:40:42 3554128 dinov2 helpers.py:102] Training  [ 6550/12500]  eta: 0:22:24  loss: 26.6956 (29.4623)  lr: 0.0000 (0.0000)  time: 0.197863  data: 0.000492  max mem: 3586
I20250120 12:40:44 3554128 dinov2 helpers.py:102] Training  [ 6560/12500]  eta: 0:22:21  loss: 26.6956 (29.4515)  lr: 0.0000 (0.0000)  time: 0.198064  data: 0.000503  max mem: 3586
I20250120 12:40:46 3554128 dinov2 helpers.py:102] Training  [ 6570/12500]  eta: 0:22:19  loss: 26.6956 (29.4513)  lr: 0.0000 (0.0000)  time: 0.198205  data: 0.000425  max mem: 3586
I20250120 12:40:48 3554128 dinov2 helpers.py:102] Training  [ 6580/12500]  eta: 0:22:16  loss: 26.5587 (29.4470)  lr: 0.0000 (0.0000)  time: 0.198143  data: 0.000426  max mem: 3586
I20250120 12:40:50 3554128 dinov2 helpers.py:102] Training  [ 6590/12500]  eta: 0:22:14  loss: 26.3445 (29.4363)  lr: 0.0000 (0.0000)  time: 0.197971  data: 0.000491  max mem: 3586
I20250120 12:40:52 3554128 dinov2 helpers.py:102] Training  [ 6600/12500]  eta: 0:22:11  loss: 26.3400 (29.4313)  lr: 0.0000 (0.0000)  time: 0.197852  data: 0.000479  max mem: 3586
I20250120 12:40:53 3554128 dinov2 helpers.py:102] Training  [ 6610/12500]  eta: 0:22:09  loss: 26.2120 (29.4220)  lr: 0.0000 (0.0000)  time: 0.197889  data: 0.000410  max mem: 3586
I20250120 12:40:55 3554128 dinov2 helpers.py:102] Training  [ 6620/12500]  eta: 0:22:06  loss: 26.2120 (29.4181)  lr: 0.0000 (0.0000)  time: 0.198005  data: 0.000407  max mem: 3586
I20250120 12:40:57 3554128 dinov2 helpers.py:102] Training  [ 6630/12500]  eta: 0:22:04  loss: 26.1548 (29.4117)  lr: 0.0000 (0.0000)  time: 0.197954  data: 0.000430  max mem: 3586
I20250120 12:40:59 3554128 dinov2 helpers.py:102] Training  [ 6640/12500]  eta: 0:22:01  loss: 25.3948 (29.4001)  lr: 0.0000 (0.0000)  time: 0.197899  data: 0.000471  max mem: 3586
I20250120 12:41:01 3554128 dinov2 helpers.py:102] Training  [ 6650/12500]  eta: 0:21:59  loss: 25.1581 (29.3901)  lr: 0.0000 (0.0000)  time: 0.197919  data: 0.000460  max mem: 3586
I20250120 12:41:03 3554128 dinov2 helpers.py:102] Training  [ 6660/12500]  eta: 0:21:56  loss: 25.1581 (29.3835)  lr: 0.0000 (0.0000)  time: 0.197991  data: 0.000425  max mem: 3586
I20250120 12:41:05 3554128 dinov2 helpers.py:102] Training  [ 6670/12500]  eta: 0:21:54  loss: 25.1581 (29.3730)  lr: 0.0000 (0.0000)  time: 0.197940  data: 0.000396  max mem: 3586
I20250120 12:41:07 3554128 dinov2 helpers.py:102] Training  [ 6680/12500]  eta: 0:21:51  loss: 25.1581 (29.3646)  lr: 0.0000 (0.0000)  time: 0.197876  data: 0.000393  max mem: 3586
I20250120 12:41:09 3554128 dinov2 helpers.py:102] Training  [ 6690/12500]  eta: 0:21:49  loss: 25.3948 (29.3588)  lr: 0.0000 (0.0000)  time: 0.197826  data: 0.000457  max mem: 3586
I20250120 12:41:11 3554128 dinov2 helpers.py:102] Training  [ 6700/12500]  eta: 0:21:46  loss: 25.1581 (29.3493)  lr: 0.0000 (0.0000)  time: 0.197929  data: 0.000510  max mem: 3586
I20250120 12:41:13 3554128 dinov2 helpers.py:102] Training  [ 6710/12500]  eta: 0:21:44  loss: 24.9719 (29.3390)  lr: 0.0000 (0.0000)  time: 0.198232  data: 0.000470  max mem: 3586
I20250120 12:41:15 3554128 dinov2 helpers.py:102] Training  [ 6720/12500]  eta: 0:21:41  loss: 23.7945 (29.3282)  lr: 0.0000 (0.0000)  time: 0.198281  data: 0.000440  max mem: 3586
I20250120 12:41:17 3554128 dinov2 helpers.py:102] Training  [ 6730/12500]  eta: 0:21:39  loss: 23.7945 (29.3260)  lr: 0.0000 (0.0000)  time: 0.197997  data: 0.000477  max mem: 3586
I20250120 12:41:19 3554128 dinov2 helpers.py:102] Training  [ 6740/12500]  eta: 0:21:36  loss: 23.7836 (29.3178)  lr: 0.0000 (0.0000)  time: 0.197653  data: 0.000471  max mem: 3586
I20250120 12:41:21 3554128 dinov2 helpers.py:102] Training  [ 6750/12500]  eta: 0:21:34  loss: 23.7836 (29.3125)  lr: 0.0000 (0.0000)  time: 0.197773  data: 0.000457  max mem: 3586
I20250120 12:41:23 3554128 dinov2 helpers.py:102] Training  [ 6760/12500]  eta: 0:21:31  loss: 23.7945 (29.3071)  lr: 0.0000 (0.0000)  time: 0.198083  data: 0.000497  max mem: 3586
I20250120 12:41:25 3554128 dinov2 helpers.py:102] Training  [ 6770/12500]  eta: 0:21:29  loss: 23.7836 (29.2965)  lr: 0.0000 (0.0000)  time: 0.198030  data: 0.000486  max mem: 3586
I20250120 12:41:27 3554128 dinov2 helpers.py:102] Training  [ 6780/12500]  eta: 0:21:26  loss: 23.2466 (29.2856)  lr: 0.0000 (0.0000)  time: 0.197743  data: 0.000481  max mem: 3586
I20250120 12:41:29 3554128 dinov2 helpers.py:102] Training  [ 6790/12500]  eta: 0:21:24  loss: 23.7270 (29.2775)  lr: 0.0000 (0.0000)  time: 0.197642  data: 0.000497  max mem: 3586
I20250120 12:41:31 3554128 dinov2 helpers.py:102] Training  [ 6800/12500]  eta: 0:21:21  loss: 23.7270 (29.2784)  lr: 0.0000 (0.0000)  time: 0.197810  data: 0.000490  max mem: 3586
I20250120 12:41:33 3554128 dinov2 helpers.py:102] Training  [ 6810/12500]  eta: 0:21:19  loss: 23.7836 (29.2748)  lr: 0.0000 (0.0000)  time: 0.197794  data: 0.000495  max mem: 3586
I20250120 12:41:35 3554128 dinov2 helpers.py:102] Training  [ 6820/12500]  eta: 0:21:16  loss: 23.7836 (29.2669)  lr: 0.0000 (0.0000)  time: 0.197791  data: 0.000475  max mem: 3586
I20250120 12:41:37 3554128 dinov2 helpers.py:102] Training  [ 6830/12500]  eta: 0:21:14  loss: 23.7270 (29.2588)  lr: 0.0000 (0.0000)  time: 0.197952  data: 0.000470  max mem: 3586
I20250120 12:41:39 3554128 dinov2 helpers.py:102] Training  [ 6840/12500]  eta: 0:21:11  loss: 23.7836 (29.2576)  lr: 0.0000 (0.0000)  time: 0.197788  data: 0.000429  max mem: 3586
I20250120 12:41:41 3554128 dinov2 helpers.py:102] Training  [ 6850/12500]  eta: 0:21:09  loss: 23.7836 (29.2487)  lr: 0.0000 (0.0000)  time: 0.197777  data: 0.000415  max mem: 3586
I20250120 12:41:43 3554128 dinov2 helpers.py:102] Training  [ 6860/12500]  eta: 0:21:07  loss: 23.7836 (29.2418)  lr: 0.0000 (0.0000)  time: 0.197857  data: 0.000443  max mem: 3586
I20250120 12:41:45 3554128 dinov2 helpers.py:102] Training  [ 6870/12500]  eta: 0:21:04  loss: 23.7836 (29.2323)  lr: 0.0000 (0.0000)  time: 0.197798  data: 0.000446  max mem: 3586
I20250120 12:41:47 3554128 dinov2 helpers.py:102] Training  [ 6880/12500]  eta: 0:21:02  loss: 23.7836 (29.2279)  lr: 0.0000 (0.0000)  time: 0.198094  data: 0.000460  max mem: 3586
I20250120 12:41:49 3554128 dinov2 helpers.py:102] Training  [ 6890/12500]  eta: 0:20:59  loss: 23.7836 (29.2243)  lr: 0.0000 (0.0000)  time: 0.197996  data: 0.000456  max mem: 3586
I20250120 12:41:51 3554128 dinov2 helpers.py:102] Training  [ 6900/12500]  eta: 0:20:57  loss: 23.7836 (29.2132)  lr: 0.0000 (0.0000)  time: 0.197840  data: 0.000464  max mem: 3586
I20250120 12:41:53 3554128 dinov2 helpers.py:102] Training  [ 6910/12500]  eta: 0:20:54  loss: 23.7836 (29.2036)  lr: 0.0000 (0.0000)  time: 0.197964  data: 0.000478  max mem: 3586
I20250120 12:41:55 3554128 dinov2 helpers.py:102] Training  [ 6920/12500]  eta: 0:20:52  loss: 23.9314 (29.2046)  lr: 0.0000 (0.0000)  time: 0.198014  data: 0.000475  max mem: 3586
I20250120 12:41:57 3554128 dinov2 helpers.py:102] Training  [ 6930/12500]  eta: 0:20:49  loss: 23.9314 (29.2002)  lr: 0.0000 (0.0000)  time: 0.197869  data: 0.000424  max mem: 3586
I20250120 12:41:59 3554128 dinov2 helpers.py:102] Training  [ 6940/12500]  eta: 0:20:47  loss: 23.9314 (29.1901)  lr: 0.0000 (0.0000)  time: 0.197729  data: 0.000427  max mem: 3586
I20250120 12:42:01 3554128 dinov2 helpers.py:102] Training  [ 6950/12500]  eta: 0:20:44  loss: 23.8831 (29.1825)  lr: 0.0000 (0.0000)  time: 0.197787  data: 0.000451  max mem: 3586
I20250120 12:42:03 3554128 dinov2 helpers.py:102] Training  [ 6960/12500]  eta: 0:20:42  loss: 23.8831 (29.1764)  lr: 0.0000 (0.0000)  time: 0.197694  data: 0.000470  max mem: 3586
I20250120 12:42:05 3554128 dinov2 helpers.py:102] Training  [ 6970/12500]  eta: 0:20:39  loss: 23.9314 (29.1690)  lr: 0.0000 (0.0000)  time: 0.197770  data: 0.000480  max mem: 3586
I20250120 12:42:07 3554128 dinov2 helpers.py:102] Training  [ 6980/12500]  eta: 0:20:37  loss: 24.0283 (29.1650)  lr: 0.0000 (0.0000)  time: 0.197914  data: 0.000472  max mem: 3586
I20250120 12:42:09 3554128 dinov2 helpers.py:102] Training  [ 6990/12500]  eta: 0:20:35  loss: 24.5386 (29.1628)  lr: 0.0000 (0.0000)  time: 0.197877  data: 0.000481  max mem: 3586
I20250120 12:42:11 3554128 dinov2 helpers.py:102] Training  [ 7000/12500]  eta: 0:20:32  loss: 24.5386 (29.1601)  lr: 0.0000 (0.0000)  time: 0.197863  data: 0.000472  max mem: 3586
I20250120 12:42:13 3554128 dinov2 helpers.py:102] Training  [ 7010/12500]  eta: 0:20:30  loss: 24.0283 (29.1521)  lr: 0.0000 (0.0000)  time: 0.197891  data: 0.000487  max mem: 3586
I20250120 12:42:15 3554128 dinov2 helpers.py:102] Training  [ 7020/12500]  eta: 0:20:27  loss: 24.5386 (29.1512)  lr: 0.0000 (0.0000)  time: 0.197859  data: 0.000470  max mem: 3586
I20250120 12:42:17 3554128 dinov2 helpers.py:102] Training  [ 7030/12500]  eta: 0:20:25  loss: 24.5386 (29.1429)  lr: 0.0000 (0.0000)  time: 0.197683  data: 0.000469  max mem: 3586
I20250120 12:42:19 3554128 dinov2 helpers.py:102] Training  [ 7040/12500]  eta: 0:20:22  loss: 24.0283 (29.1332)  lr: 0.0000 (0.0000)  time: 0.197635  data: 0.000487  max mem: 3586
I20250120 12:42:21 3554128 dinov2 helpers.py:102] Training  [ 7050/12500]  eta: 0:20:20  loss: 24.0283 (29.1240)  lr: 0.0000 (0.0000)  time: 0.197782  data: 0.000485  max mem: 3586
I20250120 12:42:23 3554128 dinov2 helpers.py:102] Training  [ 7060/12500]  eta: 0:20:17  loss: 24.0283 (29.1234)  lr: 0.0000 (0.0000)  time: 0.197891  data: 0.000472  max mem: 3586
I20250120 12:42:25 3554128 dinov2 helpers.py:102] Training  [ 7070/12500]  eta: 0:20:15  loss: 24.9473 (29.1188)  lr: 0.0000 (0.0000)  time: 0.197923  data: 0.000487  max mem: 3586
I20250120 12:42:27 3554128 dinov2 helpers.py:102] Training  [ 7080/12500]  eta: 0:20:13  loss: 24.0283 (29.1094)  lr: 0.0000 (0.0000)  time: 0.198001  data: 0.000501  max mem: 3586
I20250120 12:42:29 3554128 dinov2 helpers.py:102] Training  [ 7090/12500]  eta: 0:20:10  loss: 23.8831 (29.1008)  lr: 0.0000 (0.0000)  time: 0.198073  data: 0.000508  max mem: 3586
I20250120 12:42:30 3554128 dinov2 helpers.py:102] Training  [ 7100/12500]  eta: 0:20:08  loss: 23.8831 (29.0907)  lr: 0.0000 (0.0000)  time: 0.197902  data: 0.000506  max mem: 3586
I20250120 12:42:32 3554128 dinov2 helpers.py:102] Training  [ 7110/12500]  eta: 0:20:05  loss: 24.0283 (29.0859)  lr: 0.0000 (0.0000)  time: 0.197773  data: 0.000486  max mem: 3586
I20250120 12:42:34 3554128 dinov2 helpers.py:102] Training  [ 7120/12500]  eta: 0:20:03  loss: 24.0283 (29.0815)  lr: 0.0000 (0.0000)  time: 0.197725  data: 0.000477  max mem: 3586
I20250120 12:42:36 3554128 dinov2 helpers.py:102] Training  [ 7130/12500]  eta: 0:20:00  loss: 24.0283 (29.0762)  lr: 0.0000 (0.0000)  time: 0.197620  data: 0.000461  max mem: 3586
I20250120 12:42:38 3554128 dinov2 helpers.py:102] Training  [ 7140/12500]  eta: 0:19:58  loss: 24.0283 (29.0677)  lr: 0.0000 (0.0000)  time: 0.197574  data: 0.000469  max mem: 3586
I20250120 12:42:40 3554128 dinov2 helpers.py:102] Training  [ 7150/12500]  eta: 0:19:56  loss: 24.0283 (29.0605)  lr: 0.0000 (0.0000)  time: 0.197659  data: 0.000475  max mem: 3586
I20250120 12:42:42 3554128 dinov2 helpers.py:102] Training  [ 7160/12500]  eta: 0:19:53  loss: 24.0283 (29.0538)  lr: 0.0000 (0.0000)  time: 0.197778  data: 0.000459  max mem: 3586
I20250120 12:42:44 3554128 dinov2 helpers.py:102] Training  [ 7170/12500]  eta: 0:19:51  loss: 24.2728 (29.0495)  lr: 0.0000 (0.0000)  time: 0.197855  data: 0.000458  max mem: 3586
I20250120 12:42:46 3554128 dinov2 helpers.py:102] Training  [ 7180/12500]  eta: 0:19:48  loss: 24.2728 (29.0443)  lr: 0.0000 (0.0000)  time: 0.197859  data: 0.000419  max mem: 3586
I20250120 12:42:48 3554128 dinov2 helpers.py:102] Training  [ 7190/12500]  eta: 0:19:46  loss: 23.9145 (29.0351)  lr: 0.0000 (0.0000)  time: 0.197874  data: 0.000412  max mem: 3586
I20250120 12:42:50 3554128 dinov2 helpers.py:102] Training  [ 7200/12500]  eta: 0:19:43  loss: 23.7429 (29.0277)  lr: 0.0000 (0.0000)  time: 0.197759  data: 0.000466  max mem: 3586
I20250120 12:42:52 3554128 dinov2 helpers.py:102] Training  [ 7210/12500]  eta: 0:19:41  loss: 23.7429 (29.0179)  lr: 0.0000 (0.0000)  time: 0.197391  data: 0.000458  max mem: 3586
I20250120 12:42:54 3554128 dinov2 helpers.py:102] Training  [ 7220/12500]  eta: 0:19:39  loss: 23.7429 (29.0134)  lr: 0.0000 (0.0000)  time: 0.197163  data: 0.000422  max mem: 3586
I20250120 12:42:56 3554128 dinov2 helpers.py:102] Training  [ 7230/12500]  eta: 0:19:36  loss: 23.7429 (28.9972)  lr: 0.0000 (0.0000)  time: 0.197314  data: 0.000456  max mem: 3586
I20250120 12:42:58 3554128 dinov2 helpers.py:102] Training  [ 7240/12500]  eta: 0:19:34  loss: 23.7429 (28.9896)  lr: 0.0000 (0.0000)  time: 0.197561  data: 0.000481  max mem: 3586
I20250120 12:43:00 3554128 dinov2 helpers.py:102] Training  [ 7250/12500]  eta: 0:19:31  loss: 23.7429 (28.9816)  lr: 0.0000 (0.0000)  time: 0.197687  data: 0.000480  max mem: 3586
I20250120 12:43:02 3554128 dinov2 helpers.py:102] Training  [ 7260/12500]  eta: 0:19:29  loss: 23.7429 (28.9805)  lr: 0.0000 (0.0000)  time: 0.197542  data: 0.000485  max mem: 3586
I20250120 12:43:04 3554128 dinov2 helpers.py:102] Training  [ 7270/12500]  eta: 0:19:26  loss: 23.4508 (28.9712)  lr: 0.0000 (0.0000)  time: 0.197402  data: 0.000475  max mem: 3586
I20250120 12:43:06 3554128 dinov2 helpers.py:102] Training  [ 7280/12500]  eta: 0:19:24  loss: 23.4508 (28.9599)  lr: 0.0000 (0.0000)  time: 0.197389  data: 0.000458  max mem: 3586
I20250120 12:43:08 3554128 dinov2 helpers.py:102] Training  [ 7290/12500]  eta: 0:19:22  loss: 23.4508 (28.9514)  lr: 0.0000 (0.0000)  time: 0.197372  data: 0.000424  max mem: 3586
I20250120 12:43:10 3554128 dinov2 helpers.py:102] Training  [ 7300/12500]  eta: 0:19:19  loss: 23.7429 (28.9460)  lr: 0.0000 (0.0000)  time: 0.197426  data: 0.000449  max mem: 3586
I20250120 12:43:12 3554128 dinov2 helpers.py:102] Training  [ 7310/12500]  eta: 0:19:17  loss: 23.7429 (28.9497)  lr: 0.0000 (0.0000)  time: 0.197448  data: 0.000484  max mem: 3586
I20250120 12:43:14 3554128 dinov2 helpers.py:102] Training  [ 7320/12500]  eta: 0:19:14  loss: 23.7429 (28.9452)  lr: 0.0000 (0.0000)  time: 0.197481  data: 0.000463  max mem: 3586
I20250120 12:43:16 3554128 dinov2 helpers.py:102] Training  [ 7330/12500]  eta: 0:19:12  loss: 23.5161 (28.9378)  lr: 0.0000 (0.0000)  time: 0.197434  data: 0.000410  max mem: 3586
I20250120 12:43:18 3554128 dinov2 helpers.py:102] Training  [ 7340/12500]  eta: 0:19:10  loss: 23.5161 (28.9284)  lr: 0.0000 (0.0000)  time: 0.197519  data: 0.000433  max mem: 3586
I20250120 12:43:20 3554128 dinov2 helpers.py:102] Training  [ 7350/12500]  eta: 0:19:07  loss: 23.4508 (28.9163)  lr: 0.0000 (0.0000)  time: 0.197601  data: 0.000473  max mem: 3586
I20250120 12:43:22 3554128 dinov2 helpers.py:102] Training  [ 7360/12500]  eta: 0:19:05  loss: 23.2075 (28.9046)  lr: 0.0000 (0.0000)  time: 0.197383  data: 0.000454  max mem: 3586
I20250120 12:43:24 3554128 dinov2 helpers.py:102] Training  [ 7370/12500]  eta: 0:19:02  loss: 23.2075 (28.9018)  lr: 0.0000 (0.0000)  time: 0.197256  data: 0.000430  max mem: 3586
I20250120 12:43:26 3554128 dinov2 helpers.py:102] Training  [ 7380/12500]  eta: 0:19:00  loss: 23.2075 (28.9002)  lr: 0.0000 (0.0000)  time: 0.197303  data: 0.000447  max mem: 3586
I20250120 12:43:28 3554128 dinov2 helpers.py:102] Training  [ 7390/12500]  eta: 0:18:58  loss: 23.4508 (28.8941)  lr: 0.0000 (0.0000)  time: 0.197263  data: 0.000418  max mem: 3586
I20250120 12:43:30 3554128 dinov2 helpers.py:102] Training  [ 7400/12500]  eta: 0:18:55  loss: 23.4508 (28.8875)  lr: 0.0000 (0.0000)  time: 0.197180  data: 0.000409  max mem: 3586
I20250120 12:43:32 3554128 dinov2 helpers.py:102] Training  [ 7410/12500]  eta: 0:18:53  loss: 23.5161 (28.8836)  lr: 0.0000 (0.0000)  time: 0.197183  data: 0.000446  max mem: 3586
I20250120 12:43:34 3554128 dinov2 helpers.py:102] Training  [ 7420/12500]  eta: 0:18:50  loss: 23.4508 (28.8711)  lr: 0.0000 (0.0000)  time: 0.196931  data: 0.000394  max mem: 3586
I20250120 12:43:36 3554128 dinov2 helpers.py:102] Training  [ 7430/12500]  eta: 0:18:48  loss: 23.5161 (28.8643)  lr: 0.0000 (0.0000)  time: 0.196760  data: 0.000391  max mem: 3586
I20250120 12:43:38 3554128 dinov2 helpers.py:102] Training  [ 7440/12500]  eta: 0:18:46  loss: 23.8319 (28.8581)  lr: 0.0000 (0.0000)  time: 0.196929  data: 0.000418  max mem: 3586
I20250120 12:43:40 3554128 dinov2 helpers.py:102] Training  [ 7450/12500]  eta: 0:18:43  loss: 24.0357 (28.8539)  lr: 0.0000 (0.0000)  time: 0.197175  data: 0.000462  max mem: 3586
I20250120 12:43:42 3554128 dinov2 helpers.py:102] Training  [ 7460/12500]  eta: 0:18:41  loss: 24.0357 (28.8487)  lr: 0.0000 (0.0000)  time: 0.197229  data: 0.000504  max mem: 3586
I20250120 12:43:44 3554128 dinov2 helpers.py:102] Training  [ 7470/12500]  eta: 0:18:38  loss: 24.0357 (28.8395)  lr: 0.0000 (0.0000)  time: 0.197008  data: 0.000466  max mem: 3586
I20250120 12:43:46 3554128 dinov2 helpers.py:102] Training  [ 7480/12500]  eta: 0:18:36  loss: 24.2196 (28.8370)  lr: 0.0000 (0.0000)  time: 0.197026  data: 0.000460  max mem: 3586
I20250120 12:43:48 3554128 dinov2 helpers.py:102] Training  [ 7490/12500]  eta: 0:18:34  loss: 24.3276 (28.8354)  lr: 0.0000 (0.0000)  time: 0.197101  data: 0.000429  max mem: 3586
I20250120 12:43:49 3554128 dinov2 linear.py:272] running validation !
I20250120 12:43:51 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:38    time: 1.410839  data: 1.213965  max mem: 3586
I20250120 12:43:53 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:45    time: 0.314114  data: 0.111283  max mem: 3586
I20250120 12:43:55 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:35    time: 0.202662  data: 0.001046  max mem: 3586
I20250120 12:43:57 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.200306  data: 0.000681  max mem: 3586
I20250120 12:43:59 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199789  data: 0.000259  max mem: 3586
I20250120 12:44:01 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.199893  data: 0.000237  max mem: 3586
I20250120 12:44:03 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:20    time: 0.199873  data: 0.000244  max mem: 3586
I20250120 12:44:05 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199792  data: 0.000242  max mem: 3586
I20250120 12:44:07 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199921  data: 0.000256  max mem: 3586
I20250120 12:44:09 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.199810  data: 0.000233  max mem: 3586
I20250120 12:44:11 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199694  data: 0.000244  max mem: 3586
I20250120 12:44:13 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.200041  data: 0.000276  max mem: 3586
I20250120 12:44:15 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199990  data: 0.000267  max mem: 3586
I20250120 12:44:17 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199853  data: 0.000291  max mem: 3586
I20250120 12:44:19 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199728  data: 0.000331  max mem: 3586
I20250120 12:44:21 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199231  data: 0.000242  max mem: 3586
I20250120 12:44:21 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195184  data: 0.000212  max mem: 3586
I20250120 12:44:22 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208284 s / it)
I20250120 12:44:22 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:44:22 3554128 dinov2 linear.py:287] 
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7894, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8036, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8089, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8137, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8189, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8216, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8242, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8257, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8263, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8193, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8086, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8033, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7919, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8059, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8120, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8168, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8226, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8298, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8319, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8321, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8248, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8241, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8205, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8105, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8163, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8206, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8233, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8290, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8295, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8224, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8161, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8171, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7952, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7817, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8102, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8149, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8219, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8248, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8278, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8334, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8325, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8271, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8232, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8199, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8001, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7877, device='cuda:0')}
I20250120 12:44:22 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00050', 'accuracy': 0.833417534828186}
I20250120 12:44:22 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:44:22 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:44:22 3554128 dinov2 helpers.py:102] Training  [ 7500/12500]  eta: 0:18:53  loss: 24.2196 (28.8259)  lr: 0.0000 (0.0000)  time: 1.815985  data: 0.000403  max mem: 3586
I20250120 12:44:24 3554128 dinov2 helpers.py:102] Training  [ 7510/12500]  eta: 0:18:50  loss: 24.0357 (28.8140)  lr: 0.0000 (0.0000)  time: 1.814946  data: 0.000382  max mem: 3586
I20250120 12:44:26 3554128 dinov2 helpers.py:102] Training  [ 7520/12500]  eta: 0:18:48  loss: 24.0357 (28.8123)  lr: 0.0000 (0.0000)  time: 0.195640  data: 0.000384  max mem: 3586
I20250120 12:44:28 3554128 dinov2 helpers.py:102] Training  [ 7530/12500]  eta: 0:18:45  loss: 24.2196 (28.8121)  lr: 0.0000 (0.0000)  time: 0.196370  data: 0.000465  max mem: 3586
I20250120 12:44:30 3554128 dinov2 helpers.py:102] Training  [ 7540/12500]  eta: 0:18:43  loss: 24.2196 (28.8041)  lr: 0.0000 (0.0000)  time: 0.196229  data: 0.000512  max mem: 3586
I20250120 12:44:32 3554128 dinov2 helpers.py:102] Training  [ 7550/12500]  eta: 0:18:40  loss: 24.2196 (28.7971)  lr: 0.0000 (0.0000)  time: 0.196120  data: 0.000487  max mem: 3586
I20250120 12:44:34 3554128 dinov2 helpers.py:102] Training  [ 7560/12500]  eta: 0:18:38  loss: 24.2196 (28.7906)  lr: 0.0000 (0.0000)  time: 0.196273  data: 0.000445  max mem: 3586
I20250120 12:44:36 3554128 dinov2 helpers.py:102] Training  [ 7570/12500]  eta: 0:18:36  loss: 24.2196 (28.7852)  lr: 0.0000 (0.0000)  time: 0.196219  data: 0.000446  max mem: 3586
I20250120 12:44:38 3554128 dinov2 helpers.py:102] Training  [ 7580/12500]  eta: 0:18:33  loss: 24.2196 (28.7847)  lr: 0.0000 (0.0000)  time: 0.196093  data: 0.000453  max mem: 3586
I20250120 12:44:40 3554128 dinov2 helpers.py:102] Training  [ 7590/12500]  eta: 0:18:31  loss: 24.0357 (28.7705)  lr: 0.0000 (0.0000)  time: 0.219923  data: 0.027987  max mem: 3586
I20250120 12:44:42 3554128 dinov2 helpers.py:102] Training  [ 7600/12500]  eta: 0:18:28  loss: 24.2196 (28.7689)  lr: 0.0000 (0.0000)  time: 0.219770  data: 0.028009  max mem: 3586
I20250120 12:44:44 3554128 dinov2 helpers.py:102] Training  [ 7610/12500]  eta: 0:18:26  loss: 24.2196 (28.7637)  lr: 0.0000 (0.0000)  time: 0.195898  data: 0.000493  max mem: 3586
I20250120 12:44:46 3554128 dinov2 helpers.py:102] Training  [ 7620/12500]  eta: 0:18:24  loss: 24.6879 (28.7604)  lr: 0.0000 (0.0000)  time: 0.196189  data: 0.000476  max mem: 3586
I20250120 12:44:48 3554128 dinov2 helpers.py:102] Training  [ 7630/12500]  eta: 0:18:21  loss: 24.8204 (28.7573)  lr: 0.0000 (0.0000)  time: 0.196430  data: 0.000490  max mem: 3586
I20250120 12:44:50 3554128 dinov2 helpers.py:102] Training  [ 7640/12500]  eta: 0:18:19  loss: 24.8204 (28.7500)  lr: 0.0000 (0.0000)  time: 0.196399  data: 0.000481  max mem: 3586
I20250120 12:44:52 3554128 dinov2 helpers.py:102] Training  [ 7650/12500]  eta: 0:18:16  loss: 24.6879 (28.7367)  lr: 0.0000 (0.0000)  time: 0.196342  data: 0.000483  max mem: 3586
I20250120 12:44:54 3554128 dinov2 helpers.py:102] Training  [ 7660/12500]  eta: 0:18:14  loss: 24.6879 (28.7320)  lr: 0.0000 (0.0000)  time: 0.196442  data: 0.000463  max mem: 3586
I20250120 12:44:56 3554128 dinov2 helpers.py:102] Training  [ 7670/12500]  eta: 0:18:11  loss: 24.8204 (28.7284)  lr: 0.0000 (0.0000)  time: 0.196560  data: 0.000474  max mem: 3586
I20250120 12:44:58 3554128 dinov2 helpers.py:102] Training  [ 7680/12500]  eta: 0:18:09  loss: 24.8204 (28.7238)  lr: 0.0000 (0.0000)  time: 0.196481  data: 0.000499  max mem: 3586
I20250120 12:45:00 3554128 dinov2 helpers.py:102] Training  [ 7690/12500]  eta: 0:18:06  loss: 24.6879 (28.7119)  lr: 0.0000 (0.0000)  time: 0.196576  data: 0.000435  max mem: 3586
I20250120 12:45:02 3554128 dinov2 helpers.py:102] Training  [ 7700/12500]  eta: 0:18:04  loss: 24.6879 (28.6997)  lr: 0.0000 (0.0000)  time: 0.196769  data: 0.000447  max mem: 3586
I20250120 12:45:04 3554128 dinov2 helpers.py:102] Training  [ 7710/12500]  eta: 0:18:02  loss: 24.6879 (28.6929)  lr: 0.0000 (0.0000)  time: 0.196571  data: 0.000495  max mem: 3586
I20250120 12:45:06 3554128 dinov2 helpers.py:102] Training  [ 7720/12500]  eta: 0:17:59  loss: 24.6879 (28.6882)  lr: 0.0000 (0.0000)  time: 0.196632  data: 0.000488  max mem: 3586
I20250120 12:45:07 3554128 dinov2 helpers.py:102] Training  [ 7730/12500]  eta: 0:17:57  loss: 23.9344 (28.6819)  lr: 0.0000 (0.0000)  time: 0.196782  data: 0.000478  max mem: 3586
I20250120 12:45:09 3554128 dinov2 helpers.py:102] Training  [ 7740/12500]  eta: 0:17:54  loss: 23.9344 (28.6697)  lr: 0.0000 (0.0000)  time: 0.196787  data: 0.000458  max mem: 3586
I20250120 12:45:11 3554128 dinov2 helpers.py:102] Training  [ 7750/12500]  eta: 0:17:52  loss: 23.9344 (28.6554)  lr: 0.0000 (0.0000)  time: 0.196745  data: 0.000450  max mem: 3586
I20250120 12:45:13 3554128 dinov2 helpers.py:102] Training  [ 7760/12500]  eta: 0:17:49  loss: 23.8482 (28.6479)  lr: 0.0000 (0.0000)  time: 0.196734  data: 0.000489  max mem: 3586
I20250120 12:45:15 3554128 dinov2 helpers.py:102] Training  [ 7770/12500]  eta: 0:17:47  loss: 23.4665 (28.6396)  lr: 0.0000 (0.0000)  time: 0.196856  data: 0.000493  max mem: 3586
I20250120 12:45:17 3554128 dinov2 helpers.py:102] Training  [ 7780/12500]  eta: 0:17:44  loss: 23.1288 (28.6299)  lr: 0.0000 (0.0000)  time: 0.196988  data: 0.000465  max mem: 3586
I20250120 12:45:19 3554128 dinov2 helpers.py:102] Training  [ 7790/12500]  eta: 0:17:42  loss: 23.1288 (28.6221)  lr: 0.0000 (0.0000)  time: 0.197106  data: 0.000475  max mem: 3586
I20250120 12:45:21 3554128 dinov2 helpers.py:102] Training  [ 7800/12500]  eta: 0:17:40  loss: 23.1288 (28.6188)  lr: 0.0000 (0.0000)  time: 0.197175  data: 0.000459  max mem: 3586
I20250120 12:45:28 3554128 dinov2 helpers.py:102] Training  [ 7810/12500]  eta: 0:17:40  loss: 23.1288 (28.6123)  lr: 0.0000 (0.0000)  time: 0.432863  data: 0.251463  max mem: 3586
I20250120 12:45:30 3554128 dinov2 helpers.py:102] Training  [ 7820/12500]  eta: 0:17:38  loss: 23.1288 (28.6083)  lr: 0.0000 (0.0000)  time: 0.431384  data: 0.251804  max mem: 3586
I20250120 12:45:32 3554128 dinov2 helpers.py:102] Training  [ 7830/12500]  eta: 0:17:35  loss: 23.1288 (28.6056)  lr: 0.0000 (0.0000)  time: 0.194432  data: 0.000892  max mem: 3586
I20250120 12:45:34 3554128 dinov2 helpers.py:102] Training  [ 7840/12500]  eta: 0:17:33  loss: 22.8622 (28.5947)  lr: 0.0000 (0.0000)  time: 0.194788  data: 0.000598  max mem: 3586
I20250120 12:45:36 3554128 dinov2 helpers.py:102] Training  [ 7850/12500]  eta: 0:17:30  loss: 22.8622 (28.5831)  lr: 0.0000 (0.0000)  time: 0.195136  data: 0.000488  max mem: 3586
I20250120 12:45:38 3554128 dinov2 helpers.py:102] Training  [ 7860/12500]  eta: 0:17:28  loss: 22.8622 (28.5792)  lr: 0.0000 (0.0000)  time: 0.195330  data: 0.000457  max mem: 3586
I20250120 12:45:40 3554128 dinov2 helpers.py:102] Training  [ 7870/12500]  eta: 0:17:25  loss: 22.8622 (28.5725)  lr: 0.0000 (0.0000)  time: 0.195366  data: 0.000493  max mem: 3586
I20250120 12:45:42 3554128 dinov2 helpers.py:102] Training  [ 7880/12500]  eta: 0:17:23  loss: 22.5087 (28.5623)  lr: 0.0000 (0.0000)  time: 0.195389  data: 0.000509  max mem: 3586
I20250120 12:45:44 3554128 dinov2 helpers.py:102] Training  [ 7890/12500]  eta: 0:17:20  loss: 22.8622 (28.5586)  lr: 0.0000 (0.0000)  time: 0.195542  data: 0.000468  max mem: 3586
I20250120 12:45:46 3554128 dinov2 helpers.py:102] Training  [ 7900/12500]  eta: 0:17:18  loss: 23.3688 (28.5534)  lr: 0.0000 (0.0000)  time: 0.195663  data: 0.000459  max mem: 3586
I20250120 12:45:48 3554128 dinov2 helpers.py:102] Training  [ 7910/12500]  eta: 0:17:16  loss: 23.3688 (28.5486)  lr: 0.0000 (0.0000)  time: 0.195744  data: 0.000473  max mem: 3586
I20250120 12:45:49 3554128 dinov2 helpers.py:102] Training  [ 7920/12500]  eta: 0:17:13  loss: 23.3688 (28.5463)  lr: 0.0000 (0.0000)  time: 0.195909  data: 0.000447  max mem: 3586
I20250120 12:45:51 3554128 dinov2 helpers.py:102] Training  [ 7930/12500]  eta: 0:17:11  loss: 22.8622 (28.5380)  lr: 0.0000 (0.0000)  time: 0.196105  data: 0.000463  max mem: 3586
I20250120 12:45:53 3554128 dinov2 helpers.py:102] Training  [ 7940/12500]  eta: 0:17:08  loss: 23.3688 (28.5342)  lr: 0.0000 (0.0000)  time: 0.196257  data: 0.000504  max mem: 3586
I20250120 12:45:55 3554128 dinov2 helpers.py:102] Training  [ 7950/12500]  eta: 0:17:06  loss: 23.3688 (28.5275)  lr: 0.0000 (0.0000)  time: 0.196276  data: 0.000494  max mem: 3586
I20250120 12:45:57 3554128 dinov2 helpers.py:102] Training  [ 7960/12500]  eta: 0:17:03  loss: 23.3688 (28.5200)  lr: 0.0000 (0.0000)  time: 0.196322  data: 0.000473  max mem: 3586
I20250120 12:45:59 3554128 dinov2 helpers.py:102] Training  [ 7970/12500]  eta: 0:17:01  loss: 23.5252 (28.5176)  lr: 0.0000 (0.0000)  time: 0.196370  data: 0.000462  max mem: 3586
I20250120 12:46:01 3554128 dinov2 helpers.py:102] Training  [ 7980/12500]  eta: 0:16:59  loss: 24.4743 (28.5131)  lr: 0.0000 (0.0000)  time: 0.196274  data: 0.000481  max mem: 3586
I20250120 12:46:03 3554128 dinov2 helpers.py:102] Training  [ 7990/12500]  eta: 0:16:56  loss: 24.4743 (28.5051)  lr: 0.0000 (0.0000)  time: 0.196299  data: 0.000486  max mem: 3586
I20250120 12:46:05 3554128 dinov2 helpers.py:102] Training  [ 8000/12500]  eta: 0:16:54  loss: 23.8487 (28.4993)  lr: 0.0000 (0.0000)  time: 0.196548  data: 0.000492  max mem: 3586
I20250120 12:46:07 3554128 dinov2 helpers.py:102] Training  [ 8010/12500]  eta: 0:16:51  loss: 23.8487 (28.4919)  lr: 0.0000 (0.0000)  time: 0.196630  data: 0.000484  max mem: 3586
I20250120 12:46:09 3554128 dinov2 helpers.py:102] Training  [ 8020/12500]  eta: 0:16:49  loss: 23.8487 (28.4883)  lr: 0.0000 (0.0000)  time: 0.196515  data: 0.000447  max mem: 3586
I20250120 12:46:11 3554128 dinov2 helpers.py:102] Training  [ 8030/12500]  eta: 0:16:47  loss: 23.8487 (28.4848)  lr: 0.0000 (0.0000)  time: 0.196582  data: 0.000448  max mem: 3586
I20250120 12:46:13 3554128 dinov2 helpers.py:102] Training  [ 8040/12500]  eta: 0:16:44  loss: 23.8487 (28.4745)  lr: 0.0000 (0.0000)  time: 0.196686  data: 0.000455  max mem: 3586
I20250120 12:46:15 3554128 dinov2 helpers.py:102] Training  [ 8050/12500]  eta: 0:16:42  loss: 24.4743 (28.4721)  lr: 0.0000 (0.0000)  time: 0.196651  data: 0.000466  max mem: 3586
I20250120 12:46:17 3554128 dinov2 helpers.py:102] Training  [ 8060/12500]  eta: 0:16:39  loss: 23.8487 (28.4652)  lr: 0.0000 (0.0000)  time: 0.196802  data: 0.000474  max mem: 3586
I20250120 12:46:19 3554128 dinov2 helpers.py:102] Training  [ 8070/12500]  eta: 0:16:37  loss: 23.8487 (28.4576)  lr: 0.0000 (0.0000)  time: 0.196732  data: 0.000470  max mem: 3586
I20250120 12:46:21 3554128 dinov2 helpers.py:102] Training  [ 8080/12500]  eta: 0:16:35  loss: 23.8487 (28.4503)  lr: 0.0000 (0.0000)  time: 0.196784  data: 0.000480  max mem: 3586
I20250120 12:46:23 3554128 dinov2 helpers.py:102] Training  [ 8090/12500]  eta: 0:16:32  loss: 23.8487 (28.4470)  lr: 0.0000 (0.0000)  time: 0.197125  data: 0.000490  max mem: 3586
I20250120 12:46:25 3554128 dinov2 helpers.py:102] Training  [ 8100/12500]  eta: 0:16:30  loss: 23.8487 (28.4466)  lr: 0.0000 (0.0000)  time: 0.197085  data: 0.000478  max mem: 3586
I20250120 12:46:27 3554128 dinov2 helpers.py:102] Training  [ 8110/12500]  eta: 0:16:27  loss: 23.8487 (28.4421)  lr: 0.0000 (0.0000)  time: 0.197050  data: 0.000452  max mem: 3586
I20250120 12:46:29 3554128 dinov2 helpers.py:102] Training  [ 8120/12500]  eta: 0:16:25  loss: 23.2364 (28.4357)  lr: 0.0000 (0.0000)  time: 0.197009  data: 0.000460  max mem: 3586
I20250120 12:46:31 3554128 dinov2 helpers.py:102] Training  [ 8130/12500]  eta: 0:16:23  loss: 23.8487 (28.4334)  lr: 0.0000 (0.0000)  time: 0.197088  data: 0.000475  max mem: 3586
I20250120 12:46:33 3554128 dinov2 helpers.py:102] Training  [ 8140/12500]  eta: 0:16:20  loss: 23.8487 (28.4279)  lr: 0.0000 (0.0000)  time: 0.197208  data: 0.000485  max mem: 3586
I20250120 12:46:35 3554128 dinov2 helpers.py:102] Training  [ 8150/12500]  eta: 0:16:18  loss: 23.9382 (28.4232)  lr: 0.0000 (0.0000)  time: 0.197146  data: 0.000488  max mem: 3586
I20250120 12:46:37 3554128 dinov2 helpers.py:102] Training  [ 8160/12500]  eta: 0:16:15  loss: 24.6137 (28.4202)  lr: 0.0000 (0.0000)  time: 0.197261  data: 0.000480  max mem: 3586
I20250120 12:46:39 3554128 dinov2 helpers.py:102] Training  [ 8170/12500]  eta: 0:16:13  loss: 23.9382 (28.4099)  lr: 0.0000 (0.0000)  time: 0.197336  data: 0.000484  max mem: 3586
I20250120 12:46:41 3554128 dinov2 helpers.py:102] Training  [ 8180/12500]  eta: 0:16:11  loss: 23.8487 (28.4030)  lr: 0.0000 (0.0000)  time: 0.197250  data: 0.000458  max mem: 3586
I20250120 12:46:43 3554128 dinov2 helpers.py:102] Training  [ 8190/12500]  eta: 0:16:08  loss: 23.9382 (28.3982)  lr: 0.0000 (0.0000)  time: 0.197366  data: 0.000446  max mem: 3586
I20250120 12:46:45 3554128 dinov2 helpers.py:102] Training  [ 8200/12500]  eta: 0:16:06  loss: 24.4454 (28.3972)  lr: 0.0000 (0.0000)  time: 0.197447  data: 0.000440  max mem: 3586
I20250120 12:46:47 3554128 dinov2 helpers.py:102] Training  [ 8210/12500]  eta: 0:16:03  loss: 24.4454 (28.3880)  lr: 0.0000 (0.0000)  time: 0.197240  data: 0.000539  max mem: 3586
I20250120 12:46:49 3554128 dinov2 helpers.py:102] Training  [ 8220/12500]  eta: 0:16:01  loss: 24.4454 (28.3832)  lr: 0.0000 (0.0000)  time: 0.197143  data: 0.000598  max mem: 3586
I20250120 12:46:51 3554128 dinov2 helpers.py:102] Training  [ 8230/12500]  eta: 0:15:59  loss: 23.9382 (28.3713)  lr: 0.0000 (0.0000)  time: 0.197197  data: 0.000505  max mem: 3586
I20250120 12:46:57 3554128 dinov2 helpers.py:102] Training  [ 8240/12500]  eta: 0:15:59  loss: 24.4454 (28.3669)  lr: 0.0000 (0.0000)  time: 0.439916  data: 0.258687  max mem: 3586
I20250120 12:47:12 3554128 dinov2 helpers.py:102] Training  [ 8250/12500]  eta: 0:16:03  loss: 24.4454 (28.3658)  lr: 0.0000 (0.0000)  time: 1.053065  data: 0.891699  max mem: 3586
I20250120 12:47:21 3554128 dinov2 helpers.py:102] Training  [ 8260/12500]  eta: 0:16:04  loss: 24.4454 (28.3575)  lr: 0.0000 (0.0000)  time: 1.165247  data: 1.003812  max mem: 3586
I20250120 12:47:29 3554128 dinov2 helpers.py:102] Training  [ 8270/12500]  eta: 0:16:05  loss: 24.4454 (28.3510)  lr: 0.0000 (0.0000)  time: 0.877713  data: 0.712201  max mem: 3586
I20250120 12:47:33 3554128 dinov2 helpers.py:102] Training  [ 8280/12500]  eta: 0:16:03  loss: 24.4489 (28.3534)  lr: 0.0000 (0.0000)  time: 0.638418  data: 0.467818  max mem: 3586
I20250120 12:47:35 3554128 dinov2 helpers.py:102] Training  [ 8290/12500]  eta: 0:16:01  loss: 24.4489 (28.3524)  lr: 0.0000 (0.0000)  time: 0.308330  data: 0.126676  max mem: 3586
I20250120 12:47:37 3554128 dinov2 helpers.py:102] Training  [ 8300/12500]  eta: 0:15:59  loss: 24.4489 (28.3479)  lr: 0.0000 (0.0000)  time: 0.188858  data: 0.000743  max mem: 3586
I20250120 12:47:39 3554128 dinov2 helpers.py:102] Training  [ 8310/12500]  eta: 0:15:56  loss: 24.4454 (28.3362)  lr: 0.0000 (0.0000)  time: 0.189533  data: 0.000488  max mem: 3586
I20250120 12:47:41 3554128 dinov2 helpers.py:102] Training  [ 8320/12500]  eta: 0:15:54  loss: 24.4454 (28.3282)  lr: 0.0000 (0.0000)  time: 0.189866  data: 0.000470  max mem: 3586
I20250120 12:47:43 3554128 dinov2 helpers.py:102] Training  [ 8330/12500]  eta: 0:15:51  loss: 24.4454 (28.3246)  lr: 0.0000 (0.0000)  time: 0.190244  data: 0.000437  max mem: 3586
I20250120 12:47:45 3554128 dinov2 helpers.py:102] Training  [ 8340/12500]  eta: 0:15:49  loss: 24.4489 (28.3214)  lr: 0.0000 (0.0000)  time: 0.190491  data: 0.000461  max mem: 3586
I20250120 12:47:47 3554128 dinov2 helpers.py:102] Training  [ 8350/12500]  eta: 0:15:46  loss: 24.4454 (28.3137)  lr: 0.0000 (0.0000)  time: 0.191018  data: 0.000507  max mem: 3586
I20250120 12:47:49 3554128 dinov2 helpers.py:102] Training  [ 8360/12500]  eta: 0:15:44  loss: 23.0047 (28.3057)  lr: 0.0000 (0.0000)  time: 0.191600  data: 0.000511  max mem: 3586
I20250120 12:47:51 3554128 dinov2 helpers.py:102] Training  [ 8370/12500]  eta: 0:15:41  loss: 23.0047 (28.2985)  lr: 0.0000 (0.0000)  time: 0.191949  data: 0.000516  max mem: 3586
I20250120 12:47:52 3554128 dinov2 helpers.py:102] Training  [ 8380/12500]  eta: 0:15:39  loss: 24.4454 (28.2941)  lr: 0.0000 (0.0000)  time: 0.192182  data: 0.000454  max mem: 3586
I20250120 12:47:54 3554128 dinov2 helpers.py:102] Training  [ 8390/12500]  eta: 0:15:36  loss: 24.4489 (28.2926)  lr: 0.0000 (0.0000)  time: 0.192427  data: 0.000431  max mem: 3586
I20250120 12:47:56 3554128 dinov2 helpers.py:102] Training  [ 8400/12500]  eta: 0:15:34  loss: 24.4489 (28.2899)  lr: 0.0000 (0.0000)  time: 0.192900  data: 0.000473  max mem: 3586
I20250120 12:47:58 3554128 dinov2 helpers.py:102] Training  [ 8410/12500]  eta: 0:15:31  loss: 24.4489 (28.2804)  lr: 0.0000 (0.0000)  time: 0.193197  data: 0.000487  max mem: 3586
I20250120 12:48:00 3554128 dinov2 helpers.py:102] Training  [ 8420/12500]  eta: 0:15:29  loss: 24.6615 (28.2762)  lr: 0.0000 (0.0000)  time: 0.193355  data: 0.000486  max mem: 3586
I20250120 12:48:02 3554128 dinov2 helpers.py:102] Training  [ 8430/12500]  eta: 0:15:27  loss: 24.6615 (28.2700)  lr: 0.0000 (0.0000)  time: 0.193712  data: 0.000485  max mem: 3586
I20250120 12:48:04 3554128 dinov2 helpers.py:102] Training  [ 8440/12500]  eta: 0:15:24  loss: 23.0453 (28.2584)  lr: 0.0000 (0.0000)  time: 0.193908  data: 0.000490  max mem: 3586
I20250120 12:48:06 3554128 dinov2 helpers.py:102] Training  [ 8450/12500]  eta: 0:15:22  loss: 23.0047 (28.2507)  lr: 0.0000 (0.0000)  time: 0.194058  data: 0.000496  max mem: 3586
I20250120 12:48:08 3554128 dinov2 helpers.py:102] Training  [ 8460/12500]  eta: 0:15:19  loss: 23.0047 (28.2426)  lr: 0.0000 (0.0000)  time: 0.194363  data: 0.000468  max mem: 3586
I20250120 12:48:10 3554128 dinov2 helpers.py:102] Training  [ 8470/12500]  eta: 0:15:17  loss: 22.5134 (28.2359)  lr: 0.0000 (0.0000)  time: 0.194649  data: 0.000434  max mem: 3586
I20250120 12:48:12 3554128 dinov2 helpers.py:102] Training  [ 8480/12500]  eta: 0:15:14  loss: 22.5134 (28.2296)  lr: 0.0000 (0.0000)  time: 0.194723  data: 0.000465  max mem: 3586
I20250120 12:48:14 3554128 dinov2 helpers.py:102] Training  [ 8490/12500]  eta: 0:15:12  loss: 22.5134 (28.2236)  lr: 0.0000 (0.0000)  time: 0.195054  data: 0.000482  max mem: 3586
I20250120 12:48:16 3554128 dinov2 helpers.py:102] Training  [ 8500/12500]  eta: 0:15:10  loss: 22.5134 (28.2192)  lr: 0.0000 (0.0000)  time: 0.195516  data: 0.000481  max mem: 3586
I20250120 12:48:18 3554128 dinov2 helpers.py:102] Training  [ 8510/12500]  eta: 0:15:07  loss: 22.5134 (28.2124)  lr: 0.0000 (0.0000)  time: 0.195516  data: 0.000496  max mem: 3586
I20250120 12:48:20 3554128 dinov2 helpers.py:102] Training  [ 8520/12500]  eta: 0:15:05  loss: 22.5134 (28.2044)  lr: 0.0000 (0.0000)  time: 0.195569  data: 0.000484  max mem: 3586
I20250120 12:48:22 3554128 dinov2 helpers.py:102] Training  [ 8530/12500]  eta: 0:15:02  loss: 22.5134 (28.1988)  lr: 0.0000 (0.0000)  time: 0.195590  data: 0.000473  max mem: 3586
I20250120 12:48:24 3554128 dinov2 helpers.py:102] Training  [ 8540/12500]  eta: 0:15:00  loss: 22.5134 (28.1937)  lr: 0.0000 (0.0000)  time: 0.195853  data: 0.000496  max mem: 3586
I20250120 12:48:26 3554128 dinov2 helpers.py:102] Training  [ 8550/12500]  eta: 0:14:57  loss: 22.5134 (28.1861)  lr: 0.0000 (0.0000)  time: 0.196117  data: 0.000525  max mem: 3586
I20250120 12:48:28 3554128 dinov2 helpers.py:102] Training  [ 8560/12500]  eta: 0:14:55  loss: 22.9321 (28.1821)  lr: 0.0000 (0.0000)  time: 0.196138  data: 0.000509  max mem: 3586
I20250120 12:48:30 3554128 dinov2 helpers.py:102] Training  [ 8570/12500]  eta: 0:14:53  loss: 22.9321 (28.1746)  lr: 0.0000 (0.0000)  time: 0.196181  data: 0.000467  max mem: 3586
I20250120 12:48:31 3554128 dinov2 helpers.py:102] Training  [ 8580/12500]  eta: 0:14:50  loss: 22.5134 (28.1660)  lr: 0.0000 (0.0000)  time: 0.196253  data: 0.000503  max mem: 3586
I20250120 12:48:33 3554128 dinov2 helpers.py:102] Training  [ 8590/12500]  eta: 0:14:48  loss: 22.3848 (28.1579)  lr: 0.0000 (0.0000)  time: 0.196445  data: 0.000483  max mem: 3586
I20250120 12:48:35 3554128 dinov2 helpers.py:102] Training  [ 8600/12500]  eta: 0:14:45  loss: 22.3848 (28.1530)  lr: 0.0000 (0.0000)  time: 0.196429  data: 0.000428  max mem: 3586
I20250120 12:48:37 3554128 dinov2 helpers.py:102] Training  [ 8610/12500]  eta: 0:14:43  loss: 22.3848 (28.1420)  lr: 0.0000 (0.0000)  time: 0.196433  data: 0.000450  max mem: 3586
I20250120 12:48:39 3554128 dinov2 helpers.py:102] Training  [ 8620/12500]  eta: 0:14:41  loss: 22.3848 (28.1367)  lr: 0.0000 (0.0000)  time: 0.196689  data: 0.000496  max mem: 3586
I20250120 12:48:41 3554128 dinov2 helpers.py:102] Training  [ 8630/12500]  eta: 0:14:38  loss: 21.7932 (28.1294)  lr: 0.0000 (0.0000)  time: 0.196754  data: 0.000517  max mem: 3586
I20250120 12:48:43 3554128 dinov2 helpers.py:102] Training  [ 8640/12500]  eta: 0:14:36  loss: 22.3848 (28.1296)  lr: 0.0000 (0.0000)  time: 0.196942  data: 0.000454  max mem: 3586
I20250120 12:48:45 3554128 dinov2 helpers.py:102] Training  [ 8650/12500]  eta: 0:14:33  loss: 22.5134 (28.1247)  lr: 0.0000 (0.0000)  time: 0.197067  data: 0.000403  max mem: 3586
I20250120 12:48:47 3554128 dinov2 helpers.py:102] Training  [ 8660/12500]  eta: 0:14:31  loss: 22.7176 (28.1185)  lr: 0.0000 (0.0000)  time: 0.196950  data: 0.000428  max mem: 3586
I20250120 12:48:49 3554128 dinov2 helpers.py:102] Training  [ 8670/12500]  eta: 0:14:29  loss: 22.7176 (28.1104)  lr: 0.0000 (0.0000)  time: 0.196968  data: 0.000467  max mem: 3586
I20250120 12:48:51 3554128 dinov2 helpers.py:102] Training  [ 8680/12500]  eta: 0:14:26  loss: 22.3848 (28.1022)  lr: 0.0000 (0.0000)  time: 0.196993  data: 0.000481  max mem: 3586
I20250120 12:48:53 3554128 dinov2 helpers.py:102] Training  [ 8690/12500]  eta: 0:14:24  loss: 22.3848 (28.0959)  lr: 0.0000 (0.0000)  time: 0.196918  data: 0.000476  max mem: 3586
I20250120 12:48:55 3554128 dinov2 helpers.py:102] Training  [ 8700/12500]  eta: 0:14:21  loss: 21.7932 (28.0849)  lr: 0.0000 (0.0000)  time: 0.196841  data: 0.000490  max mem: 3586
I20250120 12:48:57 3554128 dinov2 helpers.py:102] Training  [ 8710/12500]  eta: 0:14:19  loss: 21.7422 (28.0740)  lr: 0.0000 (0.0000)  time: 0.196920  data: 0.000513  max mem: 3586
I20250120 12:48:59 3554128 dinov2 helpers.py:102] Training  [ 8720/12500]  eta: 0:14:17  loss: 21.7932 (28.0673)  lr: 0.0000 (0.0000)  time: 0.197037  data: 0.000490  max mem: 3586
I20250120 12:49:01 3554128 dinov2 helpers.py:102] Training  [ 8730/12500]  eta: 0:14:14  loss: 21.7932 (28.0618)  lr: 0.0000 (0.0000)  time: 0.197018  data: 0.000474  max mem: 3586
I20250120 12:49:03 3554128 dinov2 helpers.py:102] Training  [ 8740/12500]  eta: 0:14:12  loss: 21.7422 (28.0497)  lr: 0.0000 (0.0000)  time: 0.196931  data: 0.000491  max mem: 3586
I20250120 12:49:05 3554128 dinov2 linear.py:272] running validation !
I20250120 12:49:06 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:49    time: 1.478152  data: 1.277760  max mem: 3586
I20250120 12:49:08 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:46    time: 0.317976  data: 0.116587  max mem: 3586
I20250120 12:49:10 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:35    time: 0.201460  data: 0.000410  max mem: 3586
I20250120 12:49:12 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.200437  data: 0.000340  max mem: 3586
I20250120 12:49:14 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199848  data: 0.000295  max mem: 3586
I20250120 12:49:16 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.199843  data: 0.000310  max mem: 3586
I20250120 12:49:18 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.199873  data: 0.000292  max mem: 3586
I20250120 12:49:20 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199890  data: 0.000237  max mem: 3586
I20250120 12:49:22 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199909  data: 0.000252  max mem: 3586
I20250120 12:49:24 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.199712  data: 0.000248  max mem: 3586
I20250120 12:49:26 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199804  data: 0.000273  max mem: 3586
I20250120 12:49:28 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.200037  data: 0.000345  max mem: 3586
I20250120 12:49:30 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199965  data: 0.000306  max mem: 3586
I20250120 12:49:32 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199855  data: 0.000251  max mem: 3586
I20250120 12:49:34 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199707  data: 0.000293  max mem: 3586
I20250120 12:49:36 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199413  data: 0.000218  max mem: 3586
I20250120 12:49:37 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195539  data: 0.000201  max mem: 3586
I20250120 12:49:37 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208609 s / it)
I20250120 12:49:37 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:49:37 3554128 dinov2 linear.py:287] 
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7907, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8044, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8091, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8148, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8188, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8219, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8238, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8250, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8226, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8215, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8184, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8129, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7937, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8069, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8119, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8160, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8231, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8262, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8289, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8344, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8347, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8329, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8291, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8242, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8102, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8170, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8201, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8230, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8252, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8272, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8296, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8314, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8297, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8186, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8065, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7975, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8105, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8145, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8221, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8245, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8271, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8305, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8346, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8373, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8368, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8280, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8111, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7929, device='cuda:0')}
I20250120 12:49:37 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.8372575044631958}
I20250120 12:49:37 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:49:37 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:49:37 3554128 dinov2 helpers.py:102] Training  [ 8750/12500]  eta: 0:14:23  loss: 21.7932 (28.0448)  lr: 0.0000 (0.0000)  time: 1.818268  data: 0.000497  max mem: 3586
I20250120 12:49:39 3554128 dinov2 helpers.py:102] Training  [ 8760/12500]  eta: 0:14:21  loss: 21.7422 (28.0370)  lr: 0.0000 (0.0000)  time: 1.817499  data: 0.000489  max mem: 3586
I20250120 12:49:41 3554128 dinov2 helpers.py:102] Training  [ 8770/12500]  eta: 0:14:18  loss: 21.7932 (28.0306)  lr: 0.0000 (0.0000)  time: 0.195898  data: 0.000470  max mem: 3586
I20250120 12:49:43 3554128 dinov2 helpers.py:102] Training  [ 8780/12500]  eta: 0:14:16  loss: 21.7932 (28.0199)  lr: 0.0000 (0.0000)  time: 0.196380  data: 0.000408  max mem: 3586
I20250120 12:49:45 3554128 dinov2 helpers.py:102] Training  [ 8790/12500]  eta: 0:14:13  loss: 22.1853 (28.0181)  lr: 0.0000 (0.0000)  time: 0.196510  data: 0.000433  max mem: 3586
I20250120 12:49:47 3554128 dinov2 helpers.py:102] Training  [ 8800/12500]  eta: 0:14:11  loss: 21.7932 (28.0099)  lr: 0.0000 (0.0000)  time: 0.196720  data: 0.000490  max mem: 3586
I20250120 12:49:49 3554128 dinov2 helpers.py:102] Training  [ 8810/12500]  eta: 0:14:09  loss: 22.1853 (28.0059)  lr: 0.0000 (0.0000)  time: 0.196802  data: 0.000452  max mem: 3586
I20250120 12:49:51 3554128 dinov2 helpers.py:102] Training  [ 8820/12500]  eta: 0:14:06  loss: 22.1853 (28.0007)  lr: 0.0000 (0.0000)  time: 0.196885  data: 0.000453  max mem: 3586
I20250120 12:49:53 3554128 dinov2 helpers.py:102] Training  [ 8830/12500]  eta: 0:14:04  loss: 22.4151 (27.9959)  lr: 0.0000 (0.0000)  time: 0.196899  data: 0.000459  max mem: 3586
I20250120 12:49:55 3554128 dinov2 helpers.py:102] Training  [ 8840/12500]  eta: 0:14:01  loss: 22.4072 (27.9896)  lr: 0.0000 (0.0000)  time: 0.196988  data: 0.000459  max mem: 3586
I20250120 12:49:58 3554128 dinov2 helpers.py:102] Training  [ 8850/12500]  eta: 0:13:59  loss: 22.4072 (27.9852)  lr: 0.0000 (0.0000)  time: 0.221073  data: 0.027729  max mem: 3586
I20250120 12:49:59 3554128 dinov2 helpers.py:102] Training  [ 8860/12500]  eta: 0:13:57  loss: 22.4072 (27.9790)  lr: 0.0000 (0.0000)  time: 0.220894  data: 0.027721  max mem: 3586
I20250120 12:50:01 3554128 dinov2 helpers.py:102] Training  [ 8870/12500]  eta: 0:13:54  loss: 22.4072 (27.9717)  lr: 0.0000 (0.0000)  time: 0.196774  data: 0.000551  max mem: 3586
I20250120 12:50:03 3554128 dinov2 helpers.py:102] Training  [ 8880/12500]  eta: 0:13:52  loss: 22.4072 (27.9652)  lr: 0.0000 (0.0000)  time: 0.196931  data: 0.000576  max mem: 3586
I20250120 12:50:05 3554128 dinov2 helpers.py:102] Training  [ 8890/12500]  eta: 0:13:49  loss: 22.4072 (27.9592)  lr: 0.0000 (0.0000)  time: 0.197022  data: 0.000497  max mem: 3586
I20250120 12:50:15 3554128 dinov2 helpers.py:102] Training  [ 8900/12500]  eta: 0:13:50  loss: 22.4072 (27.9480)  lr: 0.0000 (0.0000)  time: 0.573989  data: 0.398602  max mem: 3586
I20250120 12:50:26 3554128 dinov2 helpers.py:102] Training  [ 8910/12500]  eta: 0:13:51  loss: 22.4151 (27.9420)  lr: 0.0000 (0.0000)  time: 1.051533  data: 0.902415  max mem: 3586
I20250120 12:50:35 3554128 dinov2 helpers.py:102] Training  [ 8920/12500]  eta: 0:13:51  loss: 22.4833 (27.9377)  lr: 0.0000 (0.0000)  time: 1.003893  data: 0.851859  max mem: 3586
I20250120 12:50:43 3554128 dinov2 helpers.py:102] Training  [ 8930/12500]  eta: 0:13:52  loss: 22.4833 (27.9356)  lr: 0.0000 (0.0000)  time: 0.844708  data: 0.680293  max mem: 3586
I20250120 12:50:48 3554128 dinov2 helpers.py:102] Training  [ 8940/12500]  eta: 0:13:50  loss: 22.6019 (27.9308)  lr: 0.0000 (0.0000)  time: 0.664236  data: 0.492670  max mem: 3586
I20250120 12:50:50 3554128 dinov2 helpers.py:102] Training  [ 8950/12500]  eta: 0:13:48  loss: 22.6019 (27.9249)  lr: 0.0000 (0.0000)  time: 0.341455  data: 0.160650  max mem: 3586
I20250120 12:50:52 3554128 dinov2 helpers.py:102] Training  [ 8960/12500]  eta: 0:13:45  loss: 22.6019 (27.9186)  lr: 0.0000 (0.0000)  time: 0.188602  data: 0.000729  max mem: 3586
I20250120 12:50:54 3554128 dinov2 helpers.py:102] Training  [ 8970/12500]  eta: 0:13:43  loss: 22.6019 (27.9108)  lr: 0.0000 (0.0000)  time: 0.189214  data: 0.000523  max mem: 3586
I20250120 12:50:56 3554128 dinov2 helpers.py:102] Training  [ 8980/12500]  eta: 0:13:40  loss: 22.6019 (27.9008)  lr: 0.0000 (0.0000)  time: 0.189627  data: 0.000509  max mem: 3586
I20250120 12:50:58 3554128 dinov2 helpers.py:102] Training  [ 8990/12500]  eta: 0:13:38  loss: 22.6019 (27.8960)  lr: 0.0000 (0.0000)  time: 0.190197  data: 0.000465  max mem: 3586
I20250120 12:51:00 3554128 dinov2 helpers.py:102] Training  [ 9000/12500]  eta: 0:13:35  loss: 22.6138 (27.8912)  lr: 0.0000 (0.0000)  time: 0.190428  data: 0.000458  max mem: 3586
I20250120 12:51:02 3554128 dinov2 helpers.py:102] Training  [ 9010/12500]  eta: 0:13:33  loss: 22.6138 (27.8872)  lr: 0.0000 (0.0000)  time: 0.190784  data: 0.000486  max mem: 3586
I20250120 12:51:03 3554128 dinov2 helpers.py:102] Training  [ 9020/12500]  eta: 0:13:30  loss: 22.6138 (27.8851)  lr: 0.0000 (0.0000)  time: 0.191407  data: 0.000493  max mem: 3586
I20250120 12:51:05 3554128 dinov2 helpers.py:102] Training  [ 9030/12500]  eta: 0:13:28  loss: 22.6138 (27.8813)  lr: 0.0000 (0.0000)  time: 0.191695  data: 0.000492  max mem: 3586
I20250120 12:51:07 3554128 dinov2 helpers.py:102] Training  [ 9040/12500]  eta: 0:13:25  loss: 22.6183 (27.8793)  lr: 0.0000 (0.0000)  time: 0.191965  data: 0.000457  max mem: 3586
I20250120 12:51:09 3554128 dinov2 helpers.py:102] Training  [ 9050/12500]  eta: 0:13:23  loss: 22.6183 (27.8740)  lr: 0.0000 (0.0000)  time: 0.192168  data: 0.000478  max mem: 3586
I20250120 12:51:11 3554128 dinov2 helpers.py:102] Training  [ 9060/12500]  eta: 0:13:20  loss: 22.6183 (27.8637)  lr: 0.0000 (0.0000)  time: 0.192591  data: 0.000493  max mem: 3586
I20250120 12:51:13 3554128 dinov2 helpers.py:102] Training  [ 9070/12500]  eta: 0:13:18  loss: 22.6183 (27.8540)  lr: 0.0000 (0.0000)  time: 0.193172  data: 0.000467  max mem: 3586
I20250120 12:51:15 3554128 dinov2 helpers.py:102] Training  [ 9080/12500]  eta: 0:13:15  loss: 22.6183 (27.8477)  lr: 0.0000 (0.0000)  time: 0.193478  data: 0.000493  max mem: 3586
I20250120 12:51:17 3554128 dinov2 helpers.py:102] Training  [ 9090/12500]  eta: 0:13:13  loss: 22.6183 (27.8395)  lr: 0.0000 (0.0000)  time: 0.193781  data: 0.000496  max mem: 3586
I20250120 12:51:19 3554128 dinov2 helpers.py:102] Training  [ 9100/12500]  eta: 0:13:10  loss: 22.6183 (27.8288)  lr: 0.0000 (0.0000)  time: 0.194026  data: 0.000473  max mem: 3586
I20250120 12:51:21 3554128 dinov2 helpers.py:102] Training  [ 9110/12500]  eta: 0:13:08  loss: 22.7685 (27.8233)  lr: 0.0000 (0.0000)  time: 0.194137  data: 0.000481  max mem: 3586
I20250120 12:51:23 3554128 dinov2 helpers.py:102] Training  [ 9120/12500]  eta: 0:13:05  loss: 22.7685 (27.8201)  lr: 0.0000 (0.0000)  time: 0.194308  data: 0.000459  max mem: 3586
I20250120 12:51:25 3554128 dinov2 helpers.py:102] Training  [ 9130/12500]  eta: 0:13:03  loss: 22.6183 (27.8113)  lr: 0.0000 (0.0000)  time: 0.194584  data: 0.000422  max mem: 3586
I20250120 12:51:27 3554128 dinov2 helpers.py:102] Training  [ 9140/12500]  eta: 0:13:01  loss: 22.6183 (27.8064)  lr: 0.0000 (0.0000)  time: 0.194627  data: 0.000430  max mem: 3586
I20250120 12:51:29 3554128 dinov2 helpers.py:102] Training  [ 9150/12500]  eta: 0:12:58  loss: 22.3312 (27.8004)  lr: 0.0000 (0.0000)  time: 0.194553  data: 0.000454  max mem: 3586
I20250120 12:51:31 3554128 dinov2 helpers.py:102] Training  [ 9160/12500]  eta: 0:12:56  loss: 22.4777 (27.7946)  lr: 0.0000 (0.0000)  time: 0.194724  data: 0.000481  max mem: 3586
I20250120 12:51:33 3554128 dinov2 helpers.py:102] Training  [ 9170/12500]  eta: 0:12:53  loss: 22.7685 (27.7894)  lr: 0.0000 (0.0000)  time: 0.195023  data: 0.000486  max mem: 3586
I20250120 12:51:35 3554128 dinov2 helpers.py:102] Training  [ 9180/12500]  eta: 0:12:51  loss: 22.7685 (27.7824)  lr: 0.0000 (0.0000)  time: 0.195096  data: 0.000460  max mem: 3586
I20250120 12:51:36 3554128 dinov2 helpers.py:102] Training  [ 9190/12500]  eta: 0:12:48  loss: 22.7685 (27.7792)  lr: 0.0000 (0.0000)  time: 0.195130  data: 0.000467  max mem: 3586
I20250120 12:51:38 3554128 dinov2 helpers.py:102] Training  [ 9200/12500]  eta: 0:12:46  loss: 22.7201 (27.7737)  lr: 0.0000 (0.0000)  time: 0.195255  data: 0.000489  max mem: 3586
I20250120 12:51:40 3554128 dinov2 helpers.py:102] Training  [ 9210/12500]  eta: 0:12:43  loss: 22.4777 (27.7664)  lr: 0.0000 (0.0000)  time: 0.195341  data: 0.000459  max mem: 3586
I20250120 12:51:42 3554128 dinov2 helpers.py:102] Training  [ 9220/12500]  eta: 0:12:41  loss: 22.3312 (27.7604)  lr: 0.0000 (0.0000)  time: 0.195366  data: 0.000438  max mem: 3586
I20250120 12:51:44 3554128 dinov2 helpers.py:102] Training  [ 9230/12500]  eta: 0:12:38  loss: 22.3312 (27.7577)  lr: 0.0000 (0.0000)  time: 0.195515  data: 0.000463  max mem: 3586
I20250120 12:51:46 3554128 dinov2 helpers.py:102] Training  [ 9240/12500]  eta: 0:12:36  loss: 22.3312 (27.7519)  lr: 0.0000 (0.0000)  time: 0.195810  data: 0.000480  max mem: 3586
I20250120 12:51:48 3554128 dinov2 helpers.py:102] Training  [ 9250/12500]  eta: 0:12:34  loss: 22.3312 (27.7473)  lr: 0.0000 (0.0000)  time: 0.195931  data: 0.000462  max mem: 3586
I20250120 12:51:50 3554128 dinov2 helpers.py:102] Training  [ 9260/12500]  eta: 0:12:31  loss: 22.4103 (27.7445)  lr: 0.0000 (0.0000)  time: 0.195847  data: 0.000457  max mem: 3586
I20250120 12:51:52 3554128 dinov2 helpers.py:102] Training  [ 9270/12500]  eta: 0:12:29  loss: 22.4103 (27.7382)  lr: 0.0000 (0.0000)  time: 0.195792  data: 0.000472  max mem: 3586
I20250120 12:51:54 3554128 dinov2 helpers.py:102] Training  [ 9280/12500]  eta: 0:12:26  loss: 22.4103 (27.7316)  lr: 0.0000 (0.0000)  time: 0.195916  data: 0.000494  max mem: 3586
I20250120 12:51:56 3554128 dinov2 helpers.py:102] Training  [ 9290/12500]  eta: 0:12:24  loss: 22.4103 (27.7213)  lr: 0.0000 (0.0000)  time: 0.195992  data: 0.000470  max mem: 3586
I20250120 12:51:58 3554128 dinov2 helpers.py:102] Training  [ 9300/12500]  eta: 0:12:21  loss: 22.4103 (27.7150)  lr: 0.0000 (0.0000)  time: 0.196120  data: 0.000465  max mem: 3586
I20250120 12:52:00 3554128 dinov2 helpers.py:102] Training  [ 9310/12500]  eta: 0:12:19  loss: 22.4103 (27.7100)  lr: 0.0000 (0.0000)  time: 0.196265  data: 0.000463  max mem: 3586
I20250120 12:52:02 3554128 dinov2 helpers.py:102] Training  [ 9320/12500]  eta: 0:12:16  loss: 22.4103 (27.7046)  lr: 0.0000 (0.0000)  time: 0.196164  data: 0.000446  max mem: 3586
I20250120 12:52:04 3554128 dinov2 helpers.py:102] Training  [ 9330/12500]  eta: 0:12:14  loss: 22.4103 (27.6963)  lr: 0.0000 (0.0000)  time: 0.196198  data: 0.000448  max mem: 3586
I20250120 12:52:06 3554128 dinov2 helpers.py:102] Training  [ 9340/12500]  eta: 0:12:12  loss: 22.3312 (27.6901)  lr: 0.0000 (0.0000)  time: 0.196317  data: 0.000401  max mem: 3586
I20250120 12:52:08 3554128 dinov2 helpers.py:102] Training  [ 9350/12500]  eta: 0:12:09  loss: 22.2892 (27.6831)  lr: 0.0000 (0.0000)  time: 0.196413  data: 0.000452  max mem: 3586
I20250120 12:52:10 3554128 dinov2 helpers.py:102] Training  [ 9360/12500]  eta: 0:12:07  loss: 22.2892 (27.6822)  lr: 0.0000 (0.0000)  time: 0.196496  data: 0.000468  max mem: 3586
I20250120 12:52:12 3554128 dinov2 helpers.py:102] Training  [ 9370/12500]  eta: 0:12:04  loss: 21.8843 (27.6740)  lr: 0.0000 (0.0000)  time: 0.196512  data: 0.000452  max mem: 3586
I20250120 12:52:14 3554128 dinov2 helpers.py:102] Training  [ 9380/12500]  eta: 0:12:02  loss: 21.8843 (27.6665)  lr: 0.0000 (0.0000)  time: 0.196682  data: 0.000496  max mem: 3586
I20250120 12:52:16 3554128 dinov2 helpers.py:102] Training  [ 9390/12500]  eta: 0:11:59  loss: 21.8843 (27.6619)  lr: 0.0000 (0.0000)  time: 0.196662  data: 0.000494  max mem: 3586
I20250120 12:52:18 3554128 dinov2 helpers.py:102] Training  [ 9400/12500]  eta: 0:11:57  loss: 21.8480 (27.6530)  lr: 0.0000 (0.0000)  time: 0.196667  data: 0.000480  max mem: 3586
I20250120 12:52:20 3554128 dinov2 helpers.py:102] Training  [ 9410/12500]  eta: 0:11:55  loss: 21.8843 (27.6494)  lr: 0.0000 (0.0000)  time: 0.196705  data: 0.000481  max mem: 3586
I20250120 12:52:22 3554128 dinov2 helpers.py:102] Training  [ 9420/12500]  eta: 0:11:52  loss: 21.8843 (27.6454)  lr: 0.0000 (0.0000)  time: 0.196816  data: 0.000486  max mem: 3586
I20250120 12:52:24 3554128 dinov2 helpers.py:102] Training  [ 9430/12500]  eta: 0:11:50  loss: 21.8843 (27.6410)  lr: 0.0000 (0.0000)  time: 0.197098  data: 0.000477  max mem: 3586
I20250120 12:52:26 3554128 dinov2 helpers.py:102] Training  [ 9440/12500]  eta: 0:11:47  loss: 21.8480 (27.6348)  lr: 0.0000 (0.0000)  time: 0.197074  data: 0.000477  max mem: 3586
I20250120 12:52:28 3554128 dinov2 helpers.py:102] Training  [ 9450/12500]  eta: 0:11:45  loss: 21.8480 (27.6292)  lr: 0.0000 (0.0000)  time: 0.196838  data: 0.000456  max mem: 3586
I20250120 12:52:29 3554128 dinov2 helpers.py:102] Training  [ 9460/12500]  eta: 0:11:42  loss: 21.8480 (27.6235)  lr: 0.0000 (0.0000)  time: 0.196902  data: 0.000468  max mem: 3586
I20250120 12:52:31 3554128 dinov2 helpers.py:102] Training  [ 9470/12500]  eta: 0:11:40  loss: 21.8480 (27.6221)  lr: 0.0000 (0.0000)  time: 0.196834  data: 0.000503  max mem: 3586
I20250120 12:52:33 3554128 dinov2 helpers.py:102] Training  [ 9480/12500]  eta: 0:11:38  loss: 22.2046 (27.6174)  lr: 0.0000 (0.0000)  time: 0.196630  data: 0.000486  max mem: 3586
I20250120 12:52:35 3554128 dinov2 helpers.py:102] Training  [ 9490/12500]  eta: 0:11:35  loss: 22.3797 (27.6156)  lr: 0.0000 (0.0000)  time: 0.196673  data: 0.000457  max mem: 3586
I20250120 12:52:37 3554128 dinov2 helpers.py:102] Training  [ 9500/12500]  eta: 0:11:33  loss: 22.6882 (27.6110)  lr: 0.0000 (0.0000)  time: 0.196706  data: 0.000434  max mem: 3586
I20250120 12:52:39 3554128 dinov2 helpers.py:102] Training  [ 9510/12500]  eta: 0:11:30  loss: 22.3797 (27.6035)  lr: 0.0000 (0.0000)  time: 0.196938  data: 0.000437  max mem: 3586
I20250120 12:52:41 3554128 dinov2 helpers.py:102] Training  [ 9520/12500]  eta: 0:11:28  loss: 22.2046 (27.5939)  lr: 0.0000 (0.0000)  time: 0.197061  data: 0.000492  max mem: 3586
I20250120 12:52:43 3554128 dinov2 helpers.py:102] Training  [ 9530/12500]  eta: 0:11:25  loss: 22.2046 (27.5874)  lr: 0.0000 (0.0000)  time: 0.197092  data: 0.000521  max mem: 3586
I20250120 12:52:45 3554128 dinov2 helpers.py:102] Training  [ 9540/12500]  eta: 0:11:23  loss: 22.2046 (27.5803)  lr: 0.0000 (0.0000)  time: 0.197112  data: 0.000475  max mem: 3586
I20250120 12:52:47 3554128 dinov2 helpers.py:102] Training  [ 9550/12500]  eta: 0:11:21  loss: 22.3797 (27.5793)  lr: 0.0000 (0.0000)  time: 0.196947  data: 0.000441  max mem: 3586
I20250120 12:52:49 3554128 dinov2 helpers.py:102] Training  [ 9560/12500]  eta: 0:11:18  loss: 22.3797 (27.5744)  lr: 0.0000 (0.0000)  time: 0.196982  data: 0.000460  max mem: 3586
I20250120 12:52:51 3554128 dinov2 helpers.py:102] Training  [ 9570/12500]  eta: 0:11:16  loss: 22.3797 (27.5652)  lr: 0.0000 (0.0000)  time: 0.197136  data: 0.000484  max mem: 3586
I20250120 12:52:53 3554128 dinov2 helpers.py:102] Training  [ 9580/12500]  eta: 0:11:13  loss: 22.8595 (27.5605)  lr: 0.0000 (0.0000)  time: 0.197192  data: 0.000485  max mem: 3586
I20250120 12:52:55 3554128 dinov2 helpers.py:102] Training  [ 9590/12500]  eta: 0:11:11  loss: 22.3797 (27.5537)  lr: 0.0000 (0.0000)  time: 0.197290  data: 0.000429  max mem: 3586
I20250120 12:52:57 3554128 dinov2 helpers.py:102] Training  [ 9600/12500]  eta: 0:11:09  loss: 22.3797 (27.5483)  lr: 0.0000 (0.0000)  time: 0.197223  data: 0.000430  max mem: 3586
I20250120 12:52:59 3554128 dinov2 helpers.py:102] Training  [ 9610/12500]  eta: 0:11:06  loss: 22.3797 (27.5436)  lr: 0.0000 (0.0000)  time: 0.197087  data: 0.000489  max mem: 3586
I20250120 12:53:01 3554128 dinov2 helpers.py:102] Training  [ 9620/12500]  eta: 0:11:04  loss: 22.3797 (27.5418)  lr: 0.0000 (0.0000)  time: 0.197140  data: 0.000499  max mem: 3586
I20250120 12:53:03 3554128 dinov2 helpers.py:102] Training  [ 9630/12500]  eta: 0:11:01  loss: 22.3454 (27.5352)  lr: 0.0000 (0.0000)  time: 0.197072  data: 0.000474  max mem: 3586
I20250120 12:53:05 3554128 dinov2 helpers.py:102] Training  [ 9640/12500]  eta: 0:10:59  loss: 22.3601 (27.5298)  lr: 0.0000 (0.0000)  time: 0.197019  data: 0.000460  max mem: 3586
I20250120 12:53:07 3554128 dinov2 helpers.py:102] Training  [ 9650/12500]  eta: 0:10:57  loss: 22.3454 (27.5209)  lr: 0.0000 (0.0000)  time: 0.197222  data: 0.000477  max mem: 3586
I20250120 12:53:09 3554128 dinov2 helpers.py:102] Training  [ 9660/12500]  eta: 0:10:54  loss: 22.3601 (27.5186)  lr: 0.0000 (0.0000)  time: 0.197295  data: 0.000499  max mem: 3586
I20250120 12:53:11 3554128 dinov2 helpers.py:102] Training  [ 9670/12500]  eta: 0:10:52  loss: 22.3601 (27.5168)  lr: 0.0000 (0.0000)  time: 0.197232  data: 0.000532  max mem: 3586
I20250120 12:53:13 3554128 dinov2 helpers.py:102] Training  [ 9680/12500]  eta: 0:10:49  loss: 22.3454 (27.5092)  lr: 0.0000 (0.0000)  time: 0.197233  data: 0.000555  max mem: 3586
I20250120 12:53:15 3554128 dinov2 helpers.py:102] Training  [ 9690/12500]  eta: 0:10:47  loss: 21.4334 (27.5011)  lr: 0.0000 (0.0000)  time: 0.197211  data: 0.000511  max mem: 3586
I20250120 12:53:17 3554128 dinov2 helpers.py:102] Training  [ 9700/12500]  eta: 0:10:45  loss: 21.4334 (27.4956)  lr: 0.0000 (0.0000)  time: 0.197191  data: 0.000444  max mem: 3586
I20250120 12:53:19 3554128 dinov2 helpers.py:102] Training  [ 9710/12500]  eta: 0:10:42  loss: 22.1875 (27.4923)  lr: 0.0000 (0.0000)  time: 0.197316  data: 0.000436  max mem: 3586
I20250120 12:53:21 3554128 dinov2 helpers.py:102] Training  [ 9720/12500]  eta: 0:10:40  loss: 22.1875 (27.4855)  lr: 0.0000 (0.0000)  time: 0.197255  data: 0.000519  max mem: 3586
I20250120 12:53:23 3554128 dinov2 helpers.py:102] Training  [ 9730/12500]  eta: 0:10:37  loss: 22.1875 (27.4800)  lr: 0.0000 (0.0000)  time: 0.197034  data: 0.000531  max mem: 3586
I20250120 12:53:25 3554128 dinov2 helpers.py:102] Training  [ 9740/12500]  eta: 0:10:35  loss: 22.3454 (27.4759)  lr: 0.0000 (0.0000)  time: 0.197044  data: 0.000495  max mem: 3586
I20250120 12:53:27 3554128 dinov2 helpers.py:102] Training  [ 9750/12500]  eta: 0:10:33  loss: 22.3454 (27.4710)  lr: 0.0000 (0.0000)  time: 0.197074  data: 0.000512  max mem: 3586
I20250120 12:53:29 3554128 dinov2 helpers.py:102] Training  [ 9760/12500]  eta: 0:10:30  loss: 22.3454 (27.4670)  lr: 0.0000 (0.0000)  time: 0.197145  data: 0.000487  max mem: 3586
I20250120 12:53:31 3554128 dinov2 helpers.py:102] Training  [ 9770/12500]  eta: 0:10:28  loss: 22.3601 (27.4641)  lr: 0.0000 (0.0000)  time: 0.197106  data: 0.000450  max mem: 3586
I20250120 12:53:33 3554128 dinov2 helpers.py:102] Training  [ 9780/12500]  eta: 0:10:25  loss: 22.3454 (27.4554)  lr: 0.0000 (0.0000)  time: 0.196998  data: 0.000458  max mem: 3586
I20250120 12:53:35 3554128 dinov2 helpers.py:102] Training  [ 9790/12500]  eta: 0:10:23  loss: 22.3454 (27.4494)  lr: 0.0000 (0.0000)  time: 0.196906  data: 0.000485  max mem: 3586
I20250120 12:53:37 3554128 dinov2 helpers.py:102] Training  [ 9800/12500]  eta: 0:10:21  loss: 22.1875 (27.4428)  lr: 0.0000 (0.0000)  time: 0.196837  data: 0.000465  max mem: 3586
I20250120 12:53:38 3554128 dinov2 helpers.py:102] Training  [ 9810/12500]  eta: 0:10:18  loss: 22.1875 (27.4382)  lr: 0.0000 (0.0000)  time: 0.197032  data: 0.000447  max mem: 3586
I20250120 12:53:40 3554128 dinov2 helpers.py:102] Training  [ 9820/12500]  eta: 0:10:16  loss: 22.1875 (27.4339)  lr: 0.0000 (0.0000)  time: 0.196975  data: 0.000457  max mem: 3586
I20250120 12:53:42 3554128 dinov2 helpers.py:102] Training  [ 9830/12500]  eta: 0:10:13  loss: 22.3601 (27.4307)  lr: 0.0000 (0.0000)  time: 0.196852  data: 0.000454  max mem: 3586
I20250120 12:53:44 3554128 dinov2 helpers.py:102] Training  [ 9840/12500]  eta: 0:10:11  loss: 22.1875 (27.4250)  lr: 0.0000 (0.0000)  time: 0.196829  data: 0.000378  max mem: 3586
I20250120 12:53:46 3554128 dinov2 helpers.py:102] Training  [ 9850/12500]  eta: 0:10:09  loss: 22.7009 (27.4208)  lr: 0.0000 (0.0000)  time: 0.196987  data: 0.000406  max mem: 3586
I20250120 12:53:48 3554128 dinov2 helpers.py:102] Training  [ 9860/12500]  eta: 0:10:06  loss: 22.1875 (27.4117)  lr: 0.0000 (0.0000)  time: 0.197193  data: 0.000524  max mem: 3586
I20250120 12:53:50 3554128 dinov2 helpers.py:102] Training  [ 9870/12500]  eta: 0:10:04  loss: 22.1855 (27.4051)  lr: 0.0000 (0.0000)  time: 0.197079  data: 0.000482  max mem: 3586
I20250120 12:53:52 3554128 dinov2 helpers.py:102] Training  [ 9880/12500]  eta: 0:10:02  loss: 22.1875 (27.4033)  lr: 0.0000 (0.0000)  time: 0.197082  data: 0.000442  max mem: 3586
I20250120 12:53:54 3554128 dinov2 helpers.py:102] Training  [ 9890/12500]  eta: 0:09:59  loss: 22.5544 (27.3984)  lr: 0.0000 (0.0000)  time: 0.197151  data: 0.000458  max mem: 3586
I20250120 12:53:56 3554128 dinov2 helpers.py:102] Training  [ 9900/12500]  eta: 0:09:57  loss: 22.7009 (27.3942)  lr: 0.0000 (0.0000)  time: 0.197128  data: 0.000425  max mem: 3586
I20250120 12:53:58 3554128 dinov2 helpers.py:102] Training  [ 9910/12500]  eta: 0:09:54  loss: 22.5544 (27.3886)  lr: 0.0000 (0.0000)  time: 0.197101  data: 0.000455  max mem: 3586
I20250120 12:54:00 3554128 dinov2 helpers.py:102] Training  [ 9920/12500]  eta: 0:09:52  loss: 22.5887 (27.3838)  lr: 0.0000 (0.0000)  time: 0.196955  data: 0.000494  max mem: 3586
I20250120 12:54:02 3554128 dinov2 helpers.py:102] Training  [ 9930/12500]  eta: 0:09:50  loss: 22.5887 (27.3770)  lr: 0.0000 (0.0000)  time: 0.197010  data: 0.000472  max mem: 3586
I20250120 12:54:04 3554128 dinov2 helpers.py:102] Training  [ 9940/12500]  eta: 0:09:47  loss: 22.5887 (27.3745)  lr: 0.0000 (0.0000)  time: 0.197104  data: 0.000471  max mem: 3586
I20250120 12:54:06 3554128 dinov2 helpers.py:102] Training  [ 9950/12500]  eta: 0:09:45  loss: 22.5887 (27.3712)  lr: 0.0000 (0.0000)  time: 0.197256  data: 0.000492  max mem: 3586
I20250120 12:54:08 3554128 dinov2 helpers.py:102] Training  [ 9960/12500]  eta: 0:09:42  loss: 22.5544 (27.3658)  lr: 0.0000 (0.0000)  time: 0.197430  data: 0.000478  max mem: 3586
I20250120 12:54:10 3554128 dinov2 helpers.py:102] Training  [ 9970/12500]  eta: 0:09:40  loss: 22.2279 (27.3606)  lr: 0.0000 (0.0000)  time: 0.197451  data: 0.000454  max mem: 3586
I20250120 12:54:12 3554128 dinov2 helpers.py:102] Training  [ 9980/12500]  eta: 0:09:38  loss: 22.2279 (27.3535)  lr: 0.0000 (0.0000)  time: 0.197393  data: 0.000476  max mem: 3586
I20250120 12:54:14 3554128 dinov2 helpers.py:102] Training  [ 9990/12500]  eta: 0:09:35  loss: 22.2279 (27.3469)  lr: 0.0000 (0.0000)  time: 0.197231  data: 0.000503  max mem: 3586
I20250120 12:54:16 3554128 dinov2 linear.py:272] running validation !
I20250120 12:54:17 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:25    time: 1.328075  data: 1.119697  max mem: 3586
I20250120 12:54:19 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:44    time: 0.306177  data: 0.105932  max mem: 3586
I20250120 12:54:21 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:34    time: 0.204059  data: 0.002626  max mem: 3586
I20250120 12:54:23 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:29    time: 0.201784  data: 0.000469  max mem: 3586
I20250120 12:54:25 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199947  data: 0.000238  max mem: 3586
I20250120 12:54:27 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.200091  data: 0.000247  max mem: 3586
I20250120 12:54:29 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:20    time: 0.199861  data: 0.000241  max mem: 3586
I20250120 12:54:31 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.200004  data: 0.000271  max mem: 3586
I20250120 12:54:33 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199862  data: 0.000292  max mem: 3586
I20250120 12:54:35 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.199804  data: 0.000272  max mem: 3586
I20250120 12:54:37 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199926  data: 0.000302  max mem: 3586
I20250120 12:54:39 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199641  data: 0.000334  max mem: 3586
I20250120 12:54:41 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199765  data: 0.000314  max mem: 3586
I20250120 12:54:43 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.200070  data: 0.000274  max mem: 3586
I20250120 12:54:45 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199781  data: 0.000287  max mem: 3586
I20250120 12:54:47 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199557  data: 0.000218  max mem: 3586
I20250120 12:54:48 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195730  data: 0.000195  max mem: 3586
I20250120 12:54:48 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208013 s / it)
I20250120 12:54:48 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:54:48 3554128 dinov2 linear.py:287] 
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7911, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8046, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8096, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8146, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8191, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8227, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8241, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8254, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8266, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8259, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8231, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8208, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7942, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8073, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8127, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8167, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8231, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8293, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8339, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8361, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8362, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8326, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8340, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8106, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8174, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8207, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8226, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8264, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8294, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8318, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8319, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8319, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8271, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8216, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8134, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8111, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8151, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8229, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8242, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8287, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8317, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8361, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8384, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8395, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8349, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8313, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8233, device='cuda:0')}
I20250120 12:54:48 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8394805788993835}
I20250120 12:54:48 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:54:48 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:54:48 3554128 dinov2 helpers.py:102] Training  [10000/12500]  eta: 0:09:41  loss: 22.4568 (27.3420)  lr: 0.0000 (0.0000)  time: 1.813854  data: 0.000449  max mem: 3586
I20250120 12:54:50 3554128 dinov2 helpers.py:102] Training  [10010/12500]  eta: 0:09:39  loss: 22.2279 (27.3355)  lr: 0.0000 (0.0000)  time: 1.812920  data: 0.000425  max mem: 3586
I20250120 12:54:52 3554128 dinov2 helpers.py:102] Training  [10020/12500]  eta: 0:09:36  loss: 22.2279 (27.3343)  lr: 0.0000 (0.0000)  time: 0.196120  data: 0.000447  max mem: 3586
I20250120 12:54:54 3554128 dinov2 helpers.py:102] Training  [10030/12500]  eta: 0:09:34  loss: 21.9411 (27.3247)  lr: 0.0000 (0.0000)  time: 0.197053  data: 0.000472  max mem: 3586
I20250120 12:54:56 3554128 dinov2 helpers.py:102] Training  [10040/12500]  eta: 0:09:31  loss: 22.2279 (27.3208)  lr: 0.0000 (0.0000)  time: 0.197100  data: 0.000478  max mem: 3586
I20250120 12:54:58 3554128 dinov2 helpers.py:102] Training  [10050/12500]  eta: 0:09:29  loss: 21.9411 (27.3137)  lr: 0.0000 (0.0000)  time: 0.197099  data: 0.000460  max mem: 3586
I20250120 12:55:00 3554128 dinov2 helpers.py:102] Training  [10060/12500]  eta: 0:09:27  loss: 21.9411 (27.3063)  lr: 0.0000 (0.0000)  time: 0.197068  data: 0.000473  max mem: 3586
I20250120 12:55:02 3554128 dinov2 helpers.py:102] Training  [10070/12500]  eta: 0:09:24  loss: 22.2279 (27.3044)  lr: 0.0000 (0.0000)  time: 0.196935  data: 0.000425  max mem: 3586
I20250120 12:55:04 3554128 dinov2 helpers.py:102] Training  [10080/12500]  eta: 0:09:22  loss: 22.2279 (27.3014)  lr: 0.0000 (0.0000)  time: 0.197222  data: 0.000400  max mem: 3586
I20250120 12:55:06 3554128 dinov2 helpers.py:102] Training  [10090/12500]  eta: 0:09:19  loss: 21.9411 (27.2949)  lr: 0.0000 (0.0000)  time: 0.197323  data: 0.000455  max mem: 3586
I20250120 12:55:08 3554128 dinov2 helpers.py:102] Training  [10100/12500]  eta: 0:09:17  loss: 21.8540 (27.2879)  lr: 0.0000 (0.0000)  time: 0.197164  data: 0.000492  max mem: 3586
I20250120 12:55:10 3554128 dinov2 helpers.py:102] Training  [10110/12500]  eta: 0:09:15  loss: 20.8787 (27.2806)  lr: 0.0000 (0.0000)  time: 0.197112  data: 0.000475  max mem: 3586
I20250120 12:55:12 3554128 dinov2 helpers.py:102] Training  [10120/12500]  eta: 0:09:12  loss: 20.8787 (27.2780)  lr: 0.0000 (0.0000)  time: 0.221315  data: 0.028259  max mem: 3586
I20250120 12:55:14 3554128 dinov2 helpers.py:102] Training  [10130/12500]  eta: 0:09:10  loss: 21.9411 (27.2735)  lr: 0.0000 (0.0000)  time: 0.221154  data: 0.028244  max mem: 3586
I20250120 12:55:16 3554128 dinov2 helpers.py:102] Training  [10140/12500]  eta: 0:09:07  loss: 21.9411 (27.2689)  lr: 0.0000 (0.0000)  time: 0.196917  data: 0.000427  max mem: 3586
I20250120 12:55:18 3554128 dinov2 helpers.py:102] Training  [10150/12500]  eta: 0:09:05  loss: 21.9411 (27.2648)  lr: 0.0000 (0.0000)  time: 0.196957  data: 0.000445  max mem: 3586
I20250120 12:55:20 3554128 dinov2 helpers.py:102] Training  [10160/12500]  eta: 0:09:03  loss: 22.2279 (27.2605)  lr: 0.0000 (0.0000)  time: 0.196803  data: 0.000454  max mem: 3586
I20250120 12:55:25 3554128 dinov2 helpers.py:102] Training  [10170/12500]  eta: 0:09:01  loss: 22.4568 (27.2571)  lr: 0.0000 (0.0000)  time: 0.321615  data: 0.128677  max mem: 3586
I20250120 12:55:29 3554128 dinov2 helpers.py:102] Training  [10180/12500]  eta: 0:08:59  loss: 22.4568 (27.2501)  lr: 0.0000 (0.0000)  time: 0.416992  data: 0.241907  max mem: 3586
I20250120 12:55:31 3554128 dinov2 helpers.py:102] Training  [10190/12500]  eta: 0:08:56  loss: 22.4568 (27.2433)  lr: 0.0000 (0.0000)  time: 0.291016  data: 0.113997  max mem: 3586
I20250120 12:55:33 3554128 dinov2 helpers.py:102] Training  [10200/12500]  eta: 0:08:54  loss: 20.8787 (27.2359)  lr: 0.0000 (0.0000)  time: 0.194534  data: 0.000779  max mem: 3586
I20250120 12:55:34 3554128 dinov2 helpers.py:102] Training  [10210/12500]  eta: 0:08:52  loss: 22.5254 (27.2321)  lr: 0.0000 (0.0000)  time: 0.194556  data: 0.000423  max mem: 3586
I20250120 12:55:36 3554128 dinov2 helpers.py:102] Training  [10220/12500]  eta: 0:08:49  loss: 21.2658 (27.2262)  lr: 0.0000 (0.0000)  time: 0.195062  data: 0.000405  max mem: 3586
I20250120 12:55:38 3554128 dinov2 helpers.py:102] Training  [10230/12500]  eta: 0:08:47  loss: 21.2658 (27.2202)  lr: 0.0000 (0.0000)  time: 0.195551  data: 0.000434  max mem: 3586
I20250120 12:55:40 3554128 dinov2 helpers.py:102] Training  [10240/12500]  eta: 0:08:44  loss: 21.2658 (27.2163)  lr: 0.0000 (0.0000)  time: 0.195551  data: 0.000444  max mem: 3586
I20250120 12:55:42 3554128 dinov2 helpers.py:102] Training  [10250/12500]  eta: 0:08:42  loss: 22.4679 (27.2117)  lr: 0.0000 (0.0000)  time: 0.195815  data: 0.000468  max mem: 3586
I20250120 12:55:44 3554128 dinov2 helpers.py:102] Training  [10260/12500]  eta: 0:08:40  loss: 22.4679 (27.2056)  lr: 0.0000 (0.0000)  time: 0.195992  data: 0.000477  max mem: 3586
I20250120 12:55:46 3554128 dinov2 helpers.py:102] Training  [10270/12500]  eta: 0:08:37  loss: 22.4679 (27.2026)  lr: 0.0000 (0.0000)  time: 0.195933  data: 0.000449  max mem: 3586
I20250120 12:55:48 3554128 dinov2 helpers.py:102] Training  [10280/12500]  eta: 0:08:35  loss: 21.2658 (27.1960)  lr: 0.0000 (0.0000)  time: 0.195898  data: 0.000435  max mem: 3586
I20250120 12:55:50 3554128 dinov2 helpers.py:102] Training  [10290/12500]  eta: 0:08:32  loss: 22.0860 (27.1911)  lr: 0.0000 (0.0000)  time: 0.195898  data: 0.000426  max mem: 3586
I20250120 12:55:52 3554128 dinov2 helpers.py:102] Training  [10300/12500]  eta: 0:08:30  loss: 22.4679 (27.1866)  lr: 0.0000 (0.0000)  time: 0.196067  data: 0.000449  max mem: 3586
I20250120 12:55:54 3554128 dinov2 helpers.py:102] Training  [10310/12500]  eta: 0:08:28  loss: 22.5254 (27.1830)  lr: 0.0000 (0.0000)  time: 0.196147  data: 0.000493  max mem: 3586
I20250120 12:55:56 3554128 dinov2 helpers.py:102] Training  [10320/12500]  eta: 0:08:25  loss: 22.4679 (27.1777)  lr: 0.0000 (0.0000)  time: 0.196105  data: 0.000448  max mem: 3586
I20250120 12:55:58 3554128 dinov2 helpers.py:102] Training  [10330/12500]  eta: 0:08:23  loss: 22.4538 (27.1731)  lr: 0.0000 (0.0000)  time: 0.196220  data: 0.000408  max mem: 3586
I20250120 12:56:00 3554128 dinov2 helpers.py:102] Training  [10340/12500]  eta: 0:08:20  loss: 22.4538 (27.1697)  lr: 0.0000 (0.0000)  time: 0.196297  data: 0.000414  max mem: 3586
I20250120 12:56:02 3554128 dinov2 helpers.py:102] Training  [10350/12500]  eta: 0:08:18  loss: 22.4538 (27.1674)  lr: 0.0000 (0.0000)  time: 0.196388  data: 0.000441  max mem: 3586
I20250120 12:56:04 3554128 dinov2 helpers.py:102] Training  [10360/12500]  eta: 0:08:16  loss: 22.4538 (27.1631)  lr: 0.0000 (0.0000)  time: 0.196415  data: 0.000483  max mem: 3586
I20250120 12:56:06 3554128 dinov2 helpers.py:102] Training  [10370/12500]  eta: 0:08:13  loss: 22.4538 (27.1591)  lr: 0.0000 (0.0000)  time: 0.196441  data: 0.000419  max mem: 3586
I20250120 12:56:08 3554128 dinov2 helpers.py:102] Training  [10380/12500]  eta: 0:08:11  loss: 22.4538 (27.1536)  lr: 0.0000 (0.0000)  time: 0.196640  data: 0.000405  max mem: 3586
I20250120 12:56:10 3554128 dinov2 helpers.py:102] Training  [10390/12500]  eta: 0:08:08  loss: 22.4538 (27.1485)  lr: 0.0000 (0.0000)  time: 0.196613  data: 0.000447  max mem: 3586
I20250120 12:56:12 3554128 dinov2 helpers.py:102] Training  [10400/12500]  eta: 0:08:06  loss: 22.4679 (27.1471)  lr: 0.0000 (0.0000)  time: 0.196533  data: 0.000424  max mem: 3586
I20250120 12:56:14 3554128 dinov2 helpers.py:102] Training  [10410/12500]  eta: 0:08:04  loss: 22.4679 (27.1442)  lr: 0.0000 (0.0000)  time: 0.196608  data: 0.000434  max mem: 3586
I20250120 12:56:16 3554128 dinov2 helpers.py:102] Training  [10420/12500]  eta: 0:08:01  loss: 22.4679 (27.1391)  lr: 0.0000 (0.0000)  time: 0.196625  data: 0.000446  max mem: 3586
I20250120 12:56:18 3554128 dinov2 helpers.py:102] Training  [10430/12500]  eta: 0:07:59  loss: 22.4679 (27.1345)  lr: 0.0000 (0.0000)  time: 0.196699  data: 0.000468  max mem: 3586
I20250120 12:56:20 3554128 dinov2 helpers.py:102] Training  [10440/12500]  eta: 0:07:57  loss: 22.4538 (27.1278)  lr: 0.0000 (0.0000)  time: 0.196802  data: 0.000479  max mem: 3586
I20250120 12:56:22 3554128 dinov2 helpers.py:102] Training  [10450/12500]  eta: 0:07:54  loss: 22.3847 (27.1229)  lr: 0.0000 (0.0000)  time: 0.196895  data: 0.000458  max mem: 3586
I20250120 12:56:24 3554128 dinov2 helpers.py:102] Training  [10460/12500]  eta: 0:07:52  loss: 22.3847 (27.1138)  lr: 0.0000 (0.0000)  time: 0.196979  data: 0.000448  max mem: 3586
I20250120 12:56:26 3554128 dinov2 helpers.py:102] Training  [10470/12500]  eta: 0:07:49  loss: 22.0860 (27.1069)  lr: 0.0000 (0.0000)  time: 0.197073  data: 0.000455  max mem: 3586
I20250120 12:56:28 3554128 dinov2 helpers.py:102] Training  [10480/12500]  eta: 0:07:47  loss: 22.3847 (27.1052)  lr: 0.0000 (0.0000)  time: 0.197251  data: 0.000493  max mem: 3586
I20250120 12:56:29 3554128 dinov2 helpers.py:102] Training  [10490/12500]  eta: 0:07:45  loss: 22.3847 (27.0992)  lr: 0.0000 (0.0000)  time: 0.197339  data: 0.000489  max mem: 3586
I20250120 12:56:31 3554128 dinov2 helpers.py:102] Training  [10500/12500]  eta: 0:07:42  loss: 22.0673 (27.0944)  lr: 0.0000 (0.0000)  time: 0.197285  data: 0.000475  max mem: 3586
I20250120 12:56:33 3554128 dinov2 helpers.py:102] Training  [10510/12500]  eta: 0:07:40  loss: 22.0673 (27.0936)  lr: 0.0000 (0.0000)  time: 0.197343  data: 0.000464  max mem: 3586
I20250120 12:56:35 3554128 dinov2 helpers.py:102] Training  [10520/12500]  eta: 0:07:37  loss: 22.3847 (27.0894)  lr: 0.0000 (0.0000)  time: 0.197252  data: 0.000426  max mem: 3586
I20250120 12:56:37 3554128 dinov2 helpers.py:102] Training  [10530/12500]  eta: 0:07:35  loss: 22.3847 (27.0851)  lr: 0.0000 (0.0000)  time: 0.197124  data: 0.000414  max mem: 3586
I20250120 12:56:39 3554128 dinov2 helpers.py:102] Training  [10540/12500]  eta: 0:07:33  loss: 22.3847 (27.0852)  lr: 0.0000 (0.0000)  time: 0.197173  data: 0.000415  max mem: 3586
I20250120 12:56:41 3554128 dinov2 helpers.py:102] Training  [10550/12500]  eta: 0:07:30  loss: 22.3847 (27.0827)  lr: 0.0000 (0.0000)  time: 0.197042  data: 0.000430  max mem: 3586
I20250120 12:56:43 3554128 dinov2 helpers.py:102] Training  [10560/12500]  eta: 0:07:28  loss: 22.3847 (27.0796)  lr: 0.0000 (0.0000)  time: 0.196991  data: 0.000423  max mem: 3586
I20250120 12:56:45 3554128 dinov2 helpers.py:102] Training  [10570/12500]  eta: 0:07:26  loss: 22.3847 (27.0771)  lr: 0.0000 (0.0000)  time: 0.196903  data: 0.000432  max mem: 3586
I20250120 12:56:47 3554128 dinov2 helpers.py:102] Training  [10580/12500]  eta: 0:07:23  loss: 22.3847 (27.0715)  lr: 0.0000 (0.0000)  time: 0.196955  data: 0.000448  max mem: 3586
I20250120 12:56:49 3554128 dinov2 helpers.py:102] Training  [10590/12500]  eta: 0:07:21  loss: 22.6166 (27.0675)  lr: 0.0000 (0.0000)  time: 0.197093  data: 0.000385  max mem: 3586
I20250120 12:56:51 3554128 dinov2 helpers.py:102] Training  [10600/12500]  eta: 0:07:18  loss: 22.3847 (27.0595)  lr: 0.0000 (0.0000)  time: 0.197005  data: 0.000390  max mem: 3586
I20250120 12:56:53 3554128 dinov2 helpers.py:102] Training  [10610/12500]  eta: 0:07:16  loss: 22.0673 (27.0538)  lr: 0.0000 (0.0000)  time: 0.197022  data: 0.000465  max mem: 3586
I20250120 12:56:55 3554128 dinov2 helpers.py:102] Training  [10620/12500]  eta: 0:07:14  loss: 22.0673 (27.0473)  lr: 0.0000 (0.0000)  time: 0.197015  data: 0.000462  max mem: 3586
I20250120 12:56:57 3554128 dinov2 helpers.py:102] Training  [10630/12500]  eta: 0:07:11  loss: 22.0673 (27.0450)  lr: 0.0000 (0.0000)  time: 0.197191  data: 0.000455  max mem: 3586
I20250120 12:56:59 3554128 dinov2 helpers.py:102] Training  [10640/12500]  eta: 0:07:09  loss: 22.6166 (27.0414)  lr: 0.0000 (0.0000)  time: 0.197188  data: 0.000480  max mem: 3586
I20250120 12:57:01 3554128 dinov2 helpers.py:102] Training  [10650/12500]  eta: 0:07:07  loss: 22.7050 (27.0390)  lr: 0.0000 (0.0000)  time: 0.196963  data: 0.000465  max mem: 3586
I20250120 12:57:03 3554128 dinov2 helpers.py:102] Training  [10660/12500]  eta: 0:07:04  loss: 22.8793 (27.0355)  lr: 0.0000 (0.0000)  time: 0.196945  data: 0.000457  max mem: 3586
I20250120 12:57:05 3554128 dinov2 helpers.py:102] Training  [10670/12500]  eta: 0:07:02  loss: 22.8793 (27.0312)  lr: 0.0000 (0.0000)  time: 0.196955  data: 0.000465  max mem: 3586
I20250120 12:57:07 3554128 dinov2 helpers.py:102] Training  [10680/12500]  eta: 0:07:00  loss: 22.8793 (27.0286)  lr: 0.0000 (0.0000)  time: 0.197231  data: 0.000456  max mem: 3586
I20250120 12:57:09 3554128 dinov2 helpers.py:102] Training  [10690/12500]  eta: 0:06:57  loss: 22.8793 (27.0208)  lr: 0.0000 (0.0000)  time: 0.197245  data: 0.000423  max mem: 3586
I20250120 12:57:11 3554128 dinov2 helpers.py:102] Training  [10700/12500]  eta: 0:06:55  loss: 23.1886 (27.0177)  lr: 0.0000 (0.0000)  time: 0.197098  data: 0.000417  max mem: 3586
I20250120 12:57:13 3554128 dinov2 helpers.py:102] Training  [10710/12500]  eta: 0:06:52  loss: 23.1886 (27.0147)  lr: 0.0000 (0.0000)  time: 0.197257  data: 0.000467  max mem: 3586
I20250120 12:57:15 3554128 dinov2 helpers.py:102] Training  [10720/12500]  eta: 0:06:50  loss: 23.1886 (27.0101)  lr: 0.0000 (0.0000)  time: 0.197236  data: 0.000466  max mem: 3586
I20250120 12:57:17 3554128 dinov2 helpers.py:102] Training  [10730/12500]  eta: 0:06:48  loss: 23.1886 (27.0058)  lr: 0.0000 (0.0000)  time: 0.197211  data: 0.000461  max mem: 3586
I20250120 12:57:19 3554128 dinov2 helpers.py:102] Training  [10740/12500]  eta: 0:06:45  loss: 22.8793 (27.0015)  lr: 0.0000 (0.0000)  time: 0.197270  data: 0.000496  max mem: 3586
I20250120 12:57:21 3554128 dinov2 helpers.py:102] Training  [10750/12500]  eta: 0:06:43  loss: 22.4236 (26.9964)  lr: 0.0000 (0.0000)  time: 0.197092  data: 0.000462  max mem: 3586
I20250120 12:57:23 3554128 dinov2 helpers.py:102] Training  [10760/12500]  eta: 0:06:41  loss: 22.3477 (26.9904)  lr: 0.0000 (0.0000)  time: 0.196911  data: 0.000454  max mem: 3586
I20250120 12:57:25 3554128 dinov2 helpers.py:102] Training  [10770/12500]  eta: 0:06:38  loss: 22.3477 (26.9874)  lr: 0.0000 (0.0000)  time: 0.197003  data: 0.000528  max mem: 3586
I20250120 12:57:27 3554128 dinov2 helpers.py:102] Training  [10780/12500]  eta: 0:06:36  loss: 22.4236 (26.9851)  lr: 0.0000 (0.0000)  time: 0.197253  data: 0.000540  max mem: 3586
I20250120 12:57:29 3554128 dinov2 helpers.py:102] Training  [10790/12500]  eta: 0:06:34  loss: 22.3477 (26.9786)  lr: 0.0000 (0.0000)  time: 0.197245  data: 0.000467  max mem: 3586
I20250120 12:57:31 3554128 dinov2 helpers.py:102] Training  [10800/12500]  eta: 0:06:31  loss: 22.3477 (26.9706)  lr: 0.0000 (0.0000)  time: 0.197195  data: 0.000409  max mem: 3586
I20250120 12:57:33 3554128 dinov2 helpers.py:102] Training  [10810/12500]  eta: 0:06:29  loss: 22.3477 (26.9644)  lr: 0.0000 (0.0000)  time: 0.197199  data: 0.000434  max mem: 3586
I20250120 12:57:35 3554128 dinov2 helpers.py:102] Training  [10820/12500]  eta: 0:06:26  loss: 22.3477 (26.9577)  lr: 0.0000 (0.0000)  time: 0.197198  data: 0.000455  max mem: 3586
I20250120 12:57:37 3554128 dinov2 helpers.py:102] Training  [10830/12500]  eta: 0:06:24  loss: 22.3358 (26.9510)  lr: 0.0000 (0.0000)  time: 0.197227  data: 0.000439  max mem: 3586
I20250120 12:57:38 3554128 dinov2 helpers.py:102] Training  [10840/12500]  eta: 0:06:22  loss: 22.1302 (26.9426)  lr: 0.0000 (0.0000)  time: 0.197117  data: 0.000450  max mem: 3586
I20250120 12:57:40 3554128 dinov2 helpers.py:102] Training  [10850/12500]  eta: 0:06:19  loss: 21.5301 (26.9356)  lr: 0.0000 (0.0000)  time: 0.197146  data: 0.000415  max mem: 3586
I20250120 12:57:42 3554128 dinov2 helpers.py:102] Training  [10860/12500]  eta: 0:06:17  loss: 21.2226 (26.9303)  lr: 0.0000 (0.0000)  time: 0.197219  data: 0.000412  max mem: 3586
I20250120 12:57:44 3554128 dinov2 helpers.py:102] Training  [10870/12500]  eta: 0:06:15  loss: 20.5926 (26.9235)  lr: 0.0000 (0.0000)  time: 0.197126  data: 0.000468  max mem: 3586
I20250120 12:57:46 3554128 dinov2 helpers.py:102] Training  [10880/12500]  eta: 0:06:12  loss: 20.5926 (26.9212)  lr: 0.0000 (0.0000)  time: 0.197321  data: 0.000459  max mem: 3586
I20250120 12:57:48 3554128 dinov2 helpers.py:102] Training  [10890/12500]  eta: 0:06:10  loss: 20.5926 (26.9147)  lr: 0.0000 (0.0000)  time: 0.197483  data: 0.000406  max mem: 3586
I20250120 12:57:50 3554128 dinov2 helpers.py:102] Training  [10900/12500]  eta: 0:06:08  loss: 20.2988 (26.9084)  lr: 0.0000 (0.0000)  time: 0.197222  data: 0.000418  max mem: 3586
I20250120 12:57:52 3554128 dinov2 helpers.py:102] Training  [10910/12500]  eta: 0:06:05  loss: 20.2988 (26.9035)  lr: 0.0000 (0.0000)  time: 0.197254  data: 0.000479  max mem: 3586
I20250120 12:57:54 3554128 dinov2 helpers.py:102] Training  [10920/12500]  eta: 0:06:03  loss: 20.0470 (26.8955)  lr: 0.0000 (0.0000)  time: 0.197315  data: 0.000495  max mem: 3586
I20250120 12:57:56 3554128 dinov2 helpers.py:102] Training  [10930/12500]  eta: 0:06:01  loss: 20.0470 (26.8904)  lr: 0.0000 (0.0000)  time: 0.197179  data: 0.000516  max mem: 3586
I20250120 12:57:58 3554128 dinov2 helpers.py:102] Training  [10940/12500]  eta: 0:05:58  loss: 20.0470 (26.8878)  lr: 0.0000 (0.0000)  time: 0.197035  data: 0.000523  max mem: 3586
I20250120 12:58:00 3554128 dinov2 helpers.py:102] Training  [10950/12500]  eta: 0:05:56  loss: 20.0470 (26.8839)  lr: 0.0000 (0.0000)  time: 0.197138  data: 0.000475  max mem: 3586
I20250120 12:58:02 3554128 dinov2 helpers.py:102] Training  [10960/12500]  eta: 0:05:54  loss: 20.0470 (26.8837)  lr: 0.0000 (0.0000)  time: 0.197184  data: 0.000411  max mem: 3586
I20250120 12:58:04 3554128 dinov2 helpers.py:102] Training  [10970/12500]  eta: 0:05:51  loss: 20.0470 (26.8787)  lr: 0.0000 (0.0000)  time: 0.197004  data: 0.000420  max mem: 3586
I20250120 12:58:06 3554128 dinov2 helpers.py:102] Training  [10980/12500]  eta: 0:05:49  loss: 20.0470 (26.8780)  lr: 0.0000 (0.0000)  time: 0.197069  data: 0.000471  max mem: 3586
I20250120 12:58:08 3554128 dinov2 helpers.py:102] Training  [10990/12500]  eta: 0:05:47  loss: 20.2988 (26.8738)  lr: 0.0000 (0.0000)  time: 0.197189  data: 0.000483  max mem: 3586
I20250120 12:58:10 3554128 dinov2 helpers.py:102] Training  [11000/12500]  eta: 0:05:44  loss: 20.2988 (26.8663)  lr: 0.0000 (0.0000)  time: 0.197306  data: 0.000454  max mem: 3586
I20250120 12:58:12 3554128 dinov2 helpers.py:102] Training  [11010/12500]  eta: 0:05:42  loss: 21.2226 (26.8627)  lr: 0.0000 (0.0000)  time: 0.197248  data: 0.000428  max mem: 3586
I20250120 12:58:14 3554128 dinov2 helpers.py:102] Training  [11020/12500]  eta: 0:05:40  loss: 21.2226 (26.8564)  lr: 0.0000 (0.0000)  time: 0.197182  data: 0.000476  max mem: 3586
I20250120 12:58:16 3554128 dinov2 helpers.py:102] Training  [11030/12500]  eta: 0:05:37  loss: 21.3025 (26.8570)  lr: 0.0000 (0.0000)  time: 0.197278  data: 0.000458  max mem: 3586
I20250120 12:58:18 3554128 dinov2 helpers.py:102] Training  [11040/12500]  eta: 0:05:35  loss: 21.3963 (26.8521)  lr: 0.0000 (0.0000)  time: 0.197194  data: 0.000448  max mem: 3586
I20250120 12:58:20 3554128 dinov2 helpers.py:102] Training  [11050/12500]  eta: 0:05:33  loss: 21.4467 (26.8478)  lr: 0.0000 (0.0000)  time: 0.197071  data: 0.000482  max mem: 3586
I20250120 12:58:22 3554128 dinov2 helpers.py:102] Training  [11060/12500]  eta: 0:05:30  loss: 21.5100 (26.8468)  lr: 0.0000 (0.0000)  time: 0.197233  data: 0.000485  max mem: 3586
I20250120 12:58:24 3554128 dinov2 helpers.py:102] Training  [11070/12500]  eta: 0:05:28  loss: 22.1282 (26.8433)  lr: 0.0000 (0.0000)  time: 0.197313  data: 0.000454  max mem: 3586
I20250120 12:58:26 3554128 dinov2 helpers.py:102] Training  [11080/12500]  eta: 0:05:25  loss: 21.5100 (26.8371)  lr: 0.0000 (0.0000)  time: 0.197155  data: 0.000450  max mem: 3586
I20250120 12:58:28 3554128 dinov2 helpers.py:102] Training  [11090/12500]  eta: 0:05:23  loss: 21.5100 (26.8317)  lr: 0.0000 (0.0000)  time: 0.197249  data: 0.000474  max mem: 3586
I20250120 12:58:30 3554128 dinov2 helpers.py:102] Training  [11100/12500]  eta: 0:05:21  loss: 21.5100 (26.8265)  lr: 0.0000 (0.0000)  time: 0.197381  data: 0.000442  max mem: 3586
I20250120 12:58:32 3554128 dinov2 helpers.py:102] Training  [11110/12500]  eta: 0:05:18  loss: 21.4467 (26.8203)  lr: 0.0000 (0.0000)  time: 0.197250  data: 0.000403  max mem: 3586
I20250120 12:58:34 3554128 dinov2 helpers.py:102] Training  [11120/12500]  eta: 0:05:16  loss: 22.1282 (26.8164)  lr: 0.0000 (0.0000)  time: 0.197256  data: 0.000410  max mem: 3586
I20250120 12:58:36 3554128 dinov2 helpers.py:102] Training  [11130/12500]  eta: 0:05:14  loss: 22.1282 (26.8105)  lr: 0.0000 (0.0000)  time: 0.197458  data: 0.000456  max mem: 3586
I20250120 12:58:38 3554128 dinov2 helpers.py:102] Training  [11140/12500]  eta: 0:05:11  loss: 22.1282 (26.8076)  lr: 0.0000 (0.0000)  time: 0.197513  data: 0.000426  max mem: 3586
I20250120 12:58:40 3554128 dinov2 helpers.py:102] Training  [11150/12500]  eta: 0:05:09  loss: 22.0259 (26.8033)  lr: 0.0000 (0.0000)  time: 0.197468  data: 0.000430  max mem: 3586
I20250120 12:58:42 3554128 dinov2 helpers.py:102] Training  [11160/12500]  eta: 0:05:07  loss: 21.4467 (26.7973)  lr: 0.0000 (0.0000)  time: 0.197248  data: 0.000376  max mem: 3586
I20250120 12:58:44 3554128 dinov2 helpers.py:102] Training  [11170/12500]  eta: 0:05:04  loss: 22.0259 (26.7980)  lr: 0.0000 (0.0000)  time: 0.197348  data: 0.000401  max mem: 3586
I20250120 12:58:46 3554128 dinov2 helpers.py:102] Training  [11180/12500]  eta: 0:05:02  loss: 22.0259 (26.7958)  lr: 0.0000 (0.0000)  time: 0.197562  data: 0.000506  max mem: 3586
I20250120 12:58:48 3554128 dinov2 helpers.py:102] Training  [11190/12500]  eta: 0:05:00  loss: 21.3963 (26.7897)  lr: 0.0000 (0.0000)  time: 0.197327  data: 0.000423  max mem: 3586
I20250120 12:58:50 3554128 dinov2 helpers.py:102] Training  [11200/12500]  eta: 0:04:57  loss: 22.0259 (26.7901)  lr: 0.0000 (0.0000)  time: 0.197235  data: 0.000414  max mem: 3586
I20250120 12:58:52 3554128 dinov2 helpers.py:102] Training  [11210/12500]  eta: 0:04:55  loss: 22.0259 (26.7894)  lr: 0.0000 (0.0000)  time: 0.197310  data: 0.000472  max mem: 3586
I20250120 12:58:53 3554128 dinov2 helpers.py:102] Training  [11220/12500]  eta: 0:04:53  loss: 22.1282 (26.7861)  lr: 0.0000 (0.0000)  time: 0.197243  data: 0.000476  max mem: 3586
I20250120 12:58:55 3554128 dinov2 helpers.py:102] Training  [11230/12500]  eta: 0:04:51  loss: 22.0259 (26.7803)  lr: 0.0000 (0.0000)  time: 0.197132  data: 0.000455  max mem: 3586
I20250120 12:58:57 3554128 dinov2 helpers.py:102] Training  [11240/12500]  eta: 0:04:48  loss: 22.0259 (26.7751)  lr: 0.0000 (0.0000)  time: 0.197150  data: 0.000445  max mem: 3586
I20250120 12:58:59 3554128 dinov2 linear.py:272] running validation !
I20250120 12:59:01 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:35    time: 1.391079  data: 1.186850  max mem: 3586
I20250120 12:59:03 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:45    time: 0.312159  data: 0.109289  max mem: 3586
I20250120 12:59:05 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:34    time: 0.202350  data: 0.001103  max mem: 3586
I20250120 12:59:07 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:29    time: 0.199750  data: 0.000467  max mem: 3586
I20250120 12:59:09 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199664  data: 0.000293  max mem: 3586
I20250120 12:59:11 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.200063  data: 0.000294  max mem: 3586
I20250120 12:59:13 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:20    time: 0.199629  data: 0.000276  max mem: 3586
I20250120 12:59:15 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199849  data: 0.000251  max mem: 3586
I20250120 12:59:17 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.200004  data: 0.000219  max mem: 3586
I20250120 12:59:19 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.199886  data: 0.000253  max mem: 3586
I20250120 12:59:21 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199783  data: 0.000307  max mem: 3586
I20250120 12:59:23 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199816  data: 0.000306  max mem: 3586
I20250120 12:59:25 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199912  data: 0.000300  max mem: 3586
I20250120 12:59:27 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199941  data: 0.000311  max mem: 3586
I20250120 12:59:29 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199845  data: 0.000272  max mem: 3586
I20250120 12:59:31 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199672  data: 0.000182  max mem: 3586
I20250120 12:59:31 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.196048  data: 0.000140  max mem: 3586
I20250120 12:59:31 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208204 s / it)
I20250120 12:59:31 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 12:59:32 3554128 dinov2 linear.py:287] 
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7911, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8047, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8097, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8148, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8186, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8230, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8241, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8267, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8276, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8277, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8270, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7944, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8072, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8123, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8169, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8230, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8268, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8294, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8331, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8362, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8392, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8393, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8380, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8108, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8172, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8208, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8259, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8286, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8317, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8336, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8355, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8349, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8352, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8307, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8110, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8153, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8229, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8254, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8299, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8323, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8353, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8385, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8417, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8419, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8417, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8333, device='cuda:0')}
I20250120 12:59:32 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_01000', 'accuracy': 0.8418552875518799}
I20250120 12:59:32 3554128 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:59:32 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:59:32 3554128 dinov2 helpers.py:102] Training  [11250/12500]  eta: 0:04:49  loss: 21.0472 (26.7690)  lr: 0.0000 (0.0000)  time: 1.815270  data: 0.000428  max mem: 3586
I20250120 12:59:34 3554128 dinov2 helpers.py:102] Training  [11260/12500]  eta: 0:04:47  loss: 21.0472 (26.7678)  lr: 0.0000 (0.0000)  time: 1.814367  data: 0.000398  max mem: 3586
I20250120 12:59:36 3554128 dinov2 helpers.py:102] Training  [11270/12500]  eta: 0:04:45  loss: 21.0472 (26.7635)  lr: 0.0000 (0.0000)  time: 0.196064  data: 0.000416  max mem: 3586
I20250120 12:59:38 3554128 dinov2 helpers.py:102] Training  [11280/12500]  eta: 0:04:42  loss: 21.9597 (26.7621)  lr: 0.0000 (0.0000)  time: 0.196905  data: 0.000432  max mem: 3586
I20250120 12:59:40 3554128 dinov2 helpers.py:102] Training  [11290/12500]  eta: 0:04:40  loss: 22.0259 (26.7584)  lr: 0.0000 (0.0000)  time: 0.196965  data: 0.000463  max mem: 3586
I20250120 12:59:42 3554128 dinov2 helpers.py:102] Training  [11300/12500]  eta: 0:04:38  loss: 22.2595 (26.7545)  lr: 0.0000 (0.0000)  time: 0.196815  data: 0.000449  max mem: 3586
I20250120 12:59:44 3554128 dinov2 helpers.py:102] Training  [11310/12500]  eta: 0:04:35  loss: 22.4793 (26.7520)  lr: 0.0000 (0.0000)  time: 0.196920  data: 0.000431  max mem: 3586
I20250120 12:59:46 3554128 dinov2 helpers.py:102] Training  [11320/12500]  eta: 0:04:33  loss: 22.2595 (26.7463)  lr: 0.0000 (0.0000)  time: 0.197184  data: 0.000457  max mem: 3586
I20250120 12:59:48 3554128 dinov2 helpers.py:102] Training  [11330/12500]  eta: 0:04:31  loss: 22.5976 (26.7445)  lr: 0.0000 (0.0000)  time: 0.197290  data: 0.000452  max mem: 3586
I20250120 12:59:49 3554128 dinov2 helpers.py:102] Training  [11340/12500]  eta: 0:04:28  loss: 22.3505 (26.7406)  lr: 0.0000 (0.0000)  time: 0.197260  data: 0.000402  max mem: 3586
I20250120 12:59:51 3554128 dinov2 helpers.py:102] Training  [11350/12500]  eta: 0:04:26  loss: 22.5976 (26.7375)  lr: 0.0000 (0.0000)  time: 0.197130  data: 0.000414  max mem: 3586
I20250120 12:59:53 3554128 dinov2 helpers.py:102] Training  [11360/12500]  eta: 0:04:24  loss: 23.0126 (26.7370)  lr: 0.0000 (0.0000)  time: 0.197035  data: 0.000447  max mem: 3586
I20250120 12:59:55 3554128 dinov2 helpers.py:102] Training  [11370/12500]  eta: 0:04:21  loss: 22.5976 (26.7331)  lr: 0.0000 (0.0000)  time: 0.196995  data: 0.000422  max mem: 3586
I20250120 12:59:57 3554128 dinov2 helpers.py:102] Training  [11380/12500]  eta: 0:04:19  loss: 22.5976 (26.7300)  lr: 0.0000 (0.0000)  time: 0.197133  data: 0.000425  max mem: 3586
I20250120 13:00:00 3554128 dinov2 helpers.py:102] Training  [11390/12500]  eta: 0:04:17  loss: 22.5976 (26.7261)  lr: 0.0000 (0.0000)  time: 0.221067  data: 0.027766  max mem: 3586
I20250120 13:00:02 3554128 dinov2 helpers.py:102] Training  [11400/12500]  eta: 0:04:14  loss: 22.5976 (26.7248)  lr: 0.0000 (0.0000)  time: 0.220915  data: 0.027786  max mem: 3586
I20250120 13:00:04 3554128 dinov2 helpers.py:102] Training  [11410/12500]  eta: 0:04:12  loss: 22.3505 (26.7171)  lr: 0.0000 (0.0000)  time: 0.197068  data: 0.000468  max mem: 3586
I20250120 13:00:06 3554128 dinov2 helpers.py:102] Training  [11420/12500]  eta: 0:04:10  loss: 22.2889 (26.7114)  lr: 0.0000 (0.0000)  time: 0.197106  data: 0.000456  max mem: 3586
I20250120 13:00:08 3554128 dinov2 helpers.py:102] Training  [11430/12500]  eta: 0:04:07  loss: 22.3505 (26.7077)  lr: 0.0000 (0.0000)  time: 0.197226  data: 0.000446  max mem: 3586
I20250120 13:00:10 3554128 dinov2 helpers.py:102] Training  [11440/12500]  eta: 0:04:05  loss: 22.4653 (26.7046)  lr: 0.0000 (0.0000)  time: 0.197196  data: 0.000453  max mem: 3586
I20250120 13:00:12 3554128 dinov2 helpers.py:102] Training  [11450/12500]  eta: 0:04:02  loss: 22.4653 (26.6965)  lr: 0.0000 (0.0000)  time: 0.197170  data: 0.000458  max mem: 3586
I20250120 13:00:14 3554128 dinov2 helpers.py:102] Training  [11460/12500]  eta: 0:04:00  loss: 22.4653 (26.6955)  lr: 0.0000 (0.0000)  time: 0.197344  data: 0.000448  max mem: 3586
I20250120 13:00:16 3554128 dinov2 helpers.py:102] Training  [11470/12500]  eta: 0:03:58  loss: 22.4653 (26.6918)  lr: 0.0000 (0.0000)  time: 0.197322  data: 0.000453  max mem: 3586
I20250120 13:00:18 3554128 dinov2 helpers.py:102] Training  [11480/12500]  eta: 0:03:55  loss: 22.3676 (26.6874)  lr: 0.0000 (0.0000)  time: 0.197290  data: 0.000451  max mem: 3586
I20250120 13:00:20 3554128 dinov2 helpers.py:102] Training  [11490/12500]  eta: 0:03:53  loss: 22.3505 (26.6826)  lr: 0.0000 (0.0000)  time: 0.197296  data: 0.000414  max mem: 3586
I20250120 13:00:22 3554128 dinov2 helpers.py:102] Training  [11500/12500]  eta: 0:03:51  loss: 22.3676 (26.6807)  lr: 0.0000 (0.0000)  time: 0.197291  data: 0.000423  max mem: 3586
I20250120 13:00:23 3554128 dinov2 helpers.py:102] Training  [11510/12500]  eta: 0:03:48  loss: 22.3676 (26.6789)  lr: 0.0000 (0.0000)  time: 0.197419  data: 0.000461  max mem: 3586
I20250120 13:00:25 3554128 dinov2 helpers.py:102] Training  [11520/12500]  eta: 0:03:46  loss: 22.4653 (26.6753)  lr: 0.0000 (0.0000)  time: 0.197580  data: 0.000460  max mem: 3586
I20250120 13:00:27 3554128 dinov2 helpers.py:102] Training  [11530/12500]  eta: 0:03:44  loss: 22.3676 (26.6677)  lr: 0.0000 (0.0000)  time: 0.197509  data: 0.000472  max mem: 3586
I20250120 13:00:29 3554128 dinov2 helpers.py:102] Training  [11540/12500]  eta: 0:03:41  loss: 22.4653 (26.6648)  lr: 0.0000 (0.0000)  time: 0.197416  data: 0.000475  max mem: 3586
I20250120 13:00:31 3554128 dinov2 helpers.py:102] Training  [11550/12500]  eta: 0:03:39  loss: 22.4653 (26.6625)  lr: 0.0000 (0.0000)  time: 0.197424  data: 0.000450  max mem: 3586
I20250120 13:00:33 3554128 dinov2 helpers.py:102] Training  [11560/12500]  eta: 0:03:37  loss: 22.4653 (26.6599)  lr: 0.0000 (0.0000)  time: 0.197355  data: 0.000427  max mem: 3586
I20250120 13:00:35 3554128 dinov2 helpers.py:102] Training  [11570/12500]  eta: 0:03:34  loss: 22.4653 (26.6553)  lr: 0.0000 (0.0000)  time: 0.197237  data: 0.000426  max mem: 3586
I20250120 13:00:37 3554128 dinov2 helpers.py:102] Training  [11580/12500]  eta: 0:03:32  loss: 22.3676 (26.6482)  lr: 0.0000 (0.0000)  time: 0.197313  data: 0.000468  max mem: 3586
I20250120 13:00:39 3554128 dinov2 helpers.py:102] Training  [11590/12500]  eta: 0:03:30  loss: 22.3676 (26.6439)  lr: 0.0000 (0.0000)  time: 0.197426  data: 0.000466  max mem: 3586
I20250120 13:00:41 3554128 dinov2 helpers.py:102] Training  [11600/12500]  eta: 0:03:27  loss: 21.6447 (26.6358)  lr: 0.0000 (0.0000)  time: 0.197445  data: 0.000424  max mem: 3586
I20250120 13:00:43 3554128 dinov2 helpers.py:102] Training  [11610/12500]  eta: 0:03:25  loss: 22.3676 (26.6342)  lr: 0.0000 (0.0000)  time: 0.197435  data: 0.000422  max mem: 3586
I20250120 13:00:45 3554128 dinov2 helpers.py:102] Training  [11620/12500]  eta: 0:03:23  loss: 22.3676 (26.6284)  lr: 0.0000 (0.0000)  time: 0.197446  data: 0.000435  max mem: 3586
I20250120 13:00:47 3554128 dinov2 helpers.py:102] Training  [11630/12500]  eta: 0:03:20  loss: 21.6447 (26.6217)  lr: 0.0000 (0.0000)  time: 0.197444  data: 0.000453  max mem: 3586
I20250120 13:00:49 3554128 dinov2 helpers.py:102] Training  [11640/12500]  eta: 0:03:18  loss: 21.6020 (26.6160)  lr: 0.0000 (0.0000)  time: 0.197461  data: 0.000467  max mem: 3586
I20250120 13:00:51 3554128 dinov2 helpers.py:102] Training  [11650/12500]  eta: 0:03:16  loss: 21.6020 (26.6109)  lr: 0.0000 (0.0000)  time: 0.197593  data: 0.000456  max mem: 3586
I20250120 13:00:53 3554128 dinov2 helpers.py:102] Training  [11660/12500]  eta: 0:03:13  loss: 21.6020 (26.6069)  lr: 0.0000 (0.0000)  time: 0.197725  data: 0.000477  max mem: 3586
I20250120 13:00:55 3554128 dinov2 helpers.py:102] Training  [11670/12500]  eta: 0:03:11  loss: 21.4385 (26.6025)  lr: 0.0000 (0.0000)  time: 0.197760  data: 0.000482  max mem: 3586
I20250120 13:00:57 3554128 dinov2 helpers.py:102] Training  [11680/12500]  eta: 0:03:09  loss: 21.4085 (26.5980)  lr: 0.0000 (0.0000)  time: 0.197466  data: 0.000444  max mem: 3586
I20250120 13:00:59 3554128 dinov2 helpers.py:102] Training  [11690/12500]  eta: 0:03:06  loss: 21.4085 (26.5917)  lr: 0.0000 (0.0000)  time: 0.197388  data: 0.000461  max mem: 3586
I20250120 13:01:01 3554128 dinov2 helpers.py:102] Training  [11700/12500]  eta: 0:03:04  loss: 21.4085 (26.5874)  lr: 0.0000 (0.0000)  time: 0.197485  data: 0.000474  max mem: 3586
I20250120 13:01:03 3554128 dinov2 helpers.py:102] Training  [11710/12500]  eta: 0:03:02  loss: 21.4085 (26.5832)  lr: 0.0000 (0.0000)  time: 0.197414  data: 0.000472  max mem: 3586
I20250120 13:01:05 3554128 dinov2 helpers.py:102] Training  [11720/12500]  eta: 0:02:59  loss: 21.4085 (26.5789)  lr: 0.0000 (0.0000)  time: 0.197531  data: 0.000500  max mem: 3586
I20250120 13:01:07 3554128 dinov2 helpers.py:102] Training  [11730/12500]  eta: 0:02:57  loss: 21.4385 (26.5759)  lr: 0.0000 (0.0000)  time: 0.197668  data: 0.000518  max mem: 3586
I20250120 13:01:09 3554128 dinov2 helpers.py:102] Training  [11740/12500]  eta: 0:02:55  loss: 21.4085 (26.5701)  lr: 0.0000 (0.0000)  time: 0.197739  data: 0.000495  max mem: 3586
I20250120 13:01:11 3554128 dinov2 helpers.py:102] Training  [11750/12500]  eta: 0:02:52  loss: 21.4085 (26.5662)  lr: 0.0000 (0.0000)  time: 0.197859  data: 0.000456  max mem: 3586
I20250120 13:01:13 3554128 dinov2 helpers.py:102] Training  [11760/12500]  eta: 0:02:50  loss: 21.4085 (26.5631)  lr: 0.0000 (0.0000)  time: 0.197866  data: 0.000435  max mem: 3586
I20250120 13:01:15 3554128 dinov2 helpers.py:102] Training  [11770/12500]  eta: 0:02:48  loss: 21.4168 (26.5587)  lr: 0.0000 (0.0000)  time: 0.197815  data: 0.000418  max mem: 3586
I20250120 13:01:17 3554128 dinov2 helpers.py:102] Training  [11780/12500]  eta: 0:02:45  loss: 21.4385 (26.5559)  lr: 0.0000 (0.0000)  time: 0.197892  data: 0.000430  max mem: 3586
I20250120 13:01:19 3554128 dinov2 helpers.py:102] Training  [11790/12500]  eta: 0:02:43  loss: 21.4168 (26.5510)  lr: 0.0000 (0.0000)  time: 0.197843  data: 0.000493  max mem: 3586
I20250120 13:01:21 3554128 dinov2 helpers.py:102] Training  [11800/12500]  eta: 0:02:41  loss: 21.4385 (26.5489)  lr: 0.0000 (0.0000)  time: 0.197713  data: 0.000457  max mem: 3586
I20250120 13:01:23 3554128 dinov2 helpers.py:102] Training  [11810/12500]  eta: 0:02:38  loss: 21.4168 (26.5423)  lr: 0.0000 (0.0000)  time: 0.197621  data: 0.000451  max mem: 3586
I20250120 13:01:25 3554128 dinov2 helpers.py:102] Training  [11820/12500]  eta: 0:02:36  loss: 21.4385 (26.5387)  lr: 0.0000 (0.0000)  time: 0.197599  data: 0.000488  max mem: 3586
I20250120 13:01:27 3554128 dinov2 helpers.py:102] Training  [11830/12500]  eta: 0:02:34  loss: 21.4385 (26.5341)  lr: 0.0000 (0.0000)  time: 0.197789  data: 0.000458  max mem: 3586
I20250120 13:01:29 3554128 dinov2 helpers.py:102] Training  [11840/12500]  eta: 0:02:31  loss: 21.4385 (26.5289)  lr: 0.0000 (0.0000)  time: 0.197846  data: 0.000478  max mem: 3586
I20250120 13:01:31 3554128 dinov2 helpers.py:102] Training  [11850/12500]  eta: 0:02:29  loss: 21.4385 (26.5217)  lr: 0.0000 (0.0000)  time: 0.197999  data: 0.000477  max mem: 3586
I20250120 13:01:33 3554128 dinov2 helpers.py:102] Training  [11860/12500]  eta: 0:02:27  loss: 21.4385 (26.5188)  lr: 0.0000 (0.0000)  time: 0.197965  data: 0.000492  max mem: 3586
I20250120 13:01:35 3554128 dinov2 helpers.py:102] Training  [11870/12500]  eta: 0:02:25  loss: 21.4999 (26.5147)  lr: 0.0000 (0.0000)  time: 0.197709  data: 0.000518  max mem: 3586
I20250120 13:01:37 3554128 dinov2 helpers.py:102] Training  [11880/12500]  eta: 0:02:22  loss: 21.5861 (26.5117)  lr: 0.0000 (0.0000)  time: 0.197665  data: 0.000503  max mem: 3586
I20250120 13:01:39 3554128 dinov2 helpers.py:102] Training  [11890/12500]  eta: 0:02:20  loss: 21.5861 (26.5076)  lr: 0.0000 (0.0000)  time: 0.197605  data: 0.000517  max mem: 3586
I20250120 13:01:41 3554128 dinov2 helpers.py:102] Training  [11900/12500]  eta: 0:02:18  loss: 21.5791 (26.5022)  lr: 0.0000 (0.0000)  time: 0.197519  data: 0.000510  max mem: 3586
I20250120 13:01:43 3554128 dinov2 helpers.py:102] Training  [11910/12500]  eta: 0:02:15  loss: 21.4999 (26.4979)  lr: 0.0000 (0.0000)  time: 0.197444  data: 0.000468  max mem: 3586
I20250120 13:01:45 3554128 dinov2 helpers.py:102] Training  [11920/12500]  eta: 0:02:13  loss: 21.4602 (26.4910)  lr: 0.0000 (0.0000)  time: 0.197359  data: 0.000433  max mem: 3586
I20250120 13:01:47 3554128 dinov2 helpers.py:102] Training  [11930/12500]  eta: 0:02:11  loss: 21.4602 (26.4894)  lr: 0.0000 (0.0000)  time: 0.197228  data: 0.000458  max mem: 3586
I20250120 13:01:48 3554128 dinov2 helpers.py:102] Training  [11940/12500]  eta: 0:02:08  loss: 21.5791 (26.4861)  lr: 0.0000 (0.0000)  time: 0.197322  data: 0.000482  max mem: 3586
I20250120 13:01:50 3554128 dinov2 helpers.py:102] Training  [11950/12500]  eta: 0:02:06  loss: 21.5791 (26.4859)  lr: 0.0000 (0.0000)  time: 0.197315  data: 0.000456  max mem: 3586
I20250120 13:01:52 3554128 dinov2 helpers.py:102] Training  [11960/12500]  eta: 0:02:04  loss: 21.5791 (26.4828)  lr: 0.0000 (0.0000)  time: 0.197264  data: 0.000462  max mem: 3586
I20250120 13:01:54 3554128 dinov2 helpers.py:102] Training  [11970/12500]  eta: 0:02:01  loss: 21.7281 (26.4857)  lr: 0.0000 (0.0000)  time: 0.197253  data: 0.000469  max mem: 3586
I20250120 13:01:56 3554128 dinov2 helpers.py:102] Training  [11980/12500]  eta: 0:01:59  loss: 21.7281 (26.4825)  lr: 0.0000 (0.0000)  time: 0.197185  data: 0.000422  max mem: 3586
I20250120 13:01:58 3554128 dinov2 helpers.py:102] Training  [11990/12500]  eta: 0:01:57  loss: 21.7281 (26.4770)  lr: 0.0000 (0.0000)  time: 0.197277  data: 0.000450  max mem: 3586
I20250120 13:02:00 3554128 dinov2 helpers.py:102] Training  [12000/12500]  eta: 0:01:54  loss: 21.5791 (26.4722)  lr: 0.0000 (0.0000)  time: 0.197369  data: 0.000528  max mem: 3586
I20250120 13:02:02 3554128 dinov2 helpers.py:102] Training  [12010/12500]  eta: 0:01:52  loss: 21.6568 (26.4682)  lr: 0.0000 (0.0000)  time: 0.197305  data: 0.000474  max mem: 3586
I20250120 13:02:04 3554128 dinov2 helpers.py:102] Training  [12020/12500]  eta: 0:01:50  loss: 21.6568 (26.4673)  lr: 0.0000 (0.0000)  time: 0.197462  data: 0.000449  max mem: 3586
I20250120 13:02:06 3554128 dinov2 helpers.py:102] Training  [12030/12500]  eta: 0:01:47  loss: 21.7281 (26.4661)  lr: 0.0000 (0.0000)  time: 0.197447  data: 0.000481  max mem: 3586
I20250120 13:02:08 3554128 dinov2 helpers.py:102] Training  [12040/12500]  eta: 0:01:45  loss: 21.7281 (26.4602)  lr: 0.0000 (0.0000)  time: 0.197432  data: 0.000474  max mem: 3586
I20250120 13:02:10 3554128 dinov2 helpers.py:102] Training  [12050/12500]  eta: 0:01:43  loss: 21.7281 (26.4553)  lr: 0.0000 (0.0000)  time: 0.197741  data: 0.000447  max mem: 3586
I20250120 13:02:12 3554128 dinov2 helpers.py:102] Training  [12060/12500]  eta: 0:01:41  loss: 21.7281 (26.4537)  lr: 0.0000 (0.0000)  time: 0.197823  data: 0.000450  max mem: 3586
I20250120 13:02:14 3554128 dinov2 helpers.py:102] Training  [12070/12500]  eta: 0:01:38  loss: 21.6568 (26.4495)  lr: 0.0000 (0.0000)  time: 0.197862  data: 0.000471  max mem: 3586
I20250120 13:02:16 3554128 dinov2 helpers.py:102] Training  [12080/12500]  eta: 0:01:36  loss: 21.6568 (26.4456)  lr: 0.0000 (0.0000)  time: 0.197752  data: 0.000480  max mem: 3586
I20250120 13:02:18 3554128 dinov2 helpers.py:102] Training  [12090/12500]  eta: 0:01:34  loss: 21.6568 (26.4402)  lr: 0.0000 (0.0000)  time: 0.197591  data: 0.000481  max mem: 3586
I20250120 13:02:20 3554128 dinov2 helpers.py:102] Training  [12100/12500]  eta: 0:01:31  loss: 21.6568 (26.4349)  lr: 0.0000 (0.0000)  time: 0.197542  data: 0.000470  max mem: 3586
I20250120 13:02:22 3554128 dinov2 helpers.py:102] Training  [12110/12500]  eta: 0:01:29  loss: 21.6636 (26.4345)  lr: 0.0000 (0.0000)  time: 0.197531  data: 0.000464  max mem: 3586
I20250120 13:02:24 3554128 dinov2 helpers.py:102] Training  [12120/12500]  eta: 0:01:27  loss: 21.6636 (26.4291)  lr: 0.0000 (0.0000)  time: 0.197545  data: 0.000463  max mem: 3586
I20250120 13:02:26 3554128 dinov2 helpers.py:102] Training  [12130/12500]  eta: 0:01:24  loss: 21.6636 (26.4261)  lr: 0.0000 (0.0000)  time: 0.197577  data: 0.000449  max mem: 3586
I20250120 13:02:28 3554128 dinov2 helpers.py:102] Training  [12140/12500]  eta: 0:01:22  loss: 21.6568 (26.4220)  lr: 0.0000 (0.0000)  time: 0.197595  data: 0.000422  max mem: 3586
I20250120 13:02:30 3554128 dinov2 helpers.py:102] Training  [12150/12500]  eta: 0:01:20  loss: 21.5254 (26.4145)  lr: 0.0000 (0.0000)  time: 0.197490  data: 0.000447  max mem: 3586
I20250120 13:02:32 3554128 dinov2 helpers.py:102] Training  [12160/12500]  eta: 0:01:18  loss: 21.4443 (26.4104)  lr: 0.0000 (0.0000)  time: 0.197356  data: 0.000451  max mem: 3586
I20250120 13:02:34 3554128 dinov2 helpers.py:102] Training  [12170/12500]  eta: 0:01:15  loss: 21.4443 (26.4076)  lr: 0.0000 (0.0000)  time: 0.197467  data: 0.000451  max mem: 3586
I20250120 13:02:36 3554128 dinov2 helpers.py:102] Training  [12180/12500]  eta: 0:01:13  loss: 21.4443 (26.4057)  lr: 0.0000 (0.0000)  time: 0.197617  data: 0.000475  max mem: 3586
I20250120 13:02:38 3554128 dinov2 helpers.py:102] Training  [12190/12500]  eta: 0:01:11  loss: 21.5254 (26.4026)  lr: 0.0000 (0.0000)  time: 0.197571  data: 0.000453  max mem: 3586
I20250120 13:02:40 3554128 dinov2 helpers.py:102] Training  [12200/12500]  eta: 0:01:08  loss: 21.6568 (26.4007)  lr: 0.0000 (0.0000)  time: 0.197563  data: 0.000437  max mem: 3586
I20250120 13:02:42 3554128 dinov2 helpers.py:102] Training  [12210/12500]  eta: 0:01:06  loss: 21.5254 (26.3960)  lr: 0.0000 (0.0000)  time: 0.197539  data: 0.000437  max mem: 3586
I20250120 13:02:44 3554128 dinov2 helpers.py:102] Training  [12220/12500]  eta: 0:01:04  loss: 21.5254 (26.3928)  lr: 0.0000 (0.0000)  time: 0.197440  data: 0.000454  max mem: 3586
I20250120 13:02:46 3554128 dinov2 helpers.py:102] Training  [12230/12500]  eta: 0:01:01  loss: 21.5254 (26.3894)  lr: 0.0000 (0.0000)  time: 0.197470  data: 0.000463  max mem: 3586
I20250120 13:02:48 3554128 dinov2 helpers.py:102] Training  [12240/12500]  eta: 0:00:59  loss: 21.6636 (26.3856)  lr: 0.0000 (0.0000)  time: 0.197676  data: 0.000459  max mem: 3586
I20250120 13:02:50 3554128 dinov2 helpers.py:102] Training  [12250/12500]  eta: 0:00:57  loss: 21.7580 (26.3833)  lr: 0.0000 (0.0000)  time: 0.197780  data: 0.000464  max mem: 3586
I20250120 13:02:52 3554128 dinov2 helpers.py:102] Training  [12260/12500]  eta: 0:00:54  loss: 21.7580 (26.3799)  lr: 0.0000 (0.0000)  time: 0.197797  data: 0.000465  max mem: 3586
I20250120 13:02:54 3554128 dinov2 helpers.py:102] Training  [12270/12500]  eta: 0:00:52  loss: 21.7580 (26.3750)  lr: 0.0000 (0.0000)  time: 0.197787  data: 0.000483  max mem: 3586
I20250120 13:02:56 3554128 dinov2 helpers.py:102] Training  [12280/12500]  eta: 0:00:50  loss: 21.7580 (26.3697)  lr: 0.0000 (0.0000)  time: 0.197627  data: 0.000447  max mem: 3586
I20250120 13:02:58 3554128 dinov2 helpers.py:102] Training  [12290/12500]  eta: 0:00:48  loss: 21.7580 (26.3633)  lr: 0.0000 (0.0000)  time: 0.197752  data: 0.000421  max mem: 3586
I20250120 13:03:00 3554128 dinov2 helpers.py:102] Training  [12300/12500]  eta: 0:00:45  loss: 21.7580 (26.3580)  lr: 0.0000 (0.0000)  time: 0.197750  data: 0.000454  max mem: 3586
I20250120 13:03:02 3554128 dinov2 helpers.py:102] Training  [12310/12500]  eta: 0:00:43  loss: 21.5254 (26.3535)  lr: 0.0000 (0.0000)  time: 0.197473  data: 0.000449  max mem: 3586
I20250120 13:03:04 3554128 dinov2 helpers.py:102] Training  [12320/12500]  eta: 0:00:41  loss: 21.7580 (26.3504)  lr: 0.0000 (0.0000)  time: 0.197509  data: 0.000422  max mem: 3586
I20250120 13:03:06 3554128 dinov2 helpers.py:102] Training  [12330/12500]  eta: 0:00:38  loss: 21.7580 (26.3490)  lr: 0.0000 (0.0000)  time: 0.197610  data: 0.000434  max mem: 3586
I20250120 13:03:08 3554128 dinov2 helpers.py:102] Training  [12340/12500]  eta: 0:00:36  loss: 21.7580 (26.3450)  lr: 0.0000 (0.0000)  time: 0.197583  data: 0.000480  max mem: 3586
I20250120 13:03:10 3554128 dinov2 helpers.py:102] Training  [12350/12500]  eta: 0:00:34  loss: 22.1571 (26.3423)  lr: 0.0000 (0.0000)  time: 0.197626  data: 0.000463  max mem: 3586
I20250120 13:03:11 3554128 dinov2 helpers.py:102] Training  [12360/12500]  eta: 0:00:32  loss: 22.1634 (26.3415)  lr: 0.0000 (0.0000)  time: 0.197718  data: 0.000451  max mem: 3586
I20250120 13:03:13 3554128 dinov2 helpers.py:102] Training  [12370/12500]  eta: 0:00:29  loss: 22.1571 (26.3354)  lr: 0.0000 (0.0000)  time: 0.197737  data: 0.000484  max mem: 3586
I20250120 13:03:15 3554128 dinov2 helpers.py:102] Training  [12380/12500]  eta: 0:00:27  loss: 22.1571 (26.3339)  lr: 0.0000 (0.0000)  time: 0.197913  data: 0.000503  max mem: 3586
I20250120 13:03:17 3554128 dinov2 helpers.py:102] Training  [12390/12500]  eta: 0:00:25  loss: 21.7580 (26.3274)  lr: 0.0000 (0.0000)  time: 0.198001  data: 0.000481  max mem: 3586
I20250120 13:03:19 3554128 dinov2 helpers.py:102] Training  [12400/12500]  eta: 0:00:22  loss: 21.7437 (26.3237)  lr: 0.0000 (0.0000)  time: 0.197963  data: 0.000450  max mem: 3586
I20250120 13:03:21 3554128 dinov2 helpers.py:102] Training  [12410/12500]  eta: 0:00:20  loss: 21.7580 (26.3204)  lr: 0.0000 (0.0000)  time: 0.197995  data: 0.000451  max mem: 3586
I20250120 13:03:23 3554128 dinov2 helpers.py:102] Training  [12420/12500]  eta: 0:00:18  loss: 21.7580 (26.3178)  lr: 0.0000 (0.0000)  time: 0.197796  data: 0.000463  max mem: 3586
I20250120 13:03:25 3554128 dinov2 helpers.py:102] Training  [12430/12500]  eta: 0:00:16  loss: 21.7580 (26.3157)  lr: 0.0000 (0.0000)  time: 0.197687  data: 0.000415  max mem: 3586
I20250120 13:03:27 3554128 dinov2 helpers.py:102] Training  [12440/12500]  eta: 0:00:13  loss: 22.1634 (26.3125)  lr: 0.0000 (0.0000)  time: 0.197691  data: 0.000385  max mem: 3586
I20250120 13:03:29 3554128 dinov2 helpers.py:102] Training  [12450/12500]  eta: 0:00:11  loss: 21.7437 (26.3088)  lr: 0.0000 (0.0000)  time: 0.197552  data: 0.000408  max mem: 3586
I20250120 13:03:31 3554128 dinov2 helpers.py:102] Training  [12460/12500]  eta: 0:00:09  loss: 21.7238 (26.3016)  lr: 0.0000 (0.0000)  time: 0.197797  data: 0.000423  max mem: 3586
I20250120 13:03:33 3554128 dinov2 helpers.py:102] Training  [12470/12500]  eta: 0:00:06  loss: 21.7238 (26.2975)  lr: 0.0000 (0.0000)  time: 0.197984  data: 0.000451  max mem: 3586
I20250120 13:03:35 3554128 dinov2 helpers.py:102] Training  [12480/12500]  eta: 0:00:04  loss: 21.7238 (26.2921)  lr: 0.0000 (0.0000)  time: 0.197757  data: 0.000416  max mem: 3586
I20250120 13:03:37 3554128 dinov2 helpers.py:102] Training  [12490/12500]  eta: 0:00:02  loss: 21.7437 (26.2924)  lr: 0.0000 (0.0000)  time: 0.197618  data: 0.000401  max mem: 3586
I20250120 13:03:39 3554128 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_B/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/model_final.pth
I20250120 13:03:39 3554128 dinov2 helpers.py:102] Training  [12499/12500]  eta: 0:00:00  loss: 21.7437 (26.2924)  lr: 0.0000 (0.0000)  time: 0.201734  data: 0.000432  max mem: 3586
I20250120 13:03:39 3554128 dinov2 helpers.py:130] Training Total time: 0:47:37 (0.228628 s / it)
I20250120 13:03:39 3554128 dinov2 linear.py:272] running validation !
I20250120 13:03:40 3554128 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:38    time: 1.411175  data: 1.199647  max mem: 3586
I20250120 13:03:42 3554128 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:45    time: 0.314258  data: 0.110217  max mem: 3586
I20250120 13:03:44 3554128 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:35    time: 0.202237  data: 0.000817  max mem: 3586
I20250120 13:03:46 3554128 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.199659  data: 0.000332  max mem: 3586
I20250120 13:03:48 3554128 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:26    time: 0.199665  data: 0.000262  max mem: 3586
I20250120 13:03:50 3554128 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.199943  data: 0.000230  max mem: 3586
I20250120 13:03:52 3554128 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:20    time: 0.199749  data: 0.000251  max mem: 3586
I20250120 13:03:54 3554128 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199904  data: 0.000256  max mem: 3586
I20250120 13:03:56 3554128 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.200076  data: 0.000287  max mem: 3586
I20250120 13:03:58 3554128 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:13    time: 0.199715  data: 0.000352  max mem: 3586
I20250120 13:04:00 3554128 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199831  data: 0.000343  max mem: 3586
I20250120 13:04:02 3554128 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199858  data: 0.000277  max mem: 3586
I20250120 13:04:04 3554128 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199906  data: 0.000263  max mem: 3586
I20250120 13:04:06 3554128 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.200056  data: 0.000253  max mem: 3586
I20250120 13:04:08 3554128 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199733  data: 0.000251  max mem: 3586
I20250120 13:04:10 3554128 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199656  data: 0.000205  max mem: 3586
I20250120 13:04:11 3554128 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.196094  data: 0.000202  max mem: 3586
I20250120 13:04:11 3554128 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.208297 s / it)
I20250120 13:04:11 3554128 dinov2 utils.py:79] Averaged stats: 
I20250120 13:04:11 3554128 dinov2 linear.py:287] 
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7911, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8047, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8098, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8149, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8185, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8231, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8245, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8262, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8268, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8279, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8287, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8281, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7945, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8072, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8124, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8169, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8228, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8261, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8294, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8326, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8366, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8387, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8403, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8414, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8108, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8172, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8209, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8237, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8260, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8286, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8316, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8344, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8353, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8354, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8379, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8321, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8110, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8155, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8228, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8246, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8298, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8327, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8365, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8384, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8412, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8441, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8441, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8379, device='cuda:0')}
I20250120 13:04:11 3554128 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_02500', 'accuracy': 0.8441289663314819}
I20250120 13:04:11 3554128 dinov2 linear.py:590] Test Results Dict {'best_classifier': 'classifier_4_blocks_avgpool_True_lr_0_02500', 'CelebAPixelatedVal_accuracy': 84.4128966331482}

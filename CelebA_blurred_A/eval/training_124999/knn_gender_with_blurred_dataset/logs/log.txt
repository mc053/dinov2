I20250215 10:49:53 3084903 dinov2 config.py:59] git:
  sha: b6e9010bb34d082e5aa136aba99cb1ecb692a4b4, status: has uncommitted changes, branch: main

I20250215 10:49:53 3084903 dinov2 config.py:60] batch_size: 256
config_file: CelebA_blurred_A/config.yaml
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_blurred_A/eval/training_124999/knn_gender_with_blurred_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_blurred_A/eval/training_124999/knn_gender_with_blurred_dataset
pretrained_weights: CelebA_blurred_A/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: CelebABlurredTrain
val_dataset_str: CelebABlurredVal
I20250215 10:49:53 3084903 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250215 10:49:53 3084903 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebABlurredABTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_blurred_A/eval/training_124999/knn_gender_with_blurred_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
  a_b_training: A
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250215 10:49:53 3084903 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250215 10:49:55 3084903 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250215 10:49:56 3084903 dinov2 utils.py:33] Pretrained weights found at CelebA_blurred_A/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250215 10:49:56 3084903 dinov2 loaders.py:134] using dataset: "CelebABlurredTrain"
I20250215 10:49:58 3084903 dinov2 loaders.py:139] # of dataset samples: 162,127
I20250215 10:49:58 3084903 dinov2 loaders.py:134] using dataset: "CelebABlurredVal"
I20250215 10:49:58 3084903 dinov2 loaders.py:139] # of dataset samples: 19,792
I20250215 10:49:58 3084903 dinov2 knn.py:260] Extracting features for train set...
I20250215 10:49:58 3084903 dinov2 loaders.py:197] sampler: distributed
I20250215 10:49:58 3084903 dinov2 loaders.py:256] using PyTorch data loader
W20250215 10:49:58 3084903 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250215 10:49:58 3084903 dinov2 loaders.py:269] # of batches: 634
I20250215 10:50:04 3084903 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20250215 10:50:04 3084903 dinov2 helpers.py:102]   [  0/634]  eta: 1:02:27    time: 5.911529  data: 3.418651  max mem: 3463
I20250215 10:50:07 3084903 dinov2 helpers.py:102]   [ 10/634]  eta: 0:08:17    time: 0.796842  data: 0.311043  max mem: 4109
I20250215 10:50:10 3084903 dinov2 helpers.py:102]   [ 20/634]  eta: 0:05:57    time: 0.315054  data: 0.000287  max mem: 4109
I20250215 10:50:14 3084903 dinov2 helpers.py:102]   [ 30/634]  eta: 0:05:05    time: 0.345500  data: 0.000335  max mem: 4109
I20250215 10:50:17 3084903 dinov2 helpers.py:102]   [ 40/634]  eta: 0:04:37    time: 0.347144  data: 0.000378  max mem: 4109
I20250215 10:50:21 3084903 dinov2 helpers.py:102]   [ 50/634]  eta: 0:04:19    time: 0.348789  data: 0.000320  max mem: 4109
I20250215 10:50:24 3084903 dinov2 helpers.py:102]   [ 60/634]  eta: 0:04:06    time: 0.350240  data: 0.000306  max mem: 4109
I20250215 10:50:28 3084903 dinov2 helpers.py:102]   [ 70/634]  eta: 0:03:55    time: 0.351774  data: 0.000303  max mem: 4109
I20250215 10:50:31 3084903 dinov2 helpers.py:102]   [ 80/634]  eta: 0:03:47    time: 0.353688  data: 0.000277  max mem: 4109
I20250215 10:50:35 3084903 dinov2 helpers.py:102]   [ 90/634]  eta: 0:03:39    time: 0.355625  data: 0.000483  max mem: 4109
I20250215 10:50:38 3084903 dinov2 helpers.py:102]   [100/634]  eta: 0:03:33    time: 0.357484  data: 0.000464  max mem: 4109
I20250215 10:50:42 3084903 dinov2 helpers.py:102]   [110/634]  eta: 0:03:27    time: 0.359263  data: 0.000344  max mem: 4109
I20250215 10:50:46 3084903 dinov2 helpers.py:102]   [120/634]  eta: 0:03:22    time: 0.360763  data: 0.000430  max mem: 4109
I20250215 10:50:49 3084903 dinov2 helpers.py:102]   [130/634]  eta: 0:03:17    time: 0.362411  data: 0.000397  max mem: 4109
I20250215 10:50:53 3084903 dinov2 helpers.py:102]   [140/634]  eta: 0:03:12    time: 0.364235  data: 0.000346  max mem: 4109
I20250215 10:50:57 3084903 dinov2 helpers.py:102]   [150/634]  eta: 0:03:07    time: 0.366179  data: 0.000330  max mem: 4109
I20250215 10:51:00 3084903 dinov2 helpers.py:102]   [160/634]  eta: 0:03:03    time: 0.368150  data: 0.000350  max mem: 4109
I20250215 10:51:04 3084903 dinov2 helpers.py:102]   [170/634]  eta: 0:02:58    time: 0.369946  data: 0.000360  max mem: 4109
I20250215 10:51:08 3084903 dinov2 helpers.py:102]   [180/634]  eta: 0:02:54    time: 0.371711  data: 0.000313  max mem: 4109
I20250215 10:51:11 3084903 dinov2 helpers.py:102]   [190/634]  eta: 0:02:50    time: 0.373382  data: 0.000312  max mem: 4109
I20250215 10:51:15 3084903 dinov2 helpers.py:102]   [200/634]  eta: 0:02:46    time: 0.375042  data: 0.000342  max mem: 4109
I20250215 10:51:19 3084903 dinov2 helpers.py:102]   [210/634]  eta: 0:02:42    time: 0.376763  data: 0.000333  max mem: 4109
I20250215 10:51:23 3084903 dinov2 helpers.py:102]   [220/634]  eta: 0:02:38    time: 0.378166  data: 0.000286  max mem: 4109
I20250215 10:51:27 3084903 dinov2 helpers.py:102]   [230/634]  eta: 0:02:34    time: 0.379506  data: 0.000236  max mem: 4109
I20250215 10:51:30 3084903 dinov2 helpers.py:102]   [240/634]  eta: 0:02:30    time: 0.380879  data: 0.000277  max mem: 4109
I20250215 10:51:34 3084903 dinov2 helpers.py:102]   [250/634]  eta: 0:02:27    time: 0.381910  data: 0.000313  max mem: 4109
I20250215 10:51:38 3084903 dinov2 helpers.py:102]   [260/634]  eta: 0:02:23    time: 0.382980  data: 0.000290  max mem: 4109
I20250215 10:51:42 3084903 dinov2 helpers.py:102]   [270/634]  eta: 0:02:19    time: 0.384069  data: 0.000297  max mem: 4109
I20250215 10:51:46 3084903 dinov2 helpers.py:102]   [280/634]  eta: 0:02:15    time: 0.384758  data: 0.000286  max mem: 4109
I20250215 10:51:50 3084903 dinov2 helpers.py:102]   [290/634]  eta: 0:02:11    time: 0.385329  data: 0.000261  max mem: 4109
I20250215 10:51:54 3084903 dinov2 helpers.py:102]   [300/634]  eta: 0:02:08    time: 0.386099  data: 0.000298  max mem: 4109
I20250215 10:51:57 3084903 dinov2 helpers.py:102]   [310/634]  eta: 0:02:04    time: 0.387273  data: 0.000322  max mem: 4109
I20250215 10:52:01 3084903 dinov2 helpers.py:102]   [320/634]  eta: 0:02:00    time: 0.387877  data: 0.000322  max mem: 4109
I20250215 10:52:05 3084903 dinov2 helpers.py:102]   [330/634]  eta: 0:01:56    time: 0.388126  data: 0.000312  max mem: 4109
I20250215 10:52:09 3084903 dinov2 helpers.py:102]   [340/634]  eta: 0:01:52    time: 0.388613  data: 0.000308  max mem: 4109
I20250215 10:52:13 3084903 dinov2 helpers.py:102]   [350/634]  eta: 0:01:49    time: 0.389005  data: 0.000325  max mem: 4109
I20250215 10:52:17 3084903 dinov2 helpers.py:102]   [360/634]  eta: 0:01:45    time: 0.389403  data: 0.000311  max mem: 4109
I20250215 10:52:21 3084903 dinov2 helpers.py:102]   [370/634]  eta: 0:01:41    time: 0.389374  data: 0.000289  max mem: 4109
I20250215 10:52:25 3084903 dinov2 helpers.py:102]   [380/634]  eta: 0:01:37    time: 0.389512  data: 0.000304  max mem: 4109
I20250215 10:52:29 3084903 dinov2 helpers.py:102]   [390/634]  eta: 0:01:33    time: 0.389941  data: 0.000336  max mem: 4109
I20250215 10:52:32 3084903 dinov2 helpers.py:102]   [400/634]  eta: 0:01:30    time: 0.390297  data: 0.000306  max mem: 4109
I20250215 10:52:36 3084903 dinov2 helpers.py:102]   [410/634]  eta: 0:01:26    time: 0.390507  data: 0.000295  max mem: 4109
I20250215 10:52:40 3084903 dinov2 helpers.py:102]   [420/634]  eta: 0:01:22    time: 0.390543  data: 0.000322  max mem: 4109
I20250215 10:52:44 3084903 dinov2 helpers.py:102]   [430/634]  eta: 0:01:18    time: 0.390916  data: 0.000320  max mem: 4109
I20250215 10:52:48 3084903 dinov2 helpers.py:102]   [440/634]  eta: 0:01:14    time: 0.391457  data: 0.000280  max mem: 4109
I20250215 10:52:52 3084903 dinov2 helpers.py:102]   [450/634]  eta: 0:01:10    time: 0.391970  data: 0.000258  max mem: 4109
I20250215 10:52:56 3084903 dinov2 helpers.py:102]   [460/634]  eta: 0:01:07    time: 0.392432  data: 0.000313  max mem: 4109
I20250215 10:53:00 3084903 dinov2 helpers.py:102]   [470/634]  eta: 0:01:03    time: 0.392829  data: 0.000306  max mem: 4109
I20250215 10:53:04 3084903 dinov2 helpers.py:102]   [480/634]  eta: 0:00:59    time: 0.392955  data: 0.000295  max mem: 4109
I20250215 10:53:08 3084903 dinov2 helpers.py:102]   [490/634]  eta: 0:00:55    time: 0.392768  data: 0.000302  max mem: 4109
I20250215 10:53:12 3084903 dinov2 helpers.py:102]   [500/634]  eta: 0:00:51    time: 0.392839  data: 0.000292  max mem: 4109
I20250215 10:53:16 3084903 dinov2 helpers.py:102]   [510/634]  eta: 0:00:47    time: 0.393059  data: 0.000279  max mem: 4109
I20250215 10:53:19 3084903 dinov2 helpers.py:102]   [520/634]  eta: 0:00:44    time: 0.393403  data: 0.000257  max mem: 4109
I20250215 10:53:23 3084903 dinov2 helpers.py:102]   [530/634]  eta: 0:00:40    time: 0.393781  data: 0.000280  max mem: 4109
I20250215 10:53:27 3084903 dinov2 helpers.py:102]   [540/634]  eta: 0:00:36    time: 0.393544  data: 0.000262  max mem: 4109
I20250215 10:53:31 3084903 dinov2 helpers.py:102]   [550/634]  eta: 0:00:32    time: 0.393149  data: 0.000282  max mem: 4109
I20250215 10:53:35 3084903 dinov2 helpers.py:102]   [560/634]  eta: 0:00:28    time: 0.393342  data: 0.000291  max mem: 4109
I20250215 10:53:39 3084903 dinov2 helpers.py:102]   [570/634]  eta: 0:00:24    time: 0.393703  data: 0.000268  max mem: 4109
I20250215 10:53:43 3084903 dinov2 helpers.py:102]   [580/634]  eta: 0:00:20    time: 0.394258  data: 0.000294  max mem: 4109
I20250215 10:53:47 3084903 dinov2 helpers.py:102]   [590/634]  eta: 0:00:17    time: 0.394502  data: 0.000281  max mem: 4109
I20250215 10:53:51 3084903 dinov2 helpers.py:102]   [600/634]  eta: 0:00:13    time: 0.394393  data: 0.000274  max mem: 4109
I20250215 10:53:55 3084903 dinov2 helpers.py:102]   [610/634]  eta: 0:00:09    time: 0.394476  data: 0.000277  max mem: 4109
I20250215 10:53:59 3084903 dinov2 helpers.py:102]   [620/634]  eta: 0:00:05    time: 0.394447  data: 0.000273  max mem: 4109
I20250215 10:54:03 3084903 dinov2 helpers.py:102]   [630/634]  eta: 0:00:01    time: 0.394282  data: 0.000347  max mem: 4109
I20250215 10:54:05 3084903 dinov2 helpers.py:102]   [633/634]  eta: 0:00:00    time: 0.431371  data: 0.000325  max mem: 4109
I20250215 10:54:05 3084903 dinov2 helpers.py:130]  Total time: 0:04:06 (0.389351 s / it)
I20250215 10:54:05 3084903 dinov2 utils.py:141] Features shape: (162127, 1024)
I20250215 10:54:05 3084903 dinov2 utils.py:142] Labels shape: (162127,)
I20250215 10:54:05 3084903 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20250215 10:54:05 3084903 dinov2 loaders.py:197] sampler: distributed
I20250215 10:54:05 3084903 dinov2 loaders.py:256] using PyTorch data loader
I20250215 10:54:05 3084903 dinov2 loaders.py:269] # of batches: 78
I20250215 10:54:05 3084903 dinov2 knn.py:299] Start the k-NN classification.
I20250215 10:54:07 3084903 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:02:42    time: 2.077991  data: 1.704869  max mem: 4109
I20250215 10:54:11 3084903 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:00:37    time: 0.547369  data: 0.155275  max mem: 4109
I20250215 10:54:15 3084903 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:00:27    time: 0.394729  data: 0.000308  max mem: 4109
I20250215 10:54:19 3084903 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:00:21    time: 0.395553  data: 0.000275  max mem: 4109
I20250215 10:54:23 3084903 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:16    time: 0.395912  data: 0.000242  max mem: 4109
I20250215 10:54:27 3084903 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:11    time: 0.395919  data: 0.000210  max mem: 4109
I20250215 10:54:31 3084903 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:07    time: 0.396054  data: 0.000201  max mem: 4109
I20250215 10:54:35 3084903 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:03    time: 0.396562  data: 0.000193  max mem: 4109
I20250215 10:54:37 3084903 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:00    time: 0.388021  data: 0.000147  max mem: 4109
I20250215 10:54:37 3084903 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.415211 s / it)
I20250215 10:54:37 3084903 dinov2 utils.py:79] Averaged stats: 
I20250215 10:54:37 3084903 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 85.79
I20250215 10:54:37 3084903 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 86.04
I20250215 10:54:37 3084903 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 86.28
I20250215 10:54:37 3084903 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 86.22

I20241203 06:31:14 1958660 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:14 1958660 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:14 1958660 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:14 1958660 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:14 1958660 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:15 1958663 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:15 1958663 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:15 1958663 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:15 1958663 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:15 1958666 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:15 1958666 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:15 1958666 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:15 1958666 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:15 1958663 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:15 1958666 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:15 1958664 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:15 1958664 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:15 1958664 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:15 1958664 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:15 1958664 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:16 1958662 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:16 1958662 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:16 1958662 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:16 1958662 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:16 1958665 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:16 1958665 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:16 1958665 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:16 1958665 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:16 1958662 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:16 1958665 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:16 1958661 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:16 1958661 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:16 1958661 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:16 1958661 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:16 1958661 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:16 1958667 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 06:31:16 1958667 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 06:31:16 1958667 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 06:31:16 1958667 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 06:31:16 1958667 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 06:31:42 1958663 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:44 1958662 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:44 1958664 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:47 1958663 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:48 1958663 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:49 1958662 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:49 1958664 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:50 1958662 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:50 1958666 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:50 1958664 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:51 1958660 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:52 1958666 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:53 1958665 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:53 1958666 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:53 1958667 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:53 1958661 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 06:31:55 1958663 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:31:55 1958663 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:31:55 1958660 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:56 1958663 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:31:56 1958660 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:56 1958663 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:31:56 1958663 dinov2 loaders.py:151] sampler: distributed
I20241203 06:31:56 1958663 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:31:56 1958663 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:31:56 1958663 dinov2 loaders.py:223] # of batches: 634
I20241203 06:31:58 1958664 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:31:58 1958664 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:31:58 1958665 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:58 1958667 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:58 1958662 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:31:58 1958662 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:31:58 1958667 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:58 1958665 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:59 1958661 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 06:31:59 1958661 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 06:31:59 1958664 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:31:59 1958664 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:31:59 1958664 dinov2 loaders.py:151] sampler: distributed
I20241203 06:31:59 1958664 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:31:59 1958664 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:31:59 1958664 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:00 1958662 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:00 1958662 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:00 1958662 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:00 1958662 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:00 1958662 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:00 1958662 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:03 1958666 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:32:03 1958666 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:32:05 1958666 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:05 1958666 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:05 1958666 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:05 1958666 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:05 1958666 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:05 1958666 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:12 1958660 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:32:12 1958660 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:32:13 1958667 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:32:13 1958667 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:32:14 1958660 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:14 1958660 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:14 1958660 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:14 1958660 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:14 1958660 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:14 1958660 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:15 1958665 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:32:15 1958665 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:32:15 1958667 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:15 1958667 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:15 1958667 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:15 1958667 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:15 1958667 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:15 1958667 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:17 1958661 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 06:32:17 1958661 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 06:32:19 1958665 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:19 1958665 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:19 1958665 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:19 1958665 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:19 1958665 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:19 1958665 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:20 1958661 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 06:32:20 1958661 dinov2 knn.py:260] Extracting features for train set...
I20241203 06:32:20 1958661 dinov2 loaders.py:151] sampler: distributed
I20241203 06:32:20 1958661 dinov2 loaders.py:210] using PyTorch data loader
W20241203 06:32:20 1958661 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 06:32:20 1958661 dinov2 loaders.py:223] # of batches: 634
I20241203 06:32:26 1958663 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:32:26 1958663 dinov2 helpers.py:102]   [  0/634]  eta: 5:16:09    time: 29.919697  data: 11.273020  max mem: 3463
I20241203 06:32:30 1958663 dinov2 helpers.py:102]   [ 10/634]  eta: 0:31:45    time: 3.053562  data: 1.026743  max mem: 4109
I20241203 06:32:34 1958662 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:32:34 1958662 dinov2 helpers.py:102]   [  0/634]  eta: 5:57:55    time: 33.872391  data: 10.146656  max mem: 3463
I20241203 06:32:35 1958664 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:32:35 1958664 dinov2 helpers.py:102]   [  0/634]  eta: 6:21:54    time: 36.142754  data: 13.571133  max mem: 3463
I20241203 06:32:41 1958663 dinov2 helpers.py:102]   [ 20/634]  eta: 0:21:53    time: 0.749944  data: 0.416262  max mem: 4109
I20241203 06:32:45 1958662 dinov2 helpers.py:102]   [ 10/634]  eta: 0:42:42    time: 4.107335  data: 0.924480  max mem: 4109
I20241203 06:32:47 1958664 dinov2 helpers.py:102]   [ 10/634]  eta: 0:45:36    time: 4.385383  data: 1.237259  max mem: 4109
I20241203 06:32:52 1958666 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:32:52 1958666 dinov2 helpers.py:102]   [  0/634]  eta: 8:16:07    time: 46.951450  data: 8.521588  max mem: 3463
I20241203 06:32:57 1958663 dinov2 helpers.py:102]   [ 30/634]  eta: 0:19:52    time: 1.381728  data: 0.487068  max mem: 4109
I20241203 06:33:03 1958662 dinov2 helpers.py:102]   [ 20/634]  eta: 0:30:34    time: 1.442869  data: 0.001853  max mem: 4109
I20241203 06:33:06 1958664 dinov2 helpers.py:102]   [ 20/634]  eta: 0:32:27    time: 1.523094  data: 0.002360  max mem: 4109
I20241203 06:33:09 1958660 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:33:09 1958660 dinov2 helpers.py:102]   [  0/634]  eta: 9:32:09    time: 54.147045  data: 10.238249  max mem: 3463
I20241203 06:33:09 1958666 dinov2 helpers.py:102]   [ 10/634]  eta: 0:59:52    time: 5.756894  data: 0.777274  max mem: 4109
I20241203 06:33:12 1958667 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:33:12 1958667 dinov2 helpers.py:102]   [  0/634]  eta: 9:56:58    time: 56.496399  data: 14.680174  max mem: 3463
I20241203 06:33:16 1958661 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:33:16 1958661 dinov2 helpers.py:102]   [  0/634]  eta: 9:50:08    time: 55.849747  data: 14.059924  max mem: 3463
I20241203 06:33:16 1958665 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 06:33:16 1958665 dinov2 helpers.py:102]   [  0/634]  eta: 10:09:41    time: 57.700058  data: 15.897041  max mem: 3464
I20241203 06:33:23 1958663 dinov2 helpers.py:102]   [ 40/634]  eta: 0:20:59    time: 2.101540  data: 0.072229  max mem: 4109
I20241203 06:33:33 1958662 dinov2 helpers.py:102]   [ 30/634]  eta: 0:30:19    time: 2.410455  data: 0.001165  max mem: 4109
I20241203 06:33:38 1958660 dinov2 helpers.py:102]   [ 10/634]  eta: 1:18:51    time: 7.583232  data: 0.932150  max mem: 4109
I20241203 06:33:40 1958664 dinov2 helpers.py:102]   [ 30/634]  eta: 0:32:39    time: 2.615300  data: 0.001048  max mem: 4109
I20241203 06:33:43 1958667 dinov2 helpers.py:102]   [ 10/634]  eta: 1:22:39    time: 7.947360  data: 1.339178  max mem: 4109
I20241203 06:33:45 1958666 dinov2 helpers.py:102]   [ 20/634]  eta: 0:48:34    time: 2.636004  data: 0.003217  max mem: 4109
I20241203 06:33:48 1958661 dinov2 helpers.py:102]   [ 10/634]  eta: 1:23:09    time: 7.995448  data: 1.279128  max mem: 4109
I20241203 06:33:49 1958665 dinov2 helpers.py:102]   [ 10/634]  eta: 1:24:58    time: 8.171024  data: 1.446256  max mem: 4109
I20241203 06:34:02 1958663 dinov2 helpers.py:102]   [ 50/634]  eta: 0:24:02    time: 3.237896  data: 0.001399  max mem: 4109
I20241203 06:34:12 1958662 dinov2 helpers.py:102]   [ 40/634]  eta: 0:31:59    time: 3.487801  data: 0.000920  max mem: 4109
I20241203 06:34:17 1958660 dinov2 helpers.py:102]   [ 20/634]  eta: 0:59:44    time: 3.422048  data: 0.001503  max mem: 4109
I20241203 06:34:19 1958664 dinov2 helpers.py:102]   [ 40/634]  eta: 0:33:44    time: 3.656556  data: 0.000982  max mem: 4109
I20241203 06:34:22 1958667 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:40    time: 3.503309  data: 0.002939  max mem: 4109
I20241203 06:34:24 1958666 dinov2 helpers.py:102]   [ 30/634]  eta: 0:45:05    time: 3.777909  data: 0.002744  max mem: 4109
I20241203 06:34:27 1958661 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:59    time: 3.568587  data: 0.001135  max mem: 4109
I20241203 06:34:28 1958665 dinov2 helpers.py:102]   [ 20/634]  eta: 1:02:58    time: 3.577119  data: 0.001120  max mem: 4109
I20241203 06:34:42 1958663 dinov2 helpers.py:102]   [ 60/634]  eta: 0:25:55    time: 3.917548  data: 0.001479  max mem: 4109
I20241203 06:34:52 1958662 dinov2 helpers.py:102]   [ 50/634]  eta: 0:32:48    time: 3.926471  data: 0.001043  max mem: 4109
I20241203 06:34:56 1958660 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:37    time: 3.931205  data: 0.001468  max mem: 4109
I20241203 06:34:58 1958664 dinov2 helpers.py:102]   [ 50/634]  eta: 0:34:12    time: 3.933010  data: 0.001160  max mem: 4109
I20241203 06:35:01 1958667 dinov2 helpers.py:102]   [ 30/634]  eta: 0:53:55    time: 3.932341  data: 0.001103  max mem: 4109
I20241203 06:35:04 1958666 dinov2 helpers.py:102]   [ 40/634]  eta: 0:43:03    time: 3.934109  data: 0.001492  max mem: 4109
I20241203 06:35:07 1958661 dinov2 helpers.py:102]   [ 30/634]  eta: 0:54:09    time: 3.941436  data: 0.001906  max mem: 4109
I20241203 06:35:08 1958665 dinov2 helpers.py:102]   [ 30/634]  eta: 0:54:50    time: 3.950490  data: 0.001171  max mem: 4109
I20241203 06:35:21 1958663 dinov2 helpers.py:102]   [ 70/634]  eta: 0:27:07    time: 3.942215  data: 0.000936  max mem: 4109
I20241203 06:35:31 1958662 dinov2 helpers.py:102]   [ 60/634]  eta: 0:33:10    time: 3.950913  data: 0.001470  max mem: 4109
I20241203 06:35:36 1958660 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:40    time: 3.950532  data: 0.002532  max mem: 4109
I20241203 06:35:38 1958664 dinov2 helpers.py:102]   [ 60/634]  eta: 0:34:18    time: 3.950446  data: 0.001221  max mem: 4109
I20241203 06:35:41 1958667 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:39    time: 3.953065  data: 0.001049  max mem: 4109
I20241203 06:35:43 1958666 dinov2 helpers.py:102]   [ 50/634]  eta: 0:41:35    time: 3.950324  data: 0.001183  max mem: 4109
I20241203 06:35:47 1958661 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:49    time: 3.954617  data: 0.002320  max mem: 4109
I20241203 06:35:47 1958665 dinov2 helpers.py:102]   [ 40/634]  eta: 0:50:22    time: 3.968152  data: 0.001294  max mem: 4109
I20241203 06:36:01 1958663 dinov2 helpers.py:102]   [ 80/634]  eta: 0:27:51    time: 3.952716  data: 0.001076  max mem: 4109
I20241203 06:36:11 1958662 dinov2 helpers.py:102]   [ 70/634]  eta: 0:33:14    time: 3.955387  data: 0.002876  max mem: 4109
I20241203 06:36:16 1958660 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:01    time: 3.955339  data: 0.002397  max mem: 4109
I20241203 06:36:18 1958664 dinov2 helpers.py:102]   [ 70/634]  eta: 0:34:11    time: 3.954352  data: 0.000840  max mem: 4109
I20241203 06:36:20 1958667 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:47    time: 3.956086  data: 0.001933  max mem: 4109
I20241203 06:36:23 1958666 dinov2 helpers.py:102]   [ 60/634]  eta: 0:40:22    time: 3.954363  data: 0.001533  max mem: 4109
I20241203 06:36:26 1958661 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:55    time: 3.956089  data: 0.001867  max mem: 4109
I20241203 06:36:27 1958665 dinov2 helpers.py:102]   [ 50/634]  eta: 0:47:23    time: 3.971296  data: 0.001458  max mem: 4109
I20241203 06:36:40 1958663 dinov2 helpers.py:102]   [ 90/634]  eta: 0:28:17    time: 3.956809  data: 0.001172  max mem: 4109
I20241203 06:36:50 1958662 dinov2 helpers.py:102]   [ 80/634]  eta: 0:33:07    time: 3.957534  data: 0.002482  max mem: 4109
I20241203 06:36:55 1958660 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:02    time: 3.959719  data: 0.001160  max mem: 4109
I20241203 06:36:57 1958664 dinov2 helpers.py:102]   [ 80/634]  eta: 0:33:57    time: 3.958858  data: 0.001304  max mem: 4109
I20241203 06:37:00 1958667 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:40    time: 3.960673  data: 0.001905  max mem: 4109
I20241203 06:37:03 1958666 dinov2 helpers.py:102]   [ 70/634]  eta: 0:39:19    time: 3.958931  data: 0.001961  max mem: 4109
I20241203 06:37:06 1958661 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:46    time: 3.961684  data: 0.001191  max mem: 4109
I20241203 06:37:07 1958665 dinov2 helpers.py:102]   [ 60/634]  eta: 0:45:10    time: 3.971574  data: 0.001384  max mem: 4109
I20241203 06:37:20 1958663 dinov2 helpers.py:102]   [100/634]  eta: 0:28:30    time: 3.959345  data: 0.001130  max mem: 4109
I20241203 06:37:30 1958662 dinov2 helpers.py:102]   [ 90/634]  eta: 0:32:54    time: 3.965940  data: 0.001074  max mem: 4109
I20241203 06:37:35 1958660 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:25    time: 3.966183  data: 0.001082  max mem: 4109
I20241203 06:37:37 1958664 dinov2 helpers.py:102]   [ 90/634]  eta: 0:33:37    time: 3.963612  data: 0.001343  max mem: 4109
I20241203 06:37:40 1958667 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:57    time: 3.965348  data: 0.000729  max mem: 4109
I20241203 06:37:42 1958666 dinov2 helpers.py:102]   [ 80/634]  eta: 0:38:23    time: 3.969031  data: 0.001824  max mem: 4109
I20241203 06:37:45 1958661 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:03    time: 3.969142  data: 0.000729  max mem: 4109
I20241203 06:37:47 1958665 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:24    time: 3.980057  data: 0.001127  max mem: 4109
I20241203 06:38:00 1958663 dinov2 helpers.py:102]   [110/634]  eta: 0:28:35    time: 3.967923  data: 0.001863  max mem: 4109
I20241203 06:38:10 1958662 dinov2 helpers.py:102]   [100/634]  eta: 0:32:36    time: 3.972026  data: 0.001844  max mem: 4109
I20241203 06:38:15 1958660 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:03    time: 3.972799  data: 0.001180  max mem: 4109
I20241203 06:38:17 1958664 dinov2 helpers.py:102]   [100/634]  eta: 0:33:14    time: 3.969304  data: 0.001025  max mem: 4109
I20241203 06:38:20 1958667 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:31    time: 3.971951  data: 0.001592  max mem: 4109
I20241203 06:38:22 1958666 dinov2 helpers.py:102]   [ 90/634]  eta: 0:37:31    time: 3.974812  data: 0.001213  max mem: 4109
I20241203 06:38:25 1958661 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:36    time: 3.974013  data: 0.000664  max mem: 4109
I20241203 06:38:27 1958665 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:56    time: 3.992130  data: 0.001001  max mem: 4109
I20241203 06:38:39 1958663 dinov2 helpers.py:102]   [120/634]  eta: 0:28:32    time: 3.977991  data: 0.001593  max mem: 4109
I20241203 06:38:50 1958662 dinov2 helpers.py:102]   [110/634]  eta: 0:32:14    time: 3.976229  data: 0.001625  max mem: 4109
I20241203 06:38:54 1958660 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:51    time: 3.976051  data: 0.001373  max mem: 4109
I20241203 06:38:56 1958664 dinov2 helpers.py:102]   [110/634]  eta: 0:32:48    time: 3.974280  data: 0.001054  max mem: 4109
I20241203 06:38:59 1958667 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:15    time: 3.976173  data: 0.001438  max mem: 4109
I20241203 06:39:02 1958666 dinov2 helpers.py:102]   [100/634]  eta: 0:36:41    time: 3.976171  data: 0.001877  max mem: 4109
I20241203 06:39:05 1958661 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:19    time: 3.974525  data: 0.000697  max mem: 4109
I20241203 06:39:06 1958665 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:37    time: 3.994149  data: 0.001896  max mem: 4109
I20241203 06:39:19 1958663 dinov2 helpers.py:102]   [130/634]  eta: 0:28:23    time: 3.976096  data: 0.000651  max mem: 4109
I20241203 06:39:29 1958662 dinov2 helpers.py:102]   [120/634]  eta: 0:31:49    time: 3.975880  data: 0.000678  max mem: 4109
I20241203 06:39:34 1958660 dinov2 helpers.py:102]   [100/634]  eta: 0:38:44    time: 3.974175  data: 0.001268  max mem: 4109
I20241203 06:39:36 1958664 dinov2 helpers.py:102]   [120/634]  eta: 0:32:20    time: 3.974368  data: 0.000803  max mem: 4109
I20241203 06:39:39 1958667 dinov2 helpers.py:102]   [100/634]  eta: 0:39:06    time: 3.974380  data: 0.000732  max mem: 4109
I20241203 06:39:42 1958666 dinov2 helpers.py:102]   [110/634]  eta: 0:35:53    time: 3.976169  data: 0.001904  max mem: 4109
I20241203 06:39:45 1958661 dinov2 helpers.py:102]   [100/634]  eta: 0:39:10    time: 3.977139  data: 0.000972  max mem: 4109
I20241203 06:39:46 1958665 dinov2 helpers.py:102]   [100/634]  eta: 0:39:27    time: 3.991251  data: 0.002758  max mem: 4109
I20241203 06:39:59 1958663 dinov2 helpers.py:102]   [140/634]  eta: 0:28:10    time: 3.974305  data: 0.000939  max mem: 4109
I20241203 06:40:09 1958662 dinov2 helpers.py:102]   [130/634]  eta: 0:31:22    time: 3.974540  data: 0.000827  max mem: 4109
I20241203 06:40:14 1958660 dinov2 helpers.py:102]   [110/634]  eta: 0:37:43    time: 3.974248  data: 0.001052  max mem: 4109
I20241203 06:40:16 1958664 dinov2 helpers.py:102]   [130/634]  eta: 0:31:50    time: 3.974365  data: 0.000489  max mem: 4109
I20241203 06:40:19 1958667 dinov2 helpers.py:102]   [110/634]  eta: 0:38:02    time: 3.974408  data: 0.000817  max mem: 4109
I20241203 06:40:21 1958666 dinov2 helpers.py:102]   [120/634]  eta: 0:35:06    time: 3.974384  data: 0.000723  max mem: 4109
I20241203 06:40:25 1958661 dinov2 helpers.py:102]   [110/634]  eta: 0:38:06    time: 3.976941  data: 0.000974  max mem: 4109
I20241203 06:40:26 1958665 dinov2 helpers.py:102]   [110/634]  eta: 0:38:21    time: 3.991364  data: 0.002297  max mem: 4109
I20241203 06:40:39 1958663 dinov2 helpers.py:102]   [150/634]  eta: 0:27:54    time: 3.974419  data: 0.001695  max mem: 4109
I20241203 06:40:49 1958662 dinov2 helpers.py:102]   [140/634]  eta: 0:30:53    time: 3.974389  data: 0.001027  max mem: 4109
I20241203 06:40:54 1958660 dinov2 helpers.py:102]   [120/634]  eta: 0:36:45    time: 3.974355  data: 0.002011  max mem: 4109
I20241203 06:40:56 1958664 dinov2 helpers.py:102]   [140/634]  eta: 0:31:18    time: 3.974288  data: 0.001176  max mem: 4109
I20241203 06:40:59 1958667 dinov2 helpers.py:102]   [120/634]  eta: 0:37:02    time: 3.974335  data: 0.000739  max mem: 4109
I20241203 06:41:01 1958666 dinov2 helpers.py:102]   [130/634]  eta: 0:34:20    time: 3.974455  data: 0.000540  max mem: 4109
I20241203 06:41:04 1958661 dinov2 helpers.py:102]   [120/634]  eta: 0:37:06    time: 3.974206  data: 0.001004  max mem: 4109
I20241203 06:41:06 1958665 dinov2 helpers.py:102]   [120/634]  eta: 0:37:20    time: 3.990504  data: 0.001637  max mem: 4109
I20241203 06:41:18 1958663 dinov2 helpers.py:102]   [160/634]  eta: 0:27:34    time: 3.974326  data: 0.001650  max mem: 4109
I20241203 06:41:29 1958662 dinov2 helpers.py:102]   [150/634]  eta: 0:30:23    time: 3.974495  data: 0.000834  max mem: 4109
I20241203 06:41:33 1958660 dinov2 helpers.py:102]   [130/634]  eta: 0:35:50    time: 3.974328  data: 0.002055  max mem: 4109
I20241203 06:41:35 1958664 dinov2 helpers.py:102]   [150/634]  eta: 0:30:46    time: 3.974365  data: 0.001376  max mem: 4109
I20241203 06:41:38 1958667 dinov2 helpers.py:102]   [130/634]  eta: 0:36:06    time: 3.974307  data: 0.001293  max mem: 4109
I20241203 06:41:41 1958666 dinov2 helpers.py:102]   [140/634]  eta: 0:33:35    time: 3.974286  data: 0.000613  max mem: 4109
I20241203 06:41:44 1958661 dinov2 helpers.py:102]   [130/634]  eta: 0:36:09    time: 3.974236  data: 0.001548  max mem: 4109
I20241203 06:41:46 1958665 dinov2 helpers.py:102]   [130/634]  eta: 0:36:22    time: 3.983275  data: 0.001421  max mem: 4109
I20241203 06:41:58 1958663 dinov2 helpers.py:102]   [170/634]  eta: 0:27:12    time: 3.974193  data: 0.001141  max mem: 4109
I20241203 06:42:08 1958662 dinov2 helpers.py:102]   [160/634]  eta: 0:29:51    time: 3.974113  data: 0.000708  max mem: 4109
I20241203 06:42:13 1958660 dinov2 helpers.py:102]   [140/634]  eta: 0:34:57    time: 3.974108  data: 0.001344  max mem: 4109
I20241203 06:42:15 1958664 dinov2 helpers.py:102]   [160/634]  eta: 0:30:12    time: 3.974193  data: 0.000804  max mem: 4109
I20241203 06:42:18 1958667 dinov2 helpers.py:102]   [140/634]  eta: 0:35:11    time: 3.974154  data: 0.001374  max mem: 4109
I20241203 06:42:21 1958666 dinov2 helpers.py:102]   [150/634]  eta: 0:32:51    time: 3.974030  data: 0.000911  max mem: 4109
I20241203 06:42:24 1958661 dinov2 helpers.py:102]   [140/634]  eta: 0:35:14    time: 3.974047  data: 0.001478  max mem: 4109
I20241203 06:42:26 1958665 dinov2 helpers.py:102]   [140/634]  eta: 0:35:26    time: 3.978692  data: 0.001623  max mem: 4109
I20241203 06:42:38 1958663 dinov2 helpers.py:102]   [180/634]  eta: 0:26:49    time: 3.973885  data: 0.001194  max mem: 4109
I20241203 06:42:48 1958662 dinov2 helpers.py:102]   [170/634]  eta: 0:29:19    time: 3.972504  data: 0.001144  max mem: 4109
I20241203 06:42:53 1958660 dinov2 helpers.py:102]   [150/634]  eta: 0:34:06    time: 3.973728  data: 0.001298  max mem: 4109
I20241203 06:42:55 1958664 dinov2 helpers.py:102]   [170/634]  eta: 0:29:38    time: 3.973652  data: 0.001454  max mem: 4109
I20241203 06:42:58 1958667 dinov2 helpers.py:102]   [150/634]  eta: 0:34:19    time: 3.973727  data: 0.001488  max mem: 4109
I20241203 06:43:00 1958666 dinov2 helpers.py:102]   [160/634]  eta: 0:32:07    time: 3.973639  data: 0.000937  max mem: 4109
I20241203 06:43:03 1958661 dinov2 helpers.py:102]   [150/634]  eta: 0:34:21    time: 3.973561  data: 0.001449  max mem: 4109
I20241203 06:43:06 1958665 dinov2 helpers.py:102]   [150/634]  eta: 0:34:33    time: 3.977207  data: 0.001597  max mem: 4109
I20241203 06:43:18 1958663 dinov2 helpers.py:102]   [190/634]  eta: 0:26:23    time: 3.973414  data: 0.001034  max mem: 4109
I20241203 06:43:28 1958662 dinov2 helpers.py:102]   [180/634]  eta: 0:28:45    time: 3.972486  data: 0.001214  max mem: 4109
I20241203 06:43:33 1958660 dinov2 helpers.py:102]   [160/634]  eta: 0:33:16    time: 3.973329  data: 0.001107  max mem: 4109
I20241203 06:43:34 1958664 dinov2 helpers.py:102]   [180/634]  eta: 0:29:03    time: 3.973223  data: 0.001254  max mem: 4109
I20241203 06:43:37 1958667 dinov2 helpers.py:102]   [160/634]  eta: 0:33:28    time: 3.973233  data: 0.001689  max mem: 4109
I20241203 06:43:40 1958666 dinov2 helpers.py:102]   [170/634]  eta: 0:31:24    time: 3.973196  data: 0.001048  max mem: 4109
I20241203 06:43:43 1958661 dinov2 helpers.py:102]   [160/634]  eta: 0:33:30    time: 3.973286  data: 0.002253  max mem: 4109
I20241203 06:43:45 1958665 dinov2 helpers.py:102]   [160/634]  eta: 0:33:41    time: 3.974119  data: 0.002102  max mem: 4109
I20241203 06:43:57 1958663 dinov2 helpers.py:102]   [200/634]  eta: 0:25:56    time: 3.973363  data: 0.000897  max mem: 4109
I20241203 06:44:08 1958662 dinov2 helpers.py:102]   [190/634]  eta: 0:28:11    time: 3.974237  data: 0.000948  max mem: 4109
I20241203 06:44:12 1958660 dinov2 helpers.py:102]   [170/634]  eta: 0:32:27    time: 3.973390  data: 0.001320  max mem: 4109
I20241203 06:44:14 1958664 dinov2 helpers.py:102]   [190/634]  eta: 0:28:28    time: 3.973423  data: 0.000857  max mem: 4109
I20241203 06:44:17 1958667 dinov2 helpers.py:102]   [170/634]  eta: 0:32:38    time: 3.973374  data: 0.001907  max mem: 4109
I20241203 06:44:20 1958666 dinov2 helpers.py:102]   [180/634]  eta: 0:30:41    time: 3.973548  data: 0.001497  max mem: 4109
I20241203 06:44:23 1958661 dinov2 helpers.py:102]   [170/634]  eta: 0:32:41    time: 3.973745  data: 0.002618  max mem: 4109
I20241203 06:44:25 1958665 dinov2 helpers.py:102]   [170/634]  eta: 0:32:50    time: 3.973607  data: 0.001671  max mem: 4109
I20241203 06:44:37 1958663 dinov2 helpers.py:102]   [210/634]  eta: 0:25:28    time: 3.973687  data: 0.000964  max mem: 4109
I20241203 06:44:47 1958662 dinov2 helpers.py:102]   [200/634]  eta: 0:27:37    time: 3.974607  data: 0.000882  max mem: 4109
I20241203 06:44:52 1958660 dinov2 helpers.py:102]   [180/634]  eta: 0:31:40    time: 3.973798  data: 0.001127  max mem: 4109
I20241203 06:44:54 1958664 dinov2 helpers.py:102]   [200/634]  eta: 0:27:52    time: 3.973796  data: 0.001220  max mem: 4109
I20241203 06:44:57 1958667 dinov2 helpers.py:102]   [180/634]  eta: 0:31:50    time: 3.973764  data: 0.001787  max mem: 4109
I20241203 06:44:59 1958666 dinov2 helpers.py:102]   [190/634]  eta: 0:29:59    time: 3.974142  data: 0.002345  max mem: 4109
I20241203 06:45:03 1958661 dinov2 helpers.py:102]   [180/634]  eta: 0:31:52    time: 3.973960  data: 0.001824  max mem: 4109
I20241203 06:45:05 1958665 dinov2 helpers.py:102]   [180/634]  eta: 0:32:01    time: 3.973901  data: 0.000644  max mem: 4109
I20241203 06:45:17 1958663 dinov2 helpers.py:102]   [220/634]  eta: 0:24:59    time: 3.973808  data: 0.001053  max mem: 4109
I20241203 06:45:27 1958662 dinov2 helpers.py:102]   [210/634]  eta: 0:27:02    time: 3.973899  data: 0.001008  max mem: 4109
I20241203 06:45:32 1958660 dinov2 helpers.py:102]   [190/634]  eta: 0:30:53    time: 3.973809  data: 0.001704  max mem: 4109
I20241203 06:45:34 1958664 dinov2 helpers.py:102]   [210/634]  eta: 0:27:16    time: 3.973864  data: 0.001108  max mem: 4109
I20241203 06:45:37 1958667 dinov2 helpers.py:102]   [190/634]  eta: 0:31:02    time: 3.974014  data: 0.001126  max mem: 4109
I20241203 06:45:39 1958666 dinov2 helpers.py:102]   [200/634]  eta: 0:29:17    time: 3.973748  data: 0.002007  max mem: 4109
I20241203 06:45:42 1958661 dinov2 helpers.py:102]   [190/634]  eta: 0:31:04    time: 3.973604  data: 0.001119  max mem: 4109
I20241203 06:45:44 1958665 dinov2 helpers.py:102]   [190/634]  eta: 0:31:13    time: 3.974595  data: 0.001150  max mem: 4109
I20241203 06:45:56 1958663 dinov2 helpers.py:102]   [230/634]  eta: 0:24:29    time: 3.973732  data: 0.001392  max mem: 4109
I20241203 06:46:07 1958662 dinov2 helpers.py:102]   [220/634]  eta: 0:26:26    time: 3.974115  data: 0.000890  max mem: 4109
I20241203 06:46:12 1958660 dinov2 helpers.py:102]   [200/634]  eta: 0:30:07    time: 3.973732  data: 0.001794  max mem: 4109
I20241203 06:46:13 1958664 dinov2 helpers.py:102]   [220/634]  eta: 0:26:40    time: 3.973721  data: 0.000921  max mem: 4109
I20241203 06:46:16 1958667 dinov2 helpers.py:102]   [200/634]  eta: 0:30:16    time: 3.973796  data: 0.001227  max mem: 4109
I20241203 06:46:19 1958666 dinov2 helpers.py:102]   [210/634]  eta: 0:28:35    time: 3.973736  data: 0.000826  max mem: 4109
I20241203 06:46:22 1958661 dinov2 helpers.py:102]   [200/634]  eta: 0:30:17    time: 3.973712  data: 0.001074  max mem: 4109
I20241203 06:46:24 1958665 dinov2 helpers.py:102]   [200/634]  eta: 0:30:25    time: 3.973844  data: 0.001368  max mem: 4109
I20241203 06:46:36 1958663 dinov2 helpers.py:102]   [240/634]  eta: 0:23:58    time: 3.973794  data: 0.001396  max mem: 4109
I20241203 06:46:47 1958662 dinov2 helpers.py:102]   [230/634]  eta: 0:25:50    time: 3.974131  data: 0.000580  max mem: 4109
I20241203 06:46:51 1958660 dinov2 helpers.py:102]   [210/634]  eta: 0:29:22    time: 3.974309  data: 0.001731  max mem: 4109
I20241203 06:46:53 1958664 dinov2 helpers.py:102]   [230/634]  eta: 0:26:03    time: 3.973867  data: 0.001488  max mem: 4109
I20241203 06:46:56 1958667 dinov2 helpers.py:102]   [210/634]  eta: 0:29:30    time: 3.973668  data: 0.002465  max mem: 4109
I20241203 06:46:59 1958666 dinov2 helpers.py:102]   [220/634]  eta: 0:27:53    time: 3.973895  data: 0.000663  max mem: 4109
I20241203 06:47:02 1958661 dinov2 helpers.py:102]   [210/634]  eta: 0:29:31    time: 3.973934  data: 0.000841  max mem: 4109
I20241203 06:47:04 1958665 dinov2 helpers.py:102]   [210/634]  eta: 0:29:38    time: 3.973061  data: 0.000844  max mem: 4109
I20241203 06:47:16 1958663 dinov2 helpers.py:102]   [250/634]  eta: 0:23:27    time: 3.974056  data: 0.000987  max mem: 4109
I20241203 06:47:26 1958662 dinov2 helpers.py:102]   [240/634]  eta: 0:25:14    time: 3.973542  data: 0.001482  max mem: 4109
I20241203 06:47:31 1958660 dinov2 helpers.py:102]   [220/634]  eta: 0:28:37    time: 3.973863  data: 0.001660  max mem: 4109
I20241203 06:47:33 1958664 dinov2 helpers.py:102]   [240/634]  eta: 0:25:26    time: 3.973913  data: 0.001634  max mem: 4109
I20241203 06:47:36 1958667 dinov2 helpers.py:102]   [220/634]  eta: 0:28:44    time: 3.973900  data: 0.002890  max mem: 4109
I20241203 06:47:38 1958666 dinov2 helpers.py:102]   [230/634]  eta: 0:27:11    time: 3.973934  data: 0.000714  max mem: 4109
I20241203 06:47:42 1958661 dinov2 helpers.py:102]   [220/634]  eta: 0:28:46    time: 3.973871  data: 0.001094  max mem: 4109
I20241203 06:47:44 1958665 dinov2 helpers.py:102]   [220/634]  eta: 0:28:52    time: 3.973806  data: 0.000540  max mem: 4109
I20241203 06:47:56 1958663 dinov2 helpers.py:102]   [260/634]  eta: 0:22:54    time: 3.973966  data: 0.000917  max mem: 4109
I20241203 06:48:06 1958662 dinov2 helpers.py:102]   [250/634]  eta: 0:24:38    time: 3.973685  data: 0.001465  max mem: 4109
I20241203 06:48:11 1958660 dinov2 helpers.py:102]   [230/634]  eta: 0:27:52    time: 3.973621  data: 0.001943  max mem: 4109
I20241203 06:48:13 1958664 dinov2 helpers.py:102]   [250/634]  eta: 0:24:49    time: 3.973989  data: 0.001180  max mem: 4109
I20241203 06:48:16 1958667 dinov2 helpers.py:102]   [230/634]  eta: 0:27:59    time: 3.974025  data: 0.001575  max mem: 4109
I20241203 06:48:18 1958666 dinov2 helpers.py:102]   [240/634]  eta: 0:26:30    time: 3.973988  data: 0.000937  max mem: 4109
I20241203 06:48:21 1958661 dinov2 helpers.py:102]   [230/634]  eta: 0:28:01    time: 3.973987  data: 0.001144  max mem: 4109
I20241203 06:48:23 1958665 dinov2 helpers.py:102]   [230/634]  eta: 0:28:07    time: 3.974134  data: 0.000754  max mem: 4109
I20241203 06:48:35 1958663 dinov2 helpers.py:102]   [270/634]  eta: 0:22:22    time: 3.973981  data: 0.000969  max mem: 4109
I20241203 06:48:46 1958662 dinov2 helpers.py:102]   [260/634]  eta: 0:24:01    time: 3.974326  data: 0.000568  max mem: 4109
I20241203 06:48:51 1958660 dinov2 helpers.py:102]   [240/634]  eta: 0:27:08    time: 3.974338  data: 0.001908  max mem: 4109
I20241203 06:48:52 1958664 dinov2 helpers.py:102]   [260/634]  eta: 0:24:11    time: 3.974260  data: 0.001167  max mem: 4109
I20241203 06:48:55 1958667 dinov2 helpers.py:102]   [240/634]  eta: 0:27:15    time: 3.974230  data: 0.001171  max mem: 4109
I20241203 06:48:58 1958666 dinov2 helpers.py:102]   [250/634]  eta: 0:25:48    time: 3.973988  data: 0.000830  max mem: 4109
I20241203 06:49:01 1958661 dinov2 helpers.py:102]   [240/634]  eta: 0:27:16    time: 3.974234  data: 0.001098  max mem: 4109
I20241203 06:49:03 1958665 dinov2 helpers.py:102]   [240/634]  eta: 0:27:22    time: 3.974351  data: 0.000802  max mem: 4109
I20241203 06:49:15 1958663 dinov2 helpers.py:102]   [280/634]  eta: 0:21:48    time: 3.974209  data: 0.001359  max mem: 4109
I20241203 06:49:26 1958662 dinov2 helpers.py:102]   [270/634]  eta: 0:23:24    time: 3.974239  data: 0.000554  max mem: 4109
I20241203 06:49:30 1958660 dinov2 helpers.py:102]   [250/634]  eta: 0:26:24    time: 3.974160  data: 0.001003  max mem: 4109
I20241203 06:49:32 1958664 dinov2 helpers.py:102]   [270/634]  eta: 0:23:34    time: 3.974190  data: 0.001317  max mem: 4109
I20241203 06:49:35 1958667 dinov2 helpers.py:102]   [250/634]  eta: 0:26:30    time: 3.974365  data: 0.001302  max mem: 4109
I20241203 06:49:38 1958666 dinov2 helpers.py:102]   [260/634]  eta: 0:25:07    time: 3.974158  data: 0.000635  max mem: 4109
I20241203 06:49:41 1958661 dinov2 helpers.py:102]   [250/634]  eta: 0:26:32    time: 3.973244  data: 0.001582  max mem: 4109
I20241203 06:49:43 1958665 dinov2 helpers.py:102]   [250/634]  eta: 0:26:37    time: 3.976810  data: 0.000539  max mem: 4109
I20241203 06:49:55 1958663 dinov2 helpers.py:102]   [290/634]  eta: 0:21:15    time: 3.974138  data: 0.001530  max mem: 4109
I20241203 06:50:05 1958662 dinov2 helpers.py:102]   [280/634]  eta: 0:22:47    time: 3.973846  data: 0.000502  max mem: 4109
I20241203 06:50:10 1958660 dinov2 helpers.py:102]   [260/634]  eta: 0:25:41    time: 3.973838  data: 0.001371  max mem: 4109
I20241203 06:50:12 1958664 dinov2 helpers.py:102]   [280/634]  eta: 0:22:56    time: 3.975725  data: 0.001298  max mem: 4109
I20241203 06:50:15 1958667 dinov2 helpers.py:102]   [260/634]  eta: 0:25:47    time: 3.974046  data: 0.001997  max mem: 4109
I20241203 06:50:17 1958666 dinov2 helpers.py:102]   [270/634]  eta: 0:24:26    time: 3.973729  data: 0.000732  max mem: 4109
I20241203 06:50:21 1958661 dinov2 helpers.py:102]   [260/634]  eta: 0:25:48    time: 3.972825  data: 0.001681  max mem: 4109
I20241203 06:50:23 1958665 dinov2 helpers.py:102]   [260/634]  eta: 0:25:53    time: 3.976315  data: 0.000666  max mem: 4109
I20241203 06:50:35 1958663 dinov2 helpers.py:102]   [300/634]  eta: 0:20:41    time: 3.973650  data: 0.002910  max mem: 4109
I20241203 06:50:45 1958662 dinov2 helpers.py:102]   [290/634]  eta: 0:22:10    time: 3.973875  data: 0.000872  max mem: 4109
I20241203 06:50:50 1958660 dinov2 helpers.py:102]   [270/634]  eta: 0:24:58    time: 3.973649  data: 0.001584  max mem: 4109
I20241203 06:50:52 1958664 dinov2 helpers.py:102]   [290/634]  eta: 0:22:18    time: 3.975258  data: 0.000925  max mem: 4109
I20241203 06:50:55 1958667 dinov2 helpers.py:102]   [270/634]  eta: 0:25:03    time: 3.973272  data: 0.002320  max mem: 4109
I20241203 06:50:57 1958666 dinov2 helpers.py:102]   [280/634]  eta: 0:23:45    time: 3.973468  data: 0.001026  max mem: 4109
I20241203 06:51:00 1958661 dinov2 helpers.py:102]   [270/634]  eta: 0:25:04    time: 3.973441  data: 0.001677  max mem: 4109
I20241203 06:51:02 1958665 dinov2 helpers.py:102]   [270/634]  eta: 0:25:09    time: 3.973425  data: 0.001044  max mem: 4109
I20241203 06:51:14 1958663 dinov2 helpers.py:102]   [310/634]  eta: 0:20:06    time: 3.973205  data: 0.002845  max mem: 4109
I20241203 06:51:25 1958662 dinov2 helpers.py:102]   [300/634]  eta: 0:21:32    time: 3.971412  data: 0.000967  max mem: 4109
I20241203 06:51:29 1958660 dinov2 helpers.py:102]   [280/634]  eta: 0:24:15    time: 3.972314  data: 0.001138  max mem: 4109
I20241203 06:51:31 1958664 dinov2 helpers.py:102]   [300/634]  eta: 0:21:40    time: 3.972141  data: 0.000938  max mem: 4109
I20241203 06:51:34 1958667 dinov2 helpers.py:102]   [280/634]  eta: 0:24:20    time: 3.971539  data: 0.001709  max mem: 4109
I20241203 06:51:37 1958666 dinov2 helpers.py:102]   [290/634]  eta: 0:23:04    time: 3.970410  data: 0.001497  max mem: 4109
I20241203 06:51:40 1958661 dinov2 helpers.py:102]   [280/634]  eta: 0:24:21    time: 3.970367  data: 0.001294  max mem: 4109
I20241203 06:51:42 1958665 dinov2 helpers.py:102]   [280/634]  eta: 0:24:25    time: 3.973125  data: 0.001026  max mem: 4109
I20241203 06:51:54 1958663 dinov2 helpers.py:102]   [320/634]  eta: 0:19:31    time: 3.971801  data: 0.002370  max mem: 4109
I20241203 06:52:04 1958662 dinov2 helpers.py:102]   [310/634]  eta: 0:20:54    time: 3.969722  data: 0.000747  max mem: 4109
I20241203 06:52:09 1958660 dinov2 helpers.py:102]   [290/634]  eta: 0:23:32    time: 3.965190  data: 0.000623  max mem: 4109
I20241203 06:52:11 1958664 dinov2 helpers.py:102]   [310/634]  eta: 0:21:02    time: 3.967923  data: 0.000897  max mem: 4109
I20241203 06:52:14 1958667 dinov2 helpers.py:102]   [290/634]  eta: 0:23:36    time: 3.967035  data: 0.001076  max mem: 4109
I20241203 06:52:16 1958666 dinov2 helpers.py:102]   [300/634]  eta: 0:22:23    time: 3.962391  data: 0.001205  max mem: 4109
I20241203 06:52:20 1958661 dinov2 helpers.py:102]   [290/634]  eta: 0:23:37    time: 3.965932  data: 0.001215  max mem: 4109
I20241203 06:52:22 1958665 dinov2 helpers.py:102]   [290/634]  eta: 0:23:42    time: 3.972982  data: 0.002712  max mem: 4109
I20241203 06:52:34 1958663 dinov2 helpers.py:102]   [330/634]  eta: 0:18:56    time: 3.964800  data: 0.002038  max mem: 4109
I20241203 06:52:44 1958662 dinov2 helpers.py:102]   [320/634]  eta: 0:20:17    time: 3.966356  data: 0.001211  max mem: 4109
I20241203 06:52:49 1958660 dinov2 helpers.py:102]   [300/634]  eta: 0:22:49    time: 3.960834  data: 0.000711  max mem: 4109
I20241203 06:52:51 1958664 dinov2 helpers.py:102]   [320/634]  eta: 0:20:24    time: 3.961819  data: 0.001160  max mem: 4109
I20241203 06:52:54 1958667 dinov2 helpers.py:102]   [300/634]  eta: 0:22:54    time: 3.962258  data: 0.000855  max mem: 4109
I20241203 06:52:56 1958666 dinov2 helpers.py:102]   [310/634]  eta: 0:21:42    time: 3.957265  data: 0.001141  max mem: 4109
I20241203 06:52:59 1958661 dinov2 helpers.py:102]   [300/634]  eta: 0:22:54    time: 3.959063  data: 0.001112  max mem: 4109
I20241203 06:53:02 1958665 dinov2 helpers.py:102]   [300/634]  eta: 0:22:59    time: 3.974206  data: 0.002888  max mem: 4109
I20241203 06:53:13 1958663 dinov2 helpers.py:102]   [340/634]  eta: 0:18:20    time: 3.957306  data: 0.000577  max mem: 4109
I20241203 06:53:24 1958662 dinov2 helpers.py:102]   [330/634]  eta: 0:19:39    time: 3.961462  data: 0.001226  max mem: 4109
I20241203 06:53:28 1958660 dinov2 helpers.py:102]   [310/634]  eta: 0:22:07    time: 3.964451  data: 0.000840  max mem: 4109
I20241203 06:53:30 1958664 dinov2 helpers.py:102]   [330/634]  eta: 0:19:45    time: 3.959998  data: 0.001359  max mem: 4109
I20241203 06:53:33 1958667 dinov2 helpers.py:102]   [310/634]  eta: 0:22:11    time: 3.961646  data: 0.001213  max mem: 4109
I20241203 06:53:36 1958666 dinov2 helpers.py:102]   [320/634]  eta: 0:21:01    time: 3.958241  data: 0.001552  max mem: 4109
I20241203 06:53:39 1958661 dinov2 helpers.py:102]   [310/634]  eta: 0:22:12    time: 3.957255  data: 0.000954  max mem: 4109
I20241203 06:53:41 1958665 dinov2 helpers.py:102]   [310/634]  eta: 0:22:16    time: 3.974339  data: 0.001641  max mem: 4109
I20241203 06:53:53 1958663 dinov2 helpers.py:102]   [350/634]  eta: 0:17:45    time: 3.957292  data: 0.000671  max mem: 4109
I20241203 06:54:03 1958662 dinov2 helpers.py:102]   [340/634]  eta: 0:19:00    time: 3.957375  data: 0.000862  max mem: 4109
I20241203 06:54:08 1958660 dinov2 helpers.py:102]   [320/634]  eta: 0:21:24    time: 3.963576  data: 0.001058  max mem: 4109
I20241203 06:54:10 1958664 dinov2 helpers.py:102]   [340/634]  eta: 0:19:07    time: 3.961768  data: 0.000980  max mem: 4109
I20241203 06:54:13 1958667 dinov2 helpers.py:102]   [320/634]  eta: 0:21:28    time: 3.958153  data: 0.001540  max mem: 4109
I20241203 06:54:15 1958666 dinov2 helpers.py:102]   [330/634]  eta: 0:20:21    time: 3.956328  data: 0.001119  max mem: 4109
I20241203 06:54:18 1958661 dinov2 helpers.py:102]   [320/634]  eta: 0:21:29    time: 3.961715  data: 0.002304  max mem: 4109
I20241203 06:54:21 1958665 dinov2 helpers.py:102]   [320/634]  eta: 0:21:33    time: 3.973379  data: 0.001338  max mem: 4109
I20241203 06:54:32 1958663 dinov2 helpers.py:102]   [360/634]  eta: 0:17:09    time: 3.958976  data: 0.000943  max mem: 4109
I20241203 06:54:43 1958662 dinov2 helpers.py:102]   [350/634]  eta: 0:18:22    time: 3.956607  data: 0.000969  max mem: 4109
I20241203 06:54:47 1958660 dinov2 helpers.py:102]   [330/634]  eta: 0:20:42    time: 3.958845  data: 0.001485  max mem: 4109
I20241203 06:54:49 1958664 dinov2 helpers.py:102]   [350/634]  eta: 0:18:28    time: 3.963474  data: 0.001242  max mem: 4109
I20241203 06:54:52 1958667 dinov2 helpers.py:102]   [330/634]  eta: 0:20:46    time: 3.960044  data: 0.003394  max mem: 4109
I20241203 06:54:55 1958666 dinov2 helpers.py:102]   [340/634]  eta: 0:19:40    time: 3.957314  data: 0.001549  max mem: 4109
I20241203 06:54:58 1958661 dinov2 helpers.py:102]   [330/634]  eta: 0:20:47    time: 3.962757  data: 0.002346  max mem: 4109
I20241203 06:55:01 1958665 dinov2 helpers.py:102]   [330/634]  eta: 0:20:51    time: 3.973785  data: 0.001357  max mem: 4109
I20241203 06:55:12 1958663 dinov2 helpers.py:102]   [370/634]  eta: 0:16:33    time: 3.962856  data: 0.001388  max mem: 4109
I20241203 06:55:22 1958662 dinov2 helpers.py:102]   [360/634]  eta: 0:17:44    time: 3.962864  data: 0.001484  max mem: 4109
I20241203 06:55:27 1958660 dinov2 helpers.py:102]   [340/634]  eta: 0:20:00    time: 3.960315  data: 0.002050  max mem: 4109
I20241203 06:55:29 1958664 dinov2 helpers.py:102]   [360/634]  eta: 0:17:50    time: 3.962176  data: 0.001379  max mem: 4109
I20241203 06:55:32 1958667 dinov2 helpers.py:102]   [340/634]  eta: 0:20:04    time: 3.963048  data: 0.003080  max mem: 4109
I20241203 06:55:34 1958666 dinov2 helpers.py:102]   [350/634]  eta: 0:18:59    time: 3.963149  data: 0.001546  max mem: 4109
I20241203 06:55:38 1958661 dinov2 helpers.py:102]   [340/634]  eta: 0:20:04    time: 3.965034  data: 0.002922  max mem: 4109
I20241203 06:55:41 1958665 dinov2 helpers.py:102]   [340/634]  eta: 0:20:08    time: 3.974929  data: 0.002255  max mem: 4109
I20241203 06:55:52 1958663 dinov2 helpers.py:102]   [380/634]  eta: 0:15:57    time: 3.968786  data: 0.001971  max mem: 4109
I20241203 06:56:02 1958662 dinov2 helpers.py:102]   [370/634]  eta: 0:17:06    time: 3.965966  data: 0.001328  max mem: 4109
I20241203 06:56:07 1958660 dinov2 helpers.py:102]   [350/634]  eta: 0:19:18    time: 3.965310  data: 0.002041  max mem: 4109
I20241203 06:56:09 1958664 dinov2 helpers.py:102]   [370/634]  eta: 0:17:11    time: 3.965376  data: 0.001249  max mem: 4109
I20241203 06:56:12 1958667 dinov2 helpers.py:102]   [350/634]  eta: 0:19:22    time: 3.963495  data: 0.001511  max mem: 4109
I20241203 06:56:14 1958666 dinov2 helpers.py:102]   [360/634]  eta: 0:18:19    time: 3.965303  data: 0.001304  max mem: 4109
I20241203 06:56:17 1958661 dinov2 helpers.py:102]   [350/634]  eta: 0:19:22    time: 3.969978  data: 0.002676  max mem: 4109
I20241203 06:56:20 1958665 dinov2 helpers.py:102]   [350/634]  eta: 0:19:26    time: 3.975064  data: 0.001826  max mem: 4109
I20241203 06:56:31 1958663 dinov2 helpers.py:102]   [390/634]  eta: 0:15:20    time: 3.970369  data: 0.001728  max mem: 4109
I20241203 06:56:42 1958662 dinov2 helpers.py:102]   [380/634]  eta: 0:16:27    time: 3.969659  data: 0.002009  max mem: 4109
I20241203 06:56:47 1958660 dinov2 helpers.py:102]   [360/634]  eta: 0:18:37    time: 3.968387  data: 0.001421  max mem: 4109
I20241203 06:56:49 1958664 dinov2 helpers.py:102]   [380/634]  eta: 0:16:32    time: 3.972064  data: 0.001339  max mem: 4109
I20241203 06:56:51 1958667 dinov2 helpers.py:102]   [360/634]  eta: 0:18:40    time: 3.970433  data: 0.001552  max mem: 4109
I20241203 06:56:54 1958666 dinov2 helpers.py:102]   [370/634]  eta: 0:17:39    time: 3.969423  data: 0.001344  max mem: 4109
I20241203 06:56:57 1958661 dinov2 helpers.py:102]   [360/634]  eta: 0:18:41    time: 3.973096  data: 0.001043  max mem: 4109
I20241203 06:57:00 1958665 dinov2 helpers.py:102]   [360/634]  eta: 0:18:44    time: 3.974974  data: 0.001179  max mem: 4109
I20241203 06:57:11 1958663 dinov2 helpers.py:102]   [400/634]  eta: 0:14:44    time: 3.971482  data: 0.001053  max mem: 4109
I20241203 06:57:22 1958662 dinov2 helpers.py:102]   [390/634]  eta: 0:15:49    time: 3.973328  data: 0.005804  max mem: 4109
I20241203 06:57:26 1958660 dinov2 helpers.py:102]   [370/634]  eta: 0:17:55    time: 3.971648  data: 0.000886  max mem: 4109
I20241203 06:57:28 1958664 dinov2 helpers.py:102]   [390/634]  eta: 0:15:54    time: 3.973447  data: 0.001645  max mem: 4109
I20241203 06:57:31 1958667 dinov2 helpers.py:102]   [370/634]  eta: 0:17:58    time: 3.973445  data: 0.000893  max mem: 4109
I20241203 06:57:33 1958666 dinov2 helpers.py:102]   [380/634]  eta: 0:16:58    time: 3.973493  data: 0.002224  max mem: 4109
I20241203 06:57:37 1958661 dinov2 helpers.py:102]   [370/634]  eta: 0:17:59    time: 3.973424  data: 0.001484  max mem: 4109
I20241203 06:57:40 1958665 dinov2 helpers.py:102]   [370/634]  eta: 0:18:02    time: 3.975344  data: 0.001183  max mem: 4109
I20241203 06:57:51 1958663 dinov2 helpers.py:102]   [410/634]  eta: 0:14:07    time: 3.973245  data: 0.001046  max mem: 4109
I20241203 06:58:01 1958662 dinov2 helpers.py:102]   [400/634]  eta: 0:15:11    time: 3.973254  data: 0.007248  max mem: 4109
I20241203 06:58:06 1958660 dinov2 helpers.py:102]   [380/634]  eta: 0:17:14    time: 3.973600  data: 0.000744  max mem: 4109
I20241203 06:58:08 1958664 dinov2 helpers.py:102]   [400/634]  eta: 0:15:15    time: 3.973626  data: 0.001442  max mem: 4109
I20241203 06:58:11 1958667 dinov2 helpers.py:102]   [380/634]  eta: 0:17:17    time: 3.973535  data: 0.001018  max mem: 4109
I20241203 06:58:13 1958666 dinov2 helpers.py:102]   [390/634]  eta: 0:16:18    time: 3.973677  data: 0.002397  max mem: 4109
I20241203 06:58:17 1958661 dinov2 helpers.py:102]   [380/634]  eta: 0:17:17    time: 3.973532  data: 0.001212  max mem: 4109
I20241203 06:58:20 1958665 dinov2 helpers.py:102]   [380/634]  eta: 0:17:20    time: 3.974417  data: 0.001602  max mem: 4109
I20241203 06:58:31 1958663 dinov2 helpers.py:102]   [420/634]  eta: 0:13:30    time: 3.972672  data: 0.001254  max mem: 4109
I20241203 06:58:41 1958662 dinov2 helpers.py:102]   [410/634]  eta: 0:14:32    time: 3.973456  data: 0.007188  max mem: 4109
I20241203 06:58:46 1958660 dinov2 helpers.py:102]   [390/634]  eta: 0:16:33    time: 3.973661  data: 0.000837  max mem: 4109
I20241203 06:58:48 1958664 dinov2 helpers.py:102]   [410/634]  eta: 0:14:36    time: 3.973746  data: 0.000948  max mem: 4109
I20241203 06:58:51 1958667 dinov2 helpers.py:102]   [390/634]  eta: 0:16:35    time: 3.973768  data: 0.001233  max mem: 4109
I20241203 06:58:53 1958666 dinov2 helpers.py:102]   [400/634]  eta: 0:15:38    time: 3.973576  data: 0.001178  max mem: 4109
I20241203 06:58:56 1958661 dinov2 helpers.py:102]   [390/634]  eta: 0:16:36    time: 3.973662  data: 0.000630  max mem: 4109
I20241203 06:58:59 1958665 dinov2 helpers.py:102]   [390/634]  eta: 0:16:38    time: 3.975429  data: 0.001299  max mem: 4109
I20241203 06:59:10 1958663 dinov2 helpers.py:102]   [430/634]  eta: 0:12:53    time: 3.972824  data: 0.001037  max mem: 4109
I20241203 06:59:21 1958662 dinov2 helpers.py:102]   [420/634]  eta: 0:13:54    time: 3.973591  data: 0.005019  max mem: 4109
I20241203 06:59:25 1958660 dinov2 helpers.py:102]   [400/634]  eta: 0:15:51    time: 3.973785  data: 0.002201  max mem: 4109
I20241203 06:59:27 1958664 dinov2 helpers.py:102]   [420/634]  eta: 0:13:57    time: 3.973715  data: 0.000808  max mem: 4109
I20241203 06:59:30 1958667 dinov2 helpers.py:102]   [400/634]  eta: 0:15:54    time: 3.974596  data: 0.000847  max mem: 4109
I20241203 06:59:33 1958666 dinov2 helpers.py:102]   [410/634]  eta: 0:14:57    time: 3.973762  data: 0.001691  max mem: 4109
I20241203 06:59:36 1958661 dinov2 helpers.py:102]   [400/634]  eta: 0:15:54    time: 3.974733  data: 0.000695  max mem: 4109
I20241203 06:59:39 1958665 dinov2 helpers.py:102]   [400/634]  eta: 0:15:57    time: 3.977413  data: 0.001005  max mem: 4109
I20241203 06:59:50 1958663 dinov2 helpers.py:102]   [440/634]  eta: 0:12:16    time: 3.975668  data: 0.000834  max mem: 4109
I20241203 07:00:01 1958662 dinov2 helpers.py:102]   [430/634]  eta: 0:13:15    time: 3.975909  data: 0.002563  max mem: 4109
I20241203 07:00:05 1958660 dinov2 helpers.py:102]   [410/634]  eta: 0:15:10    time: 3.974802  data: 0.002159  max mem: 4109
I20241203 07:00:07 1958664 dinov2 helpers.py:102]   [430/634]  eta: 0:13:18    time: 3.973811  data: 0.000800  max mem: 4109
I20241203 07:00:10 1958667 dinov2 helpers.py:102]   [410/634]  eta: 0:15:12    time: 3.974692  data: 0.000908  max mem: 4109
I20241203 07:00:12 1958666 dinov2 helpers.py:102]   [420/634]  eta: 0:14:17    time: 3.974174  data: 0.001578  max mem: 4109
I20241203 07:00:16 1958661 dinov2 helpers.py:102]   [410/634]  eta: 0:15:13    time: 3.974839  data: 0.001820  max mem: 4109
I20241203 07:00:19 1958665 dinov2 helpers.py:102]   [410/634]  eta: 0:15:15    time: 3.981198  data: 0.001041  max mem: 4109
I20241203 07:00:30 1958663 dinov2 helpers.py:102]   [450/634]  eta: 0:11:39    time: 3.975784  data: 0.000853  max mem: 4109
I20241203 07:00:40 1958662 dinov2 helpers.py:102]   [440/634]  eta: 0:12:36    time: 3.975951  data: 0.002323  max mem: 4109
I20241203 07:00:45 1958660 dinov2 helpers.py:102]   [420/634]  eta: 0:14:29    time: 3.974981  data: 0.000810  max mem: 4109
I20241203 07:00:47 1958664 dinov2 helpers.py:102]   [440/634]  eta: 0:12:40    time: 3.975955  data: 0.001829  max mem: 4109
I20241203 07:00:50 1958667 dinov2 helpers.py:102]   [420/634]  eta: 0:14:31    time: 3.974194  data: 0.000978  max mem: 4109
I20241203 07:00:52 1958666 dinov2 helpers.py:102]   [430/634]  eta: 0:13:37    time: 3.975992  data: 0.000831  max mem: 4109
I20241203 07:00:56 1958661 dinov2 helpers.py:102]   [420/634]  eta: 0:14:31    time: 3.974135  data: 0.001792  max mem: 4109
I20241203 07:00:59 1958665 dinov2 helpers.py:102]   [420/634]  eta: 0:14:34    time: 3.985939  data: 0.001148  max mem: 4109
I20241203 07:01:10 1958663 dinov2 helpers.py:102]   [460/634]  eta: 0:11:01    time: 3.974052  data: 0.000890  max mem: 4109
I20241203 07:01:20 1958662 dinov2 helpers.py:102]   [450/634]  eta: 0:11:58    time: 3.973882  data: 0.002324  max mem: 4109
I20241203 07:01:25 1958660 dinov2 helpers.py:102]   [430/634]  eta: 0:13:48    time: 3.974122  data: 0.001090  max mem: 4109
I20241203 07:01:27 1958664 dinov2 helpers.py:102]   [450/634]  eta: 0:12:01    time: 3.975895  data: 0.001687  max mem: 4109
I20241203 07:01:30 1958667 dinov2 helpers.py:102]   [430/634]  eta: 0:13:50    time: 3.974072  data: 0.000805  max mem: 4109
I20241203 07:01:32 1958666 dinov2 helpers.py:102]   [440/634]  eta: 0:12:57    time: 3.975667  data: 0.000788  max mem: 4109
I20241203 07:01:35 1958661 dinov2 helpers.py:102]   [430/634]  eta: 0:13:50    time: 3.974105  data: 0.000884  max mem: 4109
I20241203 07:01:39 1958665 dinov2 helpers.py:102]   [430/634]  eta: 0:13:53    time: 3.983960  data: 0.001308  max mem: 4109
I20241203 07:01:49 1958663 dinov2 helpers.py:102]   [470/634]  eta: 0:10:24    time: 3.974467  data: 0.001004  max mem: 4109
I20241203 07:02:00 1958662 dinov2 helpers.py:102]   [460/634]  eta: 0:11:19    time: 3.973975  data: 0.002819  max mem: 4109
I20241203 07:02:04 1958660 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.974098  data: 0.000949  max mem: 4109
I20241203 07:02:06 1958664 dinov2 helpers.py:102]   [460/634]  eta: 0:11:22    time: 3.974023  data: 0.000646  max mem: 4109
I20241203 07:02:09 1958667 dinov2 helpers.py:102]   [440/634]  eta: 0:13:09    time: 3.975783  data: 0.000893  max mem: 4109
I20241203 07:02:12 1958666 dinov2 helpers.py:102]   [450/634]  eta: 0:12:16    time: 3.973938  data: 0.000910  max mem: 4109
I20241203 07:02:15 1958661 dinov2 helpers.py:102]   [440/634]  eta: 0:13:09    time: 3.976664  data: 0.001327  max mem: 4109
I20241203 07:02:19 1958665 dinov2 helpers.py:102]   [440/634]  eta: 0:13:11    time: 3.985616  data: 0.001207  max mem: 4109
I20241203 07:02:29 1958663 dinov2 helpers.py:102]   [480/634]  eta: 0:09:46    time: 3.974115  data: 0.000889  max mem: 4109
I20241203 07:02:40 1958662 dinov2 helpers.py:102]   [470/634]  eta: 0:10:40    time: 3.975198  data: 0.003878  max mem: 4109
I20241203 07:02:44 1958660 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.974115  data: 0.000637  max mem: 4109
I20241203 07:02:46 1958664 dinov2 helpers.py:102]   [470/634]  eta: 0:10:43    time: 3.974053  data: 0.000594  max mem: 4109
I20241203 07:02:49 1958667 dinov2 helpers.py:102]   [450/634]  eta: 0:12:28    time: 3.975933  data: 0.001181  max mem: 4109
I20241203 07:02:51 1958666 dinov2 helpers.py:102]   [460/634]  eta: 0:11:36    time: 3.974199  data: 0.001280  max mem: 4109
I20241203 07:02:55 1958661 dinov2 helpers.py:102]   [450/634]  eta: 0:12:28    time: 3.975895  data: 0.001244  max mem: 4109
I20241203 07:02:58 1958665 dinov2 helpers.py:102]   [450/634]  eta: 0:12:30    time: 3.988531  data: 0.001100  max mem: 4109
I20241203 07:03:09 1958663 dinov2 helpers.py:102]   [490/634]  eta: 0:09:09    time: 3.974682  data: 0.000985  max mem: 4109
I20241203 07:03:19 1958662 dinov2 helpers.py:102]   [480/634]  eta: 0:10:01    time: 3.976058  data: 0.004408  max mem: 4109
I20241203 07:03:24 1958660 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.975948  data: 0.000801  max mem: 4109
I20241203 07:03:26 1958664 dinov2 helpers.py:102]   [480/634]  eta: 0:10:04    time: 3.974157  data: 0.001152  max mem: 4109
I20241203 07:03:29 1958667 dinov2 helpers.py:102]   [460/634]  eta: 0:11:47    time: 3.974251  data: 0.001029  max mem: 4109
I20241203 07:03:31 1958666 dinov2 helpers.py:102]   [470/634]  eta: 0:10:56    time: 3.976074  data: 0.001243  max mem: 4109
I20241203 07:03:35 1958661 dinov2 helpers.py:102]   [460/634]  eta: 0:11:47    time: 3.973413  data: 0.000770  max mem: 4109
I20241203 07:03:38 1958665 dinov2 helpers.py:102]   [460/634]  eta: 0:11:49    time: 3.987840  data: 0.001334  max mem: 4109
I20241203 07:03:49 1958663 dinov2 helpers.py:102]   [500/634]  eta: 0:08:31    time: 3.976030  data: 0.001062  max mem: 4109
I20241203 07:03:59 1958662 dinov2 helpers.py:102]   [490/634]  eta: 0:09:22    time: 3.975062  data: 0.002036  max mem: 4109
I20241203 07:04:04 1958660 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.975953  data: 0.000965  max mem: 4109
I20241203 07:04:06 1958664 dinov2 helpers.py:102]   [490/634]  eta: 0:09:24    time: 3.975992  data: 0.001078  max mem: 4109
I20241203 07:04:09 1958667 dinov2 helpers.py:102]   [470/634]  eta: 0:11:06    time: 3.976044  data: 0.001128  max mem: 4109
I20241203 07:04:11 1958666 dinov2 helpers.py:102]   [480/634]  eta: 0:10:16    time: 3.975983  data: 0.000972  max mem: 4109
I20241203 07:04:14 1958661 dinov2 helpers.py:102]   [470/634]  eta: 0:11:06    time: 3.974235  data: 0.000725  max mem: 4109
I20241203 07:04:18 1958665 dinov2 helpers.py:102]   [470/634]  eta: 0:11:08    time: 3.984993  data: 0.001356  max mem: 4109
I20241203 07:04:28 1958663 dinov2 helpers.py:102]   [510/634]  eta: 0:07:53    time: 3.975049  data: 0.000797  max mem: 4109
I20241203 07:04:39 1958662 dinov2 helpers.py:102]   [500/634]  eta: 0:08:43    time: 3.974122  data: 0.002809  max mem: 4109
I20241203 07:04:43 1958660 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.974180  data: 0.000922  max mem: 4109
I20241203 07:04:45 1958664 dinov2 helpers.py:102]   [500/634]  eta: 0:08:45    time: 3.975994  data: 0.000635  max mem: 4109
I20241203 07:04:48 1958667 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.975894  data: 0.001326  max mem: 4109
I20241203 07:04:51 1958666 dinov2 helpers.py:102]   [490/634]  eta: 0:09:36    time: 3.974143  data: 0.000860  max mem: 4109
I20241203 07:04:54 1958661 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.975890  data: 0.001148  max mem: 4109
I20241203 07:04:58 1958665 dinov2 helpers.py:102]   [480/634]  eta: 0:10:27    time: 3.985720  data: 0.000803  max mem: 4109
I20241203 07:05:08 1958663 dinov2 helpers.py:102]   [520/634]  eta: 0:07:15    time: 3.974168  data: 0.000723  max mem: 4109
I20241203 07:05:19 1958662 dinov2 helpers.py:102]   [510/634]  eta: 0:08:05    time: 3.974203  data: 0.004244  max mem: 4109
I20241203 07:05:23 1958660 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.974180  data: 0.000952  max mem: 4109
I20241203 07:05:25 1958664 dinov2 helpers.py:102]   [510/634]  eta: 0:08:06    time: 3.974164  data: 0.000831  max mem: 4109
I20241203 07:05:28 1958667 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.974220  data: 0.001733  max mem: 4109
I20241203 07:05:30 1958666 dinov2 helpers.py:102]   [500/634]  eta: 0:08:56    time: 3.974188  data: 0.000873  max mem: 4109
I20241203 07:05:34 1958661 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.975951  data: 0.001172  max mem: 4109
I20241203 07:05:38 1958665 dinov2 helpers.py:102]   [490/634]  eta: 0:09:46    time: 3.992206  data: 0.000670  max mem: 4109
I20241203 07:05:48 1958663 dinov2 helpers.py:102]   [530/634]  eta: 0:06:37    time: 3.974152  data: 0.000813  max mem: 4109
I20241203 07:05:58 1958662 dinov2 helpers.py:102]   [520/634]  eta: 0:07:26    time: 3.974401  data: 0.003222  max mem: 4109
I20241203 07:06:03 1958660 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.974169  data: 0.000825  max mem: 4109
I20241203 07:06:05 1958664 dinov2 helpers.py:102]   [520/634]  eta: 0:07:27    time: 3.974106  data: 0.000819  max mem: 4109
I20241203 07:06:08 1958667 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.974249  data: 0.002018  max mem: 4109
I20241203 07:06:10 1958666 dinov2 helpers.py:102]   [510/634]  eta: 0:08:16    time: 3.974115  data: 0.001084  max mem: 4109
I20241203 07:06:14 1958661 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.974209  data: 0.000769  max mem: 4109
I20241203 07:06:18 1958665 dinov2 helpers.py:102]   [500/634]  eta: 0:09:05    time: 3.992125  data: 0.000810  max mem: 4109
I20241203 07:06:28 1958663 dinov2 helpers.py:102]   [540/634]  eta: 0:05:59    time: 3.974158  data: 0.001217  max mem: 4109
I20241203 07:06:38 1958662 dinov2 helpers.py:102]   [530/634]  eta: 0:06:47    time: 3.973780  data: 0.002540  max mem: 4109
I20241203 07:06:43 1958660 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.974162  data: 0.000592  max mem: 4109
I20241203 07:06:45 1958664 dinov2 helpers.py:102]   [530/634]  eta: 0:06:48    time: 3.974114  data: 0.001053  max mem: 4109
I20241203 07:06:48 1958667 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.974059  data: 0.001270  max mem: 4109
I20241203 07:06:50 1958666 dinov2 helpers.py:102]   [520/634]  eta: 0:07:36    time: 3.974093  data: 0.001094  max mem: 4109
I20241203 07:06:53 1958661 dinov2 helpers.py:102]   [510/634]  eta: 0:08:23    time: 3.974195  data: 0.001497  max mem: 4109
I20241203 07:06:58 1958665 dinov2 helpers.py:102]   [510/634]  eta: 0:08:24    time: 3.990264  data: 0.000972  max mem: 4109
I20241203 07:07:07 1958663 dinov2 helpers.py:102]   [550/634]  eta: 0:05:21    time: 3.974206  data: 0.001400  max mem: 4109
I20241203 07:07:18 1958662 dinov2 helpers.py:102]   [540/634]  eta: 0:06:07    time: 3.975504  data: 0.002860  max mem: 4109
I20241203 07:07:22 1958660 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.975951  data: 0.000983  max mem: 4109
I20241203 07:07:24 1958664 dinov2 helpers.py:102]   [540/634]  eta: 0:06:09    time: 3.974241  data: 0.001014  max mem: 4109
I20241203 07:07:27 1958667 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.974280  data: 0.001489  max mem: 4109
I20241203 07:07:30 1958666 dinov2 helpers.py:102]   [530/634]  eta: 0:06:56    time: 3.974182  data: 0.001226  max mem: 4109
I20241203 07:07:33 1958661 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.974151  data: 0.001451  max mem: 4109
I20241203 07:07:38 1958665 dinov2 helpers.py:102]   [520/634]  eta: 0:07:43    time: 3.990373  data: 0.001095  max mem: 4109
I20241203 07:07:47 1958663 dinov2 helpers.py:102]   [560/634]  eta: 0:04:43    time: 3.975943  data: 0.001273  max mem: 4109
I20241203 07:07:58 1958662 dinov2 helpers.py:102]   [550/634]  eta: 0:05:28    time: 3.975906  data: 0.002328  max mem: 4109
I20241203 07:08:02 1958660 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.975872  data: 0.001090  max mem: 4109
I20241203 07:08:04 1958664 dinov2 helpers.py:102]   [550/634]  eta: 0:05:30    time: 3.974183  data: 0.000841  max mem: 4109
I20241203 07:08:07 1958667 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.974170  data: 0.001730  max mem: 4109
I20241203 07:08:09 1958666 dinov2 helpers.py:102]   [540/634]  eta: 0:06:15    time: 3.976003  data: 0.001353  max mem: 4109
I20241203 07:08:13 1958661 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.974337  data: 0.001459  max mem: 4109
I20241203 07:08:18 1958665 dinov2 helpers.py:102]   [530/634]  eta: 0:07:02    time: 3.990361  data: 0.001007  max mem: 4109
I20241203 07:08:27 1958663 dinov2 helpers.py:102]   [570/634]  eta: 0:04:05    time: 3.975930  data: 0.001045  max mem: 4109
I20241203 07:08:37 1958662 dinov2 helpers.py:102]   [560/634]  eta: 0:04:49    time: 3.974163  data: 0.001699  max mem: 4109
I20241203 07:08:42 1958660 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.974070  data: 0.000819  max mem: 4109
I20241203 07:08:44 1958664 dinov2 helpers.py:102]   [560/634]  eta: 0:04:50    time: 3.974108  data: 0.000848  max mem: 4109
I20241203 07:08:47 1958667 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.973984  data: 0.001010  max mem: 4109
I20241203 07:08:49 1958666 dinov2 helpers.py:102]   [550/634]  eta: 0:05:35    time: 3.975887  data: 0.001159  max mem: 4109
I20241203 07:08:53 1958661 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.974234  data: 0.001430  max mem: 4109
I20241203 07:08:58 1958665 dinov2 helpers.py:102]   [540/634]  eta: 0:06:22    time: 3.990345  data: 0.001030  max mem: 4109
I20241203 07:09:07 1958663 dinov2 helpers.py:102]   [580/634]  eta: 0:03:27    time: 3.974197  data: 0.001042  max mem: 4109
I20241203 07:09:17 1958662 dinov2 helpers.py:102]   [570/634]  eta: 0:04:10    time: 3.973637  data: 0.002598  max mem: 4109
I20241203 07:09:22 1958660 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.974236  data: 0.001108  max mem: 4109
I20241203 07:09:24 1958664 dinov2 helpers.py:102]   [570/634]  eta: 0:04:11    time: 3.976056  data: 0.001219  max mem: 4109
I20241203 07:09:27 1958667 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.975125  data: 0.001130  max mem: 4109
I20241203 07:09:29 1958666 dinov2 helpers.py:102]   [560/634]  eta: 0:04:55    time: 3.974157  data: 0.001024  max mem: 4109
I20241203 07:09:32 1958661 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.973980  data: 0.000912  max mem: 4109
I20241203 07:09:37 1958665 dinov2 helpers.py:102]   [550/634]  eta: 0:05:41    time: 3.990483  data: 0.001686  max mem: 4109
I20241203 07:09:46 1958663 dinov2 helpers.py:102]   [590/634]  eta: 0:02:49    time: 3.974314  data: 0.001462  max mem: 4109
I20241203 07:09:57 1958662 dinov2 helpers.py:102]   [580/634]  eta: 0:03:31    time: 3.973293  data: 0.003302  max mem: 4109
I20241203 07:10:01 1958660 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.974295  data: 0.002069  max mem: 4109
I20241203 07:10:03 1958664 dinov2 helpers.py:102]   [580/634]  eta: 0:03:32    time: 3.976067  data: 0.001228  max mem: 4109
I20241203 07:10:06 1958667 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.976140  data: 0.002514  max mem: 4109
I20241203 07:10:09 1958666 dinov2 helpers.py:102]   [570/634]  eta: 0:04:15    time: 3.974414  data: 0.001140  max mem: 4109
I20241203 07:10:12 1958661 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.976337  data: 0.001025  max mem: 4109
I20241203 07:10:17 1958665 dinov2 helpers.py:102]   [560/634]  eta: 0:05:00    time: 3.991435  data: 0.002171  max mem: 4109
I20241203 07:10:26 1958663 dinov2 helpers.py:102]   [600/634]  eta: 0:02:10    time: 3.975340  data: 0.001177  max mem: 4109
I20241203 07:10:36 1958662 dinov2 helpers.py:102]   [590/634]  eta: 0:02:52    time: 3.974625  data: 0.005145  max mem: 4109
I20241203 07:10:41 1958660 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.976079  data: 0.001990  max mem: 4109
I20241203 07:10:43 1958664 dinov2 helpers.py:102]   [590/634]  eta: 0:02:53    time: 3.974320  data: 0.000758  max mem: 4109
I20241203 07:10:46 1958667 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.975175  data: 0.003414  max mem: 4109
I20241203 07:10:48 1958666 dinov2 helpers.py:102]   [580/634]  eta: 0:03:35    time: 3.974337  data: 0.001310  max mem: 4109
I20241203 07:10:52 1958661 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.976161  data: 0.001319  max mem: 4109
I20241203 07:10:57 1958665 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.989526  data: 0.001915  max mem: 4109
I20241203 07:11:06 1958663 dinov2 helpers.py:102]   [610/634]  eta: 0:01:32    time: 3.976010  data: 0.000944  max mem: 4109
I20241203 07:11:16 1958662 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.975858  data: 0.003547  max mem: 4109
I20241203 07:11:21 1958660 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.976110  data: 0.000996  max mem: 4109
I20241203 07:11:23 1958664 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.976028  data: 0.001516  max mem: 4109
I20241203 07:11:26 1958667 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.974184  data: 0.002283  max mem: 4109
I20241203 07:11:28 1958666 dinov2 helpers.py:102]   [590/634]  eta: 0:02:55    time: 3.976271  data: 0.001679  max mem: 4109
I20241203 07:11:32 1958661 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.975709  data: 0.001451  max mem: 4109
I20241203 07:11:37 1958665 dinov2 helpers.py:102]   [580/634]  eta: 0:03:39    time: 3.988582  data: 0.001069  max mem: 4109
I20241203 07:11:46 1958663 dinov2 helpers.py:102]   [620/634]  eta: 0:00:53    time: 3.974826  data: 0.001605  max mem: 4109
I20241203 07:11:56 1958662 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.974926  data: 0.001815  max mem: 4109
I20241203 07:12:01 1958660 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.974094  data: 0.001887  max mem: 4109
I20241203 07:12:03 1958664 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.975854  data: 0.001566  max mem: 4109
I20241203 07:12:06 1958667 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.975901  data: 0.001146  max mem: 4109
I20241203 07:12:08 1958666 dinov2 helpers.py:102]   [600/634]  eta: 0:02:15    time: 3.975891  data: 0.001753  max mem: 4109
I20241203 07:12:11 1958661 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.976042  data: 0.000811  max mem: 4109
I20241203 07:12:17 1958665 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.991154  data: 0.000663  max mem: 4109
I20241203 07:12:25 1958663 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.975856  data: 0.001569  max mem: 4109
I20241203 07:12:36 1958662 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.976056  data: 0.003058  max mem: 4109
I20241203 07:12:40 1958660 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.975719  data: 0.002305  max mem: 4109
I20241203 07:12:43 1958664 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.975843  data: 0.000794  max mem: 4109
I20241203 07:12:45 1958663 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.352988  data: 0.000982  max mem: 4109
I20241203 07:12:45 1958663 dinov2 helpers.py:130]  Total time: 0:40:49 (3.862843 s / it)
I20241203 07:12:45 1958663 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:12:45 1958663 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:12:45 1958667 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.974283  data: 0.001986  max mem: 4109
I20241203 07:12:46 1958663 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:12:46 1958663 dinov2 loaders.py:151] sampler: distributed
I20241203 07:12:46 1958663 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:12:46 1958663 dinov2 loaders.py:223] # of batches: 78
I20241203 07:12:47 1958666 dinov2 helpers.py:102]   [610/634]  eta: 0:01:35    time: 3.964731  data: 0.001321  max mem: 4109
I20241203 07:12:51 1958661 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.944325  data: 0.000664  max mem: 4109
I20241203 07:12:56 1958665 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.921829  data: 0.001169  max mem: 4109
I20241203 07:13:12 1958662 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.798827  data: 0.001801  max mem: 4109
I20241203 07:13:16 1958660 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.770309  data: 0.001113  max mem: 4109
I20241203 07:13:18 1958664 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.758713  data: 0.000873  max mem: 4109
I20241203 07:13:20 1958667 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.739160  data: 0.002054  max mem: 4109
I20241203 07:13:22 1958666 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.726182  data: 0.001269  max mem: 4109
I20241203 07:13:26 1958661 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.706336  data: 0.000654  max mem: 4109
I20241203 07:13:29 1958662 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.058088  data: 0.001436  max mem: 4109
I20241203 07:13:29 1958662 dinov2 helpers.py:130]  Total time: 0:41:29 (3.926770 s / it)
I20241203 07:13:29 1958662 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:13:29 1958662 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:13:30 1958662 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:13:30 1958662 dinov2 loaders.py:151] sampler: distributed
I20241203 07:13:30 1958662 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:13:30 1958662 dinov2 loaders.py:223] # of batches: 78
I20241203 07:13:30 1958665 dinov2 helpers.py:102]   [610/634]  eta: 0:01:37    time: 3.672129  data: 0.001285  max mem: 4109
I20241203 07:13:34 1958664 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.983829  data: 0.000796  max mem: 4109
I20241203 07:13:35 1958664 dinov2 helpers.py:130]  Total time: 0:41:35 (3.935895 s / it)
I20241203 07:13:35 1958664 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:13:35 1958664 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:13:35 1958664 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:13:35 1958664 dinov2 loaders.py:151] sampler: distributed
I20241203 07:13:35 1958664 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:13:35 1958664 dinov2 loaders.py:223] # of batches: 78
I20241203 07:13:46 1958660 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.280062  data: 0.000526  max mem: 4109
I20241203 07:13:49 1958667 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.194727  data: 0.000880  max mem: 4109
I20241203 07:13:51 1958666 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.160536  data: 0.001021  max mem: 4109
I20241203 07:13:53 1958661 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.118767  data: 0.000480  max mem: 4109
I20241203 07:13:57 1958665 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.056256  data: 0.000801  max mem: 4109
I20241203 07:14:03 1958666 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.261958  data: 0.000634  max mem: 4109
I20241203 07:14:03 1958666 dinov2 helpers.py:130]  Total time: 0:41:57 (3.971576 s / it)
I20241203 07:14:03 1958666 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:14:03 1958666 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:14:04 1958666 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:14:04 1958666 dinov2 loaders.py:151] sampler: distributed
I20241203 07:14:04 1958666 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:14:04 1958666 dinov2 loaders.py:223] # of batches: 78
I20241203 07:14:10 1958660 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.695554  data: 0.002026  max mem: 4109
I20241203 07:14:13 1958667 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.607782  data: 0.000509  max mem: 4109
I20241203 07:14:16 1958661 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.500948  data: 0.000692  max mem: 4109
I20241203 07:14:19 1958665 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.410332  data: 0.001390  max mem: 4109
I20241203 07:14:20 1958660 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.674946  data: 0.001986  max mem: 4109
I20241203 07:14:20 1958660 dinov2 helpers.py:130]  Total time: 0:42:05 (3.984085 s / it)
I20241203 07:14:20 1958660 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:14:20 1958660 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:14:21 1958660 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:14:21 1958660 dinov2 loaders.py:151] sampler: distributed
I20241203 07:14:21 1958660 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:14:21 1958660 dinov2 loaders.py:223] # of batches: 78
I20241203 07:14:22 1958667 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.572569  data: 0.000449  max mem: 4109
I20241203 07:14:23 1958667 dinov2 helpers.py:130]  Total time: 0:42:07 (3.986218 s / it)
I20241203 07:14:23 1958667 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:14:23 1958667 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:14:23 1958667 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:14:23 1958667 dinov2 loaders.py:151] sampler: distributed
I20241203 07:14:23 1958667 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:14:23 1958667 dinov2 loaders.py:223] # of batches: 78
I20241203 07:14:24 1958661 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.435420  data: 0.000653  max mem: 4109
I20241203 07:14:24 1958661 dinov2 helpers.py:130]  Total time: 0:42:03 (3.980890 s / it)
I20241203 07:14:24 1958661 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:14:24 1958661 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:14:24 1958661 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:14:24 1958661 dinov2 loaders.py:151] sampler: distributed
I20241203 07:14:24 1958661 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:14:24 1958661 dinov2 loaders.py:223] # of batches: 78
I20241203 07:14:25 1958665 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.298410  data: 0.001320  max mem: 4109
I20241203 07:14:25 1958665 dinov2 helpers.py:130]  Total time: 0:42:06 (3.984896 s / it)
I20241203 07:14:25 1958665 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 07:14:25 1958665 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 07:14:25 1958665 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 07:14:25 1958665 dinov2 loaders.py:151] sampler: distributed
I20241203 07:14:25 1958665 dinov2 loaders.py:210] using PyTorch data loader
I20241203 07:14:25 1958665 dinov2 loaders.py:223] # of batches: 78
I20241203 07:14:27 1958663 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:28 1958662 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:29 1958664 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:30 1958666 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:30 1958661 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:30 1958665 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:30 1958660 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:31 1958667 dinov2 knn.py:299] Start the k-NN classification.
I20241203 07:14:36 1958663 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:11:31    time: 8.871357  data: 8.191751  max mem: 8496
I20241203 07:14:37 1958662 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:11:58    time: 9.212373  data: 8.385818  max mem: 8496
E20241203 07:14:42 1958664 submitit submission.py:68] Submitted job triggered an exception
E20241203 07:14:43 1958661 submitit submission.py:68] Submitted job triggered an exception
E20241203 07:14:44 1958665 submitit submission.py:68] Submitted job triggered an exception
E20241203 07:14:44 1958660 submitit submission.py:68] Submitted job triggered an exception
E20241203 07:14:45 1958666 submitit submission.py:68] Submitted job triggered an exception
E20241203 07:14:45 1958667 submitit submission.py:68] Submitted job triggered an exception
I20241203 07:14:53 1958663 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:02:38    time: 2.327977  data: 1.511810  max mem: 8536
I20241203 07:14:54 1958662 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:02:40    time: 2.362208  data: 1.589380  max mem: 8536
I20241203 07:15:03 1958663 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:01:38    time: 1.339950  data: 0.424702  max mem: 8536
I20241203 07:15:04 1958662 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:01:40    time: 1.350190  data: 0.458144  max mem: 8536
I20241203 07:15:13 1958663 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:01:11    time: 1.018163  data: 0.004043  max mem: 8536
I20241203 07:15:15 1958662 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:01:12    time: 1.032495  data: 0.006830  max mem: 8536
I20241203 07:15:23 1958663 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:52    time: 1.032930  data: 0.003852  max mem: 8536
I20241203 07:15:25 1958662 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:52    time: 1.041621  data: 0.006104  max mem: 8536
I20241203 07:15:34 1958663 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:36    time: 1.040013  data: 0.004821  max mem: 8536
I20241203 07:15:35 1958662 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:37    time: 1.041307  data: 0.004230  max mem: 8536
I20241203 07:15:44 1958663 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:22    time: 1.044975  data: 0.003357  max mem: 8536
I20241203 07:15:46 1958662 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:22    time: 1.035041  data: 0.002199  max mem: 8536
I20241203 07:15:55 1958663 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:09    time: 1.046826  data: 0.001463  max mem: 8536
I20241203 07:15:56 1958662 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:09    time: 1.034474  data: 0.000961  max mem: 8536
I20241203 07:16:01 1958663 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:01    time: 1.018860  data: 0.000676  max mem: 8536
I20241203 07:16:01 1958663 dinov2 helpers.py:130] Test: Total time: 0:01:34 (1.211071 s / it)
I20241203 07:16:01 1958663 dinov2 utils.py:79] Averaged stats: 
I20241203 07:16:02 1958663 dinov2 knn.py:367] ('full', 10) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958663 dinov2 knn.py:367] ('full', 20) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958663 dinov2 knn.py:367] ('full', 100) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958663 dinov2 knn.py:367] ('full', 200) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958663 submitit submission.py:56] Job completed successfully
I20241203 07:16:02 1958663 submitit submission.py:61] Exiting after successful completion
I20241203 07:16:02 1958662 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:01    time: 0.972387  data: 0.000837  max mem: 8536
I20241203 07:16:02 1958662 dinov2 helpers.py:130] Test: Total time: 0:01:34 (1.207008 s / it)
I20241203 07:16:02 1958662 dinov2 utils.py:79] Averaged stats: 
I20241203 07:16:02 1958662 dinov2 knn.py:367] ('full', 10) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958662 dinov2 knn.py:367] ('full', 20) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958662 dinov2 knn.py:367] ('full', 100) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958662 dinov2 knn.py:367] ('full', 200) classifier result: Top1: 0.00 Top5: 0.00
I20241203 07:16:02 1958662 submitit submission.py:56] Job completed successfully
I20241203 07:16:02 1958662 submitit submission.py:61] Exiting after successful completion

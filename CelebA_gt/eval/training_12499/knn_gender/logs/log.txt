I20241204 08:36:21 2519726 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:21 2519726 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:21 2519726 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:21 2519726 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:21 2519726 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:21 2519725 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:21 2519725 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:21 2519725 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:21 2519725 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:21 2519723 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:21 2519723 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:21 2519723 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:21 2519723 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:21 2519723 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:21 2519725 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:22 2519722 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:22 2519722 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:22 2519720 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:22 2519720 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:22 2519722 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:22 2519720 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:22 2519722 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:22 2519720 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:22 2519720 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:22 2519722 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:22 2519721 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:22 2519721 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:22 2519721 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:22 2519721 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:22 2519721 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:22 2519724 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:22 2519724 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:22 2519724 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:22 2519719 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 08:36:22 2519719 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 08:36:22 2519719 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 08:36:22 2519724 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:22 2519719 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 08:36:22 2519719 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:22 2519724 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 08:36:51 2519723 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:51 2519725 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:52 2519722 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:55 2519723 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:36:55 2519723 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:36:55 2519725 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:36:56 2519726 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:56 2519725 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:36:56 2519722 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:36:56 2519722 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:36:57 2519720 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:57 2519719 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:57 2519721 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:57 2519724 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 08:36:59 2519726 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:36:59 2519726 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:37:01 2519721 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:37:02 2519723 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:02 2519723 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:02 2519721 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:37:02 2519719 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:37:02 2519720 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:37:02 2519725 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:02 2519725 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:02 2519724 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 08:37:02 2519722 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:02 2519722 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:02 2519720 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:37:02 2519719 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:37:02 2519724 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 08:37:04 2519723 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:04 2519723 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:04 2519723 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:04 2519723 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:04 2519723 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:04 2519723 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:05 2519722 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:05 2519722 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:05 2519722 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:05 2519722 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:05 2519722 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:05 2519722 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:05 2519725 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:05 2519725 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:05 2519725 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:05 2519725 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:05 2519725 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:05 2519725 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:10 2519726 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:10 2519726 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:13 2519720 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:13 2519720 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:14 2519724 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:14 2519724 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:14 2519719 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:14 2519719 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:15 2519726 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:15 2519726 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:15 2519726 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:15 2519726 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:15 2519726 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:15 2519726 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:16 2519721 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 08:37:16 2519721 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 08:37:19 2519720 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:19 2519720 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:19 2519720 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:19 2519720 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:19 2519720 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:19 2519720 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:20 2519724 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:20 2519724 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:20 2519724 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:20 2519724 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:20 2519724 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:20 2519724 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:20 2519719 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:20 2519719 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:20 2519719 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:20 2519719 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:20 2519719 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:20 2519719 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:23 2519721 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 08:37:23 2519721 dinov2 knn.py:260] Extracting features for train set...
I20241204 08:37:23 2519721 dinov2 loaders.py:151] sampler: distributed
I20241204 08:37:23 2519721 dinov2 loaders.py:210] using PyTorch data loader
W20241204 08:37:23 2519721 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 08:37:23 2519721 dinov2 loaders.py:223] # of batches: 634
I20241204 08:37:36 2519722 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:37:36 2519722 dinov2 helpers.py:102]   [  0/634]  eta: 5:23:11    time: 30.585302  data: 9.102509  max mem: 3463
I20241204 08:37:36 2519723 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:37:36 2519723 dinov2 helpers.py:102]   [  0/634]  eta: 5:40:01    time: 32.179100  data: 9.397881  max mem: 3463
I20241204 08:37:42 2519725 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:37:42 2519725 dinov2 helpers.py:102]   [  0/634]  eta: 6:31:06    time: 37.013569  data: 9.244555  max mem: 3463
I20241204 08:37:44 2519722 dinov2 helpers.py:102]   [ 10/634]  eta: 0:36:29    time: 3.508850  data: 0.830129  max mem: 4109
I20241204 08:37:46 2519723 dinov2 helpers.py:102]   [ 10/634]  eta: 0:39:05    time: 3.759194  data: 0.856293  max mem: 4109
I20241204 08:37:54 2519725 dinov2 helpers.py:102]   [ 10/634]  eta: 0:46:26    time: 4.465837  data: 0.842761  max mem: 4109
I20241204 08:37:59 2519722 dinov2 helpers.py:102]   [ 20/634]  eta: 0:26:04    time: 1.146308  data: 0.001615  max mem: 4109
I20241204 08:38:01 2519723 dinov2 helpers.py:102]   [ 20/634]  eta: 0:27:27    time: 1.207697  data: 0.002160  max mem: 4109
I20241204 08:38:09 2519726 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:38:09 2519726 dinov2 helpers.py:102]   [  0/634]  eta: 9:26:24    time: 53.602863  data: 13.750059  max mem: 3463
I20241204 08:38:10 2519725 dinov2 helpers.py:102]   [ 20/634]  eta: 0:31:23    time: 1.369591  data: 0.001505  max mem: 4109
I20241204 08:38:11 2519720 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:38:11 2519720 dinov2 helpers.py:102]   [  0/634]  eta: 9:09:52    time: 52.038765  data: 11.006682  max mem: 3463
I20241204 08:38:15 2519724 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:38:15 2519724 dinov2 helpers.py:102]   [  0/634]  eta: 9:44:10    time: 55.284283  data: 15.184951  max mem: 3463
I20241204 08:38:16 2519719 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:38:16 2519719 dinov2 helpers.py:102]   [  0/634]  eta: 9:45:25    time: 55.403263  data: 15.282213  max mem: 3463
I20241204 08:38:17 2519722 dinov2 helpers.py:102]   [ 30/634]  eta: 0:23:27    time: 1.682464  data: 0.000325  max mem: 4109
I20241204 08:38:18 2519721 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 08:38:18 2519721 dinov2 helpers.py:102]   [  0/634]  eta: 9:38:03    time: 54.705601  data: 14.777169  max mem: 3463
I20241204 08:38:23 2519723 dinov2 helpers.py:102]   [ 30/634]  eta: 0:25:26    time: 1.849202  data: 0.001712  max mem: 4109
I20241204 08:38:37 2519726 dinov2 helpers.py:102]   [ 10/634]  eta: 1:17:20    time: 7.436213  data: 1.251015  max mem: 4109
I20241204 08:38:41 2519720 dinov2 helpers.py:102]   [ 10/634]  eta: 1:17:35    time: 7.461346  data: 1.004094  max mem: 4109
I20241204 08:38:46 2519725 dinov2 helpers.py:102]   [ 30/634]  eta: 0:32:34    time: 2.560078  data: 0.000811  max mem: 4109
I20241204 08:38:47 2519724 dinov2 helpers.py:102]   [ 10/634]  eta: 1:22:30    time: 7.934210  data: 1.384621  max mem: 4109
I20241204 08:38:48 2519719 dinov2 helpers.py:102]   [ 10/634]  eta: 1:22:45    time: 7.957856  data: 1.390635  max mem: 4109
I20241204 08:38:50 2519721 dinov2 helpers.py:102]   [ 10/634]  eta: 1:22:13    time: 7.905955  data: 1.348764  max mem: 4109
I20241204 08:38:56 2519722 dinov2 helpers.py:102]   [ 40/634]  eta: 0:26:53    time: 2.893344  data: 0.000505  max mem: 4109
I20241204 08:39:02 2519723 dinov2 helpers.py:102]   [ 40/634]  eta: 0:28:24    time: 3.065244  data: 0.001773  max mem: 4109
I20241204 08:39:16 2519726 dinov2 helpers.py:102]   [ 20/634]  eta: 0:59:03    time: 3.379139  data: 0.001657  max mem: 4109
I20241204 08:39:21 2519720 dinov2 helpers.py:102]   [ 20/634]  eta: 0:59:11    time: 3.471323  data: 0.002229  max mem: 4109
I20241204 08:39:25 2519725 dinov2 helpers.py:102]   [ 40/634]  eta: 0:33:44    time: 3.767488  data: 0.001032  max mem: 4109
I20241204 08:39:26 2519724 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:46    time: 3.573695  data: 0.002771  max mem: 4109
I20241204 08:39:27 2519719 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:53    time: 3.580880  data: 0.001451  max mem: 4109
I20241204 08:39:29 2519721 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:36    time: 3.586238  data: 0.003738  max mem: 4109
I20241204 08:39:36 2519722 dinov2 helpers.py:102]   [ 50/634]  eta: 0:28:47    time: 3.929790  data: 0.000618  max mem: 4109
I20241204 08:39:41 2519723 dinov2 helpers.py:102]   [ 50/634]  eta: 0:29:59    time: 3.942727  data: 0.001879  max mem: 4109
I20241204 08:39:56 2519726 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:11    time: 3.947126  data: 0.001614  max mem: 4109
I20241204 08:40:00 2519720 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:17    time: 3.947066  data: 0.000633  max mem: 4109
I20241204 08:40:05 2519725 dinov2 helpers.py:102]   [ 50/634]  eta: 0:34:13    time: 3.948851  data: 0.001117  max mem: 4109
I20241204 08:40:06 2519724 dinov2 helpers.py:102]   [ 30/634]  eta: 0:54:00    time: 3.953311  data: 0.000925  max mem: 4109
I20241204 08:40:07 2519719 dinov2 helpers.py:102]   [ 30/634]  eta: 0:54:06    time: 3.953349  data: 0.001320  max mem: 4109
I20241204 08:40:09 2519721 dinov2 helpers.py:102]   [ 30/634]  eta: 0:53:54    time: 3.952384  data: 0.001332  max mem: 4109
I20241204 08:40:15 2519722 dinov2 helpers.py:102]   [ 60/634]  eta: 0:29:52    time: 3.953298  data: 0.000545  max mem: 4109
I20241204 08:40:21 2519723 dinov2 helpers.py:102]   [ 60/634]  eta: 0:30:51    time: 3.958453  data: 0.001235  max mem: 4109
I20241204 08:40:36 2519726 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:23    time: 3.959875  data: 0.001090  max mem: 4109
I20241204 08:40:40 2519720 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:26    time: 3.956126  data: 0.000629  max mem: 4109
I20241204 08:40:44 2519725 dinov2 helpers.py:102]   [ 60/634]  eta: 0:34:20    time: 3.960504  data: 0.001779  max mem: 4109
I20241204 08:40:46 2519724 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:44    time: 3.963185  data: 0.001573  max mem: 4109
I20241204 08:40:46 2519719 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:48    time: 3.962183  data: 0.001238  max mem: 4109
I20241204 08:40:49 2519721 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:39    time: 3.961327  data: 0.001150  max mem: 4109
I20241204 08:40:55 2519722 dinov2 helpers.py:102]   [ 70/634]  eta: 0:30:27    time: 3.960418  data: 0.000665  max mem: 4109
I20241204 08:41:01 2519723 dinov2 helpers.py:102]   [ 70/634]  eta: 0:31:18    time: 3.966768  data: 0.000829  max mem: 4109
I20241204 08:41:15 2519726 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:48    time: 3.965452  data: 0.001653  max mem: 4109
I20241204 08:41:19 2519720 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:51    time: 3.961895  data: 0.001315  max mem: 4109
I20241204 08:41:24 2519725 dinov2 helpers.py:102]   [ 70/634]  eta: 0:34:14    time: 3.967333  data: 0.001522  max mem: 4109
I20241204 08:41:25 2519724 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:53    time: 3.968292  data: 0.001674  max mem: 4109
I20241204 08:41:26 2519719 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:56    time: 3.968327  data: 0.001100  max mem: 4109
I20241204 08:41:28 2519721 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:49    time: 3.965554  data: 0.001188  max mem: 4109
I20241204 08:41:35 2519722 dinov2 helpers.py:102]   [ 80/634]  eta: 0:30:44    time: 3.965509  data: 0.000684  max mem: 4109
I20241204 08:41:40 2519723 dinov2 helpers.py:102]   [ 80/634]  eta: 0:31:29    time: 3.971964  data: 0.000720  max mem: 4109
I20241204 08:41:55 2519726 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:52    time: 3.966589  data: 0.001635  max mem: 4109
I20241204 08:41:59 2519720 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:53    time: 3.964753  data: 0.002004  max mem: 4109
I20241204 08:42:04 2519725 dinov2 helpers.py:102]   [ 80/634]  eta: 0:34:00    time: 3.967430  data: 0.001067  max mem: 4109
I20241204 08:42:05 2519724 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:45    time: 3.970114  data: 0.000872  max mem: 4109
I20241204 08:42:06 2519719 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:48    time: 3.970137  data: 0.000805  max mem: 4109
I20241204 08:42:08 2519721 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:41    time: 3.966548  data: 0.001011  max mem: 4109
I20241204 08:42:14 2519722 dinov2 helpers.py:102]   [ 90/634]  eta: 0:30:49    time: 3.968729  data: 0.000584  max mem: 4109
I20241204 08:42:20 2519723 dinov2 helpers.py:102]   [ 90/634]  eta: 0:31:28    time: 3.969294  data: 0.000946  max mem: 4109
I20241204 08:42:35 2519726 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:16    time: 3.965506  data: 0.001254  max mem: 4109
I20241204 08:42:39 2519720 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:18    time: 3.964670  data: 0.002138  max mem: 4109
I20241204 08:42:43 2519725 dinov2 helpers.py:102]   [ 90/634]  eta: 0:33:40    time: 3.967407  data: 0.001799  max mem: 4109
I20241204 08:42:45 2519724 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:02    time: 3.967315  data: 0.000903  max mem: 4109
I20241204 08:42:46 2519719 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:04    time: 3.969985  data: 0.001686  max mem: 4109
I20241204 08:42:47 2519721 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:58    time: 3.964710  data: 0.000950  max mem: 4109
I20241204 08:42:54 2519722 dinov2 helpers.py:102]   [100/634]  eta: 0:30:45    time: 3.968272  data: 0.000638  max mem: 4109
I20241204 08:43:00 2519723 dinov2 helpers.py:102]   [100/634]  eta: 0:31:19    time: 3.965567  data: 0.000970  max mem: 4109
I20241204 08:43:14 2519726 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:55    time: 3.965466  data: 0.001300  max mem: 4109
I20241204 08:43:18 2519720 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:56    time: 3.963691  data: 0.003026  max mem: 4109
I20241204 08:43:23 2519725 dinov2 helpers.py:102]   [100/634]  eta: 0:33:16    time: 3.969092  data: 0.002071  max mem: 4109
I20241204 08:43:24 2519724 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:34    time: 3.963695  data: 0.001088  max mem: 4109
I20241204 08:43:25 2519719 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:37    time: 3.970953  data: 0.001944  max mem: 4109
I20241204 08:43:27 2519721 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:31    time: 3.963697  data: 0.002098  max mem: 4109
I20241204 08:43:34 2519722 dinov2 helpers.py:102]   [110/634]  eta: 0:30:35    time: 3.966062  data: 0.000678  max mem: 4109
I20241204 08:43:39 2519723 dinov2 helpers.py:102]   [110/634]  eta: 0:31:05    time: 3.964481  data: 0.000894  max mem: 4109
I20241204 08:43:54 2519726 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:43    time: 3.967221  data: 0.001175  max mem: 4109
I20241204 08:43:58 2519720 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:44    time: 3.962694  data: 0.002954  max mem: 4109
I20241204 08:44:03 2519725 dinov2 helpers.py:102]   [110/634]  eta: 0:32:50    time: 3.969837  data: 0.001381  max mem: 4109
I20241204 08:44:04 2519724 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:17    time: 3.966191  data: 0.000916  max mem: 4109
I20241204 08:44:05 2519719 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:19    time: 3.968207  data: 0.001110  max mem: 4109
I20241204 08:44:07 2519721 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:14    time: 3.967223  data: 0.002025  max mem: 4109
I20241204 08:44:13 2519722 dinov2 helpers.py:102]   [120/634]  eta: 0:30:19    time: 3.962695  data: 0.000656  max mem: 4109
I20241204 08:44:19 2519723 dinov2 helpers.py:102]   [120/634]  eta: 0:30:47    time: 3.965367  data: 0.001419  max mem: 4109
I20241204 08:44:34 2519726 dinov2 helpers.py:102]   [100/634]  eta: 0:38:37    time: 3.969345  data: 0.001022  max mem: 4109
I20241204 08:44:38 2519720 dinov2 helpers.py:102]   [100/634]  eta: 0:38:38    time: 3.965863  data: 0.001460  max mem: 4109
I20241204 08:44:42 2519725 dinov2 helpers.py:102]   [120/634]  eta: 0:32:21    time: 3.970171  data: 0.000796  max mem: 4109
I20241204 08:44:44 2519724 dinov2 helpers.py:102]   [100/634]  eta: 0:39:07    time: 3.967374  data: 0.000831  max mem: 4109
I20241204 08:44:45 2519719 dinov2 helpers.py:102]   [100/634]  eta: 0:39:09    time: 3.967296  data: 0.001719  max mem: 4109
I20241204 08:44:47 2519721 dinov2 helpers.py:102]   [100/634]  eta: 0:39:05    time: 3.968404  data: 0.001070  max mem: 4109
I20241204 08:44:53 2519722 dinov2 helpers.py:102]   [130/634]  eta: 0:30:00    time: 3.965576  data: 0.000671  max mem: 4109
I20241204 08:44:59 2519723 dinov2 helpers.py:102]   [130/634]  eta: 0:30:25    time: 3.966527  data: 0.001496  max mem: 4109
I20241204 08:45:13 2519726 dinov2 helpers.py:102]   [110/634]  eta: 0:37:36    time: 3.964783  data: 0.000924  max mem: 4109
I20241204 08:45:17 2519720 dinov2 helpers.py:102]   [110/634]  eta: 0:37:37    time: 3.966642  data: 0.000936  max mem: 4109
I20241204 08:45:22 2519725 dinov2 helpers.py:102]   [130/634]  eta: 0:31:51    time: 3.968432  data: 0.001855  max mem: 4109
I20241204 08:45:23 2519724 dinov2 helpers.py:102]   [110/634]  eta: 0:38:03    time: 3.965730  data: 0.000982  max mem: 4109
I20241204 08:45:24 2519719 dinov2 helpers.py:102]   [110/634]  eta: 0:38:05    time: 3.970840  data: 0.001662  max mem: 4109
I20241204 08:45:26 2519721 dinov2 helpers.py:102]   [110/634]  eta: 0:38:01    time: 3.965543  data: 0.001801  max mem: 4109
I20241204 08:45:33 2519722 dinov2 helpers.py:102]   [140/634]  eta: 0:29:38    time: 3.967395  data: 0.000832  max mem: 4109
I20241204 08:45:38 2519723 dinov2 helpers.py:102]   [140/634]  eta: 0:30:01    time: 3.966439  data: 0.000934  max mem: 4109
I20241204 08:45:53 2519726 dinov2 helpers.py:102]   [120/634]  eta: 0:36:38    time: 3.962367  data: 0.000907  max mem: 4109
I20241204 08:45:57 2519720 dinov2 helpers.py:102]   [120/634]  eta: 0:36:39    time: 3.961435  data: 0.001066  max mem: 4109
I20241204 08:46:02 2519725 dinov2 helpers.py:102]   [140/634]  eta: 0:31:19    time: 3.966170  data: 0.002104  max mem: 4109
I20241204 08:46:03 2519724 dinov2 helpers.py:102]   [120/634]  eta: 0:37:03    time: 3.964539  data: 0.002618  max mem: 4109
I20241204 08:46:04 2519719 dinov2 helpers.py:102]   [120/634]  eta: 0:37:05    time: 3.968942  data: 0.001732  max mem: 4109
I20241204 08:46:06 2519721 dinov2 helpers.py:102]   [120/634]  eta: 0:37:01    time: 3.964411  data: 0.002250  max mem: 4109
I20241204 08:46:12 2519722 dinov2 helpers.py:102]   [150/634]  eta: 0:29:14    time: 3.963568  data: 0.000789  max mem: 4109
I20241204 08:46:18 2519723 dinov2 helpers.py:102]   [150/634]  eta: 0:29:35    time: 3.964451  data: 0.001973  max mem: 4109
I20241204 08:46:33 2519726 dinov2 helpers.py:102]   [130/634]  eta: 0:35:44    time: 3.965141  data: 0.000720  max mem: 4109
I20241204 08:46:36 2519720 dinov2 helpers.py:102]   [130/634]  eta: 0:35:44    time: 3.960744  data: 0.000785  max mem: 4109
I20241204 08:46:41 2519725 dinov2 helpers.py:102]   [150/634]  eta: 0:30:46    time: 3.965109  data: 0.000978  max mem: 4109
I20241204 08:46:43 2519724 dinov2 helpers.py:102]   [130/634]  eta: 0:36:05    time: 3.964233  data: 0.002462  max mem: 4109
I20241204 08:46:44 2519719 dinov2 helpers.py:102]   [130/634]  eta: 0:36:07    time: 3.966967  data: 0.002368  max mem: 4109
I20241204 08:46:45 2519721 dinov2 helpers.py:102]   [130/634]  eta: 0:36:04    time: 3.961524  data: 0.002078  max mem: 4109
I20241204 08:46:52 2519722 dinov2 helpers.py:102]   [160/634]  eta: 0:28:48    time: 3.962403  data: 0.000837  max mem: 4109
I20241204 08:46:58 2519723 dinov2 helpers.py:102]   [160/634]  eta: 0:29:07    time: 3.962503  data: 0.001986  max mem: 4109
I20241204 08:47:12 2519726 dinov2 helpers.py:102]   [140/634]  eta: 0:34:51    time: 3.961030  data: 0.000701  max mem: 4109
I20241204 08:47:16 2519720 dinov2 helpers.py:102]   [140/634]  eta: 0:34:51    time: 3.966215  data: 0.000569  max mem: 4109
I20241204 08:47:21 2519725 dinov2 helpers.py:102]   [160/634]  eta: 0:30:12    time: 3.963480  data: 0.000778  max mem: 4109
I20241204 08:47:22 2519724 dinov2 helpers.py:102]   [140/634]  eta: 0:35:11    time: 3.965191  data: 0.001240  max mem: 4109
I20241204 08:47:23 2519719 dinov2 helpers.py:102]   [140/634]  eta: 0:35:13    time: 3.965280  data: 0.001670  max mem: 4109
I20241204 08:47:25 2519721 dinov2 helpers.py:102]   [140/634]  eta: 0:35:09    time: 3.959819  data: 0.001915  max mem: 4109
I20241204 08:47:32 2519722 dinov2 helpers.py:102]   [170/634]  eta: 0:28:20    time: 3.965221  data: 0.000845  max mem: 4109
I20241204 08:47:37 2519723 dinov2 helpers.py:102]   [170/634]  eta: 0:28:37    time: 3.965281  data: 0.001072  max mem: 4109
I20241204 08:47:52 2519726 dinov2 helpers.py:102]   [150/634]  eta: 0:34:00    time: 3.961709  data: 0.001018  max mem: 4109
I20241204 08:47:56 2519720 dinov2 helpers.py:102]   [150/634]  eta: 0:34:00    time: 3.964264  data: 0.000862  max mem: 4109
I20241204 08:48:01 2519725 dinov2 helpers.py:102]   [170/634]  eta: 0:29:38    time: 3.965266  data: 0.000905  max mem: 4109
I20241204 08:48:02 2519724 dinov2 helpers.py:102]   [150/634]  eta: 0:34:18    time: 3.964369  data: 0.001339  max mem: 4109
I20241204 08:48:03 2519719 dinov2 helpers.py:102]   [150/634]  eta: 0:34:20    time: 3.961725  data: 0.000961  max mem: 4109
I20241204 08:48:05 2519721 dinov2 helpers.py:102]   [150/634]  eta: 0:34:17    time: 3.963523  data: 0.001976  max mem: 4109
I20241204 08:48:11 2519722 dinov2 helpers.py:102]   [180/634]  eta: 0:27:51    time: 3.964446  data: 0.000690  max mem: 4109
I20241204 08:48:17 2519723 dinov2 helpers.py:102]   [180/634]  eta: 0:28:07    time: 3.963543  data: 0.001320  max mem: 4109
I20241204 08:48:32 2519726 dinov2 helpers.py:102]   [160/634]  eta: 0:33:10    time: 3.966115  data: 0.001131  max mem: 4109
I20241204 08:48:35 2519720 dinov2 helpers.py:102]   [160/634]  eta: 0:33:11    time: 3.965491  data: 0.000834  max mem: 4109
I20241204 08:48:40 2519725 dinov2 helpers.py:102]   [180/634]  eta: 0:29:03    time: 3.965321  data: 0.001243  max mem: 4109
I20241204 08:48:42 2519724 dinov2 helpers.py:102]   [160/634]  eta: 0:33:27    time: 3.966235  data: 0.000964  max mem: 4109
I20241204 08:48:43 2519719 dinov2 helpers.py:102]   [160/634]  eta: 0:33:28    time: 3.962648  data: 0.000975  max mem: 4109
I20241204 08:48:44 2519721 dinov2 helpers.py:102]   [160/634]  eta: 0:33:26    time: 3.966180  data: 0.001909  max mem: 4109
I20241204 08:48:51 2519722 dinov2 helpers.py:102]   [190/634]  eta: 0:27:20    time: 3.963601  data: 0.000660  max mem: 4109
I20241204 08:48:57 2519723 dinov2 helpers.py:102]   [190/634]  eta: 0:27:36    time: 3.962643  data: 0.001061  max mem: 4109
I20241204 08:49:11 2519726 dinov2 helpers.py:102]   [170/634]  eta: 0:32:22    time: 3.964602  data: 0.000797  max mem: 4109
I20241204 08:49:15 2519720 dinov2 helpers.py:102]   [170/634]  eta: 0:32:22    time: 3.967176  data: 0.000538  max mem: 4109
I20241204 08:49:20 2519725 dinov2 helpers.py:102]   [190/634]  eta: 0:28:27    time: 3.964511  data: 0.001400  max mem: 4109
I20241204 08:49:21 2519724 dinov2 helpers.py:102]   [170/634]  eta: 0:32:38    time: 3.967133  data: 0.001108  max mem: 4109
I20241204 08:49:22 2519719 dinov2 helpers.py:102]   [170/634]  eta: 0:32:39    time: 3.964441  data: 0.001167  max mem: 4109
I20241204 08:49:24 2519721 dinov2 helpers.py:102]   [170/634]  eta: 0:32:36    time: 3.965371  data: 0.001205  max mem: 4109
I20241204 08:49:31 2519722 dinov2 helpers.py:102]   [200/634]  eta: 0:26:49    time: 3.964454  data: 0.001567  max mem: 4109
I20241204 08:49:36 2519723 dinov2 helpers.py:102]   [200/634]  eta: 0:27:03    time: 3.966225  data: 0.001253  max mem: 4109
I20241204 08:49:51 2519726 dinov2 helpers.py:102]   [180/634]  eta: 0:31:35    time: 3.965181  data: 0.001076  max mem: 4109
I20241204 08:49:55 2519720 dinov2 helpers.py:102]   [180/634]  eta: 0:31:35    time: 3.963303  data: 0.000550  max mem: 4109
I20241204 08:50:00 2519725 dinov2 helpers.py:102]   [200/634]  eta: 0:27:51    time: 3.964396  data: 0.001070  max mem: 4109
I20241204 08:50:01 2519724 dinov2 helpers.py:102]   [180/634]  eta: 0:31:49    time: 3.963487  data: 0.001356  max mem: 4109
I20241204 08:50:02 2519719 dinov2 helpers.py:102]   [180/634]  eta: 0:31:50    time: 3.966206  data: 0.001430  max mem: 4109
I20241204 08:50:04 2519721 dinov2 helpers.py:102]   [180/634]  eta: 0:31:48    time: 3.963537  data: 0.001425  max mem: 4109
I20241204 08:50:10 2519722 dinov2 helpers.py:102]   [210/634]  eta: 0:26:17    time: 3.966300  data: 0.001553  max mem: 4109
I20241204 08:50:16 2519723 dinov2 helpers.py:102]   [210/634]  eta: 0:26:30    time: 3.965536  data: 0.001404  max mem: 4109
I20241204 08:50:30 2519726 dinov2 helpers.py:102]   [190/634]  eta: 0:30:48    time: 3.964485  data: 0.001595  max mem: 4109
I20241204 08:50:34 2519720 dinov2 helpers.py:102]   [190/634]  eta: 0:30:48    time: 3.964669  data: 0.000579  max mem: 4109
I20241204 08:50:39 2519725 dinov2 helpers.py:102]   [210/634]  eta: 0:27:15    time: 3.964695  data: 0.000959  max mem: 4109
I20241204 08:50:41 2519724 dinov2 helpers.py:102]   [190/634]  eta: 0:31:01    time: 3.964767  data: 0.001530  max mem: 4109
I20241204 08:50:42 2519719 dinov2 helpers.py:102]   [190/634]  eta: 0:31:02    time: 3.967441  data: 0.001802  max mem: 4109
I20241204 08:50:43 2519721 dinov2 helpers.py:102]   [190/634]  eta: 0:31:00    time: 3.963833  data: 0.001682  max mem: 4109
I20241204 08:50:50 2519722 dinov2 helpers.py:102]   [220/634]  eta: 0:25:45    time: 3.968786  data: 0.000693  max mem: 4109
I20241204 08:50:56 2519723 dinov2 helpers.py:102]   [220/634]  eta: 0:25:57    time: 3.963854  data: 0.000985  max mem: 4109
I20241204 08:51:10 2519726 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.965611  data: 0.001116  max mem: 4109
I20241204 08:51:14 2519720 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.965673  data: 0.000774  max mem: 4109
I20241204 08:51:19 2519725 dinov2 helpers.py:102]   [220/634]  eta: 0:26:39    time: 3.966494  data: 0.000939  max mem: 4109
I20241204 08:51:20 2519724 dinov2 helpers.py:102]   [200/634]  eta: 0:30:14    time: 3.964719  data: 0.001569  max mem: 4109
I20241204 08:51:21 2519719 dinov2 helpers.py:102]   [200/634]  eta: 0:30:15    time: 3.966492  data: 0.001341  max mem: 4109
I20241204 08:51:23 2519721 dinov2 helpers.py:102]   [200/634]  eta: 0:30:13    time: 3.963784  data: 0.002349  max mem: 4109
I20241204 08:51:30 2519722 dinov2 helpers.py:102]   [230/634]  eta: 0:25:12    time: 3.968103  data: 0.000754  max mem: 4109
I20241204 08:51:35 2519723 dinov2 helpers.py:102]   [230/634]  eta: 0:25:23    time: 3.961695  data: 0.000743  max mem: 4109
I20241204 08:51:50 2519726 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.968862  data: 0.000941  max mem: 4109
I20241204 08:51:54 2519720 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.963481  data: 0.000809  max mem: 4109
I20241204 08:51:58 2519725 dinov2 helpers.py:102]   [230/634]  eta: 0:26:02    time: 3.963356  data: 0.001242  max mem: 4109
I20241204 08:52:00 2519724 dinov2 helpers.py:102]   [210/634]  eta: 0:29:28    time: 3.960690  data: 0.001194  max mem: 4109
I20241204 08:52:01 2519719 dinov2 helpers.py:102]   [210/634]  eta: 0:29:29    time: 3.966878  data: 0.001647  max mem: 4109
I20241204 08:52:02 2519721 dinov2 helpers.py:102]   [210/634]  eta: 0:29:27    time: 3.957870  data: 0.002862  max mem: 4109
I20241204 08:52:09 2519722 dinov2 helpers.py:102]   [240/634]  eta: 0:24:38    time: 3.966435  data: 0.000690  max mem: 4109
I20241204 08:52:15 2519723 dinov2 helpers.py:102]   [240/634]  eta: 0:24:48    time: 3.961484  data: 0.000748  max mem: 4109
I20241204 08:52:29 2519726 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.967169  data: 0.001822  max mem: 4109
I20241204 08:52:33 2519720 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.963366  data: 0.000943  max mem: 4109
I20241204 08:52:38 2519725 dinov2 helpers.py:102]   [240/634]  eta: 0:25:25    time: 3.965232  data: 0.001354  max mem: 4109
I20241204 08:52:40 2519724 dinov2 helpers.py:102]   [220/634]  eta: 0:28:42    time: 3.961637  data: 0.001027  max mem: 4109
I20241204 08:52:41 2519719 dinov2 helpers.py:102]   [220/634]  eta: 0:28:44    time: 3.965263  data: 0.001934  max mem: 4109
I20241204 08:52:42 2519721 dinov2 helpers.py:102]   [220/634]  eta: 0:28:41    time: 3.958939  data: 0.001533  max mem: 4109
I20241204 08:52:49 2519722 dinov2 helpers.py:102]   [250/634]  eta: 0:24:04    time: 3.967048  data: 0.000704  max mem: 4109
I20241204 08:52:54 2519723 dinov2 helpers.py:102]   [250/634]  eta: 0:24:13    time: 3.962629  data: 0.000765  max mem: 4109
I20241204 08:53:09 2519726 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.964474  data: 0.001627  max mem: 4109
I20241204 08:53:13 2519720 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.962656  data: 0.000955  max mem: 4109
I20241204 08:53:18 2519725 dinov2 helpers.py:102]   [250/634]  eta: 0:24:47    time: 3.967230  data: 0.001086  max mem: 4109
I20241204 08:53:19 2519724 dinov2 helpers.py:102]   [230/634]  eta: 0:27:57    time: 3.963622  data: 0.000848  max mem: 4109
I20241204 08:53:20 2519719 dinov2 helpers.py:102]   [230/634]  eta: 0:27:58    time: 3.963659  data: 0.001966  max mem: 4109
I20241204 08:53:22 2519721 dinov2 helpers.py:102]   [230/634]  eta: 0:27:56    time: 3.964558  data: 0.001033  max mem: 4109
I20241204 08:53:29 2519722 dinov2 helpers.py:102]   [260/634]  eta: 0:23:29    time: 3.966359  data: 0.001048  max mem: 4109
I20241204 08:53:34 2519723 dinov2 helpers.py:102]   [260/634]  eta: 0:23:38    time: 3.966249  data: 0.001001  max mem: 4109
I20241204 08:53:49 2519726 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.965225  data: 0.001009  max mem: 4109
I20241204 08:53:53 2519720 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.963627  data: 0.000663  max mem: 4109
I20241204 08:53:57 2519725 dinov2 helpers.py:102]   [260/634]  eta: 0:24:10    time: 3.964381  data: 0.001283  max mem: 4109
I20241204 08:53:59 2519724 dinov2 helpers.py:102]   [240/634]  eta: 0:27:13    time: 3.964402  data: 0.000664  max mem: 4109
I20241204 08:54:00 2519719 dinov2 helpers.py:102]   [240/634]  eta: 0:27:14    time: 3.962509  data: 0.002735  max mem: 4109
I20241204 08:54:01 2519721 dinov2 helpers.py:102]   [240/634]  eta: 0:27:12    time: 3.961661  data: 0.000990  max mem: 4109
I20241204 08:54:08 2519722 dinov2 helpers.py:102]   [270/634]  eta: 0:22:54    time: 3.963537  data: 0.001277  max mem: 4109
I20241204 08:54:14 2519723 dinov2 helpers.py:102]   [270/634]  eta: 0:23:02    time: 3.966115  data: 0.001205  max mem: 4109
I20241204 08:54:28 2519726 dinov2 helpers.py:102]   [250/634]  eta: 0:26:20    time: 3.967916  data: 0.001813  max mem: 4109
I20241204 08:54:32 2519720 dinov2 helpers.py:102]   [250/634]  eta: 0:26:20    time: 3.967899  data: 0.000605  max mem: 4109
I20241204 08:54:37 2519725 dinov2 helpers.py:102]   [270/634]  eta: 0:23:32    time: 3.963421  data: 0.001069  max mem: 4109
I20241204 08:54:38 2519724 dinov2 helpers.py:102]   [250/634]  eta: 0:26:29    time: 3.964235  data: 0.000984  max mem: 4109
I20241204 08:54:40 2519719 dinov2 helpers.py:102]   [250/634]  eta: 0:26:29    time: 3.965567  data: 0.001730  max mem: 4109
I20241204 08:54:41 2519721 dinov2 helpers.py:102]   [250/634]  eta: 0:26:28    time: 3.960713  data: 0.000727  max mem: 4109
I20241204 08:54:48 2519722 dinov2 helpers.py:102]   [280/634]  eta: 0:22:18    time: 3.963496  data: 0.000945  max mem: 4109
I20241204 08:54:53 2519723 dinov2 helpers.py:102]   [280/634]  eta: 0:22:26    time: 3.962748  data: 0.001067  max mem: 4109
I20241204 08:55:08 2519726 dinov2 helpers.py:102]   [260/634]  eta: 0:25:37    time: 3.967929  data: 0.001753  max mem: 4109
I20241204 08:55:12 2519720 dinov2 helpers.py:102]   [260/634]  eta: 0:25:37    time: 3.967863  data: 0.000646  max mem: 4109
I20241204 08:55:17 2519725 dinov2 helpers.py:102]   [280/634]  eta: 0:22:55    time: 3.964356  data: 0.000777  max mem: 4109
I20241204 08:55:18 2519724 dinov2 helpers.py:102]   [260/634]  eta: 0:25:45    time: 3.964303  data: 0.001912  max mem: 4109
I20241204 08:55:19 2519719 dinov2 helpers.py:102]   [260/634]  eta: 0:25:46    time: 3.967053  data: 0.000812  max mem: 4109
I20241204 08:55:21 2519721 dinov2 helpers.py:102]   [260/634]  eta: 0:25:44    time: 3.964351  data: 0.000966  max mem: 4109
I20241204 08:55:27 2519722 dinov2 helpers.py:102]   [290/634]  eta: 0:21:43    time: 3.963490  data: 0.001052  max mem: 4109
I20241204 08:55:33 2519723 dinov2 helpers.py:102]   [290/634]  eta: 0:21:50    time: 3.962955  data: 0.000896  max mem: 4109
I20241204 08:55:48 2519726 dinov2 helpers.py:102]   [270/634]  eta: 0:24:54    time: 3.964343  data: 0.001081  max mem: 4109
I20241204 08:55:52 2519720 dinov2 helpers.py:102]   [270/634]  eta: 0:24:54    time: 3.964363  data: 0.000911  max mem: 4109
I20241204 08:55:56 2519725 dinov2 helpers.py:102]   [290/634]  eta: 0:22:17    time: 3.964327  data: 0.000827  max mem: 4109
I20241204 08:55:58 2519724 dinov2 helpers.py:102]   [270/634]  eta: 0:25:01    time: 3.967067  data: 0.002047  max mem: 4109
I20241204 08:55:59 2519719 dinov2 helpers.py:102]   [270/634]  eta: 0:25:02    time: 3.963088  data: 0.000890  max mem: 4109
I20241204 08:56:00 2519721 dinov2 helpers.py:102]   [270/634]  eta: 0:25:00    time: 3.966153  data: 0.001303  max mem: 4109
I20241204 08:56:07 2519722 dinov2 helpers.py:102]   [300/634]  eta: 0:21:07    time: 3.965208  data: 0.001063  max mem: 4109
I20241204 08:56:13 2519723 dinov2 helpers.py:102]   [300/634]  eta: 0:21:14    time: 3.961546  data: 0.000907  max mem: 4109
I20241204 08:56:27 2519726 dinov2 helpers.py:102]   [280/634]  eta: 0:24:11    time: 3.964312  data: 0.000894  max mem: 4109
I20241204 08:56:31 2519720 dinov2 helpers.py:102]   [280/634]  eta: 0:24:11    time: 3.963420  data: 0.000828  max mem: 4109
I20241204 08:56:36 2519725 dinov2 helpers.py:102]   [300/634]  eta: 0:21:39    time: 3.965265  data: 0.003448  max mem: 4109
I20241204 08:56:37 2519724 dinov2 helpers.py:102]   [280/634]  eta: 0:24:18    time: 3.967013  data: 0.001174  max mem: 4109
I20241204 08:56:38 2519719 dinov2 helpers.py:102]   [280/634]  eta: 0:24:19    time: 3.964365  data: 0.000788  max mem: 4109
I20241204 08:56:40 2519721 dinov2 helpers.py:102]   [280/634]  eta: 0:24:17    time: 3.963430  data: 0.001168  max mem: 4109
I20241204 08:56:47 2519722 dinov2 helpers.py:102]   [310/634]  eta: 0:20:31    time: 3.966993  data: 0.000697  max mem: 4109
I20241204 08:56:52 2519723 dinov2 helpers.py:102]   [310/634]  eta: 0:20:37    time: 3.962170  data: 0.001020  max mem: 4109
I20241204 08:57:07 2519726 dinov2 helpers.py:102]   [290/634]  eta: 0:23:28    time: 3.964378  data: 0.000623  max mem: 4109
I20241204 08:57:11 2519720 dinov2 helpers.py:102]   [290/634]  eta: 0:23:28    time: 3.967043  data: 0.000723  max mem: 4109
I20241204 08:57:16 2519725 dinov2 helpers.py:102]   [310/634]  eta: 0:21:01    time: 3.966450  data: 0.003623  max mem: 4109
I20241204 08:57:17 2519724 dinov2 helpers.py:102]   [290/634]  eta: 0:23:35    time: 3.967136  data: 0.001047  max mem: 4109
I20241204 08:57:18 2519719 dinov2 helpers.py:102]   [290/634]  eta: 0:23:36    time: 3.967151  data: 0.000909  max mem: 4109
I20241204 08:57:19 2519721 dinov2 helpers.py:102]   [290/634]  eta: 0:23:34    time: 3.961700  data: 0.001402  max mem: 4109
I20241204 08:57:26 2519722 dinov2 helpers.py:102]   [320/634]  eta: 0:19:54    time: 3.964282  data: 0.000584  max mem: 4109
I20241204 08:57:32 2519723 dinov2 helpers.py:102]   [320/634]  eta: 0:20:00    time: 3.964342  data: 0.000888  max mem: 4109
I20241204 08:57:47 2519726 dinov2 helpers.py:102]   [300/634]  eta: 0:22:46    time: 3.959780  data: 0.000747  max mem: 4109
I20241204 08:57:51 2519720 dinov2 helpers.py:102]   [300/634]  eta: 0:22:46    time: 3.966949  data: 0.000779  max mem: 4109
I20241204 08:57:55 2519725 dinov2 helpers.py:102]   [320/634]  eta: 0:20:22    time: 3.966007  data: 0.001700  max mem: 4109
I20241204 08:57:57 2519724 dinov2 helpers.py:102]   [300/634]  eta: 0:22:52    time: 3.966009  data: 0.001057  max mem: 4109
I20241204 08:57:58 2519719 dinov2 helpers.py:102]   [300/634]  eta: 0:22:53    time: 3.965075  data: 0.001610  max mem: 4109
I20241204 08:57:59 2519721 dinov2 helpers.py:102]   [300/634]  eta: 0:22:51    time: 3.960649  data: 0.001430  max mem: 4109
I20241204 08:58:06 2519722 dinov2 helpers.py:102]   [330/634]  eta: 0:19:18    time: 3.962300  data: 0.000587  max mem: 4109
I20241204 08:58:12 2519723 dinov2 helpers.py:102]   [330/634]  eta: 0:19:23    time: 3.966813  data: 0.001027  max mem: 4109
I20241204 08:58:26 2519726 dinov2 helpers.py:102]   [310/634]  eta: 0:22:04    time: 3.961450  data: 0.000858  max mem: 4109
I20241204 08:58:30 2519720 dinov2 helpers.py:102]   [310/634]  eta: 0:22:04    time: 3.962263  data: 0.000719  max mem: 4109
I20241204 08:58:35 2519725 dinov2 helpers.py:102]   [330/634]  eta: 0:19:44    time: 3.965611  data: 0.001608  max mem: 4109
I20241204 08:58:36 2519724 dinov2 helpers.py:102]   [310/634]  eta: 0:22:10    time: 3.965791  data: 0.001079  max mem: 4109
I20241204 08:58:37 2519719 dinov2 helpers.py:102]   [310/634]  eta: 0:22:10    time: 3.959483  data: 0.001813  max mem: 4109
I20241204 08:58:39 2519721 dinov2 helpers.py:102]   [310/634]  eta: 0:22:09    time: 3.963178  data: 0.001285  max mem: 4109
I20241204 08:58:46 2519722 dinov2 helpers.py:102]   [340/634]  eta: 0:18:41    time: 3.962591  data: 0.000563  max mem: 4109
I20241204 08:58:51 2519723 dinov2 helpers.py:102]   [340/634]  eta: 0:18:46    time: 3.963276  data: 0.000978  max mem: 4109
I20241204 08:59:06 2519726 dinov2 helpers.py:102]   [320/634]  eta: 0:21:22    time: 3.965105  data: 0.000840  max mem: 4109
I20241204 08:59:10 2519720 dinov2 helpers.py:102]   [320/634]  eta: 0:21:22    time: 3.962425  data: 0.000666  max mem: 4109
I20241204 08:59:15 2519725 dinov2 helpers.py:102]   [340/634]  eta: 0:19:06    time: 3.966059  data: 0.001873  max mem: 4109
I20241204 08:59:16 2519724 dinov2 helpers.py:102]   [320/634]  eta: 0:21:27    time: 3.966092  data: 0.002085  max mem: 4109
I20241204 08:59:17 2519719 dinov2 helpers.py:102]   [320/634]  eta: 0:21:28    time: 3.962471  data: 0.001654  max mem: 4109
I20241204 08:59:18 2519721 dinov2 helpers.py:102]   [320/634]  eta: 0:21:26    time: 3.966010  data: 0.001209  max mem: 4109
I20241204 08:59:25 2519722 dinov2 helpers.py:102]   [350/634]  eta: 0:18:04    time: 3.962444  data: 0.000939  max mem: 4109
I20241204 08:59:31 2519723 dinov2 helpers.py:102]   [350/634]  eta: 0:18:09    time: 3.959726  data: 0.000700  max mem: 4109
I20241204 08:59:46 2519726 dinov2 helpers.py:102]   [330/634]  eta: 0:20:40    time: 3.964083  data: 0.000769  max mem: 4109
I20241204 08:59:49 2519720 dinov2 helpers.py:102]   [330/634]  eta: 0:20:40    time: 3.959631  data: 0.000715  max mem: 4109
I20241204 08:59:54 2519725 dinov2 helpers.py:102]   [350/634]  eta: 0:18:27    time: 3.963275  data: 0.001937  max mem: 4109
I20241204 08:59:56 2519724 dinov2 helpers.py:102]   [330/634]  eta: 0:20:45    time: 3.967759  data: 0.002140  max mem: 4109
I20241204 08:59:57 2519719 dinov2 helpers.py:102]   [330/634]  eta: 0:20:45    time: 3.965114  data: 0.001504  max mem: 4109
I20241204 08:59:58 2519721 dinov2 helpers.py:102]   [330/634]  eta: 0:20:44    time: 3.961540  data: 0.001300  max mem: 4109
I20241204 09:00:05 2519722 dinov2 helpers.py:102]   [360/634]  eta: 0:17:27    time: 3.963891  data: 0.001333  max mem: 4109
I20241204 09:00:10 2519723 dinov2 helpers.py:102]   [360/634]  eta: 0:17:32    time: 3.961351  data: 0.000671  max mem: 4109
I20241204 09:00:25 2519726 dinov2 helpers.py:102]   [340/634]  eta: 0:19:58    time: 3.960374  data: 0.000962  max mem: 4109
I20241204 09:00:29 2519720 dinov2 helpers.py:102]   [340/634]  eta: 0:19:58    time: 3.957673  data: 0.000798  max mem: 4109
I20241204 09:00:34 2519725 dinov2 helpers.py:102]   [360/634]  eta: 0:17:49    time: 3.960323  data: 0.001080  max mem: 4109
I20241204 09:00:35 2519724 dinov2 helpers.py:102]   [340/634]  eta: 0:20:03    time: 3.964821  data: 0.001160  max mem: 4109
I20241204 09:00:36 2519719 dinov2 helpers.py:102]   [340/634]  eta: 0:20:03    time: 3.964827  data: 0.000822  max mem: 4109
I20241204 09:00:38 2519721 dinov2 helpers.py:102]   [340/634]  eta: 0:20:02    time: 3.957657  data: 0.001353  max mem: 4109
I20241204 09:00:45 2519722 dinov2 helpers.py:102]   [370/634]  eta: 0:16:50    time: 3.964865  data: 0.001320  max mem: 4109
I20241204 09:00:50 2519723 dinov2 helpers.py:102]   [370/634]  eta: 0:16:54    time: 3.962172  data: 0.000843  max mem: 4109
I20241204 09:01:05 2519726 dinov2 helpers.py:102]   [350/634]  eta: 0:19:16    time: 3.958521  data: 0.001066  max mem: 4109
I20241204 09:01:09 2519720 dinov2 helpers.py:102]   [350/634]  eta: 0:19:16    time: 3.959462  data: 0.000710  max mem: 4109
I20241204 09:01:14 2519725 dinov2 helpers.py:102]   [370/634]  eta: 0:17:10    time: 3.964759  data: 0.000858  max mem: 4109
I20241204 09:01:15 2519724 dinov2 helpers.py:102]   [350/634]  eta: 0:19:21    time: 3.958481  data: 0.000906  max mem: 4109
I20241204 09:01:16 2519719 dinov2 helpers.py:102]   [350/634]  eta: 0:19:21    time: 3.962916  data: 0.000998  max mem: 4109
I20241204 09:01:17 2519721 dinov2 helpers.py:102]   [350/634]  eta: 0:19:20    time: 3.957467  data: 0.000822  max mem: 4109
I20241204 09:01:24 2519722 dinov2 helpers.py:102]   [380/634]  eta: 0:16:12    time: 3.961114  data: 0.001987  max mem: 4109
I20241204 09:01:30 2519723 dinov2 helpers.py:102]   [380/634]  eta: 0:16:16    time: 3.961318  data: 0.000948  max mem: 4109
I20241204 09:01:44 2519726 dinov2 helpers.py:102]   [360/634]  eta: 0:18:34    time: 3.955783  data: 0.001841  max mem: 4109
I20241204 09:01:48 2519720 dinov2 helpers.py:102]   [360/634]  eta: 0:18:34    time: 3.960185  data: 0.000689  max mem: 4109
I20241204 09:01:53 2519725 dinov2 helpers.py:102]   [380/634]  eta: 0:16:31    time: 3.963786  data: 0.000724  max mem: 4109
I20241204 09:01:55 2519724 dinov2 helpers.py:102]   [360/634]  eta: 0:18:39    time: 3.958345  data: 0.001102  max mem: 4109
I20241204 09:01:56 2519719 dinov2 helpers.py:102]   [360/634]  eta: 0:18:39    time: 3.960143  data: 0.001387  max mem: 4109
I20241204 09:01:57 2519721 dinov2 helpers.py:102]   [360/634]  eta: 0:18:38    time: 3.957468  data: 0.000798  max mem: 4109
I20241204 09:02:04 2519722 dinov2 helpers.py:102]   [390/634]  eta: 0:15:35    time: 3.960140  data: 0.001797  max mem: 4109
I20241204 09:02:09 2519723 dinov2 helpers.py:102]   [390/634]  eta: 0:15:39    time: 3.957494  data: 0.000898  max mem: 4109
I20241204 09:02:24 2519726 dinov2 helpers.py:102]   [370/634]  eta: 0:17:53    time: 3.955639  data: 0.002449  max mem: 4109
I20241204 09:02:28 2519720 dinov2 helpers.py:102]   [370/634]  eta: 0:17:53    time: 3.960079  data: 0.000893  max mem: 4109
I20241204 09:02:33 2519725 dinov2 helpers.py:102]   [390/634]  eta: 0:15:53    time: 3.956434  data: 0.000692  max mem: 4109
I20241204 09:02:34 2519724 dinov2 helpers.py:102]   [370/634]  eta: 0:17:57    time: 3.960038  data: 0.001366  max mem: 4109
I20241204 09:02:35 2519719 dinov2 helpers.py:102]   [370/634]  eta: 0:17:57    time: 3.962766  data: 0.001074  max mem: 4109
I20241204 09:02:36 2519721 dinov2 helpers.py:102]   [370/634]  eta: 0:17:56    time: 3.954659  data: 0.000888  max mem: 4109
I20241204 09:02:43 2519722 dinov2 helpers.py:102]   [400/634]  eta: 0:14:57    time: 3.957365  data: 0.000973  max mem: 4109
I20241204 09:02:49 2519723 dinov2 helpers.py:102]   [400/634]  eta: 0:15:01    time: 3.960101  data: 0.000921  max mem: 4109
I20241204 09:03:03 2519726 dinov2 helpers.py:102]   [380/634]  eta: 0:17:12    time: 3.957289  data: 0.001604  max mem: 4109
I20241204 09:03:07 2519720 dinov2 helpers.py:102]   [380/634]  eta: 0:17:12    time: 3.957236  data: 0.000956  max mem: 4109
I20241204 09:03:12 2519725 dinov2 helpers.py:102]   [400/634]  eta: 0:15:14    time: 3.954497  data: 0.000760  max mem: 4109
I20241204 09:03:14 2519724 dinov2 helpers.py:102]   [380/634]  eta: 0:17:15    time: 3.959004  data: 0.001184  max mem: 4109
I20241204 09:03:15 2519719 dinov2 helpers.py:102]   [380/634]  eta: 0:17:16    time: 3.961691  data: 0.000770  max mem: 4109
I20241204 09:03:16 2519721 dinov2 helpers.py:102]   [380/634]  eta: 0:17:15    time: 3.954480  data: 0.000785  max mem: 4109
I20241204 09:03:23 2519722 dinov2 helpers.py:102]   [410/634]  eta: 0:14:20    time: 3.957117  data: 0.000965  max mem: 4109
I20241204 09:03:28 2519723 dinov2 helpers.py:102]   [410/634]  eta: 0:14:23    time: 3.959733  data: 0.001320  max mem: 4109
I20241204 09:03:43 2519726 dinov2 helpers.py:102]   [390/634]  eta: 0:16:30    time: 3.956231  data: 0.001215  max mem: 4109
I20241204 09:03:47 2519720 dinov2 helpers.py:102]   [390/634]  eta: 0:16:30    time: 3.958904  data: 0.000817  max mem: 4109
I20241204 09:03:52 2519725 dinov2 helpers.py:102]   [410/634]  eta: 0:14:35    time: 3.956248  data: 0.000703  max mem: 4109
I20241204 09:03:53 2519724 dinov2 helpers.py:102]   [390/634]  eta: 0:16:34    time: 3.956247  data: 0.001667  max mem: 4109
I20241204 09:03:54 2519719 dinov2 helpers.py:102]   [390/634]  eta: 0:16:34    time: 3.957987  data: 0.000686  max mem: 4109
I20241204 09:03:55 2519721 dinov2 helpers.py:102]   [390/634]  eta: 0:16:33    time: 3.959864  data: 0.000793  max mem: 4109
I20241204 09:04:03 2519722 dinov2 helpers.py:102]   [420/634]  eta: 0:13:42    time: 3.960103  data: 0.000875  max mem: 4109
I20241204 09:04:08 2519723 dinov2 helpers.py:102]   [420/634]  eta: 0:13:45    time: 3.955934  data: 0.001455  max mem: 4109
I20241204 09:04:23 2519726 dinov2 helpers.py:102]   [400/634]  eta: 0:15:49    time: 3.957895  data: 0.001279  max mem: 4109
I20241204 09:04:26 2519720 dinov2 helpers.py:102]   [400/634]  eta: 0:15:49    time: 3.959142  data: 0.001035  max mem: 4109
I20241204 09:04:31 2519725 dinov2 helpers.py:102]   [420/634]  eta: 0:13:56    time: 3.958931  data: 0.001711  max mem: 4109
I20241204 09:04:33 2519724 dinov2 helpers.py:102]   [400/634]  eta: 0:15:52    time: 3.958068  data: 0.001804  max mem: 4109
I20241204 09:04:34 2519719 dinov2 helpers.py:102]   [400/634]  eta: 0:15:53    time: 3.957171  data: 0.000901  max mem: 4109
I20241204 09:04:35 2519721 dinov2 helpers.py:102]   [400/634]  eta: 0:15:52    time: 3.961658  data: 0.001472  max mem: 4109
I20241204 09:04:42 2519722 dinov2 helpers.py:102]   [430/634]  eta: 0:13:04    time: 3.956350  data: 0.000766  max mem: 4109
I20241204 09:04:48 2519723 dinov2 helpers.py:102]   [430/634]  eta: 0:13:07    time: 3.956303  data: 0.001143  max mem: 4109
I20241204 09:05:02 2519726 dinov2 helpers.py:102]   [410/634]  eta: 0:15:08    time: 3.957188  data: 0.001629  max mem: 4109
I20241204 09:05:06 2519720 dinov2 helpers.py:102]   [410/634]  eta: 0:15:08    time: 3.954718  data: 0.001005  max mem: 4109
I20241204 09:05:11 2519725 dinov2 helpers.py:102]   [430/634]  eta: 0:13:17    time: 3.961713  data: 0.001792  max mem: 4109
I20241204 09:05:12 2519724 dinov2 helpers.py:102]   [410/634]  eta: 0:15:11    time: 3.957265  data: 0.001146  max mem: 4109
I20241204 09:05:14 2519719 dinov2 helpers.py:102]   [410/634]  eta: 0:15:11    time: 3.962666  data: 0.001126  max mem: 4109
I20241204 09:05:15 2519721 dinov2 helpers.py:102]   [410/634]  eta: 0:15:11    time: 3.957246  data: 0.001430  max mem: 4109
I20241204 09:05:22 2519722 dinov2 helpers.py:102]   [440/634]  eta: 0:12:26    time: 3.955216  data: 0.000687  max mem: 4109
I20241204 09:05:27 2519723 dinov2 helpers.py:102]   [440/634]  eta: 0:12:29    time: 3.959021  data: 0.000799  max mem: 4109
I20241204 09:05:42 2519726 dinov2 helpers.py:102]   [420/634]  eta: 0:14:27    time: 3.957219  data: 0.001568  max mem: 4109
I20241204 09:05:46 2519720 dinov2 helpers.py:102]   [420/634]  eta: 0:14:27    time: 3.954383  data: 0.000919  max mem: 4109
I20241204 09:05:51 2519725 dinov2 helpers.py:102]   [440/634]  eta: 0:12:39    time: 3.959077  data: 0.000833  max mem: 4109
I20241204 09:05:52 2519724 dinov2 helpers.py:102]   [420/634]  eta: 0:14:30    time: 3.955455  data: 0.000870  max mem: 4109
I20241204 09:05:53 2519719 dinov2 helpers.py:102]   [420/634]  eta: 0:14:30    time: 3.963555  data: 0.000959  max mem: 4109
I20241204 09:05:54 2519721 dinov2 helpers.py:102]   [420/634]  eta: 0:14:29    time: 3.954569  data: 0.000808  max mem: 4109
I20241204 09:06:01 2519722 dinov2 helpers.py:102]   [450/634]  eta: 0:11:48    time: 3.956323  data: 0.000647  max mem: 4109
I20241204 09:06:07 2519723 dinov2 helpers.py:102]   [450/634]  eta: 0:11:50    time: 3.958166  data: 0.000619  max mem: 4109
I20241204 09:06:21 2519726 dinov2 helpers.py:102]   [430/634]  eta: 0:13:46    time: 3.958935  data: 0.000997  max mem: 4109
I20241204 09:06:25 2519720 dinov2 helpers.py:102]   [430/634]  eta: 0:13:46    time: 3.956319  data: 0.001145  max mem: 4109
I20241204 09:06:30 2519725 dinov2 helpers.py:102]   [450/634]  eta: 0:12:00    time: 3.956254  data: 0.001095  max mem: 4109
I20241204 09:06:32 2519724 dinov2 helpers.py:102]   [430/634]  eta: 0:13:49    time: 3.956199  data: 0.000887  max mem: 4109
I20241204 09:06:33 2519719 dinov2 helpers.py:102]   [430/634]  eta: 0:13:49    time: 3.958905  data: 0.001062  max mem: 4109
I20241204 09:06:34 2519721 dinov2 helpers.py:102]   [430/634]  eta: 0:13:48    time: 3.954391  data: 0.000868  max mem: 4109
I20241204 09:06:41 2519722 dinov2 helpers.py:102]   [460/634]  eta: 0:11:10    time: 3.956232  data: 0.000691  max mem: 4109
I20241204 09:06:46 2519723 dinov2 helpers.py:102]   [460/634]  eta: 0:11:12    time: 3.956279  data: 0.000771  max mem: 4109
I20241204 09:07:01 2519726 dinov2 helpers.py:102]   [440/634]  eta: 0:13:05    time: 3.956263  data: 0.000783  max mem: 4109
I20241204 09:07:05 2519720 dinov2 helpers.py:102]   [440/634]  eta: 0:13:05    time: 3.956181  data: 0.000982  max mem: 4109
I20241204 09:07:10 2519725 dinov2 helpers.py:102]   [460/634]  eta: 0:11:21    time: 3.956205  data: 0.001112  max mem: 4109
I20241204 09:07:11 2519724 dinov2 helpers.py:102]   [440/634]  eta: 0:13:08    time: 3.957106  data: 0.001434  max mem: 4109
I20241204 09:07:12 2519719 dinov2 helpers.py:102]   [440/634]  eta: 0:13:08    time: 3.957756  data: 0.001246  max mem: 4109
I20241204 09:07:13 2519721 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.955291  data: 0.001173  max mem: 4109
I20241204 09:07:20 2519722 dinov2 helpers.py:102]   [470/634]  eta: 0:10:32    time: 3.956395  data: 0.001654  max mem: 4109
I20241204 09:07:26 2519723 dinov2 helpers.py:102]   [470/634]  eta: 0:10:34    time: 3.957059  data: 0.000692  max mem: 4109
I20241204 09:07:40 2519726 dinov2 helpers.py:102]   [450/634]  eta: 0:12:24    time: 3.954293  data: 0.001102  max mem: 4109
I20241204 09:07:44 2519720 dinov2 helpers.py:102]   [450/634]  eta: 0:12:24    time: 3.954075  data: 0.001242  max mem: 4109
I20241204 09:07:49 2519725 dinov2 helpers.py:102]   [470/634]  eta: 0:10:42    time: 3.954273  data: 0.001487  max mem: 4109
I20241204 09:07:51 2519724 dinov2 helpers.py:102]   [450/634]  eta: 0:12:27    time: 3.958773  data: 0.001402  max mem: 4109
I20241204 09:07:52 2519719 dinov2 helpers.py:102]   [450/634]  eta: 0:12:27    time: 3.955223  data: 0.001080  max mem: 4109
I20241204 09:07:53 2519721 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.954284  data: 0.001590  max mem: 4109
I20241204 09:08:00 2519722 dinov2 helpers.py:102]   [480/634]  eta: 0:09:53    time: 3.954306  data: 0.001624  max mem: 4109
I20241204 09:08:05 2519723 dinov2 helpers.py:102]   [480/634]  eta: 0:09:55    time: 3.953429  data: 0.002074  max mem: 4109
I20241204 09:08:20 2519726 dinov2 helpers.py:102]   [460/634]  eta: 0:11:43    time: 3.954238  data: 0.001276  max mem: 4109
I20241204 09:08:24 2519720 dinov2 helpers.py:102]   [460/634]  eta: 0:11:43    time: 3.954313  data: 0.002133  max mem: 4109
I20241204 09:08:29 2519725 dinov2 helpers.py:102]   [480/634]  eta: 0:10:03    time: 3.954244  data: 0.002180  max mem: 4109
I20241204 09:08:30 2519724 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.957838  data: 0.001167  max mem: 4109
I20241204 09:08:31 2519719 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.956277  data: 0.001408  max mem: 4109
I20241204 09:08:32 2519721 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.952480  data: 0.001436  max mem: 4109
I20241204 09:08:39 2519722 dinov2 helpers.py:102]   [490/634]  eta: 0:09:15    time: 3.953992  data: 0.000589  max mem: 4109
I20241204 09:08:45 2519723 dinov2 helpers.py:102]   [490/634]  eta: 0:09:17    time: 3.952436  data: 0.002191  max mem: 4109
I20241204 09:08:59 2519726 dinov2 helpers.py:102]   [470/634]  eta: 0:11:03    time: 3.953685  data: 0.001209  max mem: 4109
I20241204 09:09:03 2519720 dinov2 helpers.py:102]   [470/634]  eta: 0:11:03    time: 3.954191  data: 0.001731  max mem: 4109
I20241204 09:09:08 2519725 dinov2 helpers.py:102]   [490/634]  eta: 0:09:24    time: 3.954231  data: 0.001676  max mem: 4109
I20241204 09:09:10 2519724 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.954226  data: 0.001602  max mem: 4109
I20241204 09:09:11 2519719 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.955998  data: 0.001329  max mem: 4109
I20241204 09:09:12 2519721 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.954278  data: 0.000948  max mem: 4109
I20241204 09:09:19 2519722 dinov2 helpers.py:102]   [500/634]  eta: 0:08:37    time: 3.954140  data: 0.000553  max mem: 4109
I20241204 09:09:24 2519723 dinov2 helpers.py:102]   [500/634]  eta: 0:08:38    time: 3.953289  data: 0.000817  max mem: 4109
I20241204 09:09:39 2519726 dinov2 helpers.py:102]   [480/634]  eta: 0:10:22    time: 3.954472  data: 0.000992  max mem: 4109
I20241204 09:09:43 2519720 dinov2 helpers.py:102]   [480/634]  eta: 0:10:22    time: 3.954261  data: 0.001566  max mem: 4109
I20241204 09:09:48 2519725 dinov2 helpers.py:102]   [500/634]  eta: 0:08:44    time: 3.954394  data: 0.001024  max mem: 4109
I20241204 09:09:49 2519724 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.955524  data: 0.001380  max mem: 4109
I20241204 09:09:51 2519719 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.954378  data: 0.001233  max mem: 4109
I20241204 09:09:51 2519721 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.956138  data: 0.000680  max mem: 4109
I20241204 09:09:58 2519722 dinov2 helpers.py:102]   [510/634]  eta: 0:07:58    time: 3.951853  data: 0.000819  max mem: 4109
I20241204 09:10:04 2519723 dinov2 helpers.py:102]   [510/634]  eta: 0:08:00    time: 3.955301  data: 0.000954  max mem: 4109
I20241204 09:10:19 2519726 dinov2 helpers.py:102]   [490/634]  eta: 0:09:41    time: 3.957009  data: 0.001174  max mem: 4109
I20241204 09:10:22 2519720 dinov2 helpers.py:102]   [490/634]  eta: 0:09:41    time: 3.954614  data: 0.002563  max mem: 4109
I20241204 09:10:28 2519725 dinov2 helpers.py:102]   [510/634]  eta: 0:08:05    time: 3.957407  data: 0.001358  max mem: 4109
I20241204 09:10:29 2519724 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.958295  data: 0.001291  max mem: 4109
I20241204 09:10:30 2519719 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.957349  data: 0.001034  max mem: 4109
I20241204 09:10:31 2519721 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.956600  data: 0.000785  max mem: 4109
I20241204 09:10:38 2519722 dinov2 helpers.py:102]   [520/634]  eta: 0:07:20    time: 3.952996  data: 0.001547  max mem: 4109
I20241204 09:10:44 2519723 dinov2 helpers.py:102]   [520/634]  eta: 0:07:21    time: 3.957407  data: 0.001107  max mem: 4109
I20241204 09:10:58 2519726 dinov2 helpers.py:102]   [500/634]  eta: 0:09:01    time: 3.955428  data: 0.002192  max mem: 4109
I20241204 09:11:02 2519720 dinov2 helpers.py:102]   [500/634]  eta: 0:09:01    time: 3.954582  data: 0.001713  max mem: 4109
I20241204 09:11:07 2519725 dinov2 helpers.py:102]   [520/634]  eta: 0:07:26    time: 3.955467  data: 0.002507  max mem: 4109
I20241204 09:11:09 2519724 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.957124  data: 0.001860  max mem: 4109
I20241204 09:11:10 2519719 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.957291  data: 0.000516  max mem: 4109
I20241204 09:11:11 2519721 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.955533  data: 0.000979  max mem: 4109
I20241204 09:11:18 2519722 dinov2 helpers.py:102]   [530/634]  eta: 0:06:42    time: 3.955862  data: 0.001414  max mem: 4109
I20241204 09:11:23 2519723 dinov2 helpers.py:102]   [530/634]  eta: 0:06:43    time: 3.956447  data: 0.000884  max mem: 4109
I20241204 09:11:38 2519726 dinov2 helpers.py:102]   [510/634]  eta: 0:08:20    time: 3.954481  data: 0.001756  max mem: 4109
I20241204 09:11:42 2519720 dinov2 helpers.py:102]   [510/634]  eta: 0:08:20    time: 3.956338  data: 0.000676  max mem: 4109
I20241204 09:11:47 2519725 dinov2 helpers.py:102]   [530/634]  eta: 0:06:47    time: 3.954482  data: 0.002176  max mem: 4109
I20241204 09:11:48 2519724 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.956248  data: 0.001519  max mem: 4109
I20241204 09:11:49 2519719 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.955136  data: 0.000579  max mem: 4109
I20241204 09:11:50 2519721 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.955231  data: 0.000925  max mem: 4109
I20241204 09:11:57 2519722 dinov2 helpers.py:102]   [540/634]  eta: 0:06:03    time: 3.956125  data: 0.000803  max mem: 4109
I20241204 09:12:03 2519723 dinov2 helpers.py:102]   [540/634]  eta: 0:06:04    time: 3.954351  data: 0.000866  max mem: 4109
I20241204 09:12:17 2519726 dinov2 helpers.py:102]   [520/634]  eta: 0:07:39    time: 3.956357  data: 0.002196  max mem: 4109
I20241204 09:12:21 2519720 dinov2 helpers.py:102]   [520/634]  eta: 0:07:39    time: 3.955019  data: 0.000875  max mem: 4109
I20241204 09:12:26 2519725 dinov2 helpers.py:102]   [540/634]  eta: 0:06:08    time: 3.957386  data: 0.000931  max mem: 4109
I20241204 09:12:28 2519724 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.960917  data: 0.000998  max mem: 4109
I20241204 09:12:29 2519719 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.954716  data: 0.000728  max mem: 4109
I20241204 09:12:30 2519721 dinov2 helpers.py:102]   [520/634]  eta: 0:07:40    time: 3.954703  data: 0.001039  max mem: 4109
I20241204 09:12:37 2519722 dinov2 helpers.py:102]   [550/634]  eta: 0:05:24    time: 3.954337  data: 0.001000  max mem: 4109
I20241204 09:12:42 2519723 dinov2 helpers.py:102]   [550/634]  eta: 0:05:25    time: 3.954938  data: 0.000824  max mem: 4109
I20241204 09:12:57 2519726 dinov2 helpers.py:102]   [530/634]  eta: 0:06:59    time: 3.955018  data: 0.002372  max mem: 4109
I20241204 09:13:01 2519720 dinov2 helpers.py:102]   [530/634]  eta: 0:06:59    time: 3.953707  data: 0.000759  max mem: 4109
I20241204 09:13:06 2519725 dinov2 helpers.py:102]   [550/634]  eta: 0:05:29    time: 3.959532  data: 0.000912  max mem: 4109
I20241204 09:13:07 2519724 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.961440  data: 0.001630  max mem: 4109
I20241204 09:13:08 2519719 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.957109  data: 0.001057  max mem: 4109
I20241204 09:13:09 2519721 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.955950  data: 0.000899  max mem: 4109
I20241204 09:13:16 2519722 dinov2 helpers.py:102]   [560/634]  eta: 0:04:46    time: 3.955128  data: 0.000897  max mem: 4109
I20241204 09:13:22 2519723 dinov2 helpers.py:102]   [560/634]  eta: 0:04:47    time: 3.955212  data: 0.001670  max mem: 4109
I20241204 09:13:36 2519726 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.953169  data: 0.000978  max mem: 4109
I20241204 09:13:40 2519720 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.954631  data: 0.000643  max mem: 4109
I20241204 09:13:45 2519725 dinov2 helpers.py:102]   [560/634]  eta: 0:04:50    time: 3.957770  data: 0.001828  max mem: 4109
I20241204 09:13:47 2519724 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.959427  data: 0.001594  max mem: 4109
I20241204 09:13:48 2519719 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.955854  data: 0.001148  max mem: 4109
I20241204 09:13:49 2519721 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.957640  data: 0.001534  max mem: 4109
I20241204 09:13:56 2519722 dinov2 helpers.py:102]   [570/634]  eta: 0:04:07    time: 3.954866  data: 0.000948  max mem: 4109
I20241204 09:14:01 2519723 dinov2 helpers.py:102]   [570/634]  eta: 0:04:08    time: 3.952979  data: 0.001952  max mem: 4109
I20241204 09:14:16 2519726 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.954835  data: 0.001305  max mem: 4109
I20241204 09:14:20 2519720 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.954351  data: 0.000661  max mem: 4109
I20241204 09:14:25 2519725 dinov2 helpers.py:102]   [570/634]  eta: 0:04:11    time: 3.958410  data: 0.001784  max mem: 4109
I20241204 09:14:27 2519724 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.962774  data: 0.002365  max mem: 4109
I20241204 09:14:27 2519719 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.955739  data: 0.001237  max mem: 4109
I20241204 09:14:28 2519721 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.954757  data: 0.001810  max mem: 4109
I20241204 09:14:35 2519722 dinov2 helpers.py:102]   [580/634]  eta: 0:03:29    time: 3.954765  data: 0.001047  max mem: 4109
I20241204 09:14:41 2519723 dinov2 helpers.py:102]   [580/634]  eta: 0:03:29    time: 3.954684  data: 0.001023  max mem: 4109
I20241204 09:14:55 2519726 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.954653  data: 0.001438  max mem: 4109
I20241204 09:14:59 2519720 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.954651  data: 0.000735  max mem: 4109
I20241204 09:15:04 2519725 dinov2 helpers.py:102]   [580/634]  eta: 0:03:31    time: 3.957222  data: 0.000982  max mem: 4109
I20241204 09:15:06 2519724 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.959110  data: 0.002226  max mem: 4109
I20241204 09:15:07 2519719 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.957288  data: 0.001604  max mem: 4109
I20241204 09:15:08 2519721 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.954591  data: 0.001205  max mem: 4109
I20241204 09:15:15 2519722 dinov2 helpers.py:102]   [590/634]  eta: 0:02:50    time: 3.954664  data: 0.000956  max mem: 4109
I20241204 09:15:20 2519723 dinov2 helpers.py:102]   [590/634]  eta: 0:02:50    time: 3.955621  data: 0.000910  max mem: 4109
I20241204 09:15:35 2519726 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.954530  data: 0.002114  max mem: 4109
I20241204 09:15:39 2519720 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.954577  data: 0.000841  max mem: 4109
I20241204 09:15:44 2519725 dinov2 helpers.py:102]   [590/634]  eta: 0:02:52    time: 3.955455  data: 0.001080  max mem: 4109
I20241204 09:15:46 2519724 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.954672  data: 0.001005  max mem: 4109
I20241204 09:15:47 2519719 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.954611  data: 0.001573  max mem: 4109
I20241204 09:15:47 2519721 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.954618  data: 0.001201  max mem: 4109
I20241204 09:15:54 2519722 dinov2 helpers.py:102]   [600/634]  eta: 0:02:11    time: 3.955541  data: 0.001008  max mem: 4109
I20241204 09:16:00 2519723 dinov2 helpers.py:102]   [600/634]  eta: 0:02:12    time: 3.960035  data: 0.001063  max mem: 4109
I20241204 09:16:15 2519726 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.954854  data: 0.001996  max mem: 4109
I20241204 09:16:18 2519720 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.955802  data: 0.000866  max mem: 4109
I20241204 09:16:24 2519725 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.962905  data: 0.000969  max mem: 4109
I20241204 09:16:25 2519724 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.956224  data: 0.001142  max mem: 4109
I20241204 09:16:26 2519719 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.954709  data: 0.001305  max mem: 4109
I20241204 09:16:27 2519721 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.953030  data: 0.001449  max mem: 4109
I20241204 09:16:34 2519722 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.955777  data: 0.000907  max mem: 4109
I20241204 09:16:40 2519723 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.959115  data: 0.001328  max mem: 4109
I20241204 09:16:54 2519726 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.954852  data: 0.001077  max mem: 4109
I20241204 09:16:58 2519720 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.955651  data: 0.000948  max mem: 4109
I20241204 09:17:03 2519725 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.960161  data: 0.000781  max mem: 4109
I20241204 09:17:05 2519724 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.958260  data: 0.000947  max mem: 4109
I20241204 09:17:06 2519719 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.958179  data: 0.001069  max mem: 4109
I20241204 09:17:06 2519721 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.955650  data: 0.001519  max mem: 4109
I20241204 09:17:14 2519722 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.955628  data: 0.001120  max mem: 4109
I20241204 09:17:19 2519723 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.955681  data: 0.001331  max mem: 4109
I20241204 09:17:34 2519726 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.956393  data: 0.001173  max mem: 4109
I20241204 09:17:37 2519720 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.955447  data: 0.001925  max mem: 4109
I20241204 09:17:43 2519725 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.955546  data: 0.000859  max mem: 4109
I20241204 09:17:44 2519724 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.955933  data: 0.001055  max mem: 4109
I20241204 09:17:45 2519719 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.958222  data: 0.000650  max mem: 4109
I20241204 09:17:46 2519721 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.956465  data: 0.001265  max mem: 4109
I20241204 09:17:53 2519722 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.957238  data: 0.001380  max mem: 4109
I20241204 09:17:59 2519723 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.955411  data: 0.001489  max mem: 4109
I20241204 09:18:13 2519722 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.336260  data: 0.001331  max mem: 4109
I20241204 09:18:13 2519722 dinov2 helpers.py:130]  Total time: 0:41:07 (3.892559 s / it)
I20241204 09:18:13 2519722 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:18:13 2519722 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:18:13 2519726 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.954865  data: 0.001696  max mem: 4109
I20241204 09:18:14 2519722 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:18:14 2519722 dinov2 loaders.py:151] sampler: distributed
I20241204 09:18:14 2519722 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:18:14 2519722 dinov2 loaders.py:223] # of batches: 78
E20241204 09:18:14 2519722 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:18:17 2519720 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.934494  data: 0.002325  max mem: 4109
I20241204 09:18:18 2519723 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.304642  data: 0.001085  max mem: 4109
I20241204 09:18:18 2519723 dinov2 helpers.py:130]  Total time: 0:41:13 (3.901627 s / it)
I20241204 09:18:18 2519723 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:18:18 2519723 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:18:19 2519723 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:18:19 2519723 dinov2 loaders.py:151] sampler: distributed
I20241204 09:18:19 2519723 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:18:19 2519723 dinov2 loaders.py:223] # of batches: 78
E20241204 09:18:19 2519723 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:18:21 2519725 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.880791  data: 0.001288  max mem: 4109
I20241204 09:18:22 2519724 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.859070  data: 0.000974  max mem: 4109
I20241204 09:18:23 2519719 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.851496  data: 0.000469  max mem: 4109
I20241204 09:18:23 2519721 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.839916  data: 0.001338  max mem: 4109
I20241204 09:18:35 2519725 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.013235  data: 0.001091  max mem: 4109
I20241204 09:18:36 2519725 dinov2 helpers.py:130]  Total time: 0:41:30 (3.928285 s / it)
I20241204 09:18:36 2519725 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:18:36 2519725 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:18:36 2519725 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:18:36 2519725 dinov2 loaders.py:151] sampler: distributed
I20241204 09:18:36 2519725 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:18:36 2519725 dinov2 loaders.py:223] # of batches: 78
E20241204 09:18:36 2519725 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:18:42 2519726 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.440023  data: 0.001419  max mem: 4109
I20241204 09:18:45 2519720 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.366409  data: 0.002220  max mem: 4109
I20241204 09:18:49 2519724 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.239907  data: 0.000704  max mem: 4109
I20241204 09:18:50 2519719 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.221936  data: 0.002257  max mem: 4109
I20241204 09:18:50 2519721 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.207225  data: 0.001060  max mem: 4109
I20241204 09:19:07 2519726 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.699271  data: 0.000630  max mem: 4109
I20241204 09:19:10 2519720 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.646377  data: 0.001610  max mem: 4109
I20241204 09:19:14 2519724 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.592086  data: 0.000585  max mem: 4109
I20241204 09:19:14 2519719 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.584553  data: 0.002284  max mem: 4109
I20241204 09:19:15 2519721 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.580551  data: 0.000667  max mem: 4109
I20241204 09:19:19 2519726 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.816904  data: 0.000605  max mem: 4109
I20241204 09:19:19 2519726 dinov2 helpers.py:130]  Total time: 0:42:04 (3.981278 s / it)
I20241204 09:19:19 2519726 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:19:19 2519726 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:19:20 2519726 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:19:20 2519726 dinov2 loaders.py:151] sampler: distributed
I20241204 09:19:20 2519726 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:19:20 2519726 dinov2 loaders.py:223] # of batches: 78
E20241204 09:19:20 2519726 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:19:21 2519720 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.777339  data: 0.000498  max mem: 4109
I20241204 09:19:22 2519720 dinov2 helpers.py:130]  Total time: 0:42:02 (3.978678 s / it)
I20241204 09:19:22 2519720 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:19:22 2519720 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:19:22 2519720 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:19:22 2519720 dinov2 loaders.py:151] sampler: distributed
I20241204 09:19:22 2519720 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:19:22 2519720 dinov2 loaders.py:223] # of batches: 78
E20241204 09:19:22 2519720 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:19:24 2519724 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.651591  data: 0.000511  max mem: 4109
I20241204 09:19:24 2519724 dinov2 helpers.py:130]  Total time: 0:42:04 (3.981964 s / it)
I20241204 09:19:24 2519724 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:19:24 2519724 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:19:24 2519719 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.633176  data: 0.001281  max mem: 4109
I20241204 09:19:24 2519724 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:19:24 2519724 dinov2 loaders.py:151] sampler: distributed
I20241204 09:19:24 2519724 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:19:24 2519724 dinov2 loaders.py:223] # of batches: 78
E20241204 09:19:24 2519724 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:19:25 2519719 dinov2 helpers.py:130]  Total time: 0:42:04 (3.981576 s / it)
I20241204 09:19:25 2519719 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:19:25 2519719 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:19:25 2519719 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:19:25 2519719 dinov2 loaders.py:151] sampler: distributed
I20241204 09:19:25 2519719 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:19:25 2519719 dinov2 loaders.py:223] # of batches: 78
E20241204 09:19:25 2519719 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:19:25 2519721 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.642664  data: 0.000596  max mem: 4109
I20241204 09:19:25 2519721 dinov2 helpers.py:130]  Total time: 0:42:02 (3.978483 s / it)
I20241204 09:19:25 2519721 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 09:19:25 2519721 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 09:19:25 2519721 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 09:19:25 2519721 dinov2 loaders.py:151] sampler: distributed
I20241204 09:19:25 2519721 dinov2 loaders.py:210] using PyTorch data loader
I20241204 09:19:25 2519721 dinov2 loaders.py:223] # of batches: 78
E20241204 09:19:25 2519721 submitit submission.py:68] Submitted job triggered an exception
I20241204 09:27:36 2542583 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:36 2542583 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:36 2542583 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:36 2542583 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:36 2542581 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:36 2542581 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:36 2542581 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:36 2542581 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:36 2542583 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:36 2542581 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:36 2542578 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:36 2542578 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:36 2542578 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:36 2542578 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:36 2542578 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:36 2542580 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:36 2542580 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:36 2542580 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:36 2542580 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:36 2542580 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:37 2542579 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:37 2542579 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:37 2542579 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:37 2542579 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:37 2542584 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:37 2542584 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:37 2542584 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:37 2542584 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:37 2542579 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:37 2542585 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:37 2542585 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:37 2542585 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:37 2542585 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:37 2542584 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:37 2542585 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:27:37 2542582 dinov2 config.py:59] git:
  sha: 4c4cfbb972cf0b759288a3e90703e8753dba7c6a, status: has uncommitted changes, branch: main

I20241204 09:27:37 2542582 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_12499/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241204 09:27:37 2542582 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241204 09:27:37 2542582 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_12499/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241204 09:27:37 2542582 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241204 09:28:06 2542581 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:06 2542583 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:07 2542585 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:10 2542581 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:10 2542583 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:10 2542581 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:10 2542583 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:10 2542585 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:11 2542585 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:12 2542579 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:12 2542580 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:12 2542578 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:12 2542584 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:13 2542582 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241204 09:28:16 2542584 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:16 2542583 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:16 2542583 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:16 2542584 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:16 2542581 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:16 2542581 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:16 2542579 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:17 2542585 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:17 2542585 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:17 2542580 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:17 2542579 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:17 2542578 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:17 2542580 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:17 2542578 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:18 2542582 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_12499/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241204 09:28:18 2542582 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241204 09:28:18 2542583 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:18 2542583 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:18 2542583 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:18 2542583 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:18 2542583 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:18 2542583 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:19 2542581 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:19 2542581 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:19 2542581 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:19 2542581 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:19 2542581 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:19 2542581 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:21 2542585 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:21 2542585 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:21 2542585 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:21 2542585 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:21 2542585 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:21 2542585 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:28 2542578 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:28 2542578 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:29 2542582 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:29 2542582 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:29 2542584 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:29 2542584 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:31 2542579 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:31 2542579 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:32 2542580 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241204 09:28:32 2542580 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241204 09:28:32 2542578 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:32 2542578 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:32 2542578 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:32 2542578 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:32 2542578 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:32 2542578 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:32 2542584 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:32 2542584 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:32 2542584 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:32 2542584 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:32 2542584 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:32 2542584 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:34 2542582 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:34 2542582 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:34 2542582 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:34 2542582 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:34 2542582 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:34 2542582 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:37 2542580 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:37 2542580 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:37 2542580 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:37 2542580 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:37 2542580 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:37 2542580 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:37 2542579 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241204 09:28:37 2542579 dinov2 knn.py:260] Extracting features for train set...
I20241204 09:28:37 2542579 dinov2 loaders.py:151] sampler: distributed
I20241204 09:28:37 2542579 dinov2 loaders.py:210] using PyTorch data loader
W20241204 09:28:37 2542579 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241204 09:28:37 2542579 dinov2 loaders.py:223] # of batches: 634
I20241204 09:28:49 2542583 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:28:49 2542583 dinov2 helpers.py:102]   [  0/634]  eta: 5:26:54    time: 30.937246  data: 12.085441  max mem: 3463
I20241204 09:28:53 2542581 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:28:53 2542581 dinov2 helpers.py:102]   [  0/634]  eta: 5:56:31    time: 33.741253  data: 12.525873  max mem: 3463
I20241204 09:28:54 2542583 dinov2 helpers.py:102]   [ 10/634]  eta: 0:33:20    time: 3.206051  data: 1.101923  max mem: 4109
I20241204 09:29:00 2542585 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:00 2542585 dinov2 helpers.py:102]   [  0/634]  eta: 7:01:06    time: 39.853306  data: 11.662855  max mem: 3463
I20241204 09:29:01 2542581 dinov2 helpers.py:102]   [ 10/634]  eta: 0:39:56    time: 3.839883  data: 1.143331  max mem: 4109
I20241204 09:29:05 2542583 dinov2 helpers.py:102]   [ 20/634]  eta: 0:22:52    time: 0.799965  data: 0.230902  max mem: 4109
I20241204 09:29:13 2542585 dinov2 helpers.py:102]   [ 10/634]  eta: 0:49:20    time: 4.744048  data: 1.062105  max mem: 4109
I20241204 09:29:16 2542581 dinov2 helpers.py:102]   [ 20/634]  eta: 0:27:52    time: 1.173089  data: 0.003153  max mem: 4109
I20241204 09:29:20 2542583 dinov2 helpers.py:102]   [ 30/634]  eta: 0:20:06    time: 1.333365  data: 0.229320  max mem: 4109
I20241204 09:29:22 2542582 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:22 2542582 dinov2 helpers.py:102]   [  0/634]  eta: 8:28:55    time: 48.163261  data: 11.113194  max mem: 3463
I20241204 09:29:23 2542584 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:23 2542584 dinov2 helpers.py:102]   [  0/634]  eta: 8:57:19    time: 50.850861  data: 15.873216  max mem: 3463
I20241204 09:29:26 2542578 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:26 2542578 dinov2 helpers.py:102]   [  0/634]  eta: 9:31:58    time: 54.129700  data: 16.126030  max mem: 3463
I20241204 09:29:27 2542580 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:27 2542580 dinov2 helpers.py:102]   [  0/634]  eta: 8:52:39    time: 50.409206  data: 10.497227  max mem: 3464
I20241204 09:29:31 2542579 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241204 09:29:31 2542579 dinov2 helpers.py:102]   [  0/634]  eta: 9:24:51    time: 53.456341  data: 13.724692  max mem: 3463
I20241204 09:29:35 2542585 dinov2 helpers.py:102]   [ 20/634]  eta: 0:36:01    time: 1.703644  data: 0.001380  max mem: 4109
I20241204 09:29:44 2542581 dinov2 helpers.py:102]   [ 30/634]  eta: 0:27:32    time: 2.127627  data: 0.000965  max mem: 4109
I20241204 09:29:51 2542582 dinov2 helpers.py:102]   [ 10/634]  eta: 1:13:13    time: 7.040928  data: 1.013548  max mem: 4109
I20241204 09:29:53 2542584 dinov2 helpers.py:102]   [ 10/634]  eta: 1:16:27    time: 7.351701  data: 1.448629  max mem: 4109
I20241204 09:29:54 2542583 dinov2 helpers.py:102]   [ 40/634]  eta: 0:23:08    time: 2.444503  data: 0.000831  max mem: 4109
I20241204 09:29:58 2542578 dinov2 helpers.py:102]   [ 10/634]  eta: 1:21:10    time: 7.804709  data: 1.467992  max mem: 4109
I20241204 09:29:59 2542580 dinov2 helpers.py:102]   [ 10/634]  eta: 1:17:56    time: 7.494479  data: 0.954772  max mem: 4109
I20241204 09:30:03 2542579 dinov2 helpers.py:102]   [ 10/634]  eta: 1:20:58    time: 7.785364  data: 1.249971  max mem: 4109
I20241204 09:30:14 2542585 dinov2 helpers.py:102]   [ 30/634]  eta: 0:36:44    time: 3.047681  data: 0.000896  max mem: 4109
I20241204 09:30:23 2542581 dinov2 helpers.py:102]   [ 40/634]  eta: 0:29:58    time: 3.347573  data: 0.001507  max mem: 4109
I20241204 09:30:31 2542582 dinov2 helpers.py:102]   [ 20/634]  eta: 0:56:56    time: 3.434427  data: 0.002736  max mem: 4109
I20241204 09:30:33 2542584 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:37    time: 3.472946  data: 0.003611  max mem: 4109
I20241204 09:30:34 2542583 dinov2 helpers.py:102]   [ 50/634]  eta: 0:25:49    time: 3.668434  data: 0.001595  max mem: 4109
I20241204 09:30:38 2542578 dinov2 helpers.py:102]   [ 20/634]  eta: 1:01:03    time: 3.559235  data: 0.002358  max mem: 4109
I20241204 09:30:39 2542580 dinov2 helpers.py:102]   [ 20/634]  eta: 0:59:26    time: 3.579020  data: 0.000577  max mem: 4109
I20241204 09:30:42 2542579 dinov2 helpers.py:102]   [ 20/634]  eta: 1:00:58    time: 3.582774  data: 0.001683  max mem: 4109
I20241204 09:30:53 2542585 dinov2 helpers.py:102]   [ 40/634]  eta: 0:36:51    time: 3.935811  data: 0.000780  max mem: 4109
I20241204 09:31:03 2542581 dinov2 helpers.py:102]   [ 50/634]  eta: 0:31:14    time: 3.944906  data: 0.001782  max mem: 4109
I20241204 09:31:10 2542582 dinov2 helpers.py:102]   [ 30/634]  eta: 0:50:46    time: 3.946702  data: 0.001377  max mem: 4109
I20241204 09:31:12 2542584 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:56    time: 3.954845  data: 0.000916  max mem: 4109
I20241204 09:31:13 2542583 dinov2 helpers.py:102]   [ 60/634]  eta: 0:27:25    time: 3.954778  data: 0.001685  max mem: 4109
I20241204 09:31:17 2542578 dinov2 helpers.py:102]   [ 30/634]  eta: 0:53:32    time: 3.952178  data: 0.002630  max mem: 4109
I20241204 09:31:19 2542580 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:30    time: 3.963911  data: 0.000760  max mem: 4109
I20241204 09:31:22 2542579 dinov2 helpers.py:102]   [ 30/634]  eta: 0:53:29    time: 3.953817  data: 0.000781  max mem: 4109
I20241204 09:31:33 2542585 dinov2 helpers.py:102]   [ 50/634]  eta: 0:36:41    time: 3.956609  data: 0.000564  max mem: 4109
I20241204 09:31:43 2542581 dinov2 helpers.py:102]   [ 60/634]  eta: 0:31:53    time: 3.958396  data: 0.001022  max mem: 4109
I20241204 09:31:50 2542582 dinov2 helpers.py:102]   [ 40/634]  eta: 0:47:20    time: 3.961096  data: 0.000774  max mem: 4109
I20241204 09:31:52 2542584 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:12    time: 3.967388  data: 0.002724  max mem: 4109
I20241204 09:31:53 2542583 dinov2 helpers.py:102]   [ 70/634]  eta: 0:28:25    time: 3.967384  data: 0.001237  max mem: 4109
I20241204 09:31:57 2542578 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:24    time: 3.965561  data: 0.002836  max mem: 4109
I20241204 09:31:58 2542580 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:39    time: 3.974757  data: 0.000862  max mem: 4109
I20241204 09:32:02 2542579 dinov2 helpers.py:102]   [ 40/634]  eta: 0:49:21    time: 3.966787  data: 0.000781  max mem: 4109
I20241204 09:32:13 2542585 dinov2 helpers.py:102]   [ 60/634]  eta: 0:36:23    time: 3.968067  data: 0.001009  max mem: 4109
I20241204 09:32:22 2542581 dinov2 helpers.py:102]   [ 70/634]  eta: 0:32:10    time: 3.968413  data: 0.000970  max mem: 4109
I20241204 09:32:30 2542582 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:00    time: 3.972029  data: 0.001443  max mem: 4109
I20241204 09:32:32 2542584 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:41    time: 3.971378  data: 0.002759  max mem: 4109
I20241204 09:32:33 2542583 dinov2 helpers.py:102]   [ 80/634]  eta: 0:28:59    time: 3.974099  data: 0.000964  max mem: 4109
I20241204 09:32:37 2542578 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:38    time: 3.973274  data: 0.001868  max mem: 4109
I20241204 09:32:38 2542580 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:02    time: 3.976905  data: 0.000847  max mem: 4109
I20241204 09:32:41 2542579 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:36    time: 3.973326  data: 0.000845  max mem: 4109
I20241204 09:32:52 2542585 dinov2 helpers.py:102]   [ 70/634]  eta: 0:35:58    time: 3.973529  data: 0.000986  max mem: 4109
I20241204 09:33:02 2542581 dinov2 helpers.py:102]   [ 80/634]  eta: 0:32:14    time: 3.974436  data: 0.001012  max mem: 4109
I20241204 09:33:09 2542582 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:12    time: 3.974362  data: 0.001509  max mem: 4109
I20241204 09:33:11 2542584 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:46    time: 3.975402  data: 0.001007  max mem: 4109
I20241204 09:33:12 2542583 dinov2 helpers.py:102]   [ 90/634]  eta: 0:29:18    time: 3.974520  data: 0.000948  max mem: 4109
I20241204 09:33:16 2542578 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:33    time: 3.975695  data: 0.000699  max mem: 4109
I20241204 09:33:18 2542580 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:05    time: 3.982545  data: 0.001204  max mem: 4109
I20241204 09:33:21 2542579 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:31    time: 3.973631  data: 0.001570  max mem: 4109
I20241204 09:33:32 2542585 dinov2 helpers.py:102]   [ 80/634]  eta: 0:35:30    time: 3.975595  data: 0.000723  max mem: 4109
I20241204 09:33:42 2542581 dinov2 helpers.py:102]   [ 90/634]  eta: 0:32:08    time: 3.975685  data: 0.000984  max mem: 4109
I20241204 09:33:49 2542582 dinov2 helpers.py:102]   [ 70/634]  eta: 0:41:45    time: 3.976611  data: 0.001007  max mem: 4109
I20241204 09:33:51 2542584 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:13    time: 3.978405  data: 0.001452  max mem: 4109
I20241204 09:33:52 2542583 dinov2 helpers.py:102]   [100/634]  eta: 0:29:25    time: 3.974000  data: 0.001016  max mem: 4109
I20241204 09:33:56 2542578 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:53    time: 3.979377  data: 0.000925  max mem: 4109
I20241204 09:33:58 2542580 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:30    time: 3.991944  data: 0.001179  max mem: 4109
I20241204 09:34:01 2542579 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:51    time: 3.976729  data: 0.001737  max mem: 4109
I20241204 09:34:12 2542585 dinov2 helpers.py:102]   [ 90/634]  eta: 0:35:00    time: 3.978613  data: 0.000709  max mem: 4109
I20241204 09:34:22 2542581 dinov2 helpers.py:102]   [100/634]  eta: 0:31:55    time: 3.978486  data: 0.001578  max mem: 4109
I20241204 09:34:29 2542582 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:28    time: 3.977610  data: 0.001161  max mem: 4109
I20241204 09:34:31 2542584 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:53    time: 3.978591  data: 0.001151  max mem: 4109
I20241204 09:34:32 2542583 dinov2 helpers.py:102]   [110/634]  eta: 0:29:24    time: 3.977572  data: 0.000864  max mem: 4109
I20241204 09:34:36 2542578 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:27    time: 3.979066  data: 0.001279  max mem: 4109
I20241204 09:34:38 2542580 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:08    time: 3.992026  data: 0.000822  max mem: 4109
I20241204 09:34:41 2542579 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:25    time: 3.977600  data: 0.001157  max mem: 4109
I20241204 09:34:52 2542585 dinov2 helpers.py:102]   [100/634]  eta: 0:34:27    time: 3.977503  data: 0.001031  max mem: 4109
I20241204 09:35:01 2542581 dinov2 helpers.py:102]   [110/634]  eta: 0:31:38    time: 3.979213  data: 0.001513  max mem: 4109
I20241204 09:35:09 2542582 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:20    time: 3.976577  data: 0.001059  max mem: 4109
I20241204 09:35:11 2542584 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:42    time: 3.979308  data: 0.000545  max mem: 4109
I20241204 09:35:12 2542583 dinov2 helpers.py:102]   [120/634]  eta: 0:29:16    time: 3.981916  data: 0.000917  max mem: 4109
I20241204 09:35:16 2542578 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:11    time: 3.975611  data: 0.000944  max mem: 4109
I20241204 09:35:18 2542580 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:56    time: 3.989964  data: 0.001651  max mem: 4109
I20241204 09:35:21 2542579 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:10    time: 3.976549  data: 0.001114  max mem: 4109
I20241204 09:35:31 2542585 dinov2 helpers.py:102]   [110/634]  eta: 0:33:53    time: 3.976423  data: 0.001386  max mem: 4109
I20241204 09:35:41 2542581 dinov2 helpers.py:102]   [120/634]  eta: 0:31:17    time: 3.975744  data: 0.000850  max mem: 4109
I20241204 09:35:48 2542582 dinov2 helpers.py:102]   [100/634]  eta: 0:38:17    time: 3.975834  data: 0.001127  max mem: 4109
I20241204 09:35:51 2542584 dinov2 helpers.py:102]   [100/634]  eta: 0:38:37    time: 3.980217  data: 0.000873  max mem: 4109
I20241204 09:35:52 2542583 dinov2 helpers.py:102]   [130/634]  eta: 0:29:03    time: 3.978565  data: 0.001098  max mem: 4109
I20241204 09:35:55 2542578 dinov2 helpers.py:102]   [100/634]  eta: 0:39:03    time: 3.975856  data: 0.000601  max mem: 4109
I20241204 09:35:58 2542580 dinov2 helpers.py:102]   [100/634]  eta: 0:38:50    time: 3.991069  data: 0.002467  max mem: 4109
I20241204 09:36:00 2542579 dinov2 helpers.py:102]   [100/634]  eta: 0:39:02    time: 3.976124  data: 0.001174  max mem: 4109
I20241204 09:36:11 2542585 dinov2 helpers.py:102]   [120/634]  eta: 0:33:19    time: 3.975883  data: 0.001074  max mem: 4109
I20241204 09:36:21 2542581 dinov2 helpers.py:102]   [130/634]  eta: 0:30:53    time: 3.974116  data: 0.000784  max mem: 4109
I20241204 09:36:28 2542582 dinov2 helpers.py:102]   [110/634]  eta: 0:37:19    time: 3.974128  data: 0.001369  max mem: 4109
I20241204 09:36:30 2542584 dinov2 helpers.py:102]   [110/634]  eta: 0:37:36    time: 3.976819  data: 0.001252  max mem: 4109
I20241204 09:36:31 2542583 dinov2 helpers.py:102]   [140/634]  eta: 0:28:47    time: 3.975969  data: 0.001172  max mem: 4109
I20241204 09:36:35 2542578 dinov2 helpers.py:102]   [110/634]  eta: 0:38:00    time: 3.976833  data: 0.000797  max mem: 4109
I20241204 09:36:38 2542580 dinov2 helpers.py:102]   [110/634]  eta: 0:37:49    time: 3.991280  data: 0.002294  max mem: 4109
I20241204 09:36:40 2542579 dinov2 helpers.py:102]   [110/634]  eta: 0:37:58    time: 3.974236  data: 0.001291  max mem: 4109
I20241204 09:36:51 2542585 dinov2 helpers.py:102]   [130/634]  eta: 0:32:43    time: 3.974144  data: 0.000908  max mem: 4109
I20241204 09:37:01 2542581 dinov2 helpers.py:102]   [140/634]  eta: 0:30:26    time: 3.974211  data: 0.000723  max mem: 4109
I20241204 09:37:08 2542582 dinov2 helpers.py:102]   [120/634]  eta: 0:36:24    time: 3.975924  data: 0.002050  max mem: 4109
I20241204 09:37:10 2542584 dinov2 helpers.py:102]   [120/634]  eta: 0:36:39    time: 3.976840  data: 0.002649  max mem: 4109
I20241204 09:37:11 2542583 dinov2 helpers.py:102]   [150/634]  eta: 0:28:27    time: 3.976804  data: 0.001098  max mem: 4109
I20241204 09:37:15 2542578 dinov2 helpers.py:102]   [120/634]  eta: 0:37:00    time: 3.976061  data: 0.001176  max mem: 4109
I20241204 09:37:18 2542580 dinov2 helpers.py:102]   [120/634]  eta: 0:36:51    time: 3.991227  data: 0.001956  max mem: 4109
I20241204 09:37:20 2542579 dinov2 helpers.py:102]   [120/634]  eta: 0:36:59    time: 3.975541  data: 0.001244  max mem: 4109
I20241204 09:37:31 2542585 dinov2 helpers.py:102]   [140/634]  eta: 0:32:07    time: 3.974084  data: 0.000792  max mem: 4109
I20241204 09:37:40 2542581 dinov2 helpers.py:102]   [150/634]  eta: 0:29:58    time: 3.978561  data: 0.000796  max mem: 4109
I20241204 09:37:48 2542582 dinov2 helpers.py:102]   [130/634]  eta: 0:35:31    time: 3.977749  data: 0.002833  max mem: 4109
I20241204 09:37:50 2542584 dinov2 helpers.py:102]   [130/634]  eta: 0:35:45    time: 3.978547  data: 0.002333  max mem: 4109
I20241204 09:37:51 2542583 dinov2 helpers.py:102]   [160/634]  eta: 0:28:05    time: 3.976751  data: 0.000953  max mem: 4109
I20241204 09:37:55 2542578 dinov2 helpers.py:102]   [130/634]  eta: 0:36:04    time: 3.975855  data: 0.001123  max mem: 4109
I20241204 09:37:58 2542580 dinov2 helpers.py:102]   [130/634]  eta: 0:35:56    time: 3.991971  data: 0.001719  max mem: 4109
I20241204 09:38:00 2542579 dinov2 helpers.py:102]   [130/634]  eta: 0:36:03    time: 3.978371  data: 0.000894  max mem: 4109
I20241204 09:38:10 2542585 dinov2 helpers.py:102]   [150/634]  eta: 0:31:30    time: 3.975875  data: 0.001774  max mem: 4109
I20241204 09:38:20 2542581 dinov2 helpers.py:102]   [160/634]  eta: 0:29:29    time: 3.978760  data: 0.000754  max mem: 4109
I20241204 09:38:28 2542582 dinov2 helpers.py:102]   [140/634]  eta: 0:34:40    time: 3.979539  data: 0.002039  max mem: 4109
I20241204 09:38:30 2542584 dinov2 helpers.py:102]   [140/634]  eta: 0:34:53    time: 3.975874  data: 0.000722  max mem: 4109
I20241204 09:38:31 2542583 dinov2 helpers.py:102]   [170/634]  eta: 0:27:41    time: 3.979522  data: 0.001342  max mem: 4109
I20241204 09:38:35 2542578 dinov2 helpers.py:102]   [140/634]  eta: 0:35:10    time: 3.978134  data: 0.000893  max mem: 4109
I20241204 09:38:37 2542580 dinov2 helpers.py:102]   [140/634]  eta: 0:35:03    time: 3.992374  data: 0.001253  max mem: 4109
I20241204 09:38:39 2542579 dinov2 helpers.py:102]   [140/634]  eta: 0:35:09    time: 3.979488  data: 0.000790  max mem: 4109
I20241204 09:38:50 2542585 dinov2 helpers.py:102]   [160/634]  eta: 0:30:53    time: 3.978681  data: 0.002328  max mem: 4109
I20241204 09:39:00 2542581 dinov2 helpers.py:102]   [170/634]  eta: 0:28:58    time: 3.974284  data: 0.000630  max mem: 4109
I20241204 09:39:07 2542582 dinov2 helpers.py:102]   [150/634]  eta: 0:33:50    time: 3.979553  data: 0.001927  max mem: 4109
I20241204 09:39:10 2542584 dinov2 helpers.py:102]   [150/634]  eta: 0:34:02    time: 3.979668  data: 0.000881  max mem: 4109
I20241204 09:39:11 2542583 dinov2 helpers.py:102]   [180/634]  eta: 0:27:15    time: 3.979581  data: 0.001277  max mem: 4109
I20241204 09:39:14 2542578 dinov2 helpers.py:102]   [150/634]  eta: 0:34:18    time: 3.979712  data: 0.000741  max mem: 4109
I20241204 09:39:17 2542580 dinov2 helpers.py:102]   [150/634]  eta: 0:34:12    time: 3.993483  data: 0.000886  max mem: 4109
I20241204 09:39:19 2542579 dinov2 helpers.py:102]   [150/634]  eta: 0:34:17    time: 3.977064  data: 0.001256  max mem: 4109
I20241204 09:39:30 2542585 dinov2 helpers.py:102]   [170/634]  eta: 0:30:16    time: 3.979636  data: 0.001296  max mem: 4109
I20241204 09:39:40 2542581 dinov2 helpers.py:102]   [180/634]  eta: 0:28:26    time: 3.977727  data: 0.001537  max mem: 4109
I20241204 09:39:47 2542582 dinov2 helpers.py:102]   [160/634]  eta: 0:33:02    time: 3.978676  data: 0.001907  max mem: 4109
I20241204 09:39:49 2542584 dinov2 helpers.py:102]   [160/634]  eta: 0:33:13    time: 3.981415  data: 0.001871  max mem: 4109
I20241204 09:39:50 2542583 dinov2 helpers.py:102]   [190/634]  eta: 0:26:48    time: 3.978845  data: 0.000887  max mem: 4109
I20241204 09:39:54 2542578 dinov2 helpers.py:102]   [160/634]  eta: 0:33:27    time: 3.979919  data: 0.001061  max mem: 4109
I20241204 09:39:57 2542580 dinov2 helpers.py:102]   [160/634]  eta: 0:33:22    time: 3.991879  data: 0.000861  max mem: 4109
I20241204 09:39:59 2542579 dinov2 helpers.py:102]   [160/634]  eta: 0:33:26    time: 3.976081  data: 0.001139  max mem: 4109
I20241204 09:40:10 2542585 dinov2 helpers.py:102]   [180/634]  eta: 0:29:38    time: 3.976896  data: 0.000799  max mem: 4109
I20241204 09:40:19 2542581 dinov2 helpers.py:102]   [190/634]  eta: 0:27:54    time: 3.979551  data: 0.001507  max mem: 4109
I20241204 09:40:27 2542582 dinov2 helpers.py:102]   [170/634]  eta: 0:32:14    time: 3.977771  data: 0.001019  max mem: 4109
I20241204 09:40:29 2542584 dinov2 helpers.py:102]   [170/634]  eta: 0:32:25    time: 3.981269  data: 0.001850  max mem: 4109
I20241204 09:40:30 2542583 dinov2 helpers.py:102]   [200/634]  eta: 0:26:20    time: 3.979687  data: 0.001026  max mem: 4109
I20241204 09:40:34 2542578 dinov2 helpers.py:102]   [170/634]  eta: 0:32:38    time: 3.980466  data: 0.002253  max mem: 4109
I20241204 09:40:37 2542580 dinov2 helpers.py:102]   [170/634]  eta: 0:32:34    time: 3.992657  data: 0.001148  max mem: 4109
I20241204 09:40:39 2542579 dinov2 helpers.py:102]   [170/634]  eta: 0:32:37    time: 3.977816  data: 0.000901  max mem: 4109
I20241204 09:40:50 2542585 dinov2 helpers.py:102]   [190/634]  eta: 0:29:01    time: 3.978723  data: 0.000822  max mem: 4109
I20241204 09:40:59 2542581 dinov2 helpers.py:102]   [200/634]  eta: 0:27:21    time: 3.978580  data: 0.000638  max mem: 4109
I20241204 09:41:07 2542582 dinov2 helpers.py:102]   [180/634]  eta: 0:31:28    time: 3.979604  data: 0.000942  max mem: 4109
I20241204 09:41:09 2542584 dinov2 helpers.py:102]   [180/634]  eta: 0:31:38    time: 3.984981  data: 0.002298  max mem: 4109
I20241204 09:41:10 2542583 dinov2 helpers.py:102]   [210/634]  eta: 0:25:50    time: 3.979561  data: 0.001378  max mem: 4109
I20241204 09:41:14 2542578 dinov2 helpers.py:102]   [180/634]  eta: 0:31:50    time: 3.978736  data: 0.001791  max mem: 4109
I20241204 09:41:17 2542580 dinov2 helpers.py:102]   [180/634]  eta: 0:31:46    time: 3.994965  data: 0.001168  max mem: 4109
I20241204 09:41:18 2542579 dinov2 helpers.py:102]   [180/634]  eta: 0:31:49    time: 3.979699  data: 0.000901  max mem: 4109
I20241204 09:41:29 2542585 dinov2 helpers.py:102]   [200/634]  eta: 0:28:23    time: 3.983239  data: 0.000913  max mem: 4109
I20241204 09:41:39 2542581 dinov2 helpers.py:102]   [210/634]  eta: 0:26:47    time: 3.979567  data: 0.000620  max mem: 4109
I20241204 09:41:47 2542582 dinov2 helpers.py:102]   [190/634]  eta: 0:30:42    time: 3.984986  data: 0.000870  max mem: 4109
I20241204 09:41:49 2542584 dinov2 helpers.py:102]   [190/634]  eta: 0:30:51    time: 3.985096  data: 0.002448  max mem: 4109
I20241204 09:41:50 2542583 dinov2 helpers.py:102]   [220/634]  eta: 0:25:20    time: 3.983114  data: 0.001149  max mem: 4109
I20241204 09:41:54 2542578 dinov2 helpers.py:102]   [190/634]  eta: 0:31:02    time: 3.980482  data: 0.000850  max mem: 4109
I20241204 09:41:57 2542580 dinov2 helpers.py:102]   [190/634]  eta: 0:31:00    time: 3.993215  data: 0.000802  max mem: 4109
I20241204 09:41:58 2542579 dinov2 helpers.py:102]   [190/634]  eta: 0:31:02    time: 3.981290  data: 0.000760  max mem: 4109
I20241204 09:42:09 2542585 dinov2 helpers.py:102]   [210/634]  eta: 0:27:45    time: 3.985050  data: 0.000739  max mem: 4109
I20241204 09:42:19 2542581 dinov2 helpers.py:102]   [220/634]  eta: 0:26:12    time: 3.979651  data: 0.001181  max mem: 4109
I20241204 09:42:26 2542582 dinov2 helpers.py:102]   [200/634]  eta: 0:29:57    time: 3.983215  data: 0.002160  max mem: 4109
I20241204 09:42:29 2542584 dinov2 helpers.py:102]   [200/634]  eta: 0:30:06    time: 3.985033  data: 0.001013  max mem: 4109
I20241204 09:42:30 2542583 dinov2 helpers.py:102]   [230/634]  eta: 0:24:48    time: 3.984893  data: 0.000663  max mem: 4109
I20241204 09:42:33 2542578 dinov2 helpers.py:102]   [200/634]  eta: 0:30:16    time: 3.985078  data: 0.000998  max mem: 4109
I20241204 09:42:37 2542580 dinov2 helpers.py:102]   [200/634]  eta: 0:30:13    time: 3.993109  data: 0.000660  max mem: 4109
I20241204 09:42:38 2542579 dinov2 helpers.py:102]   [200/634]  eta: 0:30:15    time: 3.977808  data: 0.000681  max mem: 4109
I20241204 09:42:49 2542585 dinov2 helpers.py:102]   [220/634]  eta: 0:27:07    time: 3.985099  data: 0.000781  max mem: 4109
I20241204 09:42:59 2542581 dinov2 helpers.py:102]   [230/634]  eta: 0:25:38    time: 3.980602  data: 0.001444  max mem: 4109
I20241204 09:43:06 2542582 dinov2 helpers.py:102]   [210/634]  eta: 0:29:13    time: 3.980605  data: 0.002127  max mem: 4109
I20241204 09:43:09 2542584 dinov2 helpers.py:102]   [210/634]  eta: 0:29:20    time: 3.987705  data: 0.000831  max mem: 4109
I20241204 09:43:09 2542583 dinov2 helpers.py:102]   [240/634]  eta: 0:24:16    time: 3.985043  data: 0.000671  max mem: 4109
I20241204 09:43:13 2542578 dinov2 helpers.py:102]   [210/634]  eta: 0:29:30    time: 3.988622  data: 0.000939  max mem: 4109
I20241204 09:43:17 2542580 dinov2 helpers.py:102]   [210/634]  eta: 0:29:28    time: 3.991337  data: 0.001563  max mem: 4109
I20241204 09:43:18 2542579 dinov2 helpers.py:102]   [210/634]  eta: 0:29:29    time: 3.977088  data: 0.000973  max mem: 4109
I20241204 09:43:29 2542585 dinov2 helpers.py:102]   [230/634]  eta: 0:26:28    time: 3.982305  data: 0.001262  max mem: 4109
I20241204 09:43:39 2542581 dinov2 helpers.py:102]   [240/634]  eta: 0:25:02    time: 3.982337  data: 0.000889  max mem: 4109
I20241204 09:43:46 2542582 dinov2 helpers.py:102]   [220/634]  eta: 0:28:28    time: 3.982285  data: 0.000834  max mem: 4109
I20241204 09:43:48 2542584 dinov2 helpers.py:102]   [220/634]  eta: 0:28:36    time: 3.989476  data: 0.001128  max mem: 4109
I20241204 09:43:49 2542583 dinov2 helpers.py:102]   [250/634]  eta: 0:23:44    time: 3.985945  data: 0.000949  max mem: 4109
I20241204 09:43:53 2542578 dinov2 helpers.py:102]   [220/634]  eta: 0:28:45    time: 3.984946  data: 0.000956  max mem: 4109
I20241204 09:43:57 2542580 dinov2 helpers.py:102]   [220/634]  eta: 0:28:43    time: 3.991253  data: 0.001636  max mem: 4109
I20241204 09:43:58 2542579 dinov2 helpers.py:102]   [220/634]  eta: 0:28:44    time: 3.979547  data: 0.001118  max mem: 4109
I20241204 09:44:09 2542585 dinov2 helpers.py:102]   [240/634]  eta: 0:25:50    time: 3.981339  data: 0.003538  max mem: 4109
I20241204 09:44:18 2542581 dinov2 helpers.py:102]   [250/634]  eta: 0:24:27    time: 3.984130  data: 0.000646  max mem: 4109
I20241204 09:44:26 2542582 dinov2 helpers.py:102]   [230/634]  eta: 0:27:45    time: 3.984233  data: 0.000916  max mem: 4109
I20241204 09:44:28 2542584 dinov2 helpers.py:102]   [230/634]  eta: 0:27:52    time: 3.986874  data: 0.001065  max mem: 4109
I20241204 09:44:29 2542583 dinov2 helpers.py:102]   [260/634]  eta: 0:23:11    time: 3.981444  data: 0.001042  max mem: 4109
I20241204 09:44:33 2542578 dinov2 helpers.py:102]   [230/634]  eta: 0:28:00    time: 3.979672  data: 0.000853  max mem: 4109
I20241204 09:44:37 2542580 dinov2 helpers.py:102]   [230/634]  eta: 0:27:58    time: 3.994997  data: 0.001706  max mem: 4109
I20241204 09:44:37 2542579 dinov2 helpers.py:102]   [230/634]  eta: 0:27:59    time: 3.977824  data: 0.000861  max mem: 4109
I20241204 09:44:49 2542585 dinov2 helpers.py:102]   [250/634]  eta: 0:25:11    time: 3.984150  data: 0.004654  max mem: 4109
I20241204 09:44:58 2542581 dinov2 helpers.py:102]   [260/634]  eta: 0:23:51    time: 3.985043  data: 0.001022  max mem: 4109
I20241204 09:45:06 2542582 dinov2 helpers.py:102]   [240/634]  eta: 0:27:01    time: 3.986049  data: 0.000740  max mem: 4109
I20241204 09:45:08 2542584 dinov2 helpers.py:102]   [240/634]  eta: 0:27:08    time: 3.986031  data: 0.000681  max mem: 4109
I20241204 09:45:09 2542583 dinov2 helpers.py:102]   [270/634]  eta: 0:22:37    time: 3.984195  data: 0.000952  max mem: 4109
I20241204 09:45:13 2542578 dinov2 helpers.py:102]   [240/634]  eta: 0:27:15    time: 3.982483  data: 0.002876  max mem: 4109
I20241204 09:45:17 2542580 dinov2 helpers.py:102]   [240/634]  eta: 0:27:14    time: 3.994983  data: 0.003774  max mem: 4109
I20241204 09:45:17 2542579 dinov2 helpers.py:102]   [240/634]  eta: 0:27:14    time: 3.977909  data: 0.001044  max mem: 4109
I20241204 09:45:28 2542585 dinov2 helpers.py:102]   [260/634]  eta: 0:24:32    time: 3.985356  data: 0.002514  max mem: 4109
I20241204 09:45:38 2542581 dinov2 helpers.py:102]   [270/634]  eta: 0:23:15    time: 3.984140  data: 0.002229  max mem: 4109
I20241204 09:45:46 2542582 dinov2 helpers.py:102]   [250/634]  eta: 0:26:18    time: 3.984060  data: 0.000586  max mem: 4109
I20241204 09:45:48 2542584 dinov2 helpers.py:102]   [250/634]  eta: 0:26:24    time: 3.984107  data: 0.001759  max mem: 4109
I20241204 09:45:49 2542583 dinov2 helpers.py:102]   [280/634]  eta: 0:22:03    time: 3.991334  data: 0.001237  max mem: 4109
I20241204 09:45:53 2542578 dinov2 helpers.py:102]   [250/634]  eta: 0:26:31    time: 3.985034  data: 0.002787  max mem: 4109
I20241204 09:45:57 2542580 dinov2 helpers.py:102]   [250/634]  eta: 0:26:30    time: 3.992147  data: 0.002956  max mem: 4109
I20241204 09:45:57 2542579 dinov2 helpers.py:102]   [250/634]  eta: 0:26:30    time: 3.981424  data: 0.001105  max mem: 4109
I20241204 09:46:08 2542585 dinov2 helpers.py:102]   [270/634]  eta: 0:23:54    time: 3.987259  data: 0.000882  max mem: 4109
I20241204 09:46:18 2542581 dinov2 helpers.py:102]   [280/634]  eta: 0:22:38    time: 3.979689  data: 0.001936  max mem: 4109
I20241204 09:46:25 2542582 dinov2 helpers.py:102]   [260/634]  eta: 0:25:35    time: 3.981545  data: 0.000750  max mem: 4109
I20241204 09:46:28 2542584 dinov2 helpers.py:102]   [260/634]  eta: 0:25:41    time: 3.985989  data: 0.001833  max mem: 4109
I20241204 09:46:29 2542583 dinov2 helpers.py:102]   [290/634]  eta: 0:21:29    time: 3.989571  data: 0.001278  max mem: 4109
I20241204 09:46:32 2542578 dinov2 helpers.py:102]   [260/634]  eta: 0:25:47    time: 3.984108  data: 0.000618  max mem: 4109
I20241204 09:46:37 2542580 dinov2 helpers.py:102]   [260/634]  eta: 0:25:47    time: 3.993146  data: 0.000905  max mem: 4109
I20241204 09:46:37 2542579 dinov2 helpers.py:102]   [260/634]  eta: 0:25:47    time: 3.984272  data: 0.000785  max mem: 4109
I20241204 09:46:48 2542585 dinov2 helpers.py:102]   [280/634]  eta: 0:23:15    time: 3.988471  data: 0.000585  max mem: 4109
I20241204 09:46:58 2542581 dinov2 helpers.py:102]   [290/634]  eta: 0:22:02    time: 3.981650  data: 0.000828  max mem: 4109
I20241204 09:47:05 2542582 dinov2 helpers.py:102]   [270/634]  eta: 0:24:52    time: 3.977930  data: 0.000880  max mem: 4109
I20241204 09:47:08 2542584 dinov2 helpers.py:102]   [270/634]  eta: 0:24:58    time: 3.989692  data: 0.000662  max mem: 4109
I20241204 09:47:09 2542583 dinov2 helpers.py:102]   [300/634]  eta: 0:20:54    time: 3.985265  data: 0.001609  max mem: 4109
I20241204 09:47:12 2542578 dinov2 helpers.py:102]   [270/634]  eta: 0:25:04    time: 3.985192  data: 0.000872  max mem: 4109
I20241204 09:47:17 2542580 dinov2 helpers.py:102]   [270/634]  eta: 0:25:03    time: 3.994999  data: 0.001633  max mem: 4109
I20241204 09:47:17 2542579 dinov2 helpers.py:102]   [270/634]  eta: 0:25:03    time: 3.982396  data: 0.000697  max mem: 4109
I20241204 09:47:28 2542585 dinov2 helpers.py:102]   [290/634]  eta: 0:22:36    time: 3.982974  data: 0.001285  max mem: 4109
I20241204 09:47:38 2542581 dinov2 helpers.py:102]   [300/634]  eta: 0:21:25    time: 3.986971  data: 0.001614  max mem: 4109
I20241204 09:47:45 2542582 dinov2 helpers.py:102]   [280/634]  eta: 0:24:10    time: 3.978797  data: 0.000886  max mem: 4109
I20241204 09:47:48 2542584 dinov2 helpers.py:102]   [280/634]  eta: 0:24:15    time: 3.990601  data: 0.000894  max mem: 4109
I20241204 09:47:48 2542583 dinov2 helpers.py:102]   [310/634]  eta: 0:20:19    time: 3.982395  data: 0.001655  max mem: 4109
I20241204 09:47:52 2542578 dinov2 helpers.py:102]   [280/634]  eta: 0:24:21    time: 3.982435  data: 0.001631  max mem: 4109
I20241204 09:47:57 2542579 dinov2 helpers.py:102]   [280/634]  eta: 0:24:20    time: 3.981442  data: 0.001057  max mem: 4109
I20241204 09:47:57 2542580 dinov2 helpers.py:102]   [280/634]  eta: 0:24:20    time: 3.993348  data: 0.002138  max mem: 4109
I20241204 09:48:08 2542585 dinov2 helpers.py:102]   [300/634]  eta: 0:21:57    time: 3.983258  data: 0.001235  max mem: 4109
I20241204 09:48:17 2542581 dinov2 helpers.py:102]   [310/634]  eta: 0:20:48    time: 3.988549  data: 0.001715  max mem: 4109
I20241204 09:48:25 2542582 dinov2 helpers.py:102]   [290/634]  eta: 0:23:27    time: 3.981421  data: 0.000661  max mem: 4109
I20241204 09:48:28 2542584 dinov2 helpers.py:102]   [290/634]  eta: 0:23:33    time: 3.988564  data: 0.001784  max mem: 4109
I20241204 09:48:28 2542583 dinov2 helpers.py:102]   [320/634]  eta: 0:19:43    time: 3.983949  data: 0.000916  max mem: 4109
I20241204 09:48:32 2542578 dinov2 helpers.py:102]   [290/634]  eta: 0:23:38    time: 3.981358  data: 0.001447  max mem: 4109
I20241204 09:48:36 2542579 dinov2 helpers.py:102]   [290/634]  eta: 0:23:37    time: 3.983319  data: 0.002152  max mem: 4109
I20241204 09:48:36 2542580 dinov2 helpers.py:102]   [290/634]  eta: 0:23:37    time: 3.992265  data: 0.001202  max mem: 4109
I20241204 09:48:48 2542585 dinov2 helpers.py:102]   [310/634]  eta: 0:21:18    time: 3.987661  data: 0.000569  max mem: 4109
I20241204 09:48:57 2542581 dinov2 helpers.py:102]   [320/634]  eta: 0:20:11    time: 3.986867  data: 0.001107  max mem: 4109
I20241204 09:49:05 2542582 dinov2 helpers.py:102]   [300/634]  eta: 0:22:45    time: 3.981395  data: 0.001696  max mem: 4109
I20241204 09:49:07 2542584 dinov2 helpers.py:102]   [300/634]  eta: 0:22:50    time: 3.985792  data: 0.001707  max mem: 4109
I20241204 09:49:08 2542583 dinov2 helpers.py:102]   [330/634]  eta: 0:19:07    time: 3.986768  data: 0.000720  max mem: 4109
I20241204 09:49:12 2542578 dinov2 helpers.py:102]   [300/634]  eta: 0:22:55    time: 3.985830  data: 0.000811  max mem: 4109
I20241204 09:49:16 2542579 dinov2 helpers.py:102]   [300/634]  eta: 0:22:54    time: 3.982225  data: 0.001891  max mem: 4109
I20241204 09:49:16 2542580 dinov2 helpers.py:102]   [300/634]  eta: 0:22:55    time: 3.992956  data: 0.000680  max mem: 4109
I20241204 09:49:28 2542585 dinov2 helpers.py:102]   [320/634]  eta: 0:20:39    time: 3.984939  data: 0.000569  max mem: 4109
I20241204 09:49:37 2542581 dinov2 helpers.py:102]   [330/634]  eta: 0:19:33    time: 3.985910  data: 0.001477  max mem: 4109
I20241204 09:49:44 2542582 dinov2 helpers.py:102]   [310/634]  eta: 0:22:03    time: 3.983260  data: 0.002059  max mem: 4109
I20241204 09:49:47 2542584 dinov2 helpers.py:102]   [310/634]  eta: 0:22:08    time: 3.988639  data: 0.001064  max mem: 4109
I20241204 09:49:48 2542583 dinov2 helpers.py:102]   [340/634]  eta: 0:18:31    time: 3.987876  data: 0.000966  max mem: 4109
I20241204 09:49:52 2542578 dinov2 helpers.py:102]   [310/634]  eta: 0:22:12    time: 3.986856  data: 0.000874  max mem: 4109
I20241204 09:49:56 2542579 dinov2 helpers.py:102]   [310/634]  eta: 0:22:12    time: 3.984140  data: 0.001137  max mem: 4109
I20241204 09:49:56 2542580 dinov2 helpers.py:102]   [310/634]  eta: 0:22:12    time: 3.992361  data: 0.001044  max mem: 4109
I20241204 09:50:07 2542585 dinov2 helpers.py:102]   [330/634]  eta: 0:20:00    time: 3.984186  data: 0.000621  max mem: 4109
I20241204 09:50:17 2542581 dinov2 helpers.py:102]   [340/634]  eta: 0:18:56    time: 3.984183  data: 0.001152  max mem: 4109
I20241204 09:50:24 2542582 dinov2 helpers.py:102]   [320/634]  eta: 0:21:21    time: 3.980521  data: 0.000965  max mem: 4109
I20241204 09:50:27 2542584 dinov2 helpers.py:102]   [320/634]  eta: 0:21:26    time: 3.985048  data: 0.000836  max mem: 4109
I20241204 09:50:28 2542583 dinov2 helpers.py:102]   [350/634]  eta: 0:17:55    time: 3.988661  data: 0.000950  max mem: 4109
I20241204 09:50:32 2542578 dinov2 helpers.py:102]   [320/634]  eta: 0:21:30    time: 3.985942  data: 0.002007  max mem: 4109
I20241204 09:50:36 2542579 dinov2 helpers.py:102]   [320/634]  eta: 0:21:29    time: 3.985943  data: 0.001198  max mem: 4109
I20241204 09:50:36 2542580 dinov2 helpers.py:102]   [320/634]  eta: 0:21:30    time: 3.991302  data: 0.001037  max mem: 4109
I20241204 09:50:47 2542585 dinov2 helpers.py:102]   [340/634]  eta: 0:19:21    time: 3.983189  data: 0.000640  max mem: 4109
I20241204 09:50:57 2542581 dinov2 helpers.py:102]   [350/634]  eta: 0:18:18    time: 3.979518  data: 0.000771  max mem: 4109
I20241204 09:51:04 2542582 dinov2 helpers.py:102]   [330/634]  eta: 0:20:40    time: 3.976894  data: 0.001886  max mem: 4109
I20241204 09:51:07 2542584 dinov2 helpers.py:102]   [330/634]  eta: 0:20:44    time: 3.982232  data: 0.000639  max mem: 4109
I20241204 09:51:08 2542583 dinov2 helpers.py:102]   [360/634]  eta: 0:17:19    time: 3.987518  data: 0.000979  max mem: 4109
I20241204 09:51:11 2542578 dinov2 helpers.py:102]   [330/634]  eta: 0:20:48    time: 3.983972  data: 0.002456  max mem: 4109
I20241204 09:51:16 2542579 dinov2 helpers.py:102]   [330/634]  eta: 0:20:47    time: 3.979370  data: 0.000822  max mem: 4109
I20241204 09:51:16 2542580 dinov2 helpers.py:102]   [330/634]  eta: 0:20:48    time: 3.991912  data: 0.000725  max mem: 4109
I20241204 09:51:27 2542585 dinov2 helpers.py:102]   [350/634]  eta: 0:18:41    time: 3.980914  data: 0.000656  max mem: 4109
I20241204 09:51:37 2542581 dinov2 helpers.py:102]   [360/634]  eta: 0:17:40    time: 3.976664  data: 0.001315  max mem: 4109
I20241204 09:51:44 2542582 dinov2 helpers.py:102]   [340/634]  eta: 0:19:58    time: 3.977725  data: 0.001954  max mem: 4109
I20241204 09:51:47 2542584 dinov2 helpers.py:102]   [340/634]  eta: 0:20:02    time: 3.982192  data: 0.001282  max mem: 4109
I20241204 09:51:48 2542583 dinov2 helpers.py:102]   [370/634]  eta: 0:16:42    time: 3.984948  data: 0.000885  max mem: 4109
I20241204 09:51:51 2542578 dinov2 helpers.py:102]   [340/634]  eta: 0:20:06    time: 3.978613  data: 0.001114  max mem: 4109
I20241204 09:51:55 2542579 dinov2 helpers.py:102]   [340/634]  eta: 0:20:05    time: 3.976020  data: 0.001095  max mem: 4109
I20241204 09:51:56 2542580 dinov2 helpers.py:102]   [340/634]  eta: 0:20:06    time: 3.994795  data: 0.001220  max mem: 4109
I20241204 09:52:07 2542585 dinov2 helpers.py:102]   [360/634]  eta: 0:18:02    time: 3.978657  data: 0.000629  max mem: 4109
I20241204 09:52:16 2542581 dinov2 helpers.py:102]   [370/634]  eta: 0:17:02    time: 3.975961  data: 0.001259  max mem: 4109
I20241204 09:52:24 2542582 dinov2 helpers.py:102]   [350/634]  eta: 0:19:16    time: 3.980250  data: 0.000838  max mem: 4109
I20241204 09:52:27 2542584 dinov2 helpers.py:102]   [350/634]  eta: 0:19:20    time: 3.979372  data: 0.001879  max mem: 4109
I20241204 09:52:28 2542583 dinov2 helpers.py:102]   [380/634]  eta: 0:16:06    time: 3.985759  data: 0.001773  max mem: 4109
I20241204 09:52:31 2542578 dinov2 helpers.py:102]   [350/634]  eta: 0:19:24    time: 3.977698  data: 0.000574  max mem: 4109
I20241204 09:52:35 2542579 dinov2 helpers.py:102]   [350/634]  eta: 0:19:23    time: 3.978577  data: 0.001144  max mem: 4109
I20241204 09:52:36 2542580 dinov2 helpers.py:102]   [350/634]  eta: 0:19:24    time: 3.992109  data: 0.001347  max mem: 4109
I20241204 09:52:47 2542585 dinov2 helpers.py:102]   [370/634]  eta: 0:17:23    time: 3.976187  data: 0.000669  max mem: 4109
I20241204 09:52:56 2542581 dinov2 helpers.py:102]   [380/634]  eta: 0:16:24    time: 3.979496  data: 0.001055  max mem: 4109
I20241204 09:53:03 2542582 dinov2 helpers.py:102]   [360/634]  eta: 0:18:35    time: 3.979396  data: 0.000786  max mem: 4109
I20241204 09:53:06 2542584 dinov2 helpers.py:102]   [360/634]  eta: 0:18:38    time: 3.979373  data: 0.002036  max mem: 4109
I20241204 09:53:07 2542583 dinov2 helpers.py:102]   [390/634]  eta: 0:15:29    time: 3.984849  data: 0.001868  max mem: 4109
I20241204 09:53:11 2542578 dinov2 helpers.py:102]   [360/634]  eta: 0:18:42    time: 3.982202  data: 0.000689  max mem: 4109
I20241204 09:53:15 2542579 dinov2 helpers.py:102]   [360/634]  eta: 0:18:41    time: 3.980195  data: 0.000922  max mem: 4109
I20241204 09:53:16 2542580 dinov2 helpers.py:102]   [360/634]  eta: 0:18:42    time: 3.991128  data: 0.001051  max mem: 4109
I20241204 09:53:26 2542585 dinov2 helpers.py:102]   [380/634]  eta: 0:16:43    time: 3.977669  data: 0.000657  max mem: 4109
I20241204 09:53:36 2542581 dinov2 helpers.py:102]   [390/634]  eta: 0:15:46    time: 3.981335  data: 0.001252  max mem: 4109
I20241204 09:53:43 2542582 dinov2 helpers.py:102]   [370/634]  eta: 0:17:54    time: 3.980461  data: 0.001060  max mem: 4109
I20241204 09:53:46 2542584 dinov2 helpers.py:102]   [370/634]  eta: 0:17:57    time: 3.982582  data: 0.001457  max mem: 4109
I20241204 09:53:47 2542583 dinov2 helpers.py:102]   [400/634]  eta: 0:14:52    time: 3.982224  data: 0.000645  max mem: 4109
I20241204 09:53:51 2542578 dinov2 helpers.py:102]   [370/634]  eta: 0:18:00    time: 3.984003  data: 0.001387  max mem: 4109
I20241204 09:53:55 2542579 dinov2 helpers.py:102]   [370/634]  eta: 0:17:59    time: 3.979553  data: 0.000817  max mem: 4109
I20241204 09:53:56 2542580 dinov2 helpers.py:102]   [370/634]  eta: 0:18:00    time: 3.993948  data: 0.000989  max mem: 4109
I20241204 09:54:06 2542585 dinov2 helpers.py:102]   [390/634]  eta: 0:16:04    time: 3.980444  data: 0.000698  max mem: 4109
I20241204 09:54:16 2542581 dinov2 helpers.py:102]   [400/634]  eta: 0:15:08    time: 3.978543  data: 0.000879  max mem: 4109
I20241204 09:54:23 2542582 dinov2 helpers.py:102]   [380/634]  eta: 0:17:12    time: 3.981246  data: 0.001040  max mem: 4109
I20241204 09:54:26 2542584 dinov2 helpers.py:102]   [380/634]  eta: 0:17:15    time: 3.985931  data: 0.000637  max mem: 4109
I20241204 09:54:27 2542583 dinov2 helpers.py:102]   [410/634]  eta: 0:14:14    time: 3.985719  data: 0.000906  max mem: 4109
I20241204 09:54:30 2542578 dinov2 helpers.py:102]   [380/634]  eta: 0:17:18    time: 3.984831  data: 0.001501  max mem: 4109
I20241204 09:54:35 2542579 dinov2 helpers.py:102]   [380/634]  eta: 0:17:18    time: 3.982266  data: 0.000760  max mem: 4109
I20241204 09:54:36 2542580 dinov2 helpers.py:102]   [380/634]  eta: 0:17:19    time: 3.993181  data: 0.001124  max mem: 4109
I20241204 09:54:46 2542585 dinov2 helpers.py:102]   [400/634]  eta: 0:15:25    time: 3.984071  data: 0.000876  max mem: 4109
I20241204 09:54:55 2542581 dinov2 helpers.py:102]   [410/634]  eta: 0:14:29    time: 3.978622  data: 0.000779  max mem: 4109
I20241204 09:55:03 2542582 dinov2 helpers.py:102]   [390/634]  eta: 0:16:31    time: 3.982255  data: 0.000931  max mem: 4109
I20241204 09:55:06 2542584 dinov2 helpers.py:102]   [390/634]  eta: 0:16:34    time: 3.989133  data: 0.001025  max mem: 4109
I20241204 09:55:07 2542583 dinov2 helpers.py:102]   [420/634]  eta: 0:13:37    time: 3.986784  data: 0.001230  max mem: 4109
I20241204 09:55:10 2542578 dinov2 helpers.py:102]   [390/634]  eta: 0:16:37    time: 3.984116  data: 0.000888  max mem: 4109
I20241204 09:55:14 2542579 dinov2 helpers.py:102]   [390/634]  eta: 0:16:36    time: 3.985008  data: 0.001151  max mem: 4109
I20241204 09:55:16 2542580 dinov2 helpers.py:102]   [390/634]  eta: 0:16:37    time: 3.993028  data: 0.001896  max mem: 4109
I20241204 09:55:26 2542585 dinov2 helpers.py:102]   [410/634]  eta: 0:14:45    time: 3.985076  data: 0.000779  max mem: 4109
I20241204 09:55:35 2542581 dinov2 helpers.py:102]   [420/634]  eta: 0:13:51    time: 3.983335  data: 0.001222  max mem: 4109
I20241204 09:55:43 2542582 dinov2 helpers.py:102]   [400/634]  eta: 0:15:50    time: 3.987008  data: 0.001340  max mem: 4109
I20241204 09:55:46 2542584 dinov2 helpers.py:102]   [400/634]  eta: 0:15:53    time: 3.990429  data: 0.001698  max mem: 4109
I20241204 09:55:47 2542583 dinov2 helpers.py:102]   [430/634]  eta: 0:13:00    time: 3.987041  data: 0.001018  max mem: 4109
I20241204 09:55:50 2542578 dinov2 helpers.py:102]   [400/634]  eta: 0:15:55    time: 3.987883  data: 0.000917  max mem: 4109
I20241204 09:55:54 2542579 dinov2 helpers.py:102]   [400/634]  eta: 0:15:55    time: 3.984278  data: 0.001146  max mem: 4109
I20241204 09:55:56 2542580 dinov2 helpers.py:102]   [400/634]  eta: 0:15:56    time: 3.993265  data: 0.003094  max mem: 4109
I20241204 09:56:06 2542585 dinov2 helpers.py:102]   [420/634]  eta: 0:14:06    time: 3.986974  data: 0.000796  max mem: 4109
I20241204 09:56:15 2542581 dinov2 helpers.py:102]   [430/634]  eta: 0:13:13    time: 3.984268  data: 0.001922  max mem: 4109
I20241204 09:56:23 2542582 dinov2 helpers.py:102]   [410/634]  eta: 0:15:09    time: 3.987907  data: 0.001032  max mem: 4109
I20241204 09:56:26 2542584 dinov2 helpers.py:102]   [410/634]  eta: 0:15:12    time: 3.990132  data: 0.003507  max mem: 4109
I20241204 09:56:27 2542583 dinov2 helpers.py:102]   [440/634]  eta: 0:12:22    time: 3.989721  data: 0.000985  max mem: 4109
I20241204 09:56:30 2542578 dinov2 helpers.py:102]   [410/634]  eta: 0:15:14    time: 3.991505  data: 0.001098  max mem: 4109
I20241204 09:56:34 2542579 dinov2 helpers.py:102]   [410/634]  eta: 0:15:13    time: 3.987015  data: 0.002216  max mem: 4109
I20241204 09:56:36 2542580 dinov2 helpers.py:102]   [410/634]  eta: 0:15:14    time: 3.992413  data: 0.002357  max mem: 4109
I20241204 09:56:46 2542585 dinov2 helpers.py:102]   [430/634]  eta: 0:13:27    time: 3.987952  data: 0.000777  max mem: 4109
I20241204 09:56:55 2542581 dinov2 helpers.py:102]   [440/634]  eta: 0:12:34    time: 3.986128  data: 0.001680  max mem: 4109
I20241204 09:57:02 2542582 dinov2 helpers.py:102]   [420/634]  eta: 0:14:28    time: 3.986071  data: 0.000655  max mem: 4109
I20241204 09:57:06 2542584 dinov2 helpers.py:102]   [420/634]  eta: 0:14:30    time: 3.991523  data: 0.003040  max mem: 4109
I20241204 09:57:07 2542583 dinov2 helpers.py:102]   [450/634]  eta: 0:11:45    time: 3.991469  data: 0.001034  max mem: 4109
I20241204 09:57:10 2542578 dinov2 helpers.py:102]   [420/634]  eta: 0:14:33    time: 3.990704  data: 0.001062  max mem: 4109
I20241204 09:57:14 2542579 dinov2 helpers.py:102]   [420/634]  eta: 0:14:32    time: 3.988831  data: 0.002366  max mem: 4109
I20241204 09:57:16 2542580 dinov2 helpers.py:102]   [420/634]  eta: 0:14:33    time: 3.991487  data: 0.000906  max mem: 4109
I20241204 09:57:26 2542585 dinov2 helpers.py:102]   [440/634]  eta: 0:12:47    time: 3.987233  data: 0.000669  max mem: 4109
I20241204 09:57:35 2542581 dinov2 helpers.py:102]   [450/634]  eta: 0:11:56    time: 3.988977  data: 0.000961  max mem: 4109
I20241204 09:57:42 2542582 dinov2 helpers.py:102]   [430/634]  eta: 0:13:47    time: 3.987319  data: 0.000955  max mem: 4109
I20241204 09:57:46 2542584 dinov2 helpers.py:102]   [430/634]  eta: 0:13:49    time: 3.991715  data: 0.000891  max mem: 4109
I20241204 09:57:47 2542583 dinov2 helpers.py:102]   [460/634]  eta: 0:11:07    time: 3.991790  data: 0.001474  max mem: 4109
I20241204 09:57:50 2542578 dinov2 helpers.py:102]   [430/634]  eta: 0:13:51    time: 3.990871  data: 0.000735  max mem: 4109
I20241204 09:57:54 2542579 dinov2 helpers.py:102]   [430/634]  eta: 0:13:51    time: 3.989173  data: 0.001288  max mem: 4109
I20241204 09:57:55 2542580 dinov2 helpers.py:102]   [430/634]  eta: 0:13:52    time: 3.992912  data: 0.001110  max mem: 4109
I20241204 09:58:05 2542585 dinov2 helpers.py:102]   [450/634]  eta: 0:12:08    time: 3.986563  data: 0.000823  max mem: 4109
I20241204 09:58:15 2542581 dinov2 helpers.py:102]   [460/634]  eta: 0:11:17    time: 3.989180  data: 0.000927  max mem: 4109
I20241204 09:58:22 2542582 dinov2 helpers.py:102]   [440/634]  eta: 0:13:06    time: 3.987386  data: 0.001131  max mem: 4109
I20241204 09:58:26 2542584 dinov2 helpers.py:102]   [440/634]  eta: 0:13:08    time: 3.990082  data: 0.001138  max mem: 4109
I20241204 09:58:26 2542583 dinov2 helpers.py:102]   [470/634]  eta: 0:10:29    time: 3.990182  data: 0.001425  max mem: 4109
I20241204 09:58:30 2542578 dinov2 helpers.py:102]   [440/634]  eta: 0:13:10    time: 3.987327  data: 0.000539  max mem: 4109
I20241204 09:58:34 2542579 dinov2 helpers.py:102]   [440/634]  eta: 0:13:10    time: 3.989211  data: 0.001122  max mem: 4109
I20241204 09:58:35 2542580 dinov2 helpers.py:102]   [440/634]  eta: 0:13:11    time: 3.994427  data: 0.001206  max mem: 4109
I20241204 09:58:45 2542585 dinov2 helpers.py:102]   [460/634]  eta: 0:11:28    time: 3.986260  data: 0.001162  max mem: 4109
I20241204 09:58:55 2542581 dinov2 helpers.py:102]   [470/634]  eta: 0:10:39    time: 3.988092  data: 0.001247  max mem: 4109
I20241204 09:59:02 2542582 dinov2 helpers.py:102]   [450/634]  eta: 0:12:25    time: 3.983439  data: 0.000928  max mem: 4109
I20241204 09:59:05 2542584 dinov2 helpers.py:102]   [450/634]  eta: 0:12:27    time: 3.987646  data: 0.001260  max mem: 4109
I20241204 09:59:06 2542583 dinov2 helpers.py:102]   [480/634]  eta: 0:09:51    time: 3.987970  data: 0.000701  max mem: 4109
I20241204 09:59:10 2542578 dinov2 helpers.py:102]   [450/634]  eta: 0:12:29    time: 3.986194  data: 0.000697  max mem: 4109
I20241204 09:59:14 2542579 dinov2 helpers.py:102]   [450/634]  eta: 0:12:29    time: 3.989022  data: 0.000929  max mem: 4109
I20241204 09:59:15 2542580 dinov2 helpers.py:102]   [450/634]  eta: 0:12:29    time: 3.993123  data: 0.001232  max mem: 4109
I20241204 09:59:25 2542585 dinov2 helpers.py:102]   [470/634]  eta: 0:10:49    time: 3.984142  data: 0.001413  max mem: 4109
I20241204 09:59:35 2542581 dinov2 helpers.py:102]   [480/634]  eta: 0:10:00    time: 3.986872  data: 0.001164  max mem: 4109
I20241204 09:59:42 2542582 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.984182  data: 0.000776  max mem: 4109
I20241204 09:59:45 2542584 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.986900  data: 0.000855  max mem: 4109
I20241204 09:59:46 2542583 dinov2 helpers.py:102]   [490/634]  eta: 0:09:13    time: 3.985923  data: 0.000828  max mem: 4109
I20241204 09:59:50 2542578 dinov2 helpers.py:102]   [460/634]  eta: 0:11:48    time: 3.986850  data: 0.000844  max mem: 4109
I20241204 09:59:54 2542579 dinov2 helpers.py:102]   [460/634]  eta: 0:11:48    time: 3.982742  data: 0.000913  max mem: 4109
I20241204 09:59:55 2542580 dinov2 helpers.py:102]   [460/634]  eta: 0:11:48    time: 3.992511  data: 0.001502  max mem: 4109
I20241204 10:00:05 2542585 dinov2 helpers.py:102]   [480/634]  eta: 0:10:09    time: 3.985081  data: 0.001094  max mem: 4109
I20241204 10:00:14 2542581 dinov2 helpers.py:102]   [490/634]  eta: 0:09:21    time: 3.982432  data: 0.001055  max mem: 4109
I20241204 10:00:22 2542582 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.985137  data: 0.000896  max mem: 4109
I20241204 10:00:25 2542584 dinov2 helpers.py:102]   [470/634]  eta: 0:11:06    time: 3.986036  data: 0.000614  max mem: 4109
I20241204 10:00:26 2542583 dinov2 helpers.py:102]   [500/634]  eta: 0:08:35    time: 3.987812  data: 0.000909  max mem: 4109
I20241204 10:00:29 2542578 dinov2 helpers.py:102]   [470/634]  eta: 0:11:07    time: 3.981523  data: 0.000919  max mem: 4109
I20241204 10:00:33 2542579 dinov2 helpers.py:102]   [470/634]  eta: 0:11:07    time: 3.978551  data: 0.000761  max mem: 4109
I20241204 10:00:35 2542580 dinov2 helpers.py:102]   [470/634]  eta: 0:11:07    time: 3.992396  data: 0.001321  max mem: 4109
I20241204 10:00:45 2542585 dinov2 helpers.py:102]   [490/634]  eta: 0:09:30    time: 3.986898  data: 0.000854  max mem: 4109
I20241204 10:00:54 2542581 dinov2 helpers.py:102]   [500/634]  eta: 0:08:42    time: 3.981597  data: 0.001191  max mem: 4109
I20241204 10:01:02 2542582 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.979863  data: 0.000869  max mem: 4109
I20241204 10:01:05 2542584 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.985133  data: 0.000662  max mem: 4109
I20241204 10:01:06 2542583 dinov2 helpers.py:102]   [510/634]  eta: 0:07:57    time: 3.987802  data: 0.000646  max mem: 4109
I20241204 10:01:09 2542578 dinov2 helpers.py:102]   [480/634]  eta: 0:10:26    time: 3.980647  data: 0.000794  max mem: 4109
I20241204 10:01:13 2542579 dinov2 helpers.py:102]   [480/634]  eta: 0:10:26    time: 3.981093  data: 0.000887  max mem: 4109
I20241204 10:01:15 2542580 dinov2 helpers.py:102]   [480/634]  eta: 0:10:26    time: 3.994787  data: 0.001143  max mem: 4109
I20241204 10:01:25 2542585 dinov2 helpers.py:102]   [500/634]  eta: 0:08:50    time: 3.984184  data: 0.000759  max mem: 4109
I20241204 10:01:34 2542581 dinov2 helpers.py:102]   [510/634]  eta: 0:08:04    time: 3.982345  data: 0.001360  max mem: 4109
I20241204 10:01:41 2542582 dinov2 helpers.py:102]   [490/634]  eta: 0:09:42    time: 3.978747  data: 0.000820  max mem: 4109
I20241204 10:01:45 2542584 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.984115  data: 0.001266  max mem: 4109
I20241204 10:01:46 2542583 dinov2 helpers.py:102]   [520/634]  eta: 0:07:19    time: 3.986005  data: 0.000543  max mem: 4109
I20241204 10:01:49 2542578 dinov2 helpers.py:102]   [490/634]  eta: 0:09:45    time: 3.982276  data: 0.000624  max mem: 4109
I20241204 10:01:53 2542579 dinov2 helpers.py:102]   [490/634]  eta: 0:09:45    time: 3.979607  data: 0.000809  max mem: 4109
I20241204 10:01:55 2542580 dinov2 helpers.py:102]   [490/634]  eta: 0:09:45    time: 3.994779  data: 0.001043  max mem: 4109
I20241204 10:02:05 2542585 dinov2 helpers.py:102]   [510/634]  eta: 0:08:11    time: 3.983287  data: 0.000546  max mem: 4109
I20241204 10:02:14 2542581 dinov2 helpers.py:102]   [520/634]  eta: 0:07:25    time: 3.981282  data: 0.001352  max mem: 4109
I20241204 10:02:21 2542582 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.979428  data: 0.000905  max mem: 4109
I20241204 10:02:25 2542584 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.984869  data: 0.001211  max mem: 4109
I20241204 10:02:26 2542583 dinov2 helpers.py:102]   [530/634]  eta: 0:06:40    time: 3.984884  data: 0.000611  max mem: 4109
I20241204 10:02:29 2542578 dinov2 helpers.py:102]   [500/634]  eta: 0:09:04    time: 3.983941  data: 0.000778  max mem: 4109
I20241204 10:02:33 2542579 dinov2 helpers.py:102]   [500/634]  eta: 0:09:04    time: 3.978626  data: 0.000556  max mem: 4109
I20241204 10:02:35 2542580 dinov2 helpers.py:102]   [500/634]  eta: 0:09:05    time: 3.992028  data: 0.001023  max mem: 4109
I20241204 10:02:44 2542585 dinov2 helpers.py:102]   [520/634]  eta: 0:07:31    time: 3.982156  data: 0.000576  max mem: 4109
I20241204 10:02:54 2542581 dinov2 helpers.py:102]   [530/634]  eta: 0:06:46    time: 3.978548  data: 0.000883  max mem: 4109
I20241204 10:03:01 2542582 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.980413  data: 0.001113  max mem: 4109
I20241204 10:03:05 2542584 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.985774  data: 0.000642  max mem: 4109
I20241204 10:03:05 2542583 dinov2 helpers.py:102]   [540/634]  eta: 0:06:02    time: 3.983047  data: 0.001053  max mem: 4109
I20241204 10:03:09 2542578 dinov2 helpers.py:102]   [510/634]  eta: 0:08:23    time: 3.987582  data: 0.000788  max mem: 4109
I20241204 10:03:13 2542579 dinov2 helpers.py:102]   [510/634]  eta: 0:08:23    time: 3.977745  data: 0.002422  max mem: 4109
I20241204 10:03:15 2542580 dinov2 helpers.py:102]   [510/634]  eta: 0:08:24    time: 3.993940  data: 0.002321  max mem: 4109
I20241204 10:03:24 2542585 dinov2 helpers.py:102]   [530/634]  eta: 0:06:51    time: 3.981258  data: 0.000728  max mem: 4109
I20241204 10:03:33 2542581 dinov2 helpers.py:102]   [540/634]  eta: 0:06:07    time: 3.977842  data: 0.001008  max mem: 4109
I20241204 10:03:41 2542582 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.983169  data: 0.001469  max mem: 4109
I20241204 10:03:44 2542584 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.980507  data: 0.000744  max mem: 4109
I20241204 10:03:45 2542583 dinov2 helpers.py:102]   [550/634]  eta: 0:05:24    time: 3.986886  data: 0.001165  max mem: 4109
I20241204 10:03:48 2542578 dinov2 helpers.py:102]   [520/634]  eta: 0:07:43    time: 3.982361  data: 0.000781  max mem: 4109
I20241204 10:03:52 2542579 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.976967  data: 0.006557  max mem: 4109
I20241204 10:03:55 2542580 dinov2 helpers.py:102]   [520/634]  eta: 0:07:43    time: 3.995992  data: 0.002078  max mem: 4109
I20241204 10:04:04 2542585 dinov2 helpers.py:102]   [540/634]  eta: 0:06:12    time: 3.979739  data: 0.000693  max mem: 4109
I20241204 10:04:13 2542581 dinov2 helpers.py:102]   [550/634]  eta: 0:05:28    time: 3.979757  data: 0.001322  max mem: 4109
I20241204 10:04:21 2542582 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.982381  data: 0.001357  max mem: 4109
I20241204 10:04:24 2542584 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.976095  data: 0.000774  max mem: 4109
I20241204 10:04:25 2542583 dinov2 helpers.py:102]   [560/634]  eta: 0:04:45    time: 3.988141  data: 0.000884  max mem: 4109
I20241204 10:04:28 2542578 dinov2 helpers.py:102]   [530/634]  eta: 0:07:02    time: 3.979014  data: 0.000890  max mem: 4109
I20241204 10:04:32 2542579 dinov2 helpers.py:102]   [530/634]  eta: 0:07:02    time: 3.976086  data: 0.007259  max mem: 4109
I20241204 10:04:35 2542580 dinov2 helpers.py:102]   [530/634]  eta: 0:07:02    time: 3.997657  data: 0.000880  max mem: 4109
I20241204 10:04:44 2542585 dinov2 helpers.py:102]   [550/634]  eta: 0:05:32    time: 3.976079  data: 0.000545  max mem: 4109
I20241204 10:04:53 2542581 dinov2 helpers.py:102]   [560/634]  eta: 0:04:49    time: 3.976069  data: 0.001282  max mem: 4109
I20241204 10:05:00 2542582 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.981379  data: 0.001213  max mem: 4109
I20241204 10:05:04 2542584 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.976853  data: 0.001491  max mem: 4109
I20241204 10:05:05 2542583 dinov2 helpers.py:102]   [570/634]  eta: 0:04:07    time: 3.981637  data: 0.000768  max mem: 4109
I20241204 10:05:08 2542578 dinov2 helpers.py:102]   [540/634]  eta: 0:06:21    time: 3.979527  data: 0.001803  max mem: 4109
I20241204 10:05:12 2542579 dinov2 helpers.py:102]   [540/634]  eta: 0:06:21    time: 3.975997  data: 0.003485  max mem: 4109
I20241204 10:05:15 2542580 dinov2 helpers.py:102]   [540/634]  eta: 0:06:21    time: 3.995529  data: 0.002475  max mem: 4109
I20241204 10:05:23 2542585 dinov2 helpers.py:102]   [560/634]  eta: 0:04:53    time: 3.975806  data: 0.000576  max mem: 4109
I20241204 10:05:33 2542581 dinov2 helpers.py:102]   [570/634]  eta: 0:04:10    time: 3.975845  data: 0.001033  max mem: 4109
I20241204 10:05:40 2542582 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.977496  data: 0.001195  max mem: 4109
I20241204 10:05:44 2542584 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.975760  data: 0.001577  max mem: 4109
I20241204 10:05:45 2542583 dinov2 helpers.py:102]   [580/634]  eta: 0:03:28    time: 3.977692  data: 0.000927  max mem: 4109
I20241204 10:05:48 2542578 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.975525  data: 0.001673  max mem: 4109
I20241204 10:05:52 2542579 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.975332  data: 0.003660  max mem: 4109
I20241204 10:05:55 2542580 dinov2 helpers.py:102]   [550/634]  eta: 0:05:41    time: 3.991938  data: 0.002306  max mem: 4109
I20241204 10:06:03 2542585 dinov2 helpers.py:102]   [570/634]  eta: 0:04:13    time: 3.974753  data: 0.002146  max mem: 4109
I20241204 10:06:12 2542581 dinov2 helpers.py:102]   [580/634]  eta: 0:03:31    time: 3.976557  data: 0.000836  max mem: 4109
I20241204 10:06:20 2542582 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.973829  data: 0.001010  max mem: 4109
I20241204 10:06:23 2542584 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.973756  data: 0.000792  max mem: 4109
I20241204 10:06:25 2542583 dinov2 helpers.py:102]   [590/634]  eta: 0:02:50    time: 3.975617  data: 0.000961  max mem: 4109
I20241204 10:06:28 2542578 dinov2 helpers.py:102]   [560/634]  eta: 0:05:00    time: 3.973709  data: 0.000612  max mem: 4109
I20241204 10:06:31 2542579 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.973176  data: 0.003421  max mem: 4109
I20241204 10:06:35 2542580 dinov2 helpers.py:102]   [560/634]  eta: 0:05:00    time: 3.986283  data: 0.000773  max mem: 4109
I20241204 10:06:43 2542585 dinov2 helpers.py:102]   [580/634]  eta: 0:03:33    time: 3.972716  data: 0.002932  max mem: 4109
I20241204 10:06:52 2542581 dinov2 helpers.py:102]   [590/634]  eta: 0:02:52    time: 3.975290  data: 0.000603  max mem: 4109
I20241204 10:07:00 2542582 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.973588  data: 0.001587  max mem: 4109
I20241204 10:07:03 2542584 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.973503  data: 0.001059  max mem: 4109
I20241204 10:07:04 2542583 dinov2 helpers.py:102]   [600/634]  eta: 0:02:11    time: 3.973338  data: 0.000934  max mem: 4109
I20241204 10:07:07 2542578 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.973526  data: 0.001066  max mem: 4109
I20241204 10:07:11 2542579 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.973857  data: 0.002775  max mem: 4109
I20241204 10:07:14 2542580 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.979743  data: 0.001078  max mem: 4109
I20241204 10:07:23 2542585 dinov2 helpers.py:102]   [590/634]  eta: 0:02:54    time: 3.973407  data: 0.001579  max mem: 4109
I20241204 10:07:32 2542581 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.974278  data: 0.000812  max mem: 4109
I20241204 10:07:39 2542582 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.973483  data: 0.001576  max mem: 4109
I20241204 10:07:43 2542584 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.973457  data: 0.001028  max mem: 4109
I20241204 10:07:44 2542583 dinov2 helpers.py:102]   [610/634]  eta: 0:01:32    time: 3.973492  data: 0.001121  max mem: 4109
I20241204 10:07:47 2542578 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.973462  data: 0.001249  max mem: 4109
I20241204 10:07:51 2542579 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.973644  data: 0.005304  max mem: 4109
I20241204 10:07:54 2542580 dinov2 helpers.py:102]   [580/634]  eta: 0:03:39    time: 3.982575  data: 0.001011  max mem: 4109
I20241204 10:08:02 2542585 dinov2 helpers.py:102]   [600/634]  eta: 0:02:14    time: 3.973576  data: 0.000939  max mem: 4109
I20241204 10:08:12 2542581 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.973603  data: 0.000841  max mem: 4109
I20241204 10:08:19 2542582 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.973576  data: 0.001074  max mem: 4109
I20241204 10:08:23 2542584 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.973881  data: 0.001257  max mem: 4109
I20241204 10:08:24 2542583 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.973627  data: 0.001639  max mem: 4109
I20241204 10:08:27 2542578 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.973678  data: 0.000775  max mem: 4109
I20241204 10:08:30 2542579 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.973036  data: 0.006680  max mem: 4109
I20241204 10:08:34 2542580 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.987141  data: 0.000955  max mem: 4109
I20241204 10:08:42 2542585 dinov2 helpers.py:102]   [610/634]  eta: 0:01:35    time: 3.973708  data: 0.001019  max mem: 4109
I20241204 10:08:51 2542581 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.973595  data: 0.000758  max mem: 4109
I20241204 10:08:59 2542582 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.973595  data: 0.001018  max mem: 4109
I20241204 10:09:02 2542584 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.974544  data: 0.001998  max mem: 4109
I20241204 10:09:03 2542583 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.975324  data: 0.001825  max mem: 4109
I20241204 10:09:07 2542578 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.975432  data: 0.000584  max mem: 4109
I20241204 10:09:10 2542579 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.974147  data: 0.004906  max mem: 4109
I20241204 10:09:14 2542580 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.981633  data: 0.000946  max mem: 4109
I20241204 10:09:22 2542585 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.974532  data: 0.001001  max mem: 4109
I20241204 10:09:23 2542583 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.355420  data: 0.001462  max mem: 4109
I20241204 10:09:23 2542583 dinov2 helpers.py:130]  Total time: 0:41:05 (3.888169 s / it)
I20241204 10:09:23 2542583 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:09:23 2542583 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:09:24 2542583 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:09:24 2542583 dinov2 loaders.py:151] sampler: distributed
I20241204 10:09:24 2542583 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:09:24 2542583 dinov2 loaders.py:223] # of batches: 78
I20241204 10:09:24 2542583 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:09:30 2542581 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.930918  data: 0.001031  max mem: 4109
I20241204 10:09:34 2542583 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:12:14    time: 9.412954  data: 5.179598  max mem: 4109
I20241204 10:09:38 2542582 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.929563  data: 0.000724  max mem: 4109
I20241204 10:09:41 2542584 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.928931  data: 0.001421  max mem: 4109
I20241204 10:09:45 2542578 dinov2 helpers.py:102]   [610/634]  eta: 0:01:37    time: 3.929298  data: 0.000802  max mem: 4109
I20241204 10:09:49 2542579 dinov2 helpers.py:102]   [610/634]  eta: 0:01:37    time: 3.927573  data: 0.003836  max mem: 4109
I20241204 10:09:50 2542581 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.305177  data: 0.000896  max mem: 4109
I20241204 10:09:50 2542581 dinov2 helpers.py:130]  Total time: 0:41:30 (3.928845 s / it)
I20241204 10:09:50 2542581 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:09:50 2542581 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:09:51 2542581 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:09:51 2542581 dinov2 loaders.py:151] sampler: distributed
I20241204 10:09:51 2542581 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:09:51 2542581 dinov2 loaders.py:223] # of batches: 78
I20241204 10:09:51 2542581 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:09:52 2542580 dinov2 helpers.py:102]   [610/634]  eta: 0:01:37    time: 3.918026  data: 0.000595  max mem: 4109
I20241204 10:10:00 2542585 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.884532  data: 0.001315  max mem: 4109
I20241204 10:10:00 2542581 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:11:25    time: 8.786588  data: 4.654113  max mem: 4109
I20241204 10:10:15 2542583 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:08    time: 4.535920  data: 0.472612  max mem: 4109
I20241204 10:10:16 2542582 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.877922  data: 0.000776  max mem: 4109
I20241204 10:10:19 2542585 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.253874  data: 0.001111  max mem: 4109
I20241204 10:10:20 2542585 dinov2 helpers.py:130]  Total time: 0:41:58 (3.973080 s / it)
I20241204 10:10:20 2542585 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:10:20 2542585 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:10:20 2542584 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.874823  data: 0.000647  max mem: 4109
I20241204 10:10:20 2542585 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:10:20 2542585 dinov2 loaders.py:151] sampler: distributed
I20241204 10:10:20 2542585 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:10:20 2542585 dinov2 loaders.py:223] # of batches: 78
I20241204 10:10:20 2542585 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:10:24 2542578 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.851429  data: 0.001598  max mem: 4109
I20241204 10:10:27 2542579 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.826169  data: 0.003986  max mem: 4109
I20241204 10:10:30 2542580 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.827867  data: 0.000574  max mem: 4109
I20241204 10:10:31 2542585 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:12:39    time: 9.735887  data: 5.645409  max mem: 4109
I20241204 10:10:41 2542581 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:02    time: 4.446047  data: 0.427533  max mem: 4109
I20241204 10:10:55 2542582 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.853534  data: 0.001226  max mem: 4109
I20241204 10:10:55 2542583 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:08    time: 4.022791  data: 0.002247  max mem: 4109
I20241204 10:10:58 2542584 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.853675  data: 0.000601  max mem: 4109
I20241204 10:11:02 2542578 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.852997  data: 0.001478  max mem: 4109
I20241204 10:11:06 2542579 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.850768  data: 0.001865  max mem: 4109
I20241204 10:11:10 2542580 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.867142  data: 0.000597  max mem: 4109
I20241204 10:11:12 2542585 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:12    time: 4.602925  data: 0.515589  max mem: 4109
I20241204 10:11:14 2542582 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.222635  data: 0.001178  max mem: 4109
I20241204 10:11:14 2542582 dinov2 helpers.py:130]  Total time: 0:42:40 (4.038558 s / it)
I20241204 10:11:14 2542582 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:11:14 2542582 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:11:15 2542582 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:11:15 2542582 dinov2 loaders.py:151] sampler: distributed
I20241204 10:11:15 2542582 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:11:15 2542582 dinov2 loaders.py:223] # of batches: 78
I20241204 10:11:15 2542582 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:11:17 2542584 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.224947  data: 0.000508  max mem: 4109
I20241204 10:11:18 2542584 dinov2 helpers.py:130]  Total time: 0:42:45 (4.046397 s / it)
I20241204 10:11:18 2542584 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:11:18 2542584 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:11:18 2542584 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:11:18 2542584 dinov2 loaders.py:151] sampler: distributed
I20241204 10:11:18 2542584 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:11:18 2542584 dinov2 loaders.py:223] # of batches: 78
I20241204 10:11:18 2542584 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:11:20 2542581 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:04    time: 3.991773  data: 0.004514  max mem: 4109
I20241204 10:11:21 2542578 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.209507  data: 0.001401  max mem: 4109
I20241204 10:11:21 2542578 dinov2 helpers.py:130]  Total time: 0:42:49 (4.052109 s / it)
I20241204 10:11:21 2542578 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:11:21 2542578 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:11:22 2542578 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:11:22 2542578 dinov2 loaders.py:151] sampler: distributed
I20241204 10:11:22 2542578 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:11:22 2542578 dinov2 loaders.py:223] # of batches: 78
I20241204 10:11:22 2542578 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:11:23 2542579 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.159043  data: 0.000862  max mem: 4109
I20241204 10:11:24 2542579 dinov2 helpers.py:130]  Total time: 0:42:46 (4.048259 s / it)
I20241204 10:11:24 2542579 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:11:24 2542579 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:11:24 2542579 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:11:24 2542579 dinov2 loaders.py:151] sampler: distributed
I20241204 10:11:24 2542579 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:11:24 2542579 dinov2 loaders.py:223] # of batches: 78
I20241204 10:11:24 2542579 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:11:25 2542582 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:11:15    time: 8.664684  data: 5.725370  max mem: 4109
I20241204 10:11:26 2542580 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.094205  data: 0.000530  max mem: 4109
I20241204 10:11:26 2542580 dinov2 helpers.py:130]  Total time: 0:42:49 (4.052512 s / it)
I20241204 10:11:26 2542580 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241204 10:11:26 2542580 dinov2 utils.py:142] Labels shape: (162127,)
I20241204 10:11:26 2542580 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241204 10:11:26 2542580 dinov2 loaders.py:151] sampler: distributed
I20241204 10:11:26 2542580 dinov2 loaders.py:210] using PyTorch data loader
I20241204 10:11:26 2542580 dinov2 loaders.py:223] # of batches: 78
I20241204 10:11:27 2542580 dinov2 knn.py:299] Start the k-NN classification.
I20241204 10:11:28 2542584 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:12:12    time: 9.385420  data: 6.741971  max mem: 4109
I20241204 10:11:30 2542583 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:13    time: 3.740088  data: 0.004730  max mem: 4109
I20241204 10:11:34 2542578 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:15:27    time: 11.893804  data: 8.937809  max mem: 4109
I20241204 10:11:39 2542579 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:17:41    time: 13.607972  data: 10.121800  max mem: 4109
I20241204 10:11:43 2542580 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:19:40    time: 15.133628  data: 11.179066  max mem: 4109
I20241204 10:11:43 2542585 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:03:47    time: 3.630666  data: 0.005521  max mem: 4109
I20241204 10:11:53 2542581 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:08    time: 3.634740  data: 0.002741  max mem: 4109
I20241204 10:11:59 2542582 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:04:25    time: 3.906785  data: 0.528509  max mem: 4109
I20241204 10:12:05 2542584 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:04:42    time: 4.159757  data: 0.615940  max mem: 4109
I20241204 10:12:07 2542583 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:30    time: 3.611634  data: 0.007248  max mem: 4109
I20241204 10:12:14 2542578 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:16    time: 4.660074  data: 0.818208  max mem: 4109
I20241204 10:12:19 2542579 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:31    time: 4.877626  data: 0.931445  max mem: 4109
I20241204 10:12:23 2542580 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:41    time: 5.026421  data: 1.022264  max mem: 4109
I20241204 10:12:23 2542585 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:09    time: 3.584557  data: 0.006977  max mem: 4109
I20241204 10:12:33 2542581 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:29    time: 3.653572  data: 0.005921  max mem: 4109
I20241204 10:12:39 2542582 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:03:48    time: 3.711481  data: 0.007718  max mem: 4109
I20241204 10:12:45 2542584 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:03:57    time: 3.823829  data: 0.005993  max mem: 4109
I20241204 10:12:47 2542583 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:50    time: 3.871425  data: 0.004981  max mem: 4109
I20241204 10:12:54 2542578 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:12    time: 3.972298  data: 0.005306  max mem: 4109
I20241204 10:12:59 2542579 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:18    time: 4.000923  data: 0.009196  max mem: 4109
I20241204 10:13:03 2542580 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:23    time: 4.009419  data: 0.004803  max mem: 4109
I20241204 10:13:03 2542585 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:30    time: 3.998812  data: 0.005228  max mem: 4109
I20241204 10:13:13 2542581 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:50    time: 3.997782  data: 0.007051  max mem: 4109
I20241204 10:13:19 2542582 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:10    time: 3.992009  data: 0.006783  max mem: 4109
I20241204 10:13:25 2542584 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:14    time: 4.008980  data: 0.005870  max mem: 4109
I20241204 10:13:27 2542583 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:11    time: 4.012664  data: 0.004328  max mem: 4109
I20241204 10:13:34 2542578 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:23    time: 4.005633  data: 0.004895  max mem: 4109
I20241204 10:13:39 2542579 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:26    time: 3.993243  data: 0.006726  max mem: 4109
I20241204 10:13:43 2542580 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:29    time: 3.998914  data: 0.005273  max mem: 4109
I20241204 10:13:43 2542585 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:51    time: 3.999327  data: 0.008425  max mem: 4109
I20241204 10:13:53 2542581 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:11    time: 3.994688  data: 0.005209  max mem: 4109
I20241204 10:13:59 2542582 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:30    time: 3.993056  data: 0.009824  max mem: 4109
I20241204 10:14:05 2542584 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:33    time: 4.009305  data: 0.002928  max mem: 4109
I20241204 10:14:08 2542583 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:31    time: 4.025664  data: 0.004005  max mem: 4109
I20241204 10:14:14 2542578 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:38    time: 4.001054  data: 0.007719  max mem: 4109
I20241204 10:14:19 2542579 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:40    time: 3.997226  data: 0.004774  max mem: 4109
I20241204 10:14:23 2542580 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:42    time: 4.002196  data: 0.005299  max mem: 4109
I20241204 10:14:23 2542585 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:11    time: 3.996685  data: 0.010287  max mem: 4109
I20241204 10:14:33 2542581 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:31    time: 3.993025  data: 0.006663  max mem: 4109
I20241204 10:14:34 2542583 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 3.920480  data: 0.001218  max mem: 4109
I20241204 10:14:34 2542583 dinov2 helpers.py:130] Test: Total time: 0:05:08 (3.957365 s / it)
I20241204 10:14:34 2542583 dinov2 utils.py:79] Averaged stats: 
I20241204 10:14:35 2542583 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:14:35 2542583 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:14:35 2542583 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:14:35 2542583 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:14:36 2542583 submitit submission.py:56] Job completed successfully
I20241204 10:14:36 2542583 submitit submission.py:61] Exiting after successful completion
I20241204 10:14:38 2542582 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:50    time: 3.954475  data: 0.009177  max mem: 4109
I20241204 10:14:44 2542584 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:52    time: 3.959440  data: 0.005263  max mem: 4109
I20241204 10:14:51 2542578 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:54    time: 3.860029  data: 0.007041  max mem: 4109
I20241204 10:14:55 2542579 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:55    time: 3.833454  data: 0.004746  max mem: 4109
I20241204 10:14:56 2542581 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 3.757114  data: 0.004128  max mem: 4109
I20241204 10:14:56 2542581 dinov2 helpers.py:130] Test: Total time: 0:05:04 (3.905824 s / it)
I20241204 10:14:56 2542581 dinov2 utils.py:79] Averaged stats: 
I20241204 10:14:58 2542581 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:14:58 2542581 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:14:58 2542581 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:14:58 2542581 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:14:58 2542581 submitit submission.py:56] Job completed successfully
I20241204 10:14:58 2542581 submitit submission.py:61] Exiting after successful completion
I20241204 10:14:59 2542580 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:55    time: 3.797821  data: 0.003809  max mem: 4109
I20241204 10:14:59 2542585 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:31    time: 3.775843  data: 0.007667  max mem: 4109
I20241204 10:15:10 2542582 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:09    time: 3.579206  data: 0.005806  max mem: 4109
I20241204 10:15:16 2542584 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:09    time: 3.538411  data: 0.005313  max mem: 4109
I20241204 10:15:19 2542585 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 3.361283  data: 0.004667  max mem: 4109
I20241204 10:15:19 2542585 dinov2 helpers.py:130] Test: Total time: 0:04:57 (3.814991 s / it)
I20241204 10:15:19 2542585 dinov2 utils.py:79] Averaged stats: 
I20241204 10:15:20 2542585 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:15:20 2542585 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:15:20 2542585 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:15:20 2542585 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:15:20 2542585 submitit submission.py:56] Job completed successfully
I20241204 10:15:20 2542585 submitit submission.py:61] Exiting after successful completion
I20241204 10:15:21 2542578 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:10    time: 3.368375  data: 0.003935  max mem: 4109
I20241204 10:15:24 2542579 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:10    time: 3.273891  data: 0.007037  max mem: 4109
I20241204 10:15:27 2542580 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:10    time: 3.214265  data: 0.007778  max mem: 4109
I20241204 10:15:37 2542582 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:29    time: 2.937565  data: 0.004593  max mem: 4109
I20241204 10:15:41 2542584 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:29    time: 2.862814  data: 0.002158  max mem: 4109
I20241204 10:15:46 2542578 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:29    time: 2.766128  data: 0.004635  max mem: 4109
I20241204 10:15:49 2542579 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:29    time: 2.684358  data: 0.004757  max mem: 4109
I20241204 10:15:52 2542580 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:29    time: 2.669774  data: 0.006864  max mem: 4109
I20241204 10:15:53 2542582 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.578204  data: 0.002259  max mem: 4109
I20241204 10:15:53 2542582 dinov2 helpers.py:130] Test: Total time: 0:04:36 (3.549876 s / it)
I20241204 10:15:53 2542582 dinov2 utils.py:79] Averaged stats: 
I20241204 10:15:54 2542582 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:15:54 2542582 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:15:54 2542582 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:15:54 2542582 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:15:54 2542582 submitit submission.py:56] Job completed successfully
I20241204 10:15:54 2542582 submitit submission.py:61] Exiting after successful completion
I20241204 10:15:57 2542584 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.522635  data: 0.001170  max mem: 4109
I20241204 10:15:57 2542584 dinov2 helpers.py:130] Test: Total time: 0:04:38 (3.567859 s / it)
I20241204 10:15:57 2542584 dinov2 utils.py:79] Averaged stats: 
I20241204 10:15:58 2542584 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:15:58 2542584 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:15:58 2542584 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:15:58 2542584 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:15:58 2542584 submitit submission.py:56] Job completed successfully
I20241204 10:15:58 2542584 submitit submission.py:61] Exiting after successful completion
I20241204 10:16:00 2542578 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.336637  data: 0.002991  max mem: 4109
I20241204 10:16:00 2542578 dinov2 helpers.py:130] Test: Total time: 0:04:37 (3.552709 s / it)
I20241204 10:16:00 2542578 dinov2 utils.py:79] Averaged stats: 
I20241204 10:16:00 2542578 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:16:00 2542578 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:16:00 2542578 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:16:00 2542578 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:16:00 2542578 submitit submission.py:56] Job completed successfully
I20241204 10:16:00 2542578 submitit submission.py:61] Exiting after successful completion
I20241204 10:16:01 2542579 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.213742  data: 0.002307  max mem: 4109
I20241204 10:16:01 2542579 dinov2 helpers.py:130] Test: Total time: 0:04:35 (3.533278 s / it)
I20241204 10:16:01 2542579 dinov2 utils.py:79] Averaged stats: 
I20241204 10:16:01 2542579 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.15
I20241204 10:16:01 2542579 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.03
I20241204 10:16:01 2542579 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:16:01 2542579 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.92
I20241204 10:16:01 2542579 submitit submission.py:56] Job completed successfully
I20241204 10:16:01 2542579 submitit submission.py:61] Exiting after successful completion
I20241204 10:16:01 2542580 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.071018  data: 0.003723  max mem: 4109
I20241204 10:16:01 2542580 dinov2 helpers.py:130] Test: Total time: 0:04:33 (3.508012 s / it)
I20241204 10:16:01 2542580 dinov2 utils.py:79] Averaged stats: 
I20241204 10:16:01 2542580 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 71.11
I20241204 10:16:01 2542580 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 72.04
I20241204 10:16:01 2542580 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 73.03
I20241204 10:16:01 2542580 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 72.93
I20241204 10:16:01 2542580 submitit submission.py:56] Job completed successfully
I20241204 10:16:01 2542580 submitit submission.py:61] Exiting after successful completion

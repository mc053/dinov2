I20241203 08:52:49 2006645 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:49 2006645 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:49 2006645 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:49 2006645 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:49 2006639 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:49 2006639 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:49 2006639 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:49 2006639 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:49 2006645 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:49 2006638 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:49 2006638 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:49 2006638 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:49 2006638 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:49 2006639 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:49 2006638 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:49 2006644 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:49 2006644 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:49 2006644 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:49 2006644 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:50 2006644 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:50 2006641 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:50 2006640 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:50 2006641 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:50 2006640 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:50 2006640 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:50 2006641 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:50 2006640 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:50 2006641 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:50 2006640 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:50 2006641 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:50 2006642 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:50 2006642 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:50 2006642 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:50 2006642 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:50 2006643 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 08:52:50 2006643 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 08:52:50 2006643 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 08:52:50 2006643 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 08:52:50 2006642 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:52:50 2006643 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 08:53:15 2006639 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:18 2006641 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:18 2006643 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:20 2006639 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:21 2006639 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:23 2006641 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:23 2006643 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:23 2006645 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:24 2006641 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:24 2006638 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:24 2006643 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:24 2006640 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:24 2006644 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:25 2006642 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 08:53:27 2006645 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:27 2006645 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:28 2006644 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:28 2006644 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:28 2006638 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:29 2006640 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:29 2006638 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:29 2006640 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:29 2006642 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 08:53:29 2006642 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 08:53:31 2006641 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:31 2006641 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:31 2006639 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:31 2006639 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:32 2006643 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:32 2006643 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:33 2006641 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:33 2006641 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:33 2006641 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:33 2006641 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:33 2006641 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:33 2006641 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:33 2006639 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:33 2006639 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:33 2006639 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:33 2006639 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:33 2006639 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:33 2006639 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:35 2006643 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:35 2006643 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:35 2006643 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:35 2006643 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:35 2006643 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:35 2006643 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:36 2006645 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:36 2006645 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:38 2006644 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:38 2006644 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:40 2006640 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:40 2006640 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:40 2006638 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:40 2006638 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:41 2006642 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 08:53:41 2006642 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 08:53:41 2006645 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:41 2006645 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:41 2006645 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:41 2006645 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:41 2006645 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:41 2006645 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:44 2006644 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:44 2006644 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:44 2006644 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:44 2006644 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:44 2006644 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:44 2006644 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:46 2006640 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:46 2006640 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:46 2006640 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:46 2006640 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:46 2006640 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:46 2006640 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:47 2006638 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:47 2006638 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:47 2006638 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:47 2006638 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:47 2006638 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:47 2006638 dinov2 loaders.py:223] # of batches: 634
I20241203 08:53:48 2006642 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 08:53:48 2006642 dinov2 knn.py:260] Extracting features for train set...
I20241203 08:53:48 2006642 dinov2 loaders.py:151] sampler: distributed
I20241203 08:53:48 2006642 dinov2 loaders.py:210] using PyTorch data loader
W20241203 08:53:48 2006642 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 08:53:48 2006642 dinov2 loaders.py:223] # of batches: 634
I20241203 08:54:06 2006641 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:06 2006639 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:06 2006639 dinov2 helpers.py:102]   [  0/634]  eta: 5:48:45    time: 33.006252  data: 12.284622  max mem: 3464
I20241203 08:54:06 2006641 dinov2 helpers.py:102]   [  0/634]  eta: 5:49:25    time: 33.069366  data: 14.145161  max mem: 3464
I20241203 08:54:12 2006643 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:12 2006643 dinov2 helpers.py:102]   [  0/634]  eta: 6:37:35    time: 37.627125  data: 15.110686  max mem: 3463
I20241203 08:54:15 2006639 dinov2 helpers.py:102]   [ 10/634]  eta: 0:40:03    time: 3.851883  data: 1.118505  max mem: 4109
I20241203 08:54:15 2006641 dinov2 helpers.py:102]   [ 10/634]  eta: 0:40:15    time: 3.871505  data: 1.287405  max mem: 4109
I20241203 08:54:25 2006643 dinov2 helpers.py:102]   [ 10/634]  eta: 0:47:12    time: 4.539339  data: 1.374440  max mem: 4109
I20241203 08:54:27 2006645 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:27 2006645 dinov2 helpers.py:102]   [  0/634]  eta: 8:15:20    time: 46.877094  data: 17.607922  max mem: 3463
I20241203 08:54:31 2006640 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:31 2006640 dinov2 helpers.py:102]   [  0/634]  eta: 7:52:59    time: 44.763302  data: 12.147860  max mem: 3463
I20241203 08:54:31 2006641 dinov2 helpers.py:102]   [ 20/634]  eta: 0:28:36    time: 1.282313  data: 0.001297  max mem: 4109
I20241203 08:54:31 2006639 dinov2 helpers.py:102]   [ 20/634]  eta: 0:28:36    time: 1.284249  data: 0.002330  max mem: 4109
I20241203 08:54:33 2006644 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:33 2006644 dinov2 helpers.py:102]   [  0/634]  eta: 8:35:17    time: 48.765141  data: 15.988430  max mem: 3463
I20241203 08:54:35 2006638 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:35 2006638 dinov2 helpers.py:102]   [  0/634]  eta: 8:30:51    time: 48.346291  data: 15.409015  max mem: 3463
I20241203 08:54:35 2006642 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 08:54:35 2006642 dinov2 helpers.py:102]   [  0/634]  eta: 8:21:48    time: 47.489548  data: 16.730663  max mem: 3464
I20241203 08:54:55 2006643 dinov2 helpers.py:102]   [ 20/634]  eta: 0:39:10    time: 2.138731  data: 0.000730  max mem: 4109
I20241203 08:54:55 2006645 dinov2 helpers.py:102]   [ 10/634]  eta: 1:10:37    time: 6.790237  data: 1.602028  max mem: 4109
I20241203 08:55:02 2006640 dinov2 helpers.py:102]   [ 10/634]  eta: 1:11:32    time: 6.878449  data: 1.105604  max mem: 4109
I20241203 08:55:05 2006644 dinov2 helpers.py:102]   [ 10/634]  eta: 1:16:15    time: 7.332472  data: 1.457364  max mem: 4109
I20241203 08:55:07 2006638 dinov2 helpers.py:102]   [ 10/634]  eta: 1:16:11    time: 7.325563  data: 1.404315  max mem: 4109
I20241203 08:55:07 2006642 dinov2 helpers.py:102]   [ 10/634]  eta: 1:15:21    time: 7.245647  data: 1.522142  max mem: 4109
I20241203 08:55:10 2006641 dinov2 helpers.py:102]   [ 30/634]  eta: 0:31:28    time: 2.718040  data: 0.001093  max mem: 4109
I20241203 08:55:10 2006639 dinov2 helpers.py:102]   [ 30/634]  eta: 0:31:29    time: 2.730355  data: 0.001842  max mem: 4109
I20241203 08:55:35 2006643 dinov2 helpers.py:102]   [ 30/634]  eta: 0:38:55    time: 3.495932  data: 0.001042  max mem: 4109
I20241203 08:55:35 2006645 dinov2 helpers.py:102]   [ 20/634]  eta: 0:55:36    time: 3.362174  data: 0.000998  max mem: 4109
I20241203 08:55:41 2006640 dinov2 helpers.py:102]   [ 20/634]  eta: 0:56:06    time: 3.519510  data: 0.001923  max mem: 4109
I20241203 08:55:44 2006644 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:33    time: 3.570991  data: 0.002572  max mem: 4109
I20241203 08:55:47 2006638 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:31    time: 3.587852  data: 0.002445  max mem: 4109
I20241203 08:55:47 2006642 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:10    time: 3.594160  data: 0.001254  max mem: 4109
I20241203 08:55:49 2006641 dinov2 helpers.py:102]   [ 40/634]  eta: 0:32:58    time: 3.892244  data: 0.001347  max mem: 4109
I20241203 08:55:49 2006639 dinov2 helpers.py:102]   [ 40/634]  eta: 0:32:59    time: 3.895993  data: 0.000750  max mem: 4109
I20241203 08:56:14 2006643 dinov2 helpers.py:102]   [ 40/634]  eta: 0:38:29    time: 3.950534  data: 0.001189  max mem: 4109
I20241203 08:56:14 2006645 dinov2 helpers.py:102]   [ 30/634]  eta: 0:49:54    time: 3.949516  data: 0.000585  max mem: 4109
I20241203 08:56:21 2006640 dinov2 helpers.py:102]   [ 30/634]  eta: 0:50:15    time: 3.954242  data: 0.001690  max mem: 4109
I20241203 08:56:24 2006644 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:52    time: 3.955061  data: 0.001108  max mem: 4109
I20241203 08:56:26 2006638 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:50    time: 3.954007  data: 0.000881  max mem: 4109
I20241203 08:56:27 2006642 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:39    time: 3.969493  data: 0.001288  max mem: 4109
I20241203 08:56:29 2006641 dinov2 helpers.py:102]   [ 50/634]  eta: 0:33:38    time: 3.966665  data: 0.001193  max mem: 4109
I20241203 08:56:29 2006639 dinov2 helpers.py:102]   [ 50/634]  eta: 0:33:39    time: 3.967729  data: 0.000632  max mem: 4109
I20241203 08:56:54 2006643 dinov2 helpers.py:102]   [ 50/634]  eta: 0:37:58    time: 3.957024  data: 0.000995  max mem: 4109
I20241203 08:56:54 2006645 dinov2 helpers.py:102]   [ 40/634]  eta: 0:46:39    time: 3.957082  data: 0.000829  max mem: 4109
I20241203 08:57:00 2006640 dinov2 helpers.py:102]   [ 40/634]  eta: 0:46:55    time: 3.958767  data: 0.001441  max mem: 4109
I20241203 08:57:04 2006644 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:08    time: 3.960294  data: 0.001203  max mem: 4109
I20241203 08:57:06 2006638 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:06    time: 3.956923  data: 0.001772  max mem: 4109
I20241203 08:57:07 2006642 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:00    time: 3.972960  data: 0.001123  max mem: 4109
I20241203 08:57:09 2006641 dinov2 helpers.py:102]   [ 60/634]  eta: 0:33:52    time: 3.972153  data: 0.001648  max mem: 4109
I20241203 08:57:09 2006639 dinov2 helpers.py:102]   [ 60/634]  eta: 0:33:53    time: 3.972223  data: 0.000793  max mem: 4109
I20241203 08:57:33 2006643 dinov2 helpers.py:102]   [ 60/634]  eta: 0:37:25    time: 3.963622  data: 0.000915  max mem: 4109
I20241203 08:57:34 2006645 dinov2 helpers.py:102]   [ 50/634]  eta: 0:44:27    time: 3.962741  data: 0.000832  max mem: 4109
I20241203 08:57:40 2006640 dinov2 helpers.py:102]   [ 50/634]  eta: 0:44:39    time: 3.964629  data: 0.001668  max mem: 4109
I20241203 08:57:43 2006644 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:37    time: 3.966547  data: 0.001230  max mem: 4109
I20241203 08:57:46 2006638 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:36    time: 3.965673  data: 0.002746  max mem: 4109
I20241203 08:57:46 2006642 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:31    time: 3.973865  data: 0.001565  max mem: 4109
I20241203 08:57:48 2006641 dinov2 helpers.py:102]   [ 70/634]  eta: 0:33:51    time: 3.974777  data: 0.001862  max mem: 4109
I20241203 08:57:49 2006639 dinov2 helpers.py:102]   [ 70/634]  eta: 0:33:52    time: 3.975492  data: 0.001353  max mem: 4109
I20241203 08:58:13 2006643 dinov2 helpers.py:102]   [ 70/634]  eta: 0:36:51    time: 3.971361  data: 0.000840  max mem: 4109
I20241203 08:58:13 2006645 dinov2 helpers.py:102]   [ 60/634]  eta: 0:42:45    time: 3.970624  data: 0.000648  max mem: 4109
I20241203 08:58:20 2006640 dinov2 helpers.py:102]   [ 60/634]  eta: 0:42:56    time: 3.972303  data: 0.001000  max mem: 4109
I20241203 08:58:23 2006644 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:43    time: 3.971600  data: 0.001144  max mem: 4109
I20241203 08:58:25 2006638 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:42    time: 3.974223  data: 0.001757  max mem: 4109
I20241203 08:58:26 2006642 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:38    time: 3.974367  data: 0.002884  max mem: 4109
I20241203 08:58:28 2006641 dinov2 helpers.py:102]   [ 80/634]  eta: 0:33:41    time: 3.979007  data: 0.001216  max mem: 4109
I20241203 08:58:28 2006639 dinov2 helpers.py:102]   [ 80/634]  eta: 0:33:41    time: 3.976069  data: 0.001342  max mem: 4109
I20241203 08:58:53 2006643 dinov2 helpers.py:102]   [ 80/634]  eta: 0:36:16    time: 3.973506  data: 0.000865  max mem: 4109
I20241203 08:58:53 2006645 dinov2 helpers.py:102]   [ 70/634]  eta: 0:41:21    time: 3.974424  data: 0.000752  max mem: 4109
I20241203 08:59:00 2006640 dinov2 helpers.py:102]   [ 70/634]  eta: 0:41:30    time: 3.973554  data: 0.000829  max mem: 4109
I20241203 08:59:03 2006644 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:10    time: 3.973606  data: 0.000827  max mem: 4109
I20241203 08:59:05 2006638 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:09    time: 3.974395  data: 0.002166  max mem: 4109
I20241203 08:59:06 2006642 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:07    time: 3.978814  data: 0.002495  max mem: 4109
I20241203 08:59:08 2006641 dinov2 helpers.py:102]   [ 90/634]  eta: 0:33:24    time: 3.977039  data: 0.000906  max mem: 4109
I20241203 08:59:08 2006639 dinov2 helpers.py:102]   [ 90/634]  eta: 0:33:24    time: 3.976272  data: 0.000745  max mem: 4109
I20241203 08:59:33 2006643 dinov2 helpers.py:102]   [ 90/634]  eta: 0:35:39    time: 3.973644  data: 0.001230  max mem: 4109
I20241203 08:59:33 2006645 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:08    time: 3.974389  data: 0.000854  max mem: 4109
I20241203 08:59:39 2006640 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:16    time: 3.973644  data: 0.000916  max mem: 4109
I20241203 08:59:42 2006644 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:50    time: 3.973705  data: 0.000737  max mem: 4109
I20241203 08:59:45 2006638 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:49    time: 3.973693  data: 0.003314  max mem: 4109
I20241203 08:59:46 2006642 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:47    time: 3.978137  data: 0.001156  max mem: 4109
I20241203 08:59:48 2006641 dinov2 helpers.py:102]   [100/634]  eta: 0:33:03    time: 3.975398  data: 0.000740  max mem: 4109
I20241203 08:59:48 2006639 dinov2 helpers.py:102]   [100/634]  eta: 0:33:03    time: 3.978193  data: 0.000725  max mem: 4109
I20241203 09:00:12 2006643 dinov2 helpers.py:102]   [100/634]  eta: 0:35:02    time: 3.973584  data: 0.001429  max mem: 4109
I20241203 09:00:12 2006645 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:02    time: 3.972586  data: 0.001240  max mem: 4109
I20241203 09:00:19 2006640 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:09    time: 3.972538  data: 0.000702  max mem: 4109
I20241203 09:00:22 2006644 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:39    time: 3.971549  data: 0.001432  max mem: 4109
I20241203 09:00:25 2006638 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:38    time: 3.973505  data: 0.002122  max mem: 4109
I20241203 09:00:25 2006642 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:36    time: 3.973394  data: 0.000779  max mem: 4109
I20241203 09:00:28 2006641 dinov2 helpers.py:102]   [110/634]  eta: 0:32:38    time: 3.975281  data: 0.000885  max mem: 4109
I20241203 09:00:28 2006639 dinov2 helpers.py:102]   [110/634]  eta: 0:32:38    time: 3.975204  data: 0.000943  max mem: 4109
I20241203 09:00:52 2006643 dinov2 helpers.py:102]   [110/634]  eta: 0:34:24    time: 3.973266  data: 0.000896  max mem: 4109
I20241203 09:00:52 2006645 dinov2 helpers.py:102]   [100/634]  eta: 0:38:01    time: 3.972359  data: 0.001131  max mem: 4109
I20241203 09:00:59 2006640 dinov2 helpers.py:102]   [100/634]  eta: 0:38:07    time: 3.971358  data: 0.000843  max mem: 4109
I20241203 09:01:02 2006644 dinov2 helpers.py:102]   [100/634]  eta: 0:38:34    time: 3.969519  data: 0.001617  max mem: 4109
I20241203 09:01:04 2006638 dinov2 helpers.py:102]   [100/634]  eta: 0:38:33    time: 3.971288  data: 0.001099  max mem: 4109
I20241203 09:01:05 2006642 dinov2 helpers.py:102]   [100/634]  eta: 0:38:32    time: 3.974021  data: 0.001003  max mem: 4109
I20241203 09:01:07 2006641 dinov2 helpers.py:102]   [120/634]  eta: 0:32:10    time: 3.973026  data: 0.001226  max mem: 4109
I20241203 09:01:07 2006639 dinov2 helpers.py:102]   [120/634]  eta: 0:32:11    time: 3.973089  data: 0.001225  max mem: 4109
I20241203 09:01:32 2006643 dinov2 helpers.py:102]   [120/634]  eta: 0:33:46    time: 3.970431  data: 0.000702  max mem: 4109
I20241203 09:01:32 2006645 dinov2 helpers.py:102]   [110/634]  eta: 0:37:04    time: 3.972275  data: 0.001019  max mem: 4109
I20241203 09:01:39 2006640 dinov2 helpers.py:102]   [110/634]  eta: 0:37:09    time: 3.970416  data: 0.000971  max mem: 4109
I20241203 09:01:42 2006644 dinov2 helpers.py:102]   [110/634]  eta: 0:37:33    time: 3.969463  data: 0.000877  max mem: 4109
I20241203 09:01:44 2006638 dinov2 helpers.py:102]   [110/634]  eta: 0:37:33    time: 3.971183  data: 0.001165  max mem: 4109
I20241203 09:01:45 2006642 dinov2 helpers.py:102]   [110/634]  eta: 0:37:32    time: 3.974872  data: 0.001094  max mem: 4109
I20241203 09:01:47 2006641 dinov2 helpers.py:102]   [130/634]  eta: 0:31:41    time: 3.974794  data: 0.001252  max mem: 4109
I20241203 09:01:47 2006639 dinov2 helpers.py:102]   [130/634]  eta: 0:31:41    time: 3.973344  data: 0.001208  max mem: 4109
I20241203 09:02:11 2006643 dinov2 helpers.py:102]   [130/634]  eta: 0:33:08    time: 3.969515  data: 0.001019  max mem: 4109
I20241203 09:02:12 2006645 dinov2 helpers.py:102]   [120/634]  eta: 0:36:10    time: 3.971351  data: 0.001260  max mem: 4109
I20241203 09:02:18 2006640 dinov2 helpers.py:102]   [120/634]  eta: 0:36:15    time: 3.971340  data: 0.000764  max mem: 4109
I20241203 09:02:21 2006644 dinov2 helpers.py:102]   [120/634]  eta: 0:36:36    time: 3.970502  data: 0.000605  max mem: 4109
I20241203 09:02:24 2006638 dinov2 helpers.py:102]   [120/634]  eta: 0:36:36    time: 3.972164  data: 0.001978  max mem: 4109
I20241203 09:02:25 2006642 dinov2 helpers.py:102]   [120/634]  eta: 0:36:35    time: 3.973935  data: 0.000718  max mem: 4109
I20241203 09:02:27 2006641 dinov2 helpers.py:102]   [140/634]  eta: 0:31:11    time: 3.974886  data: 0.000987  max mem: 4109
I20241203 09:02:27 2006639 dinov2 helpers.py:102]   [140/634]  eta: 0:31:11    time: 3.973022  data: 0.000749  max mem: 4109
I20241203 09:02:51 2006643 dinov2 helpers.py:102]   [140/634]  eta: 0:32:29    time: 3.969259  data: 0.001244  max mem: 4109
I20241203 09:02:51 2006645 dinov2 helpers.py:102]   [130/634]  eta: 0:35:18    time: 3.971984  data: 0.001431  max mem: 4109
I20241203 09:02:58 2006640 dinov2 helpers.py:102]   [130/634]  eta: 0:35:22    time: 3.971125  data: 0.000609  max mem: 4109
I20241203 09:03:01 2006644 dinov2 helpers.py:102]   [130/634]  eta: 0:35:41    time: 3.967693  data: 0.000528  max mem: 4109
I20241203 09:03:03 2006638 dinov2 helpers.py:102]   [130/634]  eta: 0:35:42    time: 3.970378  data: 0.001850  max mem: 4109
I20241203 09:03:04 2006642 dinov2 helpers.py:102]   [130/634]  eta: 0:35:41    time: 3.973906  data: 0.000744  max mem: 4109
I20241203 09:03:07 2006641 dinov2 helpers.py:102]   [150/634]  eta: 0:30:39    time: 3.973883  data: 0.000835  max mem: 4109
I20241203 09:03:07 2006639 dinov2 helpers.py:102]   [150/634]  eta: 0:30:39    time: 3.972718  data: 0.000739  max mem: 4109
I20241203 09:03:31 2006643 dinov2 helpers.py:102]   [150/634]  eta: 0:31:50    time: 3.968311  data: 0.001051  max mem: 4109
I20241203 09:03:31 2006645 dinov2 helpers.py:102]   [140/634]  eta: 0:34:28    time: 3.972808  data: 0.001887  max mem: 4109
I20241203 09:03:38 2006640 dinov2 helpers.py:102]   [140/634]  eta: 0:34:32    time: 3.969186  data: 0.000536  max mem: 4109
I20241203 09:03:41 2006644 dinov2 helpers.py:102]   [140/634]  eta: 0:34:49    time: 3.964628  data: 0.000866  max mem: 4109
I20241203 09:03:43 2006638 dinov2 helpers.py:102]   [140/634]  eta: 0:34:49    time: 3.970151  data: 0.002086  max mem: 4109
I20241203 09:03:44 2006642 dinov2 helpers.py:102]   [140/634]  eta: 0:34:49    time: 3.974699  data: 0.003963  max mem: 4109
I20241203 09:03:46 2006641 dinov2 helpers.py:102]   [160/634]  eta: 0:30:06    time: 3.973701  data: 0.000600  max mem: 4109
I20241203 09:03:46 2006639 dinov2 helpers.py:102]   [160/634]  eta: 0:30:06    time: 3.972882  data: 0.000953  max mem: 4109
I20241203 09:04:10 2006643 dinov2 helpers.py:102]   [160/634]  eta: 0:31:11    time: 3.967601  data: 0.000812  max mem: 4109
I20241203 09:04:11 2006645 dinov2 helpers.py:102]   [150/634]  eta: 0:33:39    time: 3.971210  data: 0.001398  max mem: 4109
I20241203 09:04:17 2006640 dinov2 helpers.py:102]   [150/634]  eta: 0:33:43    time: 3.969455  data: 0.000814  max mem: 4109
I20241203 09:04:20 2006644 dinov2 helpers.py:102]   [150/634]  eta: 0:33:58    time: 3.969474  data: 0.001131  max mem: 4109
I20241203 09:04:23 2006638 dinov2 helpers.py:102]   [150/634]  eta: 0:33:59    time: 3.970329  data: 0.003082  max mem: 4109
I20241203 09:04:24 2006642 dinov2 helpers.py:102]   [150/634]  eta: 0:33:58    time: 3.973974  data: 0.003977  max mem: 4109
I20241203 09:04:26 2006641 dinov2 helpers.py:102]   [170/634]  eta: 0:29:32    time: 3.973199  data: 0.001140  max mem: 4109
I20241203 09:04:26 2006639 dinov2 helpers.py:102]   [170/634]  eta: 0:29:32    time: 3.973119  data: 0.000777  max mem: 4109
I20241203 09:04:50 2006643 dinov2 helpers.py:102]   [170/634]  eta: 0:30:32    time: 3.969208  data: 0.001578  max mem: 4109
I20241203 09:04:51 2006645 dinov2 helpers.py:102]   [160/634]  eta: 0:32:52    time: 3.971492  data: 0.001765  max mem: 4109
I20241203 09:04:57 2006640 dinov2 helpers.py:102]   [160/634]  eta: 0:32:55    time: 3.969820  data: 0.001027  max mem: 4109
I20241203 09:05:00 2006644 dinov2 helpers.py:102]   [160/634]  eta: 0:33:09    time: 3.972467  data: 0.000877  max mem: 4109
I20241203 09:05:03 2006638 dinov2 helpers.py:102]   [160/634]  eta: 0:33:09    time: 3.970685  data: 0.002037  max mem: 4109
I20241203 09:05:03 2006642 dinov2 helpers.py:102]   [160/634]  eta: 0:33:09    time: 3.973370  data: 0.000947  max mem: 4109
I20241203 09:05:06 2006641 dinov2 helpers.py:102]   [180/634]  eta: 0:28:58    time: 3.973421  data: 0.001494  max mem: 4109
I20241203 09:05:06 2006639 dinov2 helpers.py:102]   [180/634]  eta: 0:28:58    time: 3.973407  data: 0.000695  max mem: 4109
I20241203 09:05:30 2006643 dinov2 helpers.py:102]   [180/634]  eta: 0:29:53    time: 3.972593  data: 0.001646  max mem: 4109
I20241203 09:05:30 2006645 dinov2 helpers.py:102]   [170/634]  eta: 0:32:05    time: 3.973501  data: 0.001894  max mem: 4109
I20241203 09:05:37 2006640 dinov2 helpers.py:102]   [170/634]  eta: 0:32:08    time: 3.969889  data: 0.000990  max mem: 4109
I20241203 09:05:40 2006644 dinov2 helpers.py:102]   [170/634]  eta: 0:32:21    time: 3.969772  data: 0.001069  max mem: 4109
I20241203 09:05:42 2006638 dinov2 helpers.py:102]   [170/634]  eta: 0:32:21    time: 3.972550  data: 0.001205  max mem: 4109
I20241203 09:05:43 2006642 dinov2 helpers.py:102]   [170/634]  eta: 0:32:21    time: 3.974340  data: 0.000957  max mem: 4109
I20241203 09:05:45 2006641 dinov2 helpers.py:102]   [190/634]  eta: 0:28:23    time: 3.973621  data: 0.000904  max mem: 4109
I20241203 09:05:45 2006639 dinov2 helpers.py:102]   [190/634]  eta: 0:28:23    time: 3.973420  data: 0.001546  max mem: 4109
I20241203 09:06:10 2006643 dinov2 helpers.py:102]   [190/634]  eta: 0:29:14    time: 3.973114  data: 0.000978  max mem: 4109
I20241203 09:06:10 2006645 dinov2 helpers.py:102]   [180/634]  eta: 0:31:19    time: 3.973506  data: 0.000731  max mem: 4109
I20241203 09:06:16 2006640 dinov2 helpers.py:102]   [180/634]  eta: 0:31:21    time: 3.969929  data: 0.000918  max mem: 4109
I20241203 09:06:19 2006644 dinov2 helpers.py:102]   [180/634]  eta: 0:31:34    time: 3.970014  data: 0.001718  max mem: 4109
I20241203 09:06:22 2006638 dinov2 helpers.py:102]   [180/634]  eta: 0:31:34    time: 3.973673  data: 0.001121  max mem: 4109
I20241203 09:06:23 2006642 dinov2 helpers.py:102]   [180/634]  eta: 0:31:34    time: 3.974478  data: 0.001064  max mem: 4109
I20241203 09:06:25 2006641 dinov2 helpers.py:102]   [200/634]  eta: 0:27:47    time: 3.973616  data: 0.000758  max mem: 4109
I20241203 09:06:25 2006639 dinov2 helpers.py:102]   [200/634]  eta: 0:27:47    time: 3.974528  data: 0.001505  max mem: 4109
I20241203 09:06:49 2006643 dinov2 helpers.py:102]   [200/634]  eta: 0:28:35    time: 3.973951  data: 0.001037  max mem: 4109
I20241203 09:06:50 2006645 dinov2 helpers.py:102]   [190/634]  eta: 0:30:34    time: 3.972722  data: 0.000541  max mem: 4109
I20241203 09:06:56 2006640 dinov2 helpers.py:102]   [190/634]  eta: 0:30:36    time: 3.971795  data: 0.000743  max mem: 4109
I20241203 09:06:59 2006644 dinov2 helpers.py:102]   [190/634]  eta: 0:30:47    time: 3.970901  data: 0.001419  max mem: 4109
I20241203 09:07:02 2006638 dinov2 helpers.py:102]   [190/634]  eta: 0:30:48    time: 3.973536  data: 0.000823  max mem: 4109
I20241203 09:07:03 2006642 dinov2 helpers.py:102]   [190/634]  eta: 0:30:48    time: 3.973619  data: 0.001228  max mem: 4109
I20241203 09:07:05 2006641 dinov2 helpers.py:102]   [210/634]  eta: 0:27:12    time: 3.973296  data: 0.001442  max mem: 4109
I20241203 09:07:05 2006639 dinov2 helpers.py:102]   [210/634]  eta: 0:27:12    time: 3.975349  data: 0.000844  max mem: 4109
I20241203 09:07:29 2006643 dinov2 helpers.py:102]   [210/634]  eta: 0:27:56    time: 3.973537  data: 0.000938  max mem: 4109
I20241203 09:07:29 2006645 dinov2 helpers.py:102]   [200/634]  eta: 0:29:49    time: 3.972550  data: 0.000813  max mem: 4109
I20241203 09:07:36 2006640 dinov2 helpers.py:102]   [200/634]  eta: 0:29:51    time: 3.971612  data: 0.000914  max mem: 4109
I20241203 09:07:39 2006644 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.971568  data: 0.000820  max mem: 4109
I20241203 09:07:41 2006638 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.973319  data: 0.000958  max mem: 4109
I20241203 09:07:42 2006642 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.973378  data: 0.001458  max mem: 4109
I20241203 09:07:45 2006641 dinov2 helpers.py:102]   [220/634]  eta: 0:26:35    time: 3.973359  data: 0.001525  max mem: 4109
I20241203 09:07:45 2006639 dinov2 helpers.py:102]   [220/634]  eta: 0:26:35    time: 3.974238  data: 0.002398  max mem: 4109
I20241203 09:08:09 2006643 dinov2 helpers.py:102]   [220/634]  eta: 0:27:17    time: 3.972931  data: 0.000828  max mem: 4109
I20241203 09:08:09 2006645 dinov2 helpers.py:102]   [210/634]  eta: 0:29:05    time: 3.973237  data: 0.001008  max mem: 4109
I20241203 09:08:16 2006640 dinov2 helpers.py:102]   [210/634]  eta: 0:29:07    time: 3.969776  data: 0.000970  max mem: 4109
I20241203 09:08:19 2006644 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.972441  data: 0.000661  max mem: 4109
I20241203 09:08:21 2006638 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.971485  data: 0.001007  max mem: 4109
I20241203 09:08:22 2006642 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.973225  data: 0.001602  max mem: 4109
I20241203 09:08:24 2006641 dinov2 helpers.py:102]   [230/634]  eta: 0:25:59    time: 3.974169  data: 0.001730  max mem: 4109
I20241203 09:08:24 2006639 dinov2 helpers.py:102]   [230/634]  eta: 0:25:59    time: 3.973282  data: 0.002928  max mem: 4109
I20241203 09:08:49 2006643 dinov2 helpers.py:102]   [230/634]  eta: 0:26:38    time: 3.973132  data: 0.001659  max mem: 4109
I20241203 09:08:49 2006645 dinov2 helpers.py:102]   [220/634]  eta: 0:28:21    time: 3.973261  data: 0.000891  max mem: 4109
I20241203 09:08:55 2006640 dinov2 helpers.py:102]   [220/634]  eta: 0:28:23    time: 3.970508  data: 0.000863  max mem: 4109
I20241203 09:08:58 2006644 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.969608  data: 0.000814  max mem: 4109
I20241203 09:09:01 2006638 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.970675  data: 0.000908  max mem: 4109
I20241203 09:09:02 2006642 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.974070  data: 0.001268  max mem: 4109
I20241203 09:09:04 2006641 dinov2 helpers.py:102]   [240/634]  eta: 0:25:22    time: 3.974081  data: 0.001497  max mem: 4109
I20241203 09:09:04 2006639 dinov2 helpers.py:102]   [240/634]  eta: 0:25:22    time: 3.973194  data: 0.001626  max mem: 4109
I20241203 09:09:28 2006643 dinov2 helpers.py:102]   [240/634]  eta: 0:25:59    time: 3.973230  data: 0.003731  max mem: 4109
I20241203 09:09:29 2006645 dinov2 helpers.py:102]   [230/634]  eta: 0:27:38    time: 3.973206  data: 0.000644  max mem: 4109
I20241203 09:09:35 2006640 dinov2 helpers.py:102]   [230/634]  eta: 0:27:39    time: 3.971291  data: 0.002263  max mem: 4109
I20241203 09:09:38 2006644 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.970449  data: 0.001163  max mem: 4109
I20241203 09:09:41 2006638 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.972307  data: 0.001018  max mem: 4109
I20241203 09:09:42 2006642 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.974173  data: 0.001919  max mem: 4109
I20241203 09:09:44 2006641 dinov2 helpers.py:102]   [250/634]  eta: 0:24:45    time: 3.973225  data: 0.000615  max mem: 4109
I20241203 09:09:44 2006639 dinov2 helpers.py:102]   [250/634]  eta: 0:24:45    time: 3.975033  data: 0.001224  max mem: 4109
I20241203 09:10:08 2006643 dinov2 helpers.py:102]   [250/634]  eta: 0:25:19    time: 3.973328  data: 0.002989  max mem: 4109
I20241203 09:10:08 2006645 dinov2 helpers.py:102]   [240/634]  eta: 0:26:54    time: 3.973286  data: 0.000517  max mem: 4109
I20241203 09:10:15 2006640 dinov2 helpers.py:102]   [240/634]  eta: 0:26:56    time: 3.972640  data: 0.002561  max mem: 4109
I20241203 09:10:18 2006644 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.973435  data: 0.001003  max mem: 4109
I20241203 09:10:20 2006638 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.973320  data: 0.002166  max mem: 4109
I20241203 09:10:21 2006642 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.973350  data: 0.002089  max mem: 4109
I20241203 09:10:24 2006641 dinov2 helpers.py:102]   [260/634]  eta: 0:24:08    time: 3.973367  data: 0.000688  max mem: 4109
I20241203 09:10:24 2006639 dinov2 helpers.py:102]   [260/634]  eta: 0:24:08    time: 3.975145  data: 0.000912  max mem: 4109
I20241203 09:10:48 2006643 dinov2 helpers.py:102]   [260/634]  eta: 0:24:40    time: 3.974306  data: 0.001858  max mem: 4109
I20241203 09:10:48 2006645 dinov2 helpers.py:102]   [250/634]  eta: 0:26:11    time: 3.973427  data: 0.000629  max mem: 4109
I20241203 09:10:54 2006640 dinov2 helpers.py:102]   [250/634]  eta: 0:26:13    time: 3.973571  data: 0.001179  max mem: 4109
I20241203 09:10:57 2006644 dinov2 helpers.py:102]   [250/634]  eta: 0:26:20    time: 3.973822  data: 0.000690  max mem: 4109
I20241203 09:11:00 2006638 dinov2 helpers.py:102]   [250/634]  eta: 0:26:21    time: 3.973505  data: 0.002357  max mem: 4109
I20241203 09:11:01 2006642 dinov2 helpers.py:102]   [250/634]  eta: 0:26:21    time: 3.975339  data: 0.002112  max mem: 4109
I20241203 09:11:03 2006641 dinov2 helpers.py:102]   [270/634]  eta: 0:23:31    time: 3.975287  data: 0.000765  max mem: 4109
I20241203 09:11:03 2006639 dinov2 helpers.py:102]   [270/634]  eta: 0:23:31    time: 3.975401  data: 0.002364  max mem: 4109
I20241203 09:11:28 2006643 dinov2 helpers.py:102]   [270/634]  eta: 0:24:01    time: 3.974630  data: 0.001654  max mem: 4109
I20241203 09:11:28 2006645 dinov2 helpers.py:102]   [260/634]  eta: 0:25:29    time: 3.973740  data: 0.000682  max mem: 4109
I20241203 09:11:34 2006640 dinov2 helpers.py:102]   [260/634]  eta: 0:25:30    time: 3.974570  data: 0.000796  max mem: 4109
I20241203 09:11:37 2006644 dinov2 helpers.py:102]   [260/634]  eta: 0:25:37    time: 3.974643  data: 0.000750  max mem: 4109
I20241203 09:11:40 2006638 dinov2 helpers.py:102]   [260/634]  eta: 0:25:37    time: 3.973671  data: 0.001154  max mem: 4109
I20241203 09:11:41 2006642 dinov2 helpers.py:102]   [260/634]  eta: 0:25:37    time: 3.979293  data: 0.002388  max mem: 4109
I20241203 09:11:43 2006641 dinov2 helpers.py:102]   [280/634]  eta: 0:22:53    time: 3.978349  data: 0.001095  max mem: 4109
I20241203 09:11:43 2006639 dinov2 helpers.py:102]   [280/634]  eta: 0:22:53    time: 3.981278  data: 0.002443  max mem: 4109
I20241203 09:12:07 2006643 dinov2 helpers.py:102]   [280/634]  eta: 0:23:21    time: 3.974062  data: 0.001223  max mem: 4109
I20241203 09:12:08 2006645 dinov2 helpers.py:102]   [270/634]  eta: 0:24:46    time: 3.974073  data: 0.000899  max mem: 4109
I20241203 09:12:14 2006640 dinov2 helpers.py:102]   [270/634]  eta: 0:24:47    time: 3.974910  data: 0.000989  max mem: 4109
I20241203 09:12:17 2006644 dinov2 helpers.py:102]   [270/634]  eta: 0:24:54    time: 3.975557  data: 0.000821  max mem: 4109
I20241203 09:12:20 2006638 dinov2 helpers.py:102]   [270/634]  eta: 0:24:54    time: 3.974141  data: 0.001404  max mem: 4109
I20241203 09:12:21 2006642 dinov2 helpers.py:102]   [270/634]  eta: 0:24:55    time: 3.985728  data: 0.001402  max mem: 4109
I20241203 09:12:23 2006641 dinov2 helpers.py:102]   [290/634]  eta: 0:22:16    time: 3.980503  data: 0.000976  max mem: 4109
I20241203 09:12:23 2006639 dinov2 helpers.py:102]   [290/634]  eta: 0:22:16    time: 3.983194  data: 0.000650  max mem: 4109
I20241203 09:12:47 2006643 dinov2 helpers.py:102]   [290/634]  eta: 0:22:42    time: 3.975115  data: 0.001801  max mem: 4109
I20241203 09:12:47 2006645 dinov2 helpers.py:102]   [280/634]  eta: 0:24:04    time: 3.974142  data: 0.000866  max mem: 4109
I20241203 09:12:54 2006640 dinov2 helpers.py:102]   [280/634]  eta: 0:24:05    time: 3.974103  data: 0.001328  max mem: 4109
I20241203 09:12:57 2006644 dinov2 helpers.py:102]   [280/634]  eta: 0:24:11    time: 3.975868  data: 0.001086  max mem: 4109
I20241203 09:12:59 2006638 dinov2 helpers.py:102]   [280/634]  eta: 0:24:12    time: 3.974122  data: 0.001643  max mem: 4109
I20241203 09:13:01 2006642 dinov2 helpers.py:102]   [280/634]  eta: 0:24:12    time: 3.991249  data: 0.001029  max mem: 4109
I20241203 09:13:03 2006641 dinov2 helpers.py:102]   [300/634]  eta: 0:21:38    time: 3.983080  data: 0.000624  max mem: 4109
I20241203 09:13:03 2006639 dinov2 helpers.py:102]   [300/634]  eta: 0:21:38    time: 3.980314  data: 0.001646  max mem: 4109
I20241203 09:13:27 2006643 dinov2 helpers.py:102]   [300/634]  eta: 0:22:02    time: 3.975163  data: 0.001410  max mem: 4109
I20241203 09:13:27 2006645 dinov2 helpers.py:102]   [290/634]  eta: 0:23:22    time: 3.974263  data: 0.000930  max mem: 4109
I20241203 09:13:33 2006640 dinov2 helpers.py:102]   [290/634]  eta: 0:23:23    time: 3.974257  data: 0.001382  max mem: 4109
I20241203 09:13:36 2006644 dinov2 helpers.py:102]   [290/634]  eta: 0:23:29    time: 3.975124  data: 0.001018  max mem: 4109
I20241203 09:13:39 2006638 dinov2 helpers.py:102]   [290/634]  eta: 0:23:29    time: 3.974068  data: 0.001926  max mem: 4109
I20241203 09:13:41 2006642 dinov2 helpers.py:102]   [290/634]  eta: 0:23:30    time: 3.994064  data: 0.001125  max mem: 4109
I20241203 09:13:43 2006641 dinov2 helpers.py:102]   [310/634]  eta: 0:21:00    time: 3.985959  data: 0.001068  max mem: 4109
I20241203 09:13:43 2006639 dinov2 helpers.py:102]   [310/634]  eta: 0:21:00    time: 3.981249  data: 0.001664  max mem: 4109
I20241203 09:14:07 2006643 dinov2 helpers.py:102]   [310/634]  eta: 0:21:23    time: 3.974207  data: 0.001326  max mem: 4109
I20241203 09:14:07 2006645 dinov2 helpers.py:102]   [300/634]  eta: 0:22:40    time: 3.974260  data: 0.001260  max mem: 4109
I20241203 09:14:13 2006640 dinov2 helpers.py:102]   [300/634]  eta: 0:22:41    time: 3.974293  data: 0.001740  max mem: 4109
I20241203 09:14:16 2006644 dinov2 helpers.py:102]   [300/634]  eta: 0:22:47    time: 3.974335  data: 0.001017  max mem: 4109
I20241203 09:14:19 2006638 dinov2 helpers.py:102]   [300/634]  eta: 0:22:47    time: 3.974240  data: 0.001789  max mem: 4109
I20241203 09:14:21 2006642 dinov2 helpers.py:102]   [300/634]  eta: 0:22:48    time: 3.994926  data: 0.001961  max mem: 4109
I20241203 09:14:23 2006641 dinov2 helpers.py:102]   [320/634]  eta: 0:20:22    time: 3.988850  data: 0.001382  max mem: 4109
I20241203 09:14:23 2006639 dinov2 helpers.py:102]   [320/634]  eta: 0:20:22    time: 3.985218  data: 0.001559  max mem: 4109
I20241203 09:14:46 2006643 dinov2 helpers.py:102]   [320/634]  eta: 0:20:43    time: 3.976107  data: 0.001292  max mem: 4109
I20241203 09:14:47 2006645 dinov2 helpers.py:102]   [310/634]  eta: 0:21:58    time: 3.974275  data: 0.001005  max mem: 4109
I20241203 09:14:53 2006640 dinov2 helpers.py:102]   [310/634]  eta: 0:21:59    time: 3.974332  data: 0.001294  max mem: 4109
I20241203 09:14:56 2006644 dinov2 helpers.py:102]   [310/634]  eta: 0:22:04    time: 3.974302  data: 0.000999  max mem: 4109
I20241203 09:14:59 2006638 dinov2 helpers.py:102]   [310/634]  eta: 0:22:05    time: 3.974300  data: 0.001025  max mem: 4109
I20241203 09:15:01 2006642 dinov2 helpers.py:102]   [310/634]  eta: 0:22:06    time: 3.990455  data: 0.003802  max mem: 4109
I20241203 09:15:02 2006639 dinov2 helpers.py:102]   [330/634]  eta: 0:19:44    time: 3.983437  data: 0.001827  max mem: 4109
I20241203 09:15:03 2006641 dinov2 helpers.py:102]   [330/634]  eta: 0:19:44    time: 3.993991  data: 0.001644  max mem: 4109
I20241203 09:15:26 2006643 dinov2 helpers.py:102]   [330/634]  eta: 0:20:04    time: 3.976023  data: 0.000959  max mem: 4109
I20241203 09:15:26 2006645 dinov2 helpers.py:102]   [320/634]  eta: 0:21:17    time: 3.974226  data: 0.000822  max mem: 4109
I20241203 09:15:33 2006640 dinov2 helpers.py:102]   [320/634]  eta: 0:21:18    time: 3.974168  data: 0.000507  max mem: 4109
I20241203 09:15:36 2006644 dinov2 helpers.py:102]   [320/634]  eta: 0:21:22    time: 3.975945  data: 0.000635  max mem: 4109
I20241203 09:15:38 2006638 dinov2 helpers.py:102]   [320/634]  eta: 0:21:23    time: 3.974066  data: 0.001041  max mem: 4109
I20241203 09:15:40 2006642 dinov2 helpers.py:102]   [320/634]  eta: 0:21:24    time: 3.988535  data: 0.003348  max mem: 4109
I20241203 09:15:42 2006639 dinov2 helpers.py:102]   [340/634]  eta: 0:19:06    time: 3.978521  data: 0.001574  max mem: 4109
I20241203 09:15:42 2006641 dinov2 helpers.py:102]   [340/634]  eta: 0:19:06    time: 3.986655  data: 0.001392  max mem: 4109
I20241203 09:16:06 2006643 dinov2 helpers.py:102]   [340/634]  eta: 0:19:24    time: 3.974061  data: 0.000917  max mem: 4109
I20241203 09:16:06 2006645 dinov2 helpers.py:102]   [330/634]  eta: 0:20:35    time: 3.974157  data: 0.000806  max mem: 4109
I20241203 09:16:12 2006640 dinov2 helpers.py:102]   [330/634]  eta: 0:20:36    time: 3.974137  data: 0.000761  max mem: 4109
I20241203 09:16:15 2006644 dinov2 helpers.py:102]   [330/634]  eta: 0:20:41    time: 3.975828  data: 0.001245  max mem: 4109
I20241203 09:16:18 2006638 dinov2 helpers.py:102]   [330/634]  eta: 0:20:41    time: 3.974059  data: 0.001570  max mem: 4109
I20241203 09:16:20 2006642 dinov2 helpers.py:102]   [330/634]  eta: 0:20:42    time: 3.982435  data: 0.001338  max mem: 4109
I20241203 09:16:22 2006639 dinov2 helpers.py:102]   [350/634]  eta: 0:18:27    time: 3.982932  data: 0.001566  max mem: 4109
I20241203 09:16:22 2006641 dinov2 helpers.py:102]   [350/634]  eta: 0:18:28    time: 3.978587  data: 0.000763  max mem: 4109
I20241203 09:16:46 2006643 dinov2 helpers.py:102]   [350/634]  eta: 0:18:45    time: 3.973965  data: 0.000742  max mem: 4109
I20241203 09:16:46 2006645 dinov2 helpers.py:102]   [340/634]  eta: 0:19:54    time: 3.973965  data: 0.000787  max mem: 4109
I20241203 09:16:52 2006640 dinov2 helpers.py:102]   [340/634]  eta: 0:19:54    time: 3.973933  data: 0.001125  max mem: 4109
I20241203 09:16:55 2006644 dinov2 helpers.py:102]   [340/634]  eta: 0:19:59    time: 3.974083  data: 0.001164  max mem: 4109
I20241203 09:16:58 2006638 dinov2 helpers.py:102]   [340/634]  eta: 0:19:59    time: 3.973969  data: 0.001987  max mem: 4109
I20241203 09:17:00 2006642 dinov2 helpers.py:102]   [340/634]  eta: 0:20:00    time: 3.973988  data: 0.000886  max mem: 4109
I20241203 09:17:02 2006641 dinov2 helpers.py:102]   [360/634]  eta: 0:17:49    time: 3.979387  data: 0.000674  max mem: 4109
I20241203 09:17:02 2006639 dinov2 helpers.py:102]   [360/634]  eta: 0:17:49    time: 3.990091  data: 0.001141  max mem: 4109
I20241203 09:17:25 2006643 dinov2 helpers.py:102]   [360/634]  eta: 0:18:05    time: 3.973884  data: 0.000501  max mem: 4109
I20241203 09:17:26 2006645 dinov2 helpers.py:102]   [350/634]  eta: 0:19:12    time: 3.973786  data: 0.001178  max mem: 4109
I20241203 09:17:32 2006640 dinov2 helpers.py:102]   [350/634]  eta: 0:19:13    time: 3.973832  data: 0.000919  max mem: 4109
I20241203 09:17:35 2006644 dinov2 helpers.py:102]   [350/634]  eta: 0:19:17    time: 3.973859  data: 0.000648  max mem: 4109
I20241203 09:17:37 2006638 dinov2 helpers.py:102]   [350/634]  eta: 0:19:17    time: 3.973092  data: 0.001238  max mem: 4109
I20241203 09:17:40 2006642 dinov2 helpers.py:102]   [350/634]  eta: 0:19:18    time: 3.979715  data: 0.002175  max mem: 4109
I20241203 09:17:42 2006641 dinov2 helpers.py:102]   [370/634]  eta: 0:17:11    time: 3.978415  data: 0.000560  max mem: 4109
I20241203 09:17:42 2006639 dinov2 helpers.py:102]   [370/634]  eta: 0:17:11    time: 3.989098  data: 0.000915  max mem: 4109
I20241203 09:18:05 2006643 dinov2 helpers.py:102]   [370/634]  eta: 0:17:26    time: 3.973739  data: 0.000567  max mem: 4109
I20241203 09:18:05 2006645 dinov2 helpers.py:102]   [360/634]  eta: 0:18:31    time: 3.973711  data: 0.001639  max mem: 4109
I20241203 09:18:12 2006640 dinov2 helpers.py:102]   [360/634]  eta: 0:18:32    time: 3.975490  data: 0.001117  max mem: 4109
I20241203 09:18:15 2006644 dinov2 helpers.py:102]   [360/634]  eta: 0:18:36    time: 3.972620  data: 0.000613  max mem: 4109
I20241203 09:18:17 2006638 dinov2 helpers.py:102]   [360/634]  eta: 0:18:36    time: 3.972717  data: 0.002338  max mem: 4109
I20241203 09:18:20 2006642 dinov2 helpers.py:102]   [360/634]  eta: 0:18:37    time: 3.983486  data: 0.002118  max mem: 4109
I20241203 09:18:21 2006641 dinov2 helpers.py:102]   [380/634]  eta: 0:16:32    time: 3.977170  data: 0.001301  max mem: 4109
I20241203 09:18:22 2006639 dinov2 helpers.py:102]   [380/634]  eta: 0:16:32    time: 3.979890  data: 0.001507  max mem: 4109
I20241203 09:18:45 2006643 dinov2 helpers.py:102]   [380/634]  eta: 0:16:46    time: 3.972390  data: 0.000975  max mem: 4109
I20241203 09:18:45 2006645 dinov2 helpers.py:102]   [370/634]  eta: 0:17:50    time: 3.973316  data: 0.001235  max mem: 4109
I20241203 09:18:51 2006640 dinov2 helpers.py:102]   [370/634]  eta: 0:17:51    time: 3.975091  data: 0.001745  max mem: 4109
I20241203 09:18:54 2006644 dinov2 helpers.py:102]   [370/634]  eta: 0:17:54    time: 3.972434  data: 0.000626  max mem: 4109
I20241203 09:18:57 2006638 dinov2 helpers.py:102]   [370/634]  eta: 0:17:54    time: 3.973067  data: 0.003081  max mem: 4109
I20241203 09:18:59 2006642 dinov2 helpers.py:102]   [370/634]  eta: 0:17:55    time: 3.976943  data: 0.001070  max mem: 4109
I20241203 09:19:01 2006641 dinov2 helpers.py:102]   [390/634]  eta: 0:15:53    time: 3.974075  data: 0.001540  max mem: 4109
I20241203 09:19:01 2006639 dinov2 helpers.py:102]   [390/634]  eta: 0:15:53    time: 3.974179  data: 0.001555  max mem: 4109
I20241203 09:19:24 2006643 dinov2 helpers.py:102]   [390/634]  eta: 0:16:07    time: 3.972253  data: 0.000963  max mem: 4109
I20241203 09:19:25 2006645 dinov2 helpers.py:102]   [380/634]  eta: 0:17:09    time: 3.974059  data: 0.000776  max mem: 4109
I20241203 09:19:31 2006640 dinov2 helpers.py:102]   [380/634]  eta: 0:17:09    time: 3.973294  data: 0.001406  max mem: 4109
I20241203 09:19:34 2006644 dinov2 helpers.py:102]   [380/634]  eta: 0:17:13    time: 3.973247  data: 0.000823  max mem: 4109
I20241203 09:19:37 2006638 dinov2 helpers.py:102]   [380/634]  eta: 0:17:13    time: 3.973230  data: 0.001698  max mem: 4109
I20241203 09:19:39 2006642 dinov2 helpers.py:102]   [380/634]  eta: 0:17:14    time: 3.977676  data: 0.001949  max mem: 4109
I20241203 09:19:41 2006641 dinov2 helpers.py:102]   [400/634]  eta: 0:15:15    time: 3.974136  data: 0.000952  max mem: 4109
I20241203 09:19:41 2006639 dinov2 helpers.py:102]   [400/634]  eta: 0:15:15    time: 3.975024  data: 0.001832  max mem: 4109
I20241203 09:20:04 2006643 dinov2 helpers.py:102]   [400/634]  eta: 0:15:27    time: 3.973439  data: 0.000630  max mem: 4109
I20241203 09:20:04 2006645 dinov2 helpers.py:102]   [390/634]  eta: 0:16:28    time: 3.974327  data: 0.000708  max mem: 4109
I20241203 09:20:11 2006640 dinov2 helpers.py:102]   [390/634]  eta: 0:16:28    time: 3.973514  data: 0.001015  max mem: 4109
I20241203 09:20:14 2006644 dinov2 helpers.py:102]   [390/634]  eta: 0:16:32    time: 3.973428  data: 0.000674  max mem: 4109
I20241203 09:20:16 2006638 dinov2 helpers.py:102]   [390/634]  eta: 0:16:32    time: 3.973503  data: 0.001381  max mem: 4109
I20241203 09:20:19 2006642 dinov2 helpers.py:102]   [390/634]  eta: 0:16:33    time: 3.985130  data: 0.001881  max mem: 4109
I20241203 09:20:21 2006641 dinov2 helpers.py:102]   [410/634]  eta: 0:14:36    time: 3.974369  data: 0.000913  max mem: 4109
I20241203 09:20:21 2006639 dinov2 helpers.py:102]   [410/634]  eta: 0:14:36    time: 3.974367  data: 0.002120  max mem: 4109
I20241203 09:20:44 2006643 dinov2 helpers.py:102]   [410/634]  eta: 0:14:47    time: 3.973715  data: 0.000913  max mem: 4109
I20241203 09:20:44 2006645 dinov2 helpers.py:102]   [400/634]  eta: 0:15:47    time: 3.973712  data: 0.001154  max mem: 4109
I20241203 09:20:51 2006640 dinov2 helpers.py:102]   [400/634]  eta: 0:15:47    time: 3.975437  data: 0.000883  max mem: 4109
I20241203 09:20:54 2006644 dinov2 helpers.py:102]   [400/634]  eta: 0:15:50    time: 3.973754  data: 0.000647  max mem: 4109
I20241203 09:20:56 2006638 dinov2 helpers.py:102]   [400/634]  eta: 0:15:50    time: 3.973862  data: 0.001387  max mem: 4109
I20241203 09:20:59 2006642 dinov2 helpers.py:102]   [400/634]  eta: 0:15:51    time: 3.989030  data: 0.001224  max mem: 4109
I20241203 09:21:00 2006641 dinov2 helpers.py:102]   [420/634]  eta: 0:13:57    time: 3.975572  data: 0.000866  max mem: 4109
I20241203 09:21:01 2006639 dinov2 helpers.py:102]   [420/634]  eta: 0:13:57    time: 3.975573  data: 0.001403  max mem: 4109
I20241203 09:21:24 2006643 dinov2 helpers.py:102]   [420/634]  eta: 0:14:08    time: 3.973915  data: 0.001017  max mem: 4109
I20241203 09:21:24 2006645 dinov2 helpers.py:102]   [410/634]  eta: 0:15:06    time: 3.973882  data: 0.001350  max mem: 4109
I20241203 09:21:30 2006640 dinov2 helpers.py:102]   [410/634]  eta: 0:15:07    time: 3.975708  data: 0.000774  max mem: 4109
I20241203 09:21:33 2006644 dinov2 helpers.py:102]   [410/634]  eta: 0:15:09    time: 3.973980  data: 0.001604  max mem: 4109
I20241203 09:21:36 2006638 dinov2 helpers.py:102]   [410/634]  eta: 0:15:09    time: 3.975792  data: 0.001079  max mem: 4109
I20241203 09:21:39 2006642 dinov2 helpers.py:102]   [410/634]  eta: 0:15:10    time: 3.987647  data: 0.000899  max mem: 4109
I20241203 09:21:40 2006641 dinov2 helpers.py:102]   [430/634]  eta: 0:13:18    time: 3.982106  data: 0.000855  max mem: 4109
I20241203 09:21:40 2006639 dinov2 helpers.py:102]   [430/634]  eta: 0:13:18    time: 3.975838  data: 0.001947  max mem: 4109
I20241203 09:22:03 2006643 dinov2 helpers.py:102]   [430/634]  eta: 0:13:28    time: 3.973870  data: 0.000845  max mem: 4109
I20241203 09:22:04 2006645 dinov2 helpers.py:102]   [420/634]  eta: 0:14:25    time: 3.973014  data: 0.000907  max mem: 4109
I20241203 09:22:10 2006640 dinov2 helpers.py:102]   [420/634]  eta: 0:14:26    time: 3.973881  data: 0.000626  max mem: 4109
I20241203 09:22:13 2006644 dinov2 helpers.py:102]   [420/634]  eta: 0:14:28    time: 3.973901  data: 0.001579  max mem: 4109
I20241203 09:22:16 2006638 dinov2 helpers.py:102]   [420/634]  eta: 0:14:28    time: 3.975555  data: 0.001219  max mem: 4109
I20241203 09:22:19 2006642 dinov2 helpers.py:102]   [420/634]  eta: 0:14:29    time: 3.981502  data: 0.000809  max mem: 4109
I20241203 09:22:20 2006641 dinov2 helpers.py:102]   [440/634]  eta: 0:12:39    time: 3.982773  data: 0.001139  max mem: 4109
I20241203 09:22:20 2006639 dinov2 helpers.py:102]   [440/634]  eta: 0:12:39    time: 3.976573  data: 0.001804  max mem: 4109
I20241203 09:22:43 2006643 dinov2 helpers.py:102]   [440/634]  eta: 0:12:49    time: 3.973804  data: 0.000836  max mem: 4109
I20241203 09:22:43 2006645 dinov2 helpers.py:102]   [430/634]  eta: 0:13:44    time: 3.973855  data: 0.000926  max mem: 4109
I20241203 09:22:50 2006640 dinov2 helpers.py:102]   [430/634]  eta: 0:13:45    time: 3.973722  data: 0.000580  max mem: 4109
I20241203 09:22:53 2006644 dinov2 helpers.py:102]   [430/634]  eta: 0:13:47    time: 3.973785  data: 0.000748  max mem: 4109
I20241203 09:22:55 2006638 dinov2 helpers.py:102]   [430/634]  eta: 0:13:47    time: 3.973788  data: 0.001230  max mem: 4109
I20241203 09:22:58 2006642 dinov2 helpers.py:102]   [430/634]  eta: 0:13:48    time: 3.982656  data: 0.000902  max mem: 4109
I20241203 09:23:00 2006641 dinov2 helpers.py:102]   [450/634]  eta: 0:12:00    time: 3.977422  data: 0.001101  max mem: 4109
I20241203 09:23:00 2006639 dinov2 helpers.py:102]   [450/634]  eta: 0:12:00    time: 3.976484  data: 0.002087  max mem: 4109
I20241203 09:23:23 2006643 dinov2 helpers.py:102]   [450/634]  eta: 0:12:09    time: 3.973916  data: 0.001061  max mem: 4109
I20241203 09:23:23 2006645 dinov2 helpers.py:102]   [440/634]  eta: 0:13:04    time: 3.974803  data: 0.000912  max mem: 4109
I20241203 09:23:30 2006640 dinov2 helpers.py:102]   [440/634]  eta: 0:13:04    time: 3.973975  data: 0.000672  max mem: 4109
I20241203 09:23:33 2006644 dinov2 helpers.py:102]   [440/634]  eta: 0:13:06    time: 3.975746  data: 0.001125  max mem: 4109
I20241203 09:23:35 2006638 dinov2 helpers.py:102]   [440/634]  eta: 0:13:06    time: 3.973978  data: 0.002489  max mem: 4109
I20241203 09:23:38 2006642 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.988045  data: 0.001902  max mem: 4109
I20241203 09:23:40 2006639 dinov2 helpers.py:102]   [460/634]  eta: 0:11:21    time: 3.973998  data: 0.002040  max mem: 4109
I20241203 09:23:40 2006641 dinov2 helpers.py:102]   [460/634]  eta: 0:11:22    time: 3.979499  data: 0.000735  max mem: 4109
I20241203 09:24:03 2006643 dinov2 helpers.py:102]   [460/634]  eta: 0:11:29    time: 3.974385  data: 0.000972  max mem: 4109
I20241203 09:24:03 2006645 dinov2 helpers.py:102]   [450/634]  eta: 0:12:23    time: 3.974041  data: 0.000935  max mem: 4109
I20241203 09:24:09 2006640 dinov2 helpers.py:102]   [450/634]  eta: 0:12:23    time: 3.976127  data: 0.001639  max mem: 4109
I20241203 09:24:12 2006644 dinov2 helpers.py:102]   [450/634]  eta: 0:12:25    time: 3.975965  data: 0.001827  max mem: 4109
I20241203 09:24:15 2006638 dinov2 helpers.py:102]   [450/634]  eta: 0:12:25    time: 3.974115  data: 0.002661  max mem: 4109
I20241203 09:24:18 2006642 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.990376  data: 0.001964  max mem: 4109
I20241203 09:24:19 2006639 dinov2 helpers.py:102]   [470/634]  eta: 0:10:43    time: 3.977718  data: 0.001463  max mem: 4109
I20241203 09:24:20 2006641 dinov2 helpers.py:102]   [470/634]  eta: 0:10:43    time: 3.980373  data: 0.000910  max mem: 4109
I20241203 09:24:42 2006643 dinov2 helpers.py:102]   [470/634]  eta: 0:10:50    time: 3.975931  data: 0.000923  max mem: 4109
I20241203 09:24:43 2006645 dinov2 helpers.py:102]   [460/634]  eta: 0:11:42    time: 3.974242  data: 0.000990  max mem: 4109
I20241203 09:24:49 2006640 dinov2 helpers.py:102]   [460/634]  eta: 0:11:43    time: 3.975918  data: 0.001596  max mem: 4109
I20241203 09:24:52 2006644 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.974105  data: 0.001683  max mem: 4109
I20241203 09:24:55 2006638 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.974131  data: 0.001164  max mem: 4109
I20241203 09:24:58 2006642 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.988454  data: 0.000795  max mem: 4109
I20241203 09:24:59 2006641 dinov2 helpers.py:102]   [480/634]  eta: 0:10:04    time: 3.978584  data: 0.000991  max mem: 4109
I20241203 09:24:59 2006639 dinov2 helpers.py:102]   [480/634]  eta: 0:10:04    time: 3.983100  data: 0.001621  max mem: 4109
I20241203 09:25:22 2006643 dinov2 helpers.py:102]   [480/634]  eta: 0:10:10    time: 3.975735  data: 0.001445  max mem: 4109
I20241203 09:25:22 2006645 dinov2 helpers.py:102]   [470/634]  eta: 0:11:02    time: 3.975827  data: 0.000759  max mem: 4109
I20241203 09:25:29 2006640 dinov2 helpers.py:102]   [470/634]  eta: 0:11:02    time: 3.973774  data: 0.000553  max mem: 4109
I20241203 09:25:32 2006644 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.974885  data: 0.001015  max mem: 4109
I20241203 09:25:34 2006638 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.975796  data: 0.001007  max mem: 4109
I20241203 09:25:38 2006642 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.979345  data: 0.001868  max mem: 4109
I20241203 09:25:39 2006641 dinov2 helpers.py:102]   [490/634]  eta: 0:09:24    time: 3.982986  data: 0.001022  max mem: 4109
I20241203 09:25:39 2006639 dinov2 helpers.py:102]   [490/634]  eta: 0:09:24    time: 3.987463  data: 0.001367  max mem: 4109
I20241203 09:26:02 2006643 dinov2 helpers.py:102]   [490/634]  eta: 0:09:31    time: 3.973577  data: 0.001201  max mem: 4109
I20241203 09:26:02 2006645 dinov2 helpers.py:102]   [480/634]  eta: 0:10:21    time: 3.975705  data: 0.000676  max mem: 4109
I20241203 09:26:09 2006640 dinov2 helpers.py:102]   [480/634]  eta: 0:10:21    time: 3.974007  data: 0.001034  max mem: 4109
I20241203 09:26:12 2006644 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.975791  data: 0.000695  max mem: 4109
I20241203 09:26:14 2006638 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.975782  data: 0.000960  max mem: 4109
I20241203 09:26:18 2006642 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.976707  data: 0.001936  max mem: 4109
I20241203 09:26:19 2006641 dinov2 helpers.py:102]   [500/634]  eta: 0:08:45    time: 3.988317  data: 0.001104  max mem: 4109
I20241203 09:26:19 2006639 dinov2 helpers.py:102]   [500/634]  eta: 0:08:45    time: 3.988375  data: 0.002128  max mem: 4109
I20241203 09:26:42 2006643 dinov2 helpers.py:102]   [500/634]  eta: 0:08:51    time: 3.972886  data: 0.000800  max mem: 4109
I20241203 09:26:42 2006645 dinov2 helpers.py:102]   [490/634]  eta: 0:09:41    time: 3.974061  data: 0.000894  max mem: 4109
I20241203 09:26:48 2006640 dinov2 helpers.py:102]   [490/634]  eta: 0:09:41    time: 3.974908  data: 0.001459  max mem: 4109
I20241203 09:26:51 2006644 dinov2 helpers.py:102]   [490/634]  eta: 0:09:42    time: 3.974940  data: 0.000619  max mem: 4109
I20241203 09:26:54 2006638 dinov2 helpers.py:102]   [490/634]  eta: 0:09:42    time: 3.974017  data: 0.000927  max mem: 4109
I20241203 09:26:58 2006642 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.982093  data: 0.000773  max mem: 4109
I20241203 09:26:59 2006641 dinov2 helpers.py:102]   [510/634]  eta: 0:08:06    time: 3.985709  data: 0.000976  max mem: 4109
I20241203 09:26:59 2006639 dinov2 helpers.py:102]   [510/634]  eta: 0:08:06    time: 3.985689  data: 0.002760  max mem: 4109
I20241203 09:27:21 2006643 dinov2 helpers.py:102]   [510/634]  eta: 0:08:11    time: 3.973639  data: 0.001523  max mem: 4109
I20241203 09:27:22 2006645 dinov2 helpers.py:102]   [500/634]  eta: 0:09:00    time: 3.976061  data: 0.001225  max mem: 4109
I20241203 09:27:28 2006640 dinov2 helpers.py:102]   [500/634]  eta: 0:09:00    time: 3.975784  data: 0.001159  max mem: 4109
I20241203 09:27:31 2006644 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.974066  data: 0.000754  max mem: 4109
I20241203 09:27:34 2006638 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.974164  data: 0.000666  max mem: 4109
I20241203 09:27:37 2006642 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.988512  data: 0.001044  max mem: 4109
I20241203 09:27:39 2006641 dinov2 helpers.py:102]   [520/634]  eta: 0:07:27    time: 3.977712  data: 0.001193  max mem: 4109
I20241203 09:27:39 2006639 dinov2 helpers.py:102]   [520/634]  eta: 0:07:27    time: 3.979578  data: 0.001744  max mem: 4109
I20241203 09:28:01 2006643 dinov2 helpers.py:102]   [520/634]  eta: 0:07:32    time: 3.974073  data: 0.001527  max mem: 4109
I20241203 09:28:01 2006645 dinov2 helpers.py:102]   [510/634]  eta: 0:08:20    time: 3.975837  data: 0.002343  max mem: 4109
I20241203 09:28:08 2006640 dinov2 helpers.py:102]   [510/634]  eta: 0:08:20    time: 3.974887  data: 0.002166  max mem: 4109
I20241203 09:28:11 2006644 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.973945  data: 0.000852  max mem: 4109
I20241203 09:28:13 2006638 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.973064  data: 0.001967  max mem: 4109
I20241203 09:28:17 2006642 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.989233  data: 0.001576  max mem: 4109
I20241203 09:28:18 2006641 dinov2 helpers.py:102]   [530/634]  eta: 0:06:48    time: 3.974011  data: 0.001201  max mem: 4109
I20241203 09:28:18 2006639 dinov2 helpers.py:102]   [530/634]  eta: 0:06:48    time: 3.976699  data: 0.001128  max mem: 4109
I20241203 09:28:41 2006643 dinov2 helpers.py:102]   [530/634]  eta: 0:06:52    time: 3.973853  data: 0.000935  max mem: 4109
I20241203 09:28:41 2006645 dinov2 helpers.py:102]   [520/634]  eta: 0:07:39    time: 3.973682  data: 0.002037  max mem: 4109
I20241203 09:28:48 2006640 dinov2 helpers.py:102]   [520/634]  eta: 0:07:39    time: 3.974081  data: 0.002136  max mem: 4109
I20241203 09:28:51 2006644 dinov2 helpers.py:102]   [520/634]  eta: 0:07:40    time: 3.973935  data: 0.000983  max mem: 4109
I20241203 09:28:53 2006638 dinov2 helpers.py:102]   [520/634]  eta: 0:07:40    time: 3.972996  data: 0.002379  max mem: 4109
I20241203 09:28:57 2006642 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.980114  data: 0.001089  max mem: 4109
I20241203 09:28:58 2006641 dinov2 helpers.py:102]   [540/634]  eta: 0:06:09    time: 3.981054  data: 0.001044  max mem: 4109
I20241203 09:28:58 2006639 dinov2 helpers.py:102]   [540/634]  eta: 0:06:09    time: 3.981929  data: 0.001165  max mem: 4109
I20241203 09:29:21 2006643 dinov2 helpers.py:102]   [540/634]  eta: 0:06:12    time: 3.973877  data: 0.001337  max mem: 4109
I20241203 09:29:21 2006645 dinov2 helpers.py:102]   [530/634]  eta: 0:06:59    time: 3.973963  data: 0.001136  max mem: 4109
I20241203 09:29:27 2006640 dinov2 helpers.py:102]   [530/634]  eta: 0:06:59    time: 3.973935  data: 0.000760  max mem: 4109
I20241203 09:29:30 2006644 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.973905  data: 0.002152  max mem: 4109
I20241203 09:29:33 2006638 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.974575  data: 0.001203  max mem: 4109
I20241203 09:29:37 2006642 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.976577  data: 0.001082  max mem: 4109
I20241203 09:29:38 2006641 dinov2 helpers.py:102]   [550/634]  eta: 0:05:30    time: 3.984769  data: 0.001232  max mem: 4109
I20241203 09:29:38 2006639 dinov2 helpers.py:102]   [550/634]  eta: 0:05:30    time: 3.984723  data: 0.000851  max mem: 4109
I20241203 09:30:00 2006643 dinov2 helpers.py:102]   [550/634]  eta: 0:05:33    time: 3.974496  data: 0.001924  max mem: 4109
I20241203 09:30:01 2006645 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.974134  data: 0.001976  max mem: 4109
I20241203 09:30:07 2006640 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.973958  data: 0.001385  max mem: 4109
I20241203 09:30:10 2006644 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.974091  data: 0.002262  max mem: 4109
I20241203 09:30:13 2006638 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.973977  data: 0.001037  max mem: 4109
I20241203 09:30:17 2006642 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.982181  data: 0.001896  max mem: 4109
I20241203 09:30:18 2006641 dinov2 helpers.py:102]   [560/634]  eta: 0:04:50    time: 3.980420  data: 0.001168  max mem: 4109
I20241203 09:30:18 2006639 dinov2 helpers.py:102]   [560/634]  eta: 0:04:50    time: 3.984924  data: 0.000868  max mem: 4109
I20241203 09:30:40 2006643 dinov2 helpers.py:102]   [560/634]  eta: 0:04:53    time: 3.974094  data: 0.001305  max mem: 4109
I20241203 09:30:40 2006645 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.974267  data: 0.002612  max mem: 4109
I20241203 09:30:47 2006640 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.974146  data: 0.001360  max mem: 4109
I20241203 09:30:50 2006644 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.974059  data: 0.001160  max mem: 4109
I20241203 09:30:52 2006638 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.973510  data: 0.000954  max mem: 4109
I20241203 09:30:57 2006642 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.986652  data: 0.002186  max mem: 4109
I20241203 09:30:58 2006641 dinov2 helpers.py:102]   [570/634]  eta: 0:04:11    time: 3.979422  data: 0.001027  max mem: 4109
I20241203 09:30:58 2006639 dinov2 helpers.py:102]   [570/634]  eta: 0:04:11    time: 3.979475  data: 0.000804  max mem: 4109
I20241203 09:31:20 2006643 dinov2 helpers.py:102]   [570/634]  eta: 0:04:13    time: 3.973538  data: 0.000833  max mem: 4109
I20241203 09:31:20 2006645 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.973992  data: 0.003165  max mem: 4109
I20241203 09:31:27 2006640 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.974147  data: 0.000697  max mem: 4109
I20241203 09:31:30 2006644 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.972980  data: 0.000706  max mem: 4109
I20241203 09:31:32 2006638 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.973886  data: 0.000819  max mem: 4109
I20241203 09:31:36 2006642 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.984586  data: 0.002393  max mem: 4109
I20241203 09:31:37 2006641 dinov2 helpers.py:102]   [580/634]  eta: 0:03:32    time: 3.978395  data: 0.000964  max mem: 4109
I20241203 09:31:38 2006639 dinov2 helpers.py:102]   [580/634]  eta: 0:03:32    time: 3.975470  data: 0.001091  max mem: 4109
I20241203 09:32:00 2006643 dinov2 helpers.py:102]   [580/634]  eta: 0:03:34    time: 3.973751  data: 0.001157  max mem: 4109
I20241203 09:32:00 2006645 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.972703  data: 0.003179  max mem: 4109
I20241203 09:32:06 2006640 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.973672  data: 0.000818  max mem: 4109
I20241203 09:32:09 2006644 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.972813  data: 0.000609  max mem: 4109
I20241203 09:32:12 2006638 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.972978  data: 0.000758  max mem: 4109
I20241203 09:32:16 2006642 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.979130  data: 0.001579  max mem: 4109
I20241203 09:32:17 2006641 dinov2 helpers.py:102]   [590/634]  eta: 0:02:53    time: 3.978159  data: 0.001313  max mem: 4109
I20241203 09:32:17 2006639 dinov2 helpers.py:102]   [590/634]  eta: 0:02:53    time: 3.975478  data: 0.001621  max mem: 4109
I20241203 09:32:39 2006643 dinov2 helpers.py:102]   [590/634]  eta: 0:02:54    time: 3.973502  data: 0.000945  max mem: 4109
I20241203 09:32:40 2006645 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.972539  data: 0.002064  max mem: 4109
I20241203 09:32:46 2006640 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.973375  data: 0.000930  max mem: 4109
I20241203 09:32:49 2006644 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.972563  data: 0.001041  max mem: 4109
I20241203 09:32:52 2006638 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.972629  data: 0.001225  max mem: 4109
I20241203 09:32:56 2006642 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.975311  data: 0.000782  max mem: 4109
I20241203 09:32:57 2006641 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.976232  data: 0.001274  max mem: 4109
I20241203 09:32:57 2006639 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.973564  data: 0.002127  max mem: 4109
I20241203 09:33:19 2006643 dinov2 helpers.py:102]   [600/634]  eta: 0:02:14    time: 3.973444  data: 0.000811  max mem: 4109
I20241203 09:33:19 2006645 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.973339  data: 0.002288  max mem: 4109
I20241203 09:33:26 2006640 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.972494  data: 0.001078  max mem: 4109
I20241203 09:33:29 2006644 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.972501  data: 0.000922  max mem: 4109
I20241203 09:33:31 2006638 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.973127  data: 0.001583  max mem: 4109
I20241203 09:33:36 2006642 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.974171  data: 0.000981  max mem: 4109
I20241203 09:33:37 2006641 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.973297  data: 0.000858  max mem: 4109
I20241203 09:33:37 2006639 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.974260  data: 0.002384  max mem: 4109
I20241203 09:33:59 2006643 dinov2 helpers.py:102]   [610/634]  eta: 0:01:35    time: 3.973145  data: 0.001297  max mem: 4109
I20241203 09:33:59 2006645 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.973121  data: 0.001941  max mem: 4109
I20241203 09:34:05 2006640 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.969481  data: 0.001029  max mem: 4109
I20241203 09:34:08 2006644 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.973159  data: 0.001386  max mem: 4109
I20241203 09:34:11 2006638 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.973043  data: 0.002731  max mem: 4109
I20241203 09:34:15 2006642 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.974782  data: 0.002770  max mem: 4109
I20241203 09:34:16 2006641 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.973851  data: 0.000813  max mem: 4109
I20241203 09:34:16 2006639 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.974000  data: 0.001853  max mem: 4109
I20241203 09:34:38 2006643 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.972888  data: 0.001346  max mem: 4109
I20241203 09:34:39 2006645 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.972904  data: 0.001001  max mem: 4109
I20241203 09:34:45 2006640 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.969294  data: 0.002339  max mem: 4109
I20241203 09:34:48 2006644 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.971118  data: 0.001544  max mem: 4109
I20241203 09:34:51 2006638 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.972902  data: 0.002480  max mem: 4109
I20241203 09:34:55 2006642 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.973855  data: 0.002826  max mem: 4109
I20241203 09:34:56 2006641 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.973835  data: 0.000730  max mem: 4109
I20241203 09:34:56 2006639 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.972856  data: 0.001360  max mem: 4109
I20241203 09:35:16 2006639 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.346170  data: 0.001021  max mem: 4109
I20241203 09:35:16 2006641 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.350383  data: 0.000569  max mem: 4109
I20241203 09:35:16 2006641 dinov2 helpers.py:130]  Total time: 0:41:43 (3.948373 s / it)
I20241203 09:35:16 2006641 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:35:16 2006641 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 09:35:16 2006639 dinov2 helpers.py:130]  Total time: 0:41:43 (3.948327 s / it)
I20241203 09:35:16 2006639 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:35:16 2006639 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:35:17 2006641 submitit submission.py:68] Submitted job triggered an exception
E20241203 09:35:17 2006639 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:35:18 2006643 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.953950  data: 0.000774  max mem: 4109
I20241203 09:35:18 2006645 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.949450  data: 0.001000  max mem: 4109
I20241203 09:35:23 2006640 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.869240  data: 0.002172  max mem: 4109
I20241203 09:35:25 2006644 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.831307  data: 0.000822  max mem: 4109
I20241203 09:35:27 2006638 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.799247  data: 0.000871  max mem: 4109
I20241203 09:35:30 2006642 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.748797  data: 0.001285  max mem: 4109
I20241203 09:35:32 2006643 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.085832  data: 0.000606  max mem: 4109
I20241203 09:35:33 2006643 dinov2 helpers.py:130]  Total time: 0:41:57 (3.971394 s / it)
I20241203 09:35:33 2006643 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:35:33 2006643 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:35:33 2006643 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:35:45 2006645 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.329760  data: 0.000974  max mem: 4109
I20241203 09:35:49 2006640 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.211351  data: 0.000570  max mem: 4109
I20241203 09:35:51 2006644 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.155698  data: 0.000982  max mem: 4109
I20241203 09:35:53 2006638 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.104615  data: 0.000701  max mem: 4109
I20241203 09:35:56 2006642 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.027928  data: 0.000986  max mem: 4109
I20241203 09:35:58 2006645 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.342904  data: 0.000928  max mem: 4109
I20241203 09:35:58 2006645 dinov2 helpers.py:130]  Total time: 0:42:17 (4.001887 s / it)
I20241203 09:35:58 2006645 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:35:58 2006645 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:35:58 2006645 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:36:01 2006640 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.209309  data: 0.000507  max mem: 4109
I20241203 09:36:01 2006640 dinov2 helpers.py:130]  Total time: 0:42:15 (3.998833 s / it)
I20241203 09:36:01 2006640 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:36:01 2006640 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:36:02 2006640 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:36:02 2006644 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.102112  data: 0.000913  max mem: 4109
I20241203 09:36:02 2006644 dinov2 helpers.py:130]  Total time: 0:42:18 (4.003448 s / it)
I20241203 09:36:02 2006644 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:36:02 2006644 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:36:03 2006644 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:36:03 2006638 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.010601  data: 0.000464  max mem: 4109
I20241203 09:36:03 2006638 dinov2 helpers.py:130]  Total time: 0:42:16 (4.000737 s / it)
I20241203 09:36:03 2006638 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:36:03 2006638 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:36:03 2006638 submitit submission.py:68] Submitted job triggered an exception
I20241203 09:36:04 2006642 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.823281  data: 0.000849  max mem: 4109
I20241203 09:36:04 2006642 dinov2 helpers.py:130]  Total time: 0:42:16 (4.000008 s / it)
I20241203 09:36:04 2006642 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 09:36:04 2006642 dinov2 utils.py:142] Labels shape: (162127,)
E20241203 09:36:04 2006642 submitit submission.py:68] Submitted job triggered an exception
I20241203 10:27:49 2030089 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:49 2030089 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:49 2030089 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:49 2030089 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:49 2030089 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:49 2030088 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:49 2030088 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:49 2030088 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:49 2030088 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:49 2030088 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:49 2030092 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:49 2030092 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:49 2030092 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:49 2030092 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:49 2030092 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:49 2030094 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:49 2030094 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:49 2030094 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:49 2030094 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:49 2030094 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:50 2030093 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:50 2030093 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:50 2030093 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:50 2030093 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:50 2030093 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:50 2030091 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:50 2030091 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:50 2030091 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:50 2030091 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:50 2030095 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:50 2030095 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:50 2030095 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:50 2030095 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:50 2030091 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:50 2030095 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:27:50 2030090 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 10:27:50 2030090 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 10:27:50 2030090 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 10:27:50 2030090 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 10:27:50 2030090 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 10:28:18 2030088 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:19 2030094 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:20 2030095 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:22 2030089 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:23 2030092 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:23 2030088 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:24 2030093 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:24 2030091 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:24 2030090 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 10:28:24 2030094 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:24 2030088 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:25 2030095 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:25 2030094 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:25 2030095 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:26 2030089 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:26 2030089 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:27 2030092 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:27 2030092 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:29 2030093 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:29 2030091 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:29 2030090 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 10:28:29 2030091 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:29 2030093 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:30 2030090 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 10:28:31 2030088 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:31 2030088 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:31 2030095 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:31 2030095 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:32 2030089 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:32 2030089 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:32 2030094 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:32 2030094 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:32 2030088 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:32 2030088 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:32 2030088 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:32 2030088 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:32 2030088 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:32 2030088 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:32 2030095 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:32 2030095 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:32 2030095 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:32 2030095 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:32 2030095 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:32 2030095 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:36 2030089 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:36 2030089 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:36 2030089 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:36 2030089 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:36 2030089 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:36 2030089 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:36 2030094 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:36 2030094 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:36 2030094 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:36 2030094 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:36 2030094 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:36 2030094 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:38 2030092 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:38 2030092 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:44 2030092 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:44 2030092 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:44 2030092 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:44 2030092 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:44 2030092 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:44 2030092 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:44 2030090 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:44 2030090 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:45 2030093 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:45 2030093 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:46 2030091 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 10:28:46 2030091 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 10:28:50 2030090 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:50 2030090 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:50 2030090 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:50 2030090 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:50 2030090 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:50 2030090 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:51 2030093 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:51 2030093 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:51 2030093 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:51 2030093 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:51 2030093 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:51 2030093 dinov2 loaders.py:223] # of batches: 634
I20241203 10:28:51 2030091 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 10:28:51 2030091 dinov2 knn.py:260] Extracting features for train set...
I20241203 10:28:51 2030091 dinov2 loaders.py:151] sampler: distributed
I20241203 10:28:51 2030091 dinov2 loaders.py:210] using PyTorch data loader
W20241203 10:28:51 2030091 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 10:28:51 2030091 dinov2 loaders.py:223] # of batches: 634
I20241203 10:29:04 2030088 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:04 2030088 dinov2 helpers.py:102]   [  0/634]  eta: 5:32:19    time: 31.450174  data: 12.099624  max mem: 3463
I20241203 10:29:05 2030095 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:05 2030095 dinov2 helpers.py:102]   [  0/634]  eta: 5:49:07    time: 33.040894  data: 8.822555  max mem: 3463
I20241203 10:29:10 2030088 dinov2 helpers.py:102]   [ 10/634]  eta: 0:35:51    time: 3.447234  data: 1.102566  max mem: 4109
I20241203 10:29:14 2030095 dinov2 helpers.py:102]   [ 10/634]  eta: 0:38:56    time: 3.743688  data: 0.803844  max mem: 4109
I20241203 10:29:18 2030089 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:18 2030089 dinov2 helpers.py:102]   [  0/634]  eta: 7:25:20    time: 42.146011  data: 9.637819  max mem: 3463
I20241203 10:29:22 2030088 dinov2 helpers.py:102]   [ 20/634]  eta: 0:24:09    time: 0.906174  data: 0.001622  max mem: 4109
I20241203 10:29:24 2030094 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:24 2030094 dinov2 helpers.py:102]   [  0/634]  eta: 8:22:16    time: 47.534664  data: 13.198504  max mem: 3463
I20241203 10:29:28 2030095 dinov2 helpers.py:102]   [ 20/634]  eta: 0:27:02    time: 1.123423  data: 0.001579  max mem: 4109
I20241203 10:29:32 2030092 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:32 2030092 dinov2 helpers.py:102]   [  0/634]  eta: 8:28:16    time: 48.101757  data: 10.681955  max mem: 3463
I20241203 10:29:32 2030089 dinov2 helpers.py:102]   [ 10/634]  eta: 0:53:37    time: 5.156942  data: 0.878520  max mem: 4109
I20241203 10:29:40 2030090 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:40 2030090 dinov2 helpers.py:102]   [  0/634]  eta: 8:42:40    time: 49.463852  data: 11.652217  max mem: 3463
I20241203 10:29:40 2030093 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:40 2030093 dinov2 helpers.py:102]   [  0/634]  eta: 8:43:53    time: 49.579433  data: 10.290846  max mem: 3463
I20241203 10:29:42 2030091 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 10:29:42 2030091 dinov2 helpers.py:102]   [  0/634]  eta: 9:01:55    time: 51.285805  data: 13.101794  max mem: 3463
I20241203 10:29:44 2030094 dinov2 helpers.py:102]   [ 10/634]  eta: 1:03:52    time: 6.142469  data: 1.200824  max mem: 4109
I20241203 10:29:46 2030088 dinov2 helpers.py:102]   [ 30/634]  eta: 0:23:51    time: 1.777208  data: 0.000422  max mem: 4109
I20241203 10:29:59 2030095 dinov2 helpers.py:102]   [ 30/634]  eta: 0:28:00    time: 2.252255  data: 0.000866  max mem: 4109
I20241203 10:29:59 2030092 dinov2 helpers.py:102]   [ 10/634]  eta: 1:11:21    time: 6.861908  data: 0.971795  max mem: 4109
I20241203 10:30:07 2030089 dinov2 helpers.py:102]   [ 20/634]  eta: 0:44:29    time: 2.457633  data: 0.001734  max mem: 4109
I20241203 10:30:12 2030090 dinov2 helpers.py:102]   [ 10/634]  eta: 1:16:52    time: 7.391366  data: 1.063384  max mem: 4109
I20241203 10:30:12 2030093 dinov2 helpers.py:102]   [ 10/634]  eta: 1:17:04    time: 7.411033  data: 0.937065  max mem: 4109
I20241203 10:30:14 2030091 dinov2 helpers.py:102]   [ 10/634]  eta: 1:18:44    time: 7.571315  data: 1.193448  max mem: 4109
I20241203 10:30:23 2030094 dinov2 helpers.py:102]   [ 20/634]  eta: 0:51:54    time: 2.949310  data: 0.000842  max mem: 4109
I20241203 10:30:25 2030088 dinov2 helpers.py:102]   [ 40/634]  eta: 0:27:08    time: 3.142532  data: 0.001331  max mem: 4109
I20241203 10:30:38 2030095 dinov2 helpers.py:102]   [ 40/634]  eta: 0:30:16    time: 3.493344  data: 0.000593  max mem: 4109
I20241203 10:30:38 2030092 dinov2 helpers.py:102]   [ 20/634]  eta: 0:55:51    time: 3.325622  data: 0.000843  max mem: 4109
I20241203 10:30:46 2030089 dinov2 helpers.py:102]   [ 30/634]  eta: 0:42:22    time: 3.689198  data: 0.000744  max mem: 4109
I20241203 10:30:51 2030090 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:46    time: 3.556644  data: 0.003782  max mem: 4109
I20241203 10:30:52 2030093 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:51    time: 3.559814  data: 0.002327  max mem: 4109
I20241203 10:30:54 2030091 dinov2 helpers.py:102]   [ 20/634]  eta: 0:59:44    time: 3.566221  data: 0.001710  max mem: 4109
I20241203 10:31:02 2030094 dinov2 helpers.py:102]   [ 30/634]  eta: 0:47:22    time: 3.916000  data: 0.001704  max mem: 4109
I20241203 10:31:04 2030088 dinov2 helpers.py:102]   [ 50/634]  eta: 0:28:58    time: 3.917352  data: 0.001718  max mem: 4109
I20241203 10:31:17 2030095 dinov2 helpers.py:102]   [ 50/634]  eta: 0:31:27    time: 3.929957  data: 0.000858  max mem: 4109
I20241203 10:31:18 2030092 dinov2 helpers.py:102]   [ 30/634]  eta: 0:50:02    time: 3.930031  data: 0.001219  max mem: 4109
I20241203 10:31:26 2030089 dinov2 helpers.py:102]   [ 40/634]  eta: 0:41:03    time: 3.935752  data: 0.000760  max mem: 4109
I20241203 10:31:30 2030090 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:59    time: 3.940264  data: 0.002718  max mem: 4109
I20241203 10:31:31 2030093 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:03    time: 3.940334  data: 0.002263  max mem: 4109
I20241203 10:31:33 2030091 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:39    time: 3.944110  data: 0.000984  max mem: 4109
I20241203 10:31:42 2030094 dinov2 helpers.py:102]   [ 40/634]  eta: 0:44:46    time: 3.944939  data: 0.001927  max mem: 4109
I20241203 10:31:44 2030088 dinov2 helpers.py:102]   [ 60/634]  eta: 0:30:00    time: 3.945817  data: 0.001530  max mem: 4109
I20241203 10:31:57 2030095 dinov2 helpers.py:102]   [ 60/634]  eta: 0:32:03    time: 3.950548  data: 0.000869  max mem: 4109
I20241203 10:31:57 2030092 dinov2 helpers.py:102]   [ 40/634]  eta: 0:46:45    time: 3.951143  data: 0.001303  max mem: 4109
I20241203 10:32:05 2030089 dinov2 helpers.py:102]   [ 50/634]  eta: 0:39:59    time: 3.952753  data: 0.001017  max mem: 4109
I20241203 10:32:10 2030090 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:13    time: 3.955080  data: 0.001801  max mem: 4109
I20241203 10:32:11 2030093 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:15    time: 3.955279  data: 0.001203  max mem: 4109
I20241203 10:32:13 2030091 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:42    time: 3.956170  data: 0.001742  max mem: 4109
I20241203 10:32:21 2030094 dinov2 helpers.py:102]   [ 50/634]  eta: 0:42:55    time: 3.953175  data: 0.000848  max mem: 4109
I20241203 10:32:23 2030088 dinov2 helpers.py:102]   [ 70/634]  eta: 0:30:33    time: 3.953020  data: 0.002771  max mem: 4109
I20241203 10:32:36 2030095 dinov2 helpers.py:102]   [ 70/634]  eta: 0:32:17    time: 3.954335  data: 0.000692  max mem: 4109
I20241203 10:32:37 2030092 dinov2 helpers.py:102]   [ 50/634]  eta: 0:44:31    time: 3.959656  data: 0.000936  max mem: 4109
I20241203 10:32:45 2030089 dinov2 helpers.py:102]   [ 60/634]  eta: 0:39:04    time: 3.957783  data: 0.001099  max mem: 4109
I20241203 10:32:50 2030090 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:40    time: 3.960584  data: 0.001095  max mem: 4109
I20241203 10:32:50 2030093 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:42    time: 3.958821  data: 0.001172  max mem: 4109
I20241203 10:32:52 2030091 dinov2 helpers.py:102]   [ 50/634]  eta: 0:46:03    time: 3.956890  data: 0.001801  max mem: 4109
I20241203 10:33:01 2030094 dinov2 helpers.py:102]   [ 60/634]  eta: 0:41:29    time: 3.957197  data: 0.000931  max mem: 4109
I20241203 10:33:03 2030088 dinov2 helpers.py:102]   [ 80/634]  eta: 0:30:50    time: 3.958974  data: 0.002490  max mem: 4109
I20241203 10:33:16 2030095 dinov2 helpers.py:102]   [ 80/634]  eta: 0:32:19    time: 3.962682  data: 0.000687  max mem: 4109
I20241203 10:33:17 2030092 dinov2 helpers.py:102]   [ 60/634]  eta: 0:42:48    time: 3.968449  data: 0.000855  max mem: 4109
I20241203 10:33:24 2030089 dinov2 helpers.py:102]   [ 70/634]  eta: 0:38:14    time: 3.966834  data: 0.001851  max mem: 4109
I20241203 10:33:29 2030090 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:45    time: 3.967801  data: 0.001019  max mem: 4109
I20241203 10:33:30 2030093 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:47    time: 3.967854  data: 0.001093  max mem: 4109
I20241203 10:33:32 2030091 dinov2 helpers.py:102]   [ 60/634]  eta: 0:44:04    time: 3.965281  data: 0.000929  max mem: 4109
I20241203 10:33:41 2030094 dinov2 helpers.py:102]   [ 70/634]  eta: 0:40:17    time: 3.967331  data: 0.001151  max mem: 4109
I20241203 10:33:43 2030088 dinov2 helpers.py:102]   [ 90/634]  eta: 0:30:54    time: 3.969191  data: 0.002138  max mem: 4109
I20241203 10:33:56 2030095 dinov2 helpers.py:102]   [ 90/634]  eta: 0:32:13    time: 3.973176  data: 0.000757  max mem: 4109
I20241203 10:33:57 2030092 dinov2 helpers.py:102]   [ 70/634]  eta: 0:41:24    time: 3.973287  data: 0.001142  max mem: 4109
I20241203 10:34:04 2030089 dinov2 helpers.py:102]   [ 80/634]  eta: 0:37:27    time: 3.973427  data: 0.002260  max mem: 4109
I20241203 10:34:09 2030090 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:12    time: 3.973322  data: 0.000980  max mem: 4109
I20241203 10:34:10 2030093 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:13    time: 3.973548  data: 0.000837  max mem: 4109
I20241203 10:34:12 2030091 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:28    time: 3.973455  data: 0.001124  max mem: 4109
I20241203 10:34:20 2030094 dinov2 helpers.py:102]   [ 80/634]  eta: 0:39:13    time: 3.973428  data: 0.000837  max mem: 4109
I20241203 10:34:22 2030088 dinov2 helpers.py:102]   [100/634]  eta: 0:30:50    time: 3.973544  data: 0.003629  max mem: 4109
I20241203 10:34:35 2030095 dinov2 helpers.py:102]   [100/634]  eta: 0:31:59    time: 3.973477  data: 0.000822  max mem: 4109
I20241203 10:34:36 2030092 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:10    time: 3.973409  data: 0.001300  max mem: 4109
I20241203 10:34:44 2030089 dinov2 helpers.py:102]   [ 90/634]  eta: 0:36:42    time: 3.973480  data: 0.001542  max mem: 4109
I20241203 10:34:49 2030090 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:52    time: 3.973501  data: 0.000860  max mem: 4109
I20241203 10:34:50 2030093 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:53    time: 3.973608  data: 0.000891  max mem: 4109
I20241203 10:34:51 2030091 dinov2 helpers.py:102]   [ 80/634]  eta: 0:41:05    time: 3.973473  data: 0.001068  max mem: 4109
I20241203 10:35:00 2030094 dinov2 helpers.py:102]   [ 90/634]  eta: 0:38:14    time: 3.973565  data: 0.000587  max mem: 4109
I20241203 10:35:02 2030088 dinov2 helpers.py:102]   [110/634]  eta: 0:30:39    time: 3.973731  data: 0.002454  max mem: 4109
I20241203 10:35:15 2030095 dinov2 helpers.py:102]   [110/634]  eta: 0:31:41    time: 3.973562  data: 0.000717  max mem: 4109
I20241203 10:35:16 2030092 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:04    time: 3.973449  data: 0.000872  max mem: 4109
I20241203 10:35:24 2030089 dinov2 helpers.py:102]   [100/634]  eta: 0:35:57    time: 3.973377  data: 0.001060  max mem: 4109
I20241203 10:35:29 2030090 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:40    time: 3.973553  data: 0.000967  max mem: 4109
I20241203 10:35:29 2030093 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:41    time: 3.973288  data: 0.001307  max mem: 4109
I20241203 10:35:31 2030091 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:52    time: 3.973415  data: 0.000534  max mem: 4109
I20241203 10:35:40 2030094 dinov2 helpers.py:102]   [100/634]  eta: 0:37:19    time: 3.973435  data: 0.000701  max mem: 4109
I20241203 10:35:42 2030088 dinov2 helpers.py:102]   [120/634]  eta: 0:30:24    time: 3.973367  data: 0.001835  max mem: 4109
I20241203 10:35:55 2030095 dinov2 helpers.py:102]   [120/634]  eta: 0:31:20    time: 3.973373  data: 0.000716  max mem: 4109
I20241203 10:35:56 2030092 dinov2 helpers.py:102]   [100/634]  eta: 0:38:03    time: 3.973356  data: 0.000579  max mem: 4109
I20241203 10:36:03 2030089 dinov2 helpers.py:102]   [110/634]  eta: 0:35:14    time: 3.973354  data: 0.000825  max mem: 4109
I20241203 10:36:08 2030090 dinov2 helpers.py:102]   [100/634]  eta: 0:38:35    time: 3.973366  data: 0.001923  max mem: 4109
I20241203 10:36:09 2030093 dinov2 helpers.py:102]   [100/634]  eta: 0:38:36    time: 3.973236  data: 0.001988  max mem: 4109
I20241203 10:36:11 2030091 dinov2 helpers.py:102]   [100/634]  eta: 0:38:46    time: 3.973359  data: 0.000966  max mem: 4109
I20241203 10:36:20 2030094 dinov2 helpers.py:102]   [110/634]  eta: 0:36:26    time: 3.973277  data: 0.001163  max mem: 4109
I20241203 10:36:22 2030088 dinov2 helpers.py:102]   [130/634]  eta: 0:30:05    time: 3.973098  data: 0.002864  max mem: 4109
I20241203 10:36:35 2030095 dinov2 helpers.py:102]   [130/634]  eta: 0:30:55    time: 3.973248  data: 0.000628  max mem: 4109
I20241203 10:36:35 2030092 dinov2 helpers.py:102]   [110/634]  eta: 0:37:06    time: 3.973282  data: 0.000685  max mem: 4109
I20241203 10:36:43 2030089 dinov2 helpers.py:102]   [120/634]  eta: 0:34:31    time: 3.973337  data: 0.000775  max mem: 4109
I20241203 10:36:48 2030090 dinov2 helpers.py:102]   [110/634]  eta: 0:37:35    time: 3.973233  data: 0.001667  max mem: 4109
I20241203 10:36:49 2030093 dinov2 helpers.py:102]   [110/634]  eta: 0:37:36    time: 3.973346  data: 0.001557  max mem: 4109
I20241203 10:36:51 2030091 dinov2 helpers.py:102]   [110/634]  eta: 0:37:44    time: 3.973347  data: 0.001279  max mem: 4109
I20241203 10:36:59 2030094 dinov2 helpers.py:102]   [120/634]  eta: 0:35:36    time: 3.973316  data: 0.001396  max mem: 4109
I20241203 10:37:01 2030088 dinov2 helpers.py:102]   [140/634]  eta: 0:29:43    time: 3.973623  data: 0.005199  max mem: 4109
I20241203 10:37:14 2030095 dinov2 helpers.py:102]   [140/634]  eta: 0:30:29    time: 3.973296  data: 0.001618  max mem: 4109
I20241203 10:37:15 2030092 dinov2 helpers.py:102]   [120/634]  eta: 0:36:12    time: 3.973328  data: 0.000772  max mem: 4109
I20241203 10:37:23 2030089 dinov2 helpers.py:102]   [130/634]  eta: 0:33:48    time: 3.973329  data: 0.001089  max mem: 4109
I20241203 10:37:28 2030090 dinov2 helpers.py:102]   [120/634]  eta: 0:36:38    time: 3.973269  data: 0.000696  max mem: 4109
I20241203 10:37:29 2030093 dinov2 helpers.py:102]   [120/634]  eta: 0:36:38    time: 3.973323  data: 0.000923  max mem: 4109
I20241203 10:37:30 2030091 dinov2 helpers.py:102]   [120/634]  eta: 0:36:46    time: 3.973297  data: 0.001085  max mem: 4109
I20241203 10:37:39 2030094 dinov2 helpers.py:102]   [130/634]  eta: 0:34:47    time: 3.973281  data: 0.001329  max mem: 4109
I20241203 10:37:41 2030088 dinov2 helpers.py:102]   [150/634]  eta: 0:29:18    time: 3.973294  data: 0.004363  max mem: 4109
I20241203 10:37:54 2030095 dinov2 helpers.py:102]   [150/634]  eta: 0:30:00    time: 3.973295  data: 0.001687  max mem: 4109
I20241203 10:37:55 2030092 dinov2 helpers.py:102]   [130/634]  eta: 0:35:20    time: 3.973322  data: 0.001493  max mem: 4109
I20241203 10:38:03 2030089 dinov2 helpers.py:102]   [140/634]  eta: 0:33:06    time: 3.973301  data: 0.001180  max mem: 4109
I20241203 10:38:08 2030090 dinov2 helpers.py:102]   [130/634]  eta: 0:35:43    time: 3.973283  data: 0.000756  max mem: 4109
I20241203 10:38:08 2030093 dinov2 helpers.py:102]   [130/634]  eta: 0:35:44    time: 3.973279  data: 0.000815  max mem: 4109
I20241203 10:38:10 2030091 dinov2 helpers.py:102]   [130/634]  eta: 0:35:51    time: 3.973266  data: 0.000760  max mem: 4109
I20241203 10:38:19 2030094 dinov2 helpers.py:102]   [140/634]  eta: 0:34:00    time: 3.973227  data: 0.001937  max mem: 4109
I20241203 10:38:21 2030088 dinov2 helpers.py:102]   [160/634]  eta: 0:28:52    time: 3.973031  data: 0.001906  max mem: 4109
I20241203 10:38:34 2030095 dinov2 helpers.py:102]   [160/634]  eta: 0:29:30    time: 3.973157  data: 0.001120  max mem: 4109
I20241203 10:38:35 2030092 dinov2 helpers.py:102]   [140/634]  eta: 0:34:30    time: 3.973120  data: 0.001629  max mem: 4109
I20241203 10:38:42 2030089 dinov2 helpers.py:102]   [150/634]  eta: 0:32:24    time: 3.973034  data: 0.001018  max mem: 4109
I20241203 10:38:47 2030090 dinov2 helpers.py:102]   [140/634]  eta: 0:34:51    time: 3.972118  data: 0.000901  max mem: 4109
I20241203 10:38:48 2030093 dinov2 helpers.py:102]   [140/634]  eta: 0:34:51    time: 3.972043  data: 0.001192  max mem: 4109
I20241203 10:38:50 2030091 dinov2 helpers.py:102]   [140/634]  eta: 0:34:58    time: 3.972102  data: 0.000660  max mem: 4109
I20241203 10:38:59 2030094 dinov2 helpers.py:102]   [150/634]  eta: 0:33:14    time: 3.972890  data: 0.001642  max mem: 4109
I20241203 10:39:00 2030088 dinov2 helpers.py:102]   [170/634]  eta: 0:28:24    time: 3.972010  data: 0.001994  max mem: 4109
I20241203 10:39:14 2030095 dinov2 helpers.py:102]   [170/634]  eta: 0:28:59    time: 3.972850  data: 0.001149  max mem: 4109
I20241203 10:39:14 2030092 dinov2 helpers.py:102]   [150/634]  eta: 0:33:41    time: 3.969141  data: 0.000850  max mem: 4109
I20241203 10:39:22 2030089 dinov2 helpers.py:102]   [160/634]  eta: 0:31:43    time: 3.970021  data: 0.001536  max mem: 4109
I20241203 10:39:27 2030090 dinov2 helpers.py:102]   [150/634]  eta: 0:34:00    time: 3.971788  data: 0.001158  max mem: 4109
I20241203 10:39:28 2030093 dinov2 helpers.py:102]   [150/634]  eta: 0:34:01    time: 3.971819  data: 0.001349  max mem: 4109
I20241203 10:39:30 2030091 dinov2 helpers.py:102]   [150/634]  eta: 0:34:06    time: 3.971845  data: 0.000771  max mem: 4109
I20241203 10:39:38 2030094 dinov2 helpers.py:102]   [160/634]  eta: 0:32:28    time: 3.972839  data: 0.000681  max mem: 4109
I20241203 10:39:40 2030088 dinov2 helpers.py:102]   [180/634]  eta: 0:27:55    time: 3.971635  data: 0.002708  max mem: 4109
I20241203 10:39:53 2030095 dinov2 helpers.py:102]   [180/634]  eta: 0:28:27    time: 3.969999  data: 0.000581  max mem: 4109
I20241203 10:39:54 2030092 dinov2 helpers.py:102]   [160/634]  eta: 0:32:53    time: 3.969128  data: 0.000562  max mem: 4109
I20241203 10:40:02 2030089 dinov2 helpers.py:102]   [170/634]  eta: 0:31:01    time: 3.969208  data: 0.001501  max mem: 4109
I20241203 10:40:07 2030090 dinov2 helpers.py:102]   [160/634]  eta: 0:33:11    time: 3.970081  data: 0.001179  max mem: 4109
I20241203 10:40:07 2030093 dinov2 helpers.py:102]   [160/634]  eta: 0:33:11    time: 3.972858  data: 0.000901  max mem: 4109
I20241203 10:40:09 2030091 dinov2 helpers.py:102]   [160/634]  eta: 0:33:17    time: 3.972781  data: 0.001083  max mem: 4109
I20241203 10:40:18 2030094 dinov2 helpers.py:102]   [170/634]  eta: 0:31:43    time: 3.972974  data: 0.000781  max mem: 4109
I20241203 10:40:20 2030088 dinov2 helpers.py:102]   [190/634]  eta: 0:27:24    time: 3.972876  data: 0.002635  max mem: 4109
I20241203 10:40:33 2030095 dinov2 helpers.py:102]   [190/634]  eta: 0:27:55    time: 3.970179  data: 0.000736  max mem: 4109
I20241203 10:40:34 2030092 dinov2 helpers.py:102]   [170/634]  eta: 0:32:06    time: 3.972953  data: 0.000724  max mem: 4109
I20241203 10:40:41 2030089 dinov2 helpers.py:102]   [180/634]  eta: 0:30:20    time: 3.972091  data: 0.000994  max mem: 4109
I20241203 10:40:46 2030090 dinov2 helpers.py:102]   [170/634]  eta: 0:32:22    time: 3.970306  data: 0.001000  max mem: 4109
I20241203 10:40:47 2030093 dinov2 helpers.py:102]   [170/634]  eta: 0:32:23    time: 3.973066  data: 0.000823  max mem: 4109
I20241203 10:40:49 2030091 dinov2 helpers.py:102]   [170/634]  eta: 0:32:28    time: 3.973109  data: 0.001074  max mem: 4109
I20241203 10:40:58 2030094 dinov2 helpers.py:102]   [180/634]  eta: 0:30:59    time: 3.972097  data: 0.000954  max mem: 4109
I20241203 10:41:00 2030088 dinov2 helpers.py:102]   [200/634]  eta: 0:26:53    time: 3.973317  data: 0.001936  max mem: 4109
I20241203 10:41:13 2030095 dinov2 helpers.py:102]   [200/634]  eta: 0:27:21    time: 3.973179  data: 0.000882  max mem: 4109
I20241203 10:41:13 2030092 dinov2 helpers.py:102]   [180/634]  eta: 0:31:20    time: 3.971379  data: 0.000792  max mem: 4109
I20241203 10:41:21 2030089 dinov2 helpers.py:102]   [190/634]  eta: 0:29:39    time: 3.973443  data: 0.000809  max mem: 4109
I20241203 10:41:26 2030090 dinov2 helpers.py:102]   [180/634]  eta: 0:31:35    time: 3.973111  data: 0.000971  max mem: 4109
I20241203 10:41:27 2030093 dinov2 helpers.py:102]   [180/634]  eta: 0:31:36    time: 3.972161  data: 0.001483  max mem: 4109
I20241203 10:41:29 2030091 dinov2 helpers.py:102]   [180/634]  eta: 0:31:40    time: 3.972319  data: 0.000913  max mem: 4109
I20241203 10:41:37 2030094 dinov2 helpers.py:102]   [190/634]  eta: 0:30:15    time: 3.971203  data: 0.001606  max mem: 4109
I20241203 10:41:39 2030088 dinov2 helpers.py:102]   [210/634]  eta: 0:26:21    time: 3.973048  data: 0.004191  max mem: 4109
I20241203 10:41:52 2030095 dinov2 helpers.py:102]   [210/634]  eta: 0:26:47    time: 3.971165  data: 0.000771  max mem: 4109
I20241203 10:41:53 2030092 dinov2 helpers.py:102]   [190/634]  eta: 0:30:34    time: 3.968466  data: 0.000868  max mem: 4109
I20241203 10:42:01 2030089 dinov2 helpers.py:102]   [200/634]  eta: 0:28:58    time: 3.969321  data: 0.000963  max mem: 4109
I20241203 10:42:06 2030090 dinov2 helpers.py:102]   [190/634]  eta: 0:30:49    time: 3.971090  data: 0.001200  max mem: 4109
I20241203 10:42:07 2030093 dinov2 helpers.py:102]   [190/634]  eta: 0:30:49    time: 3.968294  data: 0.001430  max mem: 4109
I20241203 10:42:08 2030091 dinov2 helpers.py:102]   [190/634]  eta: 0:30:53    time: 3.971810  data: 0.000808  max mem: 4109
I20241203 10:42:17 2030094 dinov2 helpers.py:102]   [200/634]  eta: 0:29:32    time: 3.971851  data: 0.001765  max mem: 4109
I20241203 10:42:19 2030088 dinov2 helpers.py:102]   [220/634]  eta: 0:25:48    time: 3.968940  data: 0.003303  max mem: 4109
I20241203 10:42:32 2030095 dinov2 helpers.py:102]   [220/634]  eta: 0:26:13    time: 3.969082  data: 0.001837  max mem: 4109
I20241203 10:42:33 2030092 dinov2 helpers.py:102]   [200/634]  eta: 0:29:50    time: 3.969976  data: 0.001025  max mem: 4109
I20241203 10:42:41 2030089 dinov2 helpers.py:102]   [210/634]  eta: 0:28:17    time: 3.968809  data: 0.001143  max mem: 4109
I20241203 10:42:46 2030090 dinov2 helpers.py:102]   [200/634]  eta: 0:30:03    time: 3.969016  data: 0.000998  max mem: 4109
I20241203 10:42:46 2030093 dinov2 helpers.py:102]   [200/634]  eta: 0:30:03    time: 3.969023  data: 0.001213  max mem: 4109
I20241203 10:42:48 2030091 dinov2 helpers.py:102]   [200/634]  eta: 0:30:07    time: 3.972525  data: 0.000934  max mem: 4109
I20241203 10:42:57 2030094 dinov2 helpers.py:102]   [210/634]  eta: 0:28:49    time: 3.971586  data: 0.001257  max mem: 4109
I20241203 10:42:59 2030088 dinov2 helpers.py:102]   [230/634]  eta: 0:25:15    time: 3.966202  data: 0.001173  max mem: 4109
I20241203 10:43:12 2030095 dinov2 helpers.py:102]   [230/634]  eta: 0:25:38    time: 3.969844  data: 0.001727  max mem: 4109
I20241203 10:43:13 2030092 dinov2 helpers.py:102]   [210/634]  eta: 0:29:05    time: 3.971639  data: 0.001628  max mem: 4109
I20241203 10:43:20 2030089 dinov2 helpers.py:102]   [220/634]  eta: 0:27:37    time: 3.972539  data: 0.000766  max mem: 4109
I20241203 10:43:25 2030090 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.968940  data: 0.001470  max mem: 4109
I20241203 10:43:26 2030093 dinov2 helpers.py:102]   [210/634]  eta: 0:29:18    time: 3.972546  data: 0.001408  max mem: 4109
I20241203 10:43:28 2030091 dinov2 helpers.py:102]   [210/634]  eta: 0:29:22    time: 3.972572  data: 0.001026  max mem: 4109
I20241203 10:43:37 2030094 dinov2 helpers.py:102]   [220/634]  eta: 0:28:06    time: 3.971566  data: 0.001134  max mem: 4109
I20241203 10:43:38 2030088 dinov2 helpers.py:102]   [240/634]  eta: 0:24:41    time: 3.968992  data: 0.001687  max mem: 4109
I20241203 10:43:52 2030095 dinov2 helpers.py:102]   [240/634]  eta: 0:25:02    time: 3.970808  data: 0.001575  max mem: 4109
I20241203 10:43:52 2030092 dinov2 helpers.py:102]   [220/634]  eta: 0:28:21    time: 3.970753  data: 0.001756  max mem: 4109
I20241203 10:44:00 2030089 dinov2 helpers.py:102]   [230/634]  eta: 0:26:56    time: 3.972518  data: 0.000663  max mem: 4109
I20241203 10:44:05 2030090 dinov2 helpers.py:102]   [220/634]  eta: 0:28:33    time: 3.970865  data: 0.001844  max mem: 4109
I20241203 10:44:06 2030093 dinov2 helpers.py:102]   [220/634]  eta: 0:28:33    time: 3.972837  data: 0.000990  max mem: 4109
I20241203 10:44:08 2030091 dinov2 helpers.py:102]   [220/634]  eta: 0:28:37    time: 3.972656  data: 0.001227  max mem: 4109
I20241203 10:44:16 2030094 dinov2 helpers.py:102]   [230/634]  eta: 0:27:23    time: 3.972814  data: 0.001284  max mem: 4109
I20241203 10:44:18 2030088 dinov2 helpers.py:102]   [250/634]  eta: 0:24:06    time: 3.971914  data: 0.001638  max mem: 4109
I20241203 10:44:31 2030095 dinov2 helpers.py:102]   [250/634]  eta: 0:24:26    time: 3.972008  data: 0.001630  max mem: 4109
I20241203 10:44:32 2030092 dinov2 helpers.py:102]   [230/634]  eta: 0:27:38    time: 3.972028  data: 0.000939  max mem: 4109
I20241203 10:44:40 2030089 dinov2 helpers.py:102]   [240/634]  eta: 0:26:16    time: 3.973016  data: 0.001120  max mem: 4109
I20241203 10:44:45 2030090 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.973047  data: 0.001589  max mem: 4109
I20241203 10:44:45 2030093 dinov2 helpers.py:102]   [230/634]  eta: 0:27:49    time: 3.973062  data: 0.001033  max mem: 4109
I20241203 10:44:47 2030091 dinov2 helpers.py:102]   [230/634]  eta: 0:27:52    time: 3.973120  data: 0.001433  max mem: 4109
I20241203 10:44:56 2030094 dinov2 helpers.py:102]   [240/634]  eta: 0:26:41    time: 3.973146  data: 0.001229  max mem: 4109
I20241203 10:44:58 2030088 dinov2 helpers.py:102]   [260/634]  eta: 0:23:32    time: 3.973159  data: 0.001208  max mem: 4109
I20241203 10:45:11 2030095 dinov2 helpers.py:102]   [260/634]  eta: 0:23:50    time: 3.973254  data: 0.000750  max mem: 4109
I20241203 10:45:12 2030092 dinov2 helpers.py:102]   [240/634]  eta: 0:26:55    time: 3.973370  data: 0.001070  max mem: 4109
I20241203 10:45:19 2030089 dinov2 helpers.py:102]   [250/634]  eta: 0:25:35    time: 3.973403  data: 0.001139  max mem: 4109
I20241203 10:45:24 2030090 dinov2 helpers.py:102]   [240/634]  eta: 0:27:05    time: 3.973489  data: 0.001301  max mem: 4109
I20241203 10:45:25 2030093 dinov2 helpers.py:102]   [240/634]  eta: 0:27:05    time: 3.973296  data: 0.001267  max mem: 4109
I20241203 10:45:27 2030091 dinov2 helpers.py:102]   [240/634]  eta: 0:27:08    time: 3.974377  data: 0.000917  max mem: 4109
I20241203 10:45:36 2030094 dinov2 helpers.py:102]   [250/634]  eta: 0:25:59    time: 3.974496  data: 0.001015  max mem: 4109
I20241203 10:45:38 2030088 dinov2 helpers.py:102]   [270/634]  eta: 0:22:57    time: 3.974637  data: 0.002249  max mem: 4109
I20241203 10:45:51 2030095 dinov2 helpers.py:102]   [270/634]  eta: 0:23:14    time: 3.973854  data: 0.000780  max mem: 4109
I20241203 10:45:52 2030092 dinov2 helpers.py:102]   [250/634]  eta: 0:26:12    time: 3.975732  data: 0.001161  max mem: 4109
I20241203 10:45:59 2030089 dinov2 helpers.py:102]   [260/634]  eta: 0:24:55    time: 3.973970  data: 0.001133  max mem: 4109
I20241203 10:46:04 2030090 dinov2 helpers.py:102]   [250/634]  eta: 0:26:21    time: 3.978574  data: 0.000884  max mem: 4109
I20241203 10:46:05 2030093 dinov2 helpers.py:102]   [250/634]  eta: 0:26:22    time: 3.978696  data: 0.001008  max mem: 4109
I20241203 10:46:07 2030091 dinov2 helpers.py:102]   [250/634]  eta: 0:26:24    time: 3.975081  data: 0.001340  max mem: 4109
I20241203 10:46:16 2030094 dinov2 helpers.py:102]   [260/634]  eta: 0:25:17    time: 3.976028  data: 0.001096  max mem: 4109
I20241203 10:46:17 2030088 dinov2 helpers.py:102]   [280/634]  eta: 0:22:21    time: 3.976933  data: 0.003720  max mem: 4109
I20241203 10:46:31 2030095 dinov2 helpers.py:102]   [280/634]  eta: 0:22:38    time: 3.977003  data: 0.001275  max mem: 4109
I20241203 10:46:31 2030092 dinov2 helpers.py:102]   [260/634]  eta: 0:25:29    time: 3.976054  data: 0.000669  max mem: 4109
I20241203 10:46:39 2030089 dinov2 helpers.py:102]   [270/634]  eta: 0:24:15    time: 3.978032  data: 0.001201  max mem: 4109
I20241203 10:46:44 2030090 dinov2 helpers.py:102]   [260/634]  eta: 0:25:38    time: 3.982560  data: 0.001047  max mem: 4109
I20241203 10:46:45 2030093 dinov2 helpers.py:102]   [260/634]  eta: 0:25:38    time: 3.982674  data: 0.000815  max mem: 4109
I20241203 10:46:47 2030091 dinov2 helpers.py:102]   [260/634]  eta: 0:25:41    time: 3.977499  data: 0.002019  max mem: 4109
I20241203 10:46:55 2030094 dinov2 helpers.py:102]   [270/634]  eta: 0:24:36    time: 3.979014  data: 0.001681  max mem: 4109
I20241203 10:46:57 2030088 dinov2 helpers.py:102]   [290/634]  eta: 0:21:46    time: 3.978973  data: 0.004087  max mem: 4109
I20241203 10:47:10 2030095 dinov2 helpers.py:102]   [290/634]  eta: 0:22:01    time: 3.980820  data: 0.001276  max mem: 4109
I20241203 10:47:11 2030092 dinov2 helpers.py:102]   [270/634]  eta: 0:24:47    time: 3.977460  data: 0.000749  max mem: 4109
I20241203 10:47:19 2030089 dinov2 helpers.py:102]   [280/634]  eta: 0:23:35    time: 3.982587  data: 0.000831  max mem: 4109
I20241203 10:47:24 2030090 dinov2 helpers.py:102]   [270/634]  eta: 0:24:55    time: 3.980810  data: 0.001009  max mem: 4109
I20241203 10:47:25 2030093 dinov2 helpers.py:102]   [270/634]  eta: 0:24:55    time: 3.980706  data: 0.002073  max mem: 4109
I20241203 10:47:27 2030091 dinov2 helpers.py:102]   [270/634]  eta: 0:24:58    time: 3.982506  data: 0.001318  max mem: 4109
I20241203 10:47:35 2030094 dinov2 helpers.py:102]   [280/634]  eta: 0:23:54    time: 3.981688  data: 0.001962  max mem: 4109
I20241203 10:47:37 2030088 dinov2 helpers.py:102]   [300/634]  eta: 0:21:10    time: 3.978022  data: 0.002589  max mem: 4109
I20241203 10:47:50 2030095 dinov2 helpers.py:102]   [300/634]  eta: 0:21:24    time: 3.979931  data: 0.000767  max mem: 4109
I20241203 10:47:51 2030092 dinov2 helpers.py:102]   [280/634]  eta: 0:24:05    time: 3.981709  data: 0.000895  max mem: 4109
I20241203 10:47:59 2030089 dinov2 helpers.py:102]   [290/634]  eta: 0:22:54    time: 3.980778  data: 0.000903  max mem: 4109
I20241203 10:48:04 2030090 dinov2 helpers.py:102]   [280/634]  eta: 0:24:12    time: 3.981630  data: 0.001170  max mem: 4109
I20241203 10:48:04 2030093 dinov2 helpers.py:102]   [280/634]  eta: 0:24:13    time: 3.978910  data: 0.002978  max mem: 4109
I20241203 10:48:06 2030091 dinov2 helpers.py:102]   [280/634]  eta: 0:24:15    time: 3.982246  data: 0.000766  max mem: 4109
I20241203 10:48:15 2030094 dinov2 helpers.py:102]   [290/634]  eta: 0:23:13    time: 3.978933  data: 0.001340  max mem: 4109
I20241203 10:48:17 2030088 dinov2 helpers.py:102]   [310/634]  eta: 0:20:33    time: 3.981660  data: 0.001069  max mem: 4109
I20241203 10:48:30 2030095 dinov2 helpers.py:102]   [310/634]  eta: 0:20:47    time: 3.978048  data: 0.000923  max mem: 4109
I20241203 10:48:31 2030092 dinov2 helpers.py:102]   [290/634]  eta: 0:23:23    time: 3.981340  data: 0.001901  max mem: 4109
I20241203 10:48:38 2030089 dinov2 helpers.py:102]   [300/634]  eta: 0:22:14    time: 3.978936  data: 0.001231  max mem: 4109
I20241203 10:48:44 2030090 dinov2 helpers.py:102]   [290/634]  eta: 0:23:30    time: 3.983408  data: 0.001149  max mem: 4109
I20241203 10:48:44 2030093 dinov2 helpers.py:102]   [290/634]  eta: 0:23:30    time: 3.977961  data: 0.001808  max mem: 4109
I20241203 10:48:46 2030091 dinov2 helpers.py:102]   [290/634]  eta: 0:23:32    time: 3.981612  data: 0.000770  max mem: 4109
I20241203 10:48:55 2030094 dinov2 helpers.py:102]   [300/634]  eta: 0:22:31    time: 3.979796  data: 0.001542  max mem: 4109
I20241203 10:48:57 2030088 dinov2 helpers.py:102]   [320/634]  eta: 0:19:57    time: 3.986162  data: 0.001200  max mem: 4109
I20241203 10:49:10 2030095 dinov2 helpers.py:102]   [320/634]  eta: 0:20:10    time: 3.979857  data: 0.001332  max mem: 4109
I20241203 10:49:10 2030092 dinov2 helpers.py:102]   [300/634]  eta: 0:22:41    time: 3.977247  data: 0.001915  max mem: 4109
I20241203 10:49:18 2030089 dinov2 helpers.py:102]   [310/634]  eta: 0:21:34    time: 3.979884  data: 0.001942  max mem: 4109
I20241203 10:49:23 2030090 dinov2 helpers.py:102]   [300/634]  eta: 0:22:48    time: 3.982594  data: 0.001052  max mem: 4109
I20241203 10:49:24 2030093 dinov2 helpers.py:102]   [300/634]  eta: 0:22:48    time: 3.979817  data: 0.000991  max mem: 4109
I20241203 10:49:26 2030091 dinov2 helpers.py:102]   [300/634]  eta: 0:22:50    time: 3.984393  data: 0.000655  max mem: 4109
I20241203 10:49:35 2030094 dinov2 helpers.py:102]   [310/634]  eta: 0:21:50    time: 3.981662  data: 0.001590  max mem: 4109
I20241203 10:49:36 2030088 dinov2 helpers.py:102]   [330/634]  eta: 0:19:20    time: 3.980665  data: 0.001080  max mem: 4109
I20241203 10:49:50 2030095 dinov2 helpers.py:102]   [330/634]  eta: 0:19:33    time: 3.981647  data: 0.001398  max mem: 4109
I20241203 10:49:50 2030092 dinov2 helpers.py:102]   [310/634]  eta: 0:21:59    time: 3.978931  data: 0.001245  max mem: 4109
I20241203 10:49:58 2030089 dinov2 helpers.py:102]   [320/634]  eta: 0:20:54    time: 3.984519  data: 0.001892  max mem: 4109
I20241203 10:50:03 2030090 dinov2 helpers.py:102]   [310/634]  eta: 0:22:06    time: 3.982630  data: 0.001311  max mem: 4109
I20241203 10:50:04 2030093 dinov2 helpers.py:102]   [310/634]  eta: 0:22:06    time: 3.981709  data: 0.001439  max mem: 4109
I20241203 10:50:06 2030091 dinov2 helpers.py:102]   [310/634]  eta: 0:22:08    time: 3.984345  data: 0.001480  max mem: 4109
I20241203 10:50:14 2030094 dinov2 helpers.py:102]   [320/634]  eta: 0:21:09    time: 3.979903  data: 0.001596  max mem: 4109
I20241203 10:50:16 2030088 dinov2 helpers.py:102]   [340/634]  eta: 0:18:44    time: 3.979858  data: 0.001088  max mem: 4109
I20241203 10:50:29 2030095 dinov2 helpers.py:102]   [340/634]  eta: 0:18:55    time: 3.980698  data: 0.001056  max mem: 4109
I20241203 10:50:30 2030092 dinov2 helpers.py:102]   [320/634]  eta: 0:21:17    time: 3.983307  data: 0.001327  max mem: 4109
I20241203 10:50:38 2030089 dinov2 helpers.py:102]   [330/634]  eta: 0:20:14    time: 3.986071  data: 0.001181  max mem: 4109
I20241203 10:50:43 2030090 dinov2 helpers.py:102]   [320/634]  eta: 0:21:24    time: 3.985170  data: 0.001058  max mem: 4109
I20241203 10:50:44 2030093 dinov2 helpers.py:102]   [320/634]  eta: 0:21:24    time: 3.979007  data: 0.001794  max mem: 4109
I20241203 10:50:46 2030091 dinov2 helpers.py:102]   [320/634]  eta: 0:21:26    time: 3.983360  data: 0.001652  max mem: 4109
I20241203 10:50:54 2030094 dinov2 helpers.py:102]   [330/634]  eta: 0:20:28    time: 3.981613  data: 0.002274  max mem: 4109
I20241203 10:50:56 2030088 dinov2 helpers.py:102]   [350/634]  eta: 0:18:07    time: 3.983400  data: 0.001190  max mem: 4109
I20241203 10:51:09 2030095 dinov2 helpers.py:102]   [350/634]  eta: 0:18:17    time: 3.978899  data: 0.001047  max mem: 4109
I20241203 10:51:10 2030092 dinov2 helpers.py:102]   [330/634]  eta: 0:20:36    time: 3.978877  data: 0.000976  max mem: 4109
I20241203 10:51:18 2030089 dinov2 helpers.py:102]   [340/634]  eta: 0:19:34    time: 3.979681  data: 0.001029  max mem: 4109
I20241203 10:51:23 2030090 dinov2 helpers.py:102]   [330/634]  eta: 0:20:42    time: 3.985988  data: 0.000789  max mem: 4109
I20241203 10:51:23 2030093 dinov2 helpers.py:102]   [330/634]  eta: 0:20:42    time: 3.981557  data: 0.002824  max mem: 4109
I20241203 10:51:25 2030091 dinov2 helpers.py:102]   [330/634]  eta: 0:20:44    time: 3.979754  data: 0.000989  max mem: 4109
I20241203 10:51:34 2030094 dinov2 helpers.py:102]   [340/634]  eta: 0:19:47    time: 3.984229  data: 0.002081  max mem: 4109
I20241203 10:51:36 2030088 dinov2 helpers.py:102]   [360/634]  eta: 0:17:30    time: 3.983298  data: 0.000895  max mem: 4109
I20241203 10:51:49 2030095 dinov2 helpers.py:102]   [360/634]  eta: 0:17:39    time: 3.977900  data: 0.001550  max mem: 4109
I20241203 10:51:50 2030092 dinov2 helpers.py:102]   [340/634]  eta: 0:19:54    time: 3.977035  data: 0.000901  max mem: 4109
I20241203 10:51:58 2030089 dinov2 helpers.py:102]   [350/634]  eta: 0:18:54    time: 3.978930  data: 0.000805  max mem: 4109
I20241203 10:52:03 2030090 dinov2 helpers.py:102]   [340/634]  eta: 0:20:00    time: 3.982513  data: 0.000851  max mem: 4109
I20241203 10:52:03 2030093 dinov2 helpers.py:102]   [340/634]  eta: 0:20:00    time: 3.981494  data: 0.002924  max mem: 4109
I20241203 10:52:05 2030091 dinov2 helpers.py:102]   [340/634]  eta: 0:20:02    time: 3.981564  data: 0.000987  max mem: 4109
I20241203 10:52:14 2030094 dinov2 helpers.py:102]   [350/634]  eta: 0:19:06    time: 3.986082  data: 0.001414  max mem: 4109
I20241203 10:52:16 2030088 dinov2 helpers.py:102]   [370/634]  eta: 0:16:52    time: 3.980836  data: 0.001596  max mem: 4109
I20241203 10:52:29 2030095 dinov2 helpers.py:102]   [370/634]  eta: 0:17:02    time: 3.976233  data: 0.002065  max mem: 4109
I20241203 10:52:30 2030092 dinov2 helpers.py:102]   [350/634]  eta: 0:19:13    time: 3.984356  data: 0.000842  max mem: 4109
I20241203 10:52:37 2030089 dinov2 helpers.py:102]   [360/634]  eta: 0:18:14    time: 3.978182  data: 0.000601  max mem: 4109
I20241203 10:52:43 2030090 dinov2 helpers.py:102]   [350/634]  eta: 0:19:18    time: 3.984521  data: 0.000894  max mem: 4109
I20241203 10:52:43 2030093 dinov2 helpers.py:102]   [350/634]  eta: 0:19:18    time: 3.981729  data: 0.002125  max mem: 4109
I20241203 10:52:45 2030091 dinov2 helpers.py:102]   [350/634]  eta: 0:19:20    time: 3.982638  data: 0.001115  max mem: 4109
I20241203 10:52:54 2030094 dinov2 helpers.py:102]   [360/634]  eta: 0:18:26    time: 3.986394  data: 0.001250  max mem: 4109
I20241203 10:52:56 2030088 dinov2 helpers.py:102]   [380/634]  eta: 0:16:15    time: 3.981822  data: 0.002254  max mem: 4109
I20241203 10:53:09 2030095 dinov2 helpers.py:102]   [380/634]  eta: 0:16:24    time: 3.979195  data: 0.001522  max mem: 4109
I20241203 10:53:09 2030092 dinov2 helpers.py:102]   [360/634]  eta: 0:18:32    time: 3.983696  data: 0.001000  max mem: 4109
I20241203 10:53:17 2030089 dinov2 helpers.py:102]   [370/634]  eta: 0:17:34    time: 3.979086  data: 0.001100  max mem: 4109
I20241203 10:53:22 2030090 dinov2 helpers.py:102]   [360/634]  eta: 0:18:37    time: 3.988999  data: 0.001781  max mem: 4109
I20241203 10:53:23 2030093 dinov2 helpers.py:102]   [360/634]  eta: 0:18:37    time: 3.990018  data: 0.001827  max mem: 4109
I20241203 10:53:25 2030091 dinov2 helpers.py:102]   [360/634]  eta: 0:18:38    time: 3.979137  data: 0.001957  max mem: 4109
I20241203 10:53:34 2030094 dinov2 helpers.py:102]   [370/634]  eta: 0:17:45    time: 3.986364  data: 0.001539  max mem: 4109
I20241203 10:53:35 2030088 dinov2 helpers.py:102]   [390/634]  eta: 0:15:37    time: 3.982632  data: 0.002535  max mem: 4109
I20241203 10:53:48 2030095 dinov2 helpers.py:102]   [390/634]  eta: 0:15:46    time: 3.985422  data: 0.002107  max mem: 4109
I20241203 10:53:49 2030092 dinov2 helpers.py:102]   [370/634]  eta: 0:17:51    time: 3.984528  data: 0.000848  max mem: 4109
I20241203 10:53:57 2030089 dinov2 helpers.py:102]   [380/634]  eta: 0:16:54    time: 3.979958  data: 0.001739  max mem: 4109
I20241203 10:54:02 2030090 dinov2 helpers.py:102]   [370/634]  eta: 0:17:55    time: 3.988000  data: 0.001943  max mem: 4109
I20241203 10:54:03 2030093 dinov2 helpers.py:102]   [370/634]  eta: 0:17:55    time: 3.988435  data: 0.001015  max mem: 4109
I20241203 10:54:05 2030091 dinov2 helpers.py:102]   [370/634]  eta: 0:17:57    time: 3.978186  data: 0.001811  max mem: 4109
I20241203 10:54:14 2030094 dinov2 helpers.py:102]   [380/634]  eta: 0:17:04    time: 3.987015  data: 0.001194  max mem: 4109
I20241203 10:54:15 2030088 dinov2 helpers.py:102]   [400/634]  eta: 0:15:00    time: 3.983567  data: 0.002469  max mem: 4109
I20241203 10:54:28 2030095 dinov2 helpers.py:102]   [400/634]  eta: 0:15:07    time: 3.984371  data: 0.002815  max mem: 4109
I20241203 10:54:29 2030092 dinov2 helpers.py:102]   [380/634]  eta: 0:17:10    time: 3.986190  data: 0.001095  max mem: 4109
I20241203 10:54:37 2030089 dinov2 helpers.py:102]   [390/634]  eta: 0:16:14    time: 3.979017  data: 0.001207  max mem: 4109
I20241203 10:54:42 2030090 dinov2 helpers.py:102]   [380/634]  eta: 0:17:14    time: 3.982618  data: 0.001060  max mem: 4109
I20241203 10:54:43 2030093 dinov2 helpers.py:102]   [380/634]  eta: 0:17:14    time: 3.985167  data: 0.000712  max mem: 4109
I20241203 10:54:44 2030091 dinov2 helpers.py:102]   [380/634]  eta: 0:17:15    time: 3.979036  data: 0.000720  max mem: 4109
I20241203 10:54:53 2030094 dinov2 helpers.py:102]   [390/634]  eta: 0:16:24    time: 3.982616  data: 0.000981  max mem: 4109
I20241203 10:54:55 2030088 dinov2 helpers.py:102]   [410/634]  eta: 0:14:22    time: 3.983507  data: 0.001467  max mem: 4109
I20241203 10:55:08 2030095 dinov2 helpers.py:102]   [410/634]  eta: 0:14:29    time: 3.978046  data: 0.001442  max mem: 4109
I20241203 10:55:09 2030092 dinov2 helpers.py:102]   [390/634]  eta: 0:16:29    time: 3.987067  data: 0.001153  max mem: 4109
I20241203 10:55:17 2030089 dinov2 helpers.py:102]   [400/634]  eta: 0:15:34    time: 3.980745  data: 0.000681  max mem: 4109
I20241203 10:55:22 2030090 dinov2 helpers.py:102]   [390/634]  eta: 0:16:33    time: 3.985236  data: 0.001078  max mem: 4109
I20241203 10:55:23 2030093 dinov2 helpers.py:102]   [390/634]  eta: 0:16:33    time: 3.983066  data: 0.000783  max mem: 4109
I20241203 10:55:24 2030091 dinov2 helpers.py:102]   [390/634]  eta: 0:16:34    time: 3.980704  data: 0.000853  max mem: 4109
I20241203 10:55:33 2030094 dinov2 helpers.py:102]   [400/634]  eta: 0:15:43    time: 3.979146  data: 0.001091  max mem: 4109
I20241203 10:55:35 2030088 dinov2 helpers.py:102]   [420/634]  eta: 0:13:44    time: 3.980843  data: 0.001533  max mem: 4109
I20241203 10:55:48 2030095 dinov2 helpers.py:102]   [420/634]  eta: 0:13:51    time: 3.976477  data: 0.000802  max mem: 4109
I20241203 10:55:49 2030092 dinov2 helpers.py:102]   [400/634]  eta: 0:15:48    time: 3.989075  data: 0.000721  max mem: 4109
I20241203 10:55:56 2030089 dinov2 helpers.py:102]   [410/634]  eta: 0:14:54    time: 3.982735  data: 0.000820  max mem: 4109
I20241203 10:56:02 2030090 dinov2 helpers.py:102]   [400/634]  eta: 0:15:52    time: 3.992607  data: 0.000964  max mem: 4109
I20241203 10:56:02 2030093 dinov2 helpers.py:102]   [400/634]  eta: 0:15:52    time: 3.981834  data: 0.000752  max mem: 4109
I20241203 10:56:04 2030091 dinov2 helpers.py:102]   [400/634]  eta: 0:15:53    time: 3.982722  data: 0.001204  max mem: 4109
I20241203 10:56:13 2030094 dinov2 helpers.py:102]   [410/634]  eta: 0:15:02    time: 3.981776  data: 0.000915  max mem: 4109
I20241203 10:56:15 2030088 dinov2 helpers.py:102]   [430/634]  eta: 0:13:06    time: 3.984488  data: 0.001917  max mem: 4109
I20241203 10:56:28 2030095 dinov2 helpers.py:102]   [430/634]  eta: 0:13:12    time: 3.983685  data: 0.000827  max mem: 4109
I20241203 10:56:29 2030092 dinov2 helpers.py:102]   [410/634]  eta: 0:15:07    time: 3.981863  data: 0.001034  max mem: 4109
I20241203 10:56:36 2030089 dinov2 helpers.py:102]   [420/634]  eta: 0:14:14    time: 3.987175  data: 0.000864  max mem: 4109
I20241203 10:56:42 2030090 dinov2 helpers.py:102]   [410/634]  eta: 0:15:10    time: 3.988333  data: 0.000755  max mem: 4109
I20241203 10:56:42 2030093 dinov2 helpers.py:102]   [410/634]  eta: 0:15:10    time: 3.986391  data: 0.001117  max mem: 4109
I20241203 10:56:44 2030091 dinov2 helpers.py:102]   [410/634]  eta: 0:15:11    time: 3.986359  data: 0.001683  max mem: 4109
I20241203 10:56:53 2030094 dinov2 helpers.py:102]   [420/634]  eta: 0:14:22    time: 3.987113  data: 0.001163  max mem: 4109
I20241203 10:56:55 2030088 dinov2 helpers.py:102]   [440/634]  eta: 0:12:28    time: 3.984449  data: 0.001329  max mem: 4109
I20241203 10:57:08 2030095 dinov2 helpers.py:102]   [440/634]  eta: 0:12:34    time: 3.988854  data: 0.001738  max mem: 4109
I20241203 10:57:09 2030092 dinov2 helpers.py:102]   [420/634]  eta: 0:14:26    time: 3.982517  data: 0.002248  max mem: 4109
I20241203 10:57:16 2030089 dinov2 helpers.py:102]   [430/634]  eta: 0:13:34    time: 3.987020  data: 0.000832  max mem: 4109
I20241203 10:57:22 2030090 dinov2 helpers.py:102]   [420/634]  eta: 0:14:29    time: 3.980724  data: 0.000960  max mem: 4109
I20241203 10:57:22 2030093 dinov2 helpers.py:102]   [420/634]  eta: 0:14:29    time: 3.984353  data: 0.001187  max mem: 4109
I20241203 10:57:24 2030091 dinov2 helpers.py:102]   [420/634]  eta: 0:14:30    time: 3.987871  data: 0.001559  max mem: 4109
I20241203 10:57:33 2030094 dinov2 helpers.py:102]   [430/634]  eta: 0:13:41    time: 3.991578  data: 0.001081  max mem: 4109
I20241203 10:57:34 2030088 dinov2 helpers.py:102]   [450/634]  eta: 0:11:50    time: 3.979877  data: 0.000850  max mem: 4109
I20241203 10:57:47 2030095 dinov2 helpers.py:102]   [450/634]  eta: 0:11:55    time: 3.983372  data: 0.001926  max mem: 4109
I20241203 10:57:48 2030092 dinov2 helpers.py:102]   [430/634]  eta: 0:13:45    time: 3.985223  data: 0.002498  max mem: 4109
I20241203 10:57:56 2030089 dinov2 helpers.py:102]   [440/634]  eta: 0:12:54    time: 3.984334  data: 0.001342  max mem: 4109
I20241203 10:58:01 2030090 dinov2 helpers.py:102]   [430/634]  eta: 0:13:48    time: 3.977837  data: 0.001251  max mem: 4109
I20241203 10:58:02 2030093 dinov2 helpers.py:102]   [430/634]  eta: 0:13:48    time: 3.980727  data: 0.000826  max mem: 4109
I20241203 10:58:04 2030091 dinov2 helpers.py:102]   [430/634]  eta: 0:13:49    time: 3.986092  data: 0.000960  max mem: 4109
I20241203 10:58:13 2030094 dinov2 helpers.py:102]   [440/634]  eta: 0:13:01    time: 3.986109  data: 0.000807  max mem: 4109
I20241203 10:58:14 2030088 dinov2 helpers.py:102]   [460/634]  eta: 0:11:12    time: 3.978925  data: 0.001349  max mem: 4109
I20241203 10:58:27 2030095 dinov2 helpers.py:102]   [460/634]  eta: 0:11:17    time: 3.982545  data: 0.000902  max mem: 4109
I20241203 10:58:28 2030092 dinov2 helpers.py:102]   [440/634]  eta: 0:13:04    time: 3.982559  data: 0.001276  max mem: 4109
I20241203 10:58:36 2030089 dinov2 helpers.py:102]   [450/634]  eta: 0:12:14    time: 3.981704  data: 0.001527  max mem: 4109
I20241203 10:58:41 2030090 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.983506  data: 0.001285  max mem: 4109
I20241203 10:58:42 2030093 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.983629  data: 0.000665  max mem: 4109
I20241203 10:58:44 2030091 dinov2 helpers.py:102]   [440/634]  eta: 0:13:08    time: 3.984384  data: 0.000878  max mem: 4109
I20241203 10:58:52 2030094 dinov2 helpers.py:102]   [450/634]  eta: 0:12:20    time: 3.982560  data: 0.000819  max mem: 4109
I20241203 10:58:54 2030088 dinov2 helpers.py:102]   [470/634]  eta: 0:10:34    time: 3.980752  data: 0.001736  max mem: 4109
I20241203 10:59:07 2030095 dinov2 helpers.py:102]   [470/634]  eta: 0:10:38    time: 3.988066  data: 0.001506  max mem: 4109
I20241203 10:59:08 2030092 dinov2 helpers.py:102]   [450/634]  eta: 0:12:24    time: 3.982629  data: 0.001073  max mem: 4109
I20241203 10:59:16 2030089 dinov2 helpers.py:102]   [460/634]  eta: 0:11:34    time: 3.981756  data: 0.001053  max mem: 4109
I20241203 10:59:21 2030090 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.985331  data: 0.000924  max mem: 4109
I20241203 10:59:22 2030093 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.987175  data: 0.000946  max mem: 4109
I20241203 10:59:23 2030091 dinov2 helpers.py:102]   [450/634]  eta: 0:12:27    time: 3.987135  data: 0.000956  max mem: 4109
I20241203 10:59:32 2030094 dinov2 helpers.py:102]   [460/634]  eta: 0:11:40    time: 3.984388  data: 0.000679  max mem: 4109
I20241203 10:59:34 2030088 dinov2 helpers.py:102]   [480/634]  eta: 0:09:55    time: 3.978175  data: 0.001417  max mem: 4109
I20241203 10:59:47 2030095 dinov2 helpers.py:102]   [480/634]  eta: 0:10:00    time: 3.989972  data: 0.001422  max mem: 4109
I20241203 10:59:48 2030092 dinov2 helpers.py:102]   [460/634]  eta: 0:11:43    time: 3.983566  data: 0.001450  max mem: 4109
I20241203 10:59:55 2030089 dinov2 helpers.py:102]   [470/634]  eta: 0:10:54    time: 3.985381  data: 0.000872  max mem: 4109
I20241203 11:00:01 2030090 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.984564  data: 0.000919  max mem: 4109
I20241203 11:00:02 2030093 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.988841  data: 0.001052  max mem: 4109
I20241203 11:00:03 2030091 dinov2 helpers.py:102]   [460/634]  eta: 0:11:46    time: 3.988120  data: 0.000843  max mem: 4109
I20241203 11:00:12 2030094 dinov2 helpers.py:102]   [470/634]  eta: 0:11:00    time: 3.984453  data: 0.001072  max mem: 4109
I20241203 11:00:14 2030088 dinov2 helpers.py:102]   [490/634]  eta: 0:09:17    time: 3.978200  data: 0.001443  max mem: 4109
I20241203 11:00:27 2030095 dinov2 helpers.py:102]   [490/634]  eta: 0:09:21    time: 3.988899  data: 0.000730  max mem: 4109
I20241203 11:00:28 2030092 dinov2 helpers.py:102]   [470/634]  eta: 0:11:02    time: 3.986298  data: 0.001309  max mem: 4109
I20241203 11:00:35 2030089 dinov2 helpers.py:102]   [480/634]  eta: 0:10:14    time: 3.987053  data: 0.000708  max mem: 4109
I20241203 11:00:41 2030090 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.987957  data: 0.001180  max mem: 4109
I20241203 11:00:41 2030093 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.986968  data: 0.000643  max mem: 4109
I20241203 11:00:43 2030091 dinov2 helpers.py:102]   [470/634]  eta: 0:11:05    time: 3.988837  data: 0.000550  max mem: 4109
I20241203 11:00:52 2030094 dinov2 helpers.py:102]   [480/634]  eta: 0:10:19    time: 3.983477  data: 0.001595  max mem: 4109
I20241203 11:00:53 2030088 dinov2 helpers.py:102]   [500/634]  eta: 0:08:39    time: 3.984461  data: 0.003372  max mem: 4109
I20241203 11:01:07 2030095 dinov2 helpers.py:102]   [500/634]  eta: 0:08:42    time: 3.985165  data: 0.000717  max mem: 4109
I20241203 11:01:08 2030092 dinov2 helpers.py:102]   [480/634]  eta: 0:10:22    time: 3.986207  data: 0.001281  max mem: 4109
I20241203 11:01:15 2030089 dinov2 helpers.py:102]   [490/634]  eta: 0:09:34    time: 3.986224  data: 0.001065  max mem: 4109
I20241203 11:01:21 2030090 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.982505  data: 0.000957  max mem: 4109
I20241203 11:01:21 2030093 dinov2 helpers.py:102]   [480/634]  eta: 0:10:24    time: 3.982618  data: 0.000741  max mem: 4109
I20241203 11:01:23 2030091 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.989825  data: 0.000685  max mem: 4109
I20241203 11:01:32 2030094 dinov2 helpers.py:102]   [490/634]  eta: 0:09:39    time: 3.983389  data: 0.001307  max mem: 4109
I20241203 11:01:33 2030088 dinov2 helpers.py:102]   [510/634]  eta: 0:08:00    time: 3.987037  data: 0.003395  max mem: 4109
I20241203 11:01:47 2030095 dinov2 helpers.py:102]   [510/634]  eta: 0:08:03    time: 3.984431  data: 0.001119  max mem: 4109
I20241203 11:01:47 2030092 dinov2 helpers.py:102]   [490/634]  eta: 0:09:41    time: 3.981700  data: 0.001007  max mem: 4109
I20241203 11:01:55 2030089 dinov2 helpers.py:102]   [500/634]  eta: 0:08:54    time: 3.979829  data: 0.001424  max mem: 4109
I20241203 11:02:00 2030090 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.980930  data: 0.000856  max mem: 4109
I20241203 11:02:01 2030093 dinov2 helpers.py:102]   [490/634]  eta: 0:09:43    time: 3.982660  data: 0.001148  max mem: 4109
I20241203 11:02:03 2030091 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.989830  data: 0.001052  max mem: 4109
I20241203 11:02:12 2030094 dinov2 helpers.py:102]   [500/634]  eta: 0:08:59    time: 3.987186  data: 0.001011  max mem: 4109
I20241203 11:02:13 2030088 dinov2 helpers.py:102]   [520/634]  eta: 0:07:22    time: 3.985262  data: 0.001643  max mem: 4109
I20241203 11:02:26 2030095 dinov2 helpers.py:102]   [520/634]  eta: 0:07:25    time: 3.982638  data: 0.001390  max mem: 4109
I20241203 11:02:27 2030092 dinov2 helpers.py:102]   [500/634]  eta: 0:09:01    time: 3.981705  data: 0.000841  max mem: 4109
I20241203 11:02:35 2030089 dinov2 helpers.py:102]   [510/634]  eta: 0:08:14    time: 3.978818  data: 0.001082  max mem: 4109
I20241203 11:02:40 2030090 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.988061  data: 0.000719  max mem: 4109
I20241203 11:02:41 2030093 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.987078  data: 0.001072  max mem: 4109
I20241203 11:02:43 2030091 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.989748  data: 0.001087  max mem: 4109
I20241203 11:02:52 2030094 dinov2 helpers.py:102]   [510/634]  eta: 0:08:18    time: 3.990894  data: 0.000904  max mem: 4109
I20241203 11:02:53 2030088 dinov2 helpers.py:102]   [530/634]  eta: 0:06:43    time: 3.981810  data: 0.001243  max mem: 4109
I20241203 11:03:06 2030095 dinov2 helpers.py:102]   [530/634]  eta: 0:06:46    time: 3.980028  data: 0.001315  max mem: 4109
I20241203 11:03:07 2030092 dinov2 helpers.py:102]   [510/634]  eta: 0:08:20    time: 3.987225  data: 0.001161  max mem: 4109
I20241203 11:03:15 2030089 dinov2 helpers.py:102]   [520/634]  eta: 0:07:34    time: 3.980904  data: 0.001238  max mem: 4109
I20241203 11:03:20 2030090 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.986251  data: 0.000836  max mem: 4109
I20241203 11:03:21 2030093 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.984535  data: 0.001372  max mem: 4109
I20241203 11:03:23 2030091 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.990927  data: 0.000809  max mem: 4109
I20241203 11:03:32 2030094 dinov2 helpers.py:102]   [520/634]  eta: 0:07:38    time: 3.991675  data: 0.001131  max mem: 4109
I20241203 11:03:33 2030088 dinov2 helpers.py:102]   [540/634]  eta: 0:06:04    time: 3.977311  data: 0.000928  max mem: 4109
I20241203 11:03:46 2030095 dinov2 helpers.py:102]   [540/634]  eta: 0:06:07    time: 3.985467  data: 0.001264  max mem: 4109
I20241203 11:03:47 2030092 dinov2 helpers.py:102]   [520/634]  eta: 0:07:40    time: 3.985415  data: 0.001071  max mem: 4109
I20241203 11:03:54 2030089 dinov2 helpers.py:102]   [530/634]  eta: 0:06:54    time: 3.980012  data: 0.002132  max mem: 4109
I20241203 11:04:00 2030090 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.978122  data: 0.000979  max mem: 4109
I20241203 11:04:01 2030093 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.980959  data: 0.002064  max mem: 4109
I20241203 11:04:03 2030091 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.991152  data: 0.000670  max mem: 4109
I20241203 11:04:11 2030094 dinov2 helpers.py:102]   [530/634]  eta: 0:06:58    time: 3.986109  data: 0.001272  max mem: 4109
I20241203 11:04:12 2030088 dinov2 helpers.py:102]   [550/634]  eta: 0:05:26    time: 3.977226  data: 0.002142  max mem: 4109
I20241203 11:04:26 2030095 dinov2 helpers.py:102]   [550/634]  eta: 0:05:28    time: 3.986177  data: 0.001632  max mem: 4109
I20241203 11:04:27 2030092 dinov2 helpers.py:102]   [530/634]  eta: 0:06:59    time: 3.978898  data: 0.001325  max mem: 4109
I20241203 11:04:34 2030089 dinov2 helpers.py:102]   [540/634]  eta: 0:06:15    time: 3.983518  data: 0.001832  max mem: 4109
I20241203 11:04:40 2030090 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.978167  data: 0.001004  max mem: 4109
I20241203 11:04:40 2030093 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.981722  data: 0.001779  max mem: 4109
I20241203 11:04:43 2030091 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.985221  data: 0.001103  max mem: 4109
I20241203 11:04:51 2030094 dinov2 helpers.py:102]   [540/634]  eta: 0:06:17    time: 3.978111  data: 0.000908  max mem: 4109
I20241203 11:04:52 2030088 dinov2 helpers.py:102]   [560/634]  eta: 0:04:47    time: 3.981860  data: 0.002181  max mem: 4109
I20241203 11:05:06 2030095 dinov2 helpers.py:102]   [560/634]  eta: 0:04:49    time: 3.984407  data: 0.001392  max mem: 4109
I20241203 11:05:07 2030092 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.981728  data: 0.001525  max mem: 4109
I20241203 11:05:14 2030089 dinov2 helpers.py:102]   [550/634]  eta: 0:05:35    time: 3.985407  data: 0.001148  max mem: 4109
I20241203 11:05:20 2030090 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.981782  data: 0.001694  max mem: 4109
I20241203 11:05:20 2030093 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.980799  data: 0.001190  max mem: 4109
I20241203 11:05:22 2030091 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.983176  data: 0.001198  max mem: 4109
I20241203 11:05:31 2030094 dinov2 helpers.py:102]   [550/634]  eta: 0:05:37    time: 3.977328  data: 0.000702  max mem: 4109
I20241203 11:05:32 2030088 dinov2 helpers.py:102]   [570/634]  eta: 0:04:08    time: 3.987178  data: 0.000992  max mem: 4109
I20241203 11:05:46 2030095 dinov2 helpers.py:102]   [570/634]  eta: 0:04:10    time: 3.988169  data: 0.000804  max mem: 4109
I20241203 11:05:46 2030092 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.982711  data: 0.001256  max mem: 4109
I20241203 11:05:54 2030089 dinov2 helpers.py:102]   [560/634]  eta: 0:04:55    time: 3.987168  data: 0.001093  max mem: 4109
I20241203 11:05:59 2030090 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.980933  data: 0.001434  max mem: 4109
I20241203 11:06:00 2030093 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.980897  data: 0.000885  max mem: 4109
I20241203 11:06:02 2030091 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.988056  data: 0.000700  max mem: 4109
I20241203 11:06:11 2030094 dinov2 helpers.py:102]   [560/634]  eta: 0:04:57    time: 3.986230  data: 0.001749  max mem: 4109
I20241203 11:06:12 2030088 dinov2 helpers.py:102]   [580/634]  eta: 0:03:30    time: 3.987013  data: 0.002101  max mem: 4109
I20241203 11:06:25 2030095 dinov2 helpers.py:102]   [580/634]  eta: 0:03:31    time: 3.987149  data: 0.000878  max mem: 4109
I20241203 11:06:26 2030092 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.980905  data: 0.001040  max mem: 4109
I20241203 11:06:34 2030089 dinov2 helpers.py:102]   [570/634]  eta: 0:04:15    time: 3.985352  data: 0.000971  max mem: 4109
I20241203 11:06:39 2030090 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.982765  data: 0.000908  max mem: 4109
I20241203 11:06:40 2030093 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.985358  data: 0.000761  max mem: 4109
I20241203 11:06:42 2030091 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.989885  data: 0.000931  max mem: 4109
I20241203 11:06:51 2030094 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.989941  data: 0.001766  max mem: 4109
I20241203 11:06:52 2030088 dinov2 helpers.py:102]   [590/634]  eta: 0:02:51    time: 3.984535  data: 0.003468  max mem: 4109
I20241203 11:07:05 2030095 dinov2 helpers.py:102]   [590/634]  eta: 0:02:52    time: 3.986224  data: 0.000721  max mem: 4109
I20241203 11:07:06 2030092 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.984465  data: 0.001994  max mem: 4109
I20241203 11:07:14 2030089 dinov2 helpers.py:102]   [580/634]  eta: 0:03:35    time: 3.981799  data: 0.001624  max mem: 4109
I20241203 11:07:19 2030090 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.986253  data: 0.001150  max mem: 4109
I20241203 11:07:20 2030093 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.988028  data: 0.001008  max mem: 4109
I20241203 11:07:22 2030091 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.986270  data: 0.001092  max mem: 4109
I20241203 11:07:31 2030094 dinov2 helpers.py:102]   [580/634]  eta: 0:03:36    time: 3.988111  data: 0.000722  max mem: 4109
I20241203 11:07:32 2030088 dinov2 helpers.py:102]   [600/634]  eta: 0:02:12    time: 3.984507  data: 0.003032  max mem: 4109
I20241203 11:07:45 2030095 dinov2 helpers.py:102]   [600/634]  eta: 0:02:13    time: 3.985418  data: 0.001348  max mem: 4109
I20241203 11:07:46 2030092 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.986230  data: 0.002661  max mem: 4109
I20241203 11:07:53 2030089 dinov2 helpers.py:102]   [590/634]  eta: 0:02:55    time: 3.979851  data: 0.001384  max mem: 4109
I20241203 11:07:59 2030090 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.985160  data: 0.001107  max mem: 4109
I20241203 11:08:00 2030093 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.986125  data: 0.001059  max mem: 4109
I20241203 11:08:02 2030091 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.984327  data: 0.001053  max mem: 4109
I20241203 11:08:11 2030094 dinov2 helpers.py:102]   [590/634]  eta: 0:02:56    time: 3.989646  data: 0.001054  max mem: 4109
I20241203 11:08:12 2030088 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.984133  data: 0.001936  max mem: 4109
I20241203 11:08:25 2030095 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.984296  data: 0.001441  max mem: 4109
I20241203 11:08:26 2030092 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.987910  data: 0.002287  max mem: 4109
I20241203 11:08:33 2030089 dinov2 helpers.py:102]   [600/634]  eta: 0:02:15    time: 3.980689  data: 0.000591  max mem: 4109
I20241203 11:08:39 2030090 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.986886  data: 0.000964  max mem: 4109
I20241203 11:08:39 2030093 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.981604  data: 0.000910  max mem: 4109
I20241203 11:08:42 2030091 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.988792  data: 0.001520  max mem: 4109
I20241203 11:08:50 2030094 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.986985  data: 0.001315  max mem: 4109
I20241203 11:08:51 2030088 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.986853  data: 0.001527  max mem: 4109
I20241203 11:09:05 2030095 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.986125  data: 0.000957  max mem: 4109
I20241203 11:09:06 2030092 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.983412  data: 0.001606  max mem: 4109
I20241203 11:09:13 2030089 dinov2 helpers.py:102]   [610/634]  eta: 0:01:35    time: 3.981769  data: 0.001503  max mem: 4109
I20241203 11:09:19 2030090 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.986397  data: 0.001218  max mem: 4109
I20241203 11:09:19 2030093 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.984475  data: 0.000849  max mem: 4109
I20241203 11:09:22 2030091 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.991651  data: 0.001319  max mem: 4109
I20241203 11:09:30 2030094 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.986293  data: 0.001150  max mem: 4109
I20241203 11:09:31 2030088 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.986293  data: 0.001642  max mem: 4109
I20241203 11:09:45 2030095 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.988139  data: 0.000864  max mem: 4109
I20241203 11:09:45 2030092 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.981736  data: 0.000973  max mem: 4109
I20241203 11:09:51 2030088 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.360571  data: 0.001383  max mem: 4109
I20241203 11:09:51 2030088 dinov2 helpers.py:130]  Total time: 0:41:18 (3.909793 s / it)
I20241203 11:09:51 2030088 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:09:51 2030088 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:09:52 2030088 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:09:52 2030088 dinov2 loaders.py:151] sampler: distributed
I20241203 11:09:52 2030088 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:09:52 2030088 dinov2 loaders.py:223] # of batches: 78
E20241203 11:09:52 2030088 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:09:53 2030089 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.973641  data: 0.001422  max mem: 4109
I20241203 11:09:58 2030090 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.942254  data: 0.001154  max mem: 4109
I20241203 11:09:58 2030093 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.942170  data: 0.000780  max mem: 4109
I20241203 11:10:00 2030091 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.926688  data: 0.000959  max mem: 4109
I20241203 11:10:03 2030095 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.287658  data: 0.000737  max mem: 4109
I20241203 11:10:03 2030095 dinov2 helpers.py:130]  Total time: 0:41:30 (3.928520 s / it)
I20241203 11:10:03 2030095 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:10:03 2030095 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:10:04 2030095 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:10:04 2030095 dinov2 loaders.py:151] sampler: distributed
I20241203 11:10:04 2030095 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:10:04 2030095 dinov2 loaders.py:223] # of batches: 78
E20241203 11:10:04 2030095 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:10:07 2030094 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.844339  data: 0.001002  max mem: 4109
I20241203 11:10:19 2030092 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.651650  data: 0.000968  max mem: 4109
I20241203 11:10:24 2030089 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.557140  data: 0.001258  max mem: 4109
I20241203 11:10:28 2030090 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.488570  data: 0.000726  max mem: 4109
I20241203 11:10:29 2030093 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.480030  data: 0.000828  max mem: 4109
I20241203 11:10:31 2030091 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.450924  data: 0.000894  max mem: 4109
I20241203 11:10:37 2030094 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.344798  data: 0.000809  max mem: 4109
I20241203 11:10:39 2030089 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.691190  data: 0.001196  max mem: 4109
I20241203 11:10:39 2030089 dinov2 helpers.py:130]  Total time: 0:42:03 (3.980189 s / it)
I20241203 11:10:39 2030089 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:10:39 2030089 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:10:40 2030089 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:10:40 2030089 dinov2 loaders.py:151] sampler: distributed
I20241203 11:10:40 2030089 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:10:40 2030089 dinov2 loaders.py:223] # of batches: 78
E20241203 11:10:40 2030089 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:10:47 2030092 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.080657  data: 0.000755  max mem: 4109
I20241203 11:10:50 2030094 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.376452  data: 0.000666  max mem: 4109
I20241203 11:10:50 2030094 dinov2 helpers.py:130]  Total time: 0:42:13 (3.996204 s / it)
I20241203 11:10:50 2030094 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:10:50 2030094 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:10:51 2030094 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:10:51 2030094 dinov2 loaders.py:151] sampler: distributed
I20241203 11:10:51 2030094 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:10:51 2030094 dinov2 loaders.py:223] # of batches: 78
E20241203 11:10:51 2030094 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:10:54 2030090 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.829795  data: 0.000589  max mem: 4109
I20241203 11:10:55 2030093 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 2.817319  data: 0.000661  max mem: 4109
I20241203 11:10:56 2030091 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 2.772884  data: 0.000624  max mem: 4109
I20241203 11:10:57 2030092 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 3.038879  data: 0.000583  max mem: 4109
I20241203 11:10:58 2030092 dinov2 helpers.py:130]  Total time: 0:42:13 (3.996638 s / it)
I20241203 11:10:58 2030092 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:10:58 2030092 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:10:58 2030092 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:10:58 2030092 dinov2 loaders.py:151] sampler: distributed
I20241203 11:10:58 2030092 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:10:58 2030092 dinov2 loaders.py:223] # of batches: 78
E20241203 11:10:58 2030092 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:11:03 2030090 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.749166  data: 0.000447  max mem: 4109
I20241203 11:11:03 2030093 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.736857  data: 0.000587  max mem: 4109
I20241203 11:11:03 2030090 dinov2 helpers.py:130]  Total time: 0:42:12 (3.994201 s / it)
I20241203 11:11:03 2030090 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:11:03 2030090 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:11:03 2030093 dinov2 helpers.py:130]  Total time: 0:42:11 (3.993643 s / it)
I20241203 11:11:03 2030093 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:11:03 2030093 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:11:03 2030090 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:11:03 2030090 dinov2 loaders.py:151] sampler: distributed
I20241203 11:11:03 2030090 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:11:03 2030090 dinov2 loaders.py:223] # of batches: 78
E20241203 11:11:03 2030090 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:11:03 2030093 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:11:03 2030093 dinov2 loaders.py:151] sampler: distributed
I20241203 11:11:03 2030093 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:11:03 2030093 dinov2 loaders.py:223] # of batches: 78
E20241203 11:11:03 2030093 submitit submission.py:68] Submitted job triggered an exception
I20241203 11:11:03 2030091 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 2.670759  data: 0.000443  max mem: 4109
I20241203 11:11:03 2030091 dinov2 helpers.py:130]  Total time: 0:42:12 (3.994414 s / it)
I20241203 11:11:03 2030091 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 11:11:03 2030091 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 11:11:03 2030091 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 11:11:03 2030091 dinov2 loaders.py:151] sampler: distributed
I20241203 11:11:03 2030091 dinov2 loaders.py:210] using PyTorch data loader
I20241203 11:11:03 2030091 dinov2 loaders.py:223] # of batches: 78
E20241203 11:11:03 2030091 submitit submission.py:68] Submitted job triggered an exception

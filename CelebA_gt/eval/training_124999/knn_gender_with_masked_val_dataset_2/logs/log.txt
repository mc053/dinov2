I20250101 06:27:39 2988961 dinov2 config.py:59] git:
  sha: 4a459e51f9dd94bae59fb75b33e085b3c8b8d818, status: has uncommitted changes, branch: main

I20250101 06:27:39 2988961 dinov2 config.py:60] batch_size: 256
config_file: CelebA_gt/config.yaml
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_masked_val_dataset_2']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_masked_val_dataset_2
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
train_dataset_str: CelebAMaskedTrain
val_dataset_str: CelebAMaskedVal
I20250101 06:27:39 2988961 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250101 06:27:39 2988961 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_masked_val_dataset_2
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250101 06:27:39 2988961 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250101 06:27:42 2988961 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250101 06:27:42 2988961 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250101 06:27:42 2988961 dinov2 loaders.py:100] using dataset: "CelebAMaskedTrain"
I20250101 06:27:44 2988961 dinov2 loaders.py:105] # of dataset samples: 162,127
I20250101 06:27:44 2988961 dinov2 loaders.py:100] using dataset: "CelebAMaskedVal"
I20250101 06:27:45 2988961 dinov2 loaders.py:105] # of dataset samples: 19,792
I20250101 06:27:45 2988961 dinov2 knn.py:260] Extracting features for train set...
I20250101 06:27:45 2988961 dinov2 loaders.py:163] sampler: distributed
I20250101 06:27:45 2988961 dinov2 loaders.py:222] using PyTorch data loader
W20250101 06:27:45 2988961 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250101 06:27:45 2988961 dinov2 loaders.py:235] # of batches: 634
I20250101 06:27:51 2988961 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20250101 06:27:51 2988961 dinov2 helpers.py:102]   [  0/634]  eta: 0:59:35    time: 5.638879  data: 2.817219  max mem: 3463
I20250101 06:27:54 2988961 dinov2 helpers.py:102]   [ 10/634]  eta: 0:08:07    time: 0.780737  data: 0.256360  max mem: 4109
I20250101 06:27:57 2988961 dinov2 helpers.py:102]   [ 20/634]  eta: 0:05:55    time: 0.325789  data: 0.000305  max mem: 4109
I20250101 06:28:01 2988961 dinov2 helpers.py:102]   [ 30/634]  eta: 0:05:06    time: 0.358255  data: 0.000312  max mem: 4109
I20250101 06:28:04 2988961 dinov2 helpers.py:102]   [ 40/634]  eta: 0:04:40    time: 0.360896  data: 0.000323  max mem: 4109
I20250101 06:28:08 2988961 dinov2 helpers.py:102]   [ 50/634]  eta: 0:04:23    time: 0.362743  data: 0.000352  max mem: 4109
I20250101 06:28:12 2988961 dinov2 helpers.py:102]   [ 60/634]  eta: 0:04:10    time: 0.364469  data: 0.000373  max mem: 4109
I20250101 06:28:15 2988961 dinov2 helpers.py:102]   [ 70/634]  eta: 0:04:01    time: 0.366532  data: 0.000398  max mem: 4109
I20250101 06:28:19 2988961 dinov2 helpers.py:102]   [ 80/634]  eta: 0:03:52    time: 0.369131  data: 0.000423  max mem: 4109
I20250101 06:28:23 2988961 dinov2 helpers.py:102]   [ 90/634]  eta: 0:03:45    time: 0.372463  data: 0.000464  max mem: 4109
I20250101 06:28:27 2988961 dinov2 helpers.py:102]   [100/634]  eta: 0:03:39    time: 0.376025  data: 0.000496  max mem: 4109
I20250101 06:28:30 2988961 dinov2 helpers.py:102]   [110/634]  eta: 0:03:34    time: 0.379015  data: 0.000570  max mem: 4109
I20250101 06:28:34 2988961 dinov2 helpers.py:102]   [120/634]  eta: 0:03:29    time: 0.381810  data: 0.000506  max mem: 4109
I20250101 06:28:38 2988961 dinov2 helpers.py:102]   [130/634]  eta: 0:03:24    time: 0.384834  data: 0.000389  max mem: 4109
I20250101 06:28:42 2988961 dinov2 helpers.py:102]   [140/634]  eta: 0:03:19    time: 0.387523  data: 0.000358  max mem: 4109
I20250101 06:28:46 2988961 dinov2 helpers.py:102]   [150/634]  eta: 0:03:15    time: 0.389621  data: 0.000332  max mem: 4109
I20250101 06:28:50 2988961 dinov2 helpers.py:102]   [160/634]  eta: 0:03:10    time: 0.391563  data: 0.000295  max mem: 4109
I20250101 06:28:54 2988961 dinov2 helpers.py:102]   [170/634]  eta: 0:03:06    time: 0.393292  data: 0.000296  max mem: 4109
I20250101 06:28:58 2988961 dinov2 helpers.py:102]   [180/634]  eta: 0:03:02    time: 0.394725  data: 0.000344  max mem: 4109
I20250101 06:29:02 2988961 dinov2 helpers.py:102]   [190/634]  eta: 0:02:58    time: 0.396306  data: 0.000348  max mem: 4109
I20250101 06:29:06 2988961 dinov2 helpers.py:102]   [200/634]  eta: 0:02:54    time: 0.397518  data: 0.000370  max mem: 4109
I20250101 06:29:10 2988961 dinov2 helpers.py:102]   [210/634]  eta: 0:02:50    time: 0.398311  data: 0.000420  max mem: 4109
I20250101 06:29:14 2988961 dinov2 helpers.py:102]   [220/634]  eta: 0:02:45    time: 0.399162  data: 0.000521  max mem: 4109
I20250101 06:29:18 2988961 dinov2 helpers.py:102]   [230/634]  eta: 0:02:41    time: 0.400016  data: 0.000548  max mem: 4109
I20250101 06:29:22 2988961 dinov2 helpers.py:102]   [240/634]  eta: 0:02:37    time: 0.401192  data: 0.000419  max mem: 4109
I20250101 06:29:26 2988961 dinov2 helpers.py:102]   [250/634]  eta: 0:02:33    time: 0.402142  data: 0.000446  max mem: 4109
I20250101 06:29:30 2988961 dinov2 helpers.py:102]   [260/634]  eta: 0:02:30    time: 0.403013  data: 0.000420  max mem: 4109
I20250101 06:29:34 2988961 dinov2 helpers.py:102]   [270/634]  eta: 0:02:26    time: 0.403765  data: 0.000323  max mem: 4109
I20250101 06:29:38 2988961 dinov2 helpers.py:102]   [280/634]  eta: 0:02:22    time: 0.404224  data: 0.000336  max mem: 4109
I20250101 06:29:42 2988961 dinov2 helpers.py:102]   [290/634]  eta: 0:02:18    time: 0.405058  data: 0.000311  max mem: 4109
I20250101 06:29:46 2988961 dinov2 helpers.py:102]   [300/634]  eta: 0:02:14    time: 0.405945  data: 0.000280  max mem: 4109
I20250101 06:29:50 2988961 dinov2 helpers.py:102]   [310/634]  eta: 0:02:10    time: 0.406603  data: 0.000271  max mem: 4109
I20250101 06:29:54 2988961 dinov2 helpers.py:102]   [320/634]  eta: 0:02:06    time: 0.406981  data: 0.000404  max mem: 4109
I20250101 06:29:58 2988961 dinov2 helpers.py:102]   [330/634]  eta: 0:02:02    time: 0.407566  data: 0.000503  max mem: 4109
I20250101 06:30:02 2988961 dinov2 helpers.py:102]   [340/634]  eta: 0:01:58    time: 0.407896  data: 0.000506  max mem: 4109
I20250101 06:30:06 2988961 dinov2 helpers.py:102]   [350/634]  eta: 0:01:54    time: 0.407915  data: 0.000492  max mem: 4109
I20250101 06:30:10 2988961 dinov2 helpers.py:102]   [360/634]  eta: 0:01:50    time: 0.408314  data: 0.000413  max mem: 4109
I20250101 06:30:14 2988961 dinov2 helpers.py:102]   [370/634]  eta: 0:01:46    time: 0.408569  data: 0.000323  max mem: 4109
I20250101 06:30:18 2988961 dinov2 helpers.py:102]   [380/634]  eta: 0:01:42    time: 0.408536  data: 0.000267  max mem: 4109
I20250101 06:30:23 2988961 dinov2 helpers.py:102]   [390/634]  eta: 0:01:38    time: 0.408874  data: 0.000272  max mem: 4109
I20250101 06:30:27 2988961 dinov2 helpers.py:102]   [400/634]  eta: 0:01:34    time: 0.409241  data: 0.000353  max mem: 4109
I20250101 06:30:31 2988961 dinov2 helpers.py:102]   [410/634]  eta: 0:01:30    time: 0.409444  data: 0.000336  max mem: 4109
I20250101 06:30:35 2988961 dinov2 helpers.py:102]   [420/634]  eta: 0:01:26    time: 0.409830  data: 0.000293  max mem: 4109
I20250101 06:30:39 2988961 dinov2 helpers.py:102]   [430/634]  eta: 0:01:22    time: 0.410659  data: 0.000343  max mem: 4109
I20250101 06:30:43 2988961 dinov2 helpers.py:102]   [440/634]  eta: 0:01:18    time: 0.411156  data: 0.000477  max mem: 4109
I20250101 06:30:47 2988961 dinov2 helpers.py:102]   [450/634]  eta: 0:01:14    time: 0.410919  data: 0.000543  max mem: 4109
I20250101 06:30:51 2988961 dinov2 helpers.py:102]   [460/634]  eta: 0:01:10    time: 0.411004  data: 0.000489  max mem: 4109
I20250101 06:30:55 2988961 dinov2 helpers.py:102]   [470/634]  eta: 0:01:06    time: 0.411265  data: 0.000545  max mem: 4109
I20250101 06:31:00 2988961 dinov2 helpers.py:102]   [480/634]  eta: 0:01:02    time: 0.411564  data: 0.000582  max mem: 4109
I20250101 06:31:04 2988961 dinov2 helpers.py:102]   [490/634]  eta: 0:00:58    time: 0.411878  data: 0.000591  max mem: 4109
I20250101 06:31:08 2988961 dinov2 helpers.py:102]   [500/634]  eta: 0:00:54    time: 0.411982  data: 0.000659  max mem: 4109
I20250101 06:31:12 2988961 dinov2 helpers.py:102]   [510/634]  eta: 0:00:50    time: 0.411875  data: 0.000622  max mem: 4109
I20250101 06:31:16 2988961 dinov2 helpers.py:102]   [520/634]  eta: 0:00:46    time: 0.411974  data: 0.000590  max mem: 4109
I20250101 06:31:20 2988961 dinov2 helpers.py:102]   [530/634]  eta: 0:00:42    time: 0.412006  data: 0.000565  max mem: 4109
I20250101 06:31:24 2988961 dinov2 helpers.py:102]   [540/634]  eta: 0:00:38    time: 0.411962  data: 0.000564  max mem: 4109
I20250101 06:31:28 2988961 dinov2 helpers.py:102]   [550/634]  eta: 0:00:34    time: 0.412058  data: 0.000596  max mem: 4109
I20250101 06:31:33 2988961 dinov2 helpers.py:102]   [560/634]  eta: 0:00:30    time: 0.412011  data: 0.000455  max mem: 4109
I20250101 06:31:37 2988961 dinov2 helpers.py:102]   [570/634]  eta: 0:00:25    time: 0.412118  data: 0.000353  max mem: 4109
I20250101 06:31:41 2988961 dinov2 helpers.py:102]   [580/634]  eta: 0:00:21    time: 0.411962  data: 0.000323  max mem: 4109
I20250101 06:31:45 2988961 dinov2 helpers.py:102]   [590/634]  eta: 0:00:17    time: 0.411788  data: 0.000495  max mem: 4109
I20250101 06:31:49 2988961 dinov2 helpers.py:102]   [600/634]  eta: 0:00:13    time: 0.412089  data: 0.000538  max mem: 4109
I20250101 06:31:53 2988961 dinov2 helpers.py:102]   [610/634]  eta: 0:00:09    time: 0.412436  data: 0.000330  max mem: 4109
I20250101 06:31:57 2988961 dinov2 helpers.py:102]   [620/634]  eta: 0:00:05    time: 0.412410  data: 0.000328  max mem: 4109
I20250101 06:32:01 2988961 dinov2 helpers.py:102]   [630/634]  eta: 0:00:01    time: 0.412377  data: 0.000444  max mem: 4109
I20250101 06:32:03 2988961 dinov2 helpers.py:102]   [633/634]  eta: 0:00:00    time: 0.451718  data: 0.000418  max mem: 4109
I20250101 06:32:04 2988961 dinov2 helpers.py:130]  Total time: 0:04:18 (0.408025 s / it)
I20250101 06:32:04 2988961 dinov2 utils.py:141] Features shape: (162127, 1024)
I20250101 06:32:04 2988961 dinov2 utils.py:142] Labels shape: (162127,)
I20250101 06:32:04 2988961 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20250101 06:32:04 2988961 dinov2 loaders.py:163] sampler: distributed
I20250101 06:32:04 2988961 dinov2 loaders.py:222] using PyTorch data loader
I20250101 06:32:04 2988961 dinov2 loaders.py:235] # of batches: 78
I20250101 06:32:04 2988961 dinov2 knn.py:299] Start the k-NN classification.
I20250101 06:32:06 2988961 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:03:32    time: 2.719190  data: 2.196016  max mem: 4109
I20250101 06:32:10 2988961 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:00:42    time: 0.619294  data: 0.200059  max mem: 4109
I20250101 06:32:15 2988961 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:00:30    time: 0.410240  data: 0.000456  max mem: 4109
I20250101 06:32:19 2988961 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:00:23    time: 0.411650  data: 0.000458  max mem: 4109
I20250101 06:32:23 2988961 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:17    time: 0.412124  data: 0.000383  max mem: 4109
I20250101 06:32:27 2988961 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:12    time: 0.412327  data: 0.000289  max mem: 4109
I20250101 06:32:31 2988961 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:08    time: 0.412804  data: 0.000275  max mem: 4109
I20250101 06:32:35 2988961 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:03    time: 0.413114  data: 0.000309  max mem: 4109
I20250101 06:32:38 2988961 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:00    time: 0.404606  data: 0.000260  max mem: 4109
I20250101 06:32:38 2988961 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.439505 s / it)
I20250101 06:32:38 2988961 dinov2 utils.py:79] Averaged stats: 
I20250101 06:32:38 2988961 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 83.52
I20250101 06:32:38 2988961 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 84.21
I20250101 06:32:38 2988961 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 84.22
I20250101 06:32:38 2988961 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 84.15

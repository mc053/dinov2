I20241203 07:39:27 1983663 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983663 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983663 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983658 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983658 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983658 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983663 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983658 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983658 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983661 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983661 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983661 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983661 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983663 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983659 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983659 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983659 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983659 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983661 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983659 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983664 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983664 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983664 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983664 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983665 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983665 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983665 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983665 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983660 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983660 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983660 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983660 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983664 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983662 dinov2 config.py:59] git:
  sha: f012955340146e72b47b4b757ccbd120c3c06fa9, status: has uncommitted changes, branch: main

I20241203 07:39:27 1983662 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAOriginalVal
I20241203 07:39:27 1983662 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241203 07:39:27 1983662 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241203 07:39:27 1983660 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983665 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:27 1983662 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241203 07:39:59 1983661 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:39:59 1983658 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:39:59 1983659 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:39:59 1983663 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:39:59 1983665 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:39:59 1983664 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:40:00 1983660 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:40:00 1983662 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241203 07:40:04 1983661 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:04 1983658 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:04 1983661 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983665 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983659 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983663 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983658 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983664 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983660 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983662 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241203 07:40:05 1983664 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983665 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983659 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983663 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983660 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:05 1983662 dinov2 loaders.py:88] using dataset: "CelebAOriginalTrain"
I20241203 07:40:08 1983661 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:08 1983661 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:09 1983661 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:09 1983661 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:09 1983661 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:09 1983661 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:09 1983661 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:09 1983661 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:10 1983665 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:10 1983665 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:10 1983663 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:10 1983663 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:11 1983665 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:11 1983665 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:11 1983665 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:11 1983665 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:11 1983665 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:11 1983665 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:12 1983663 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:12 1983663 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:12 1983663 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:12 1983663 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:12 1983663 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:12 1983663 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:13 1983658 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:13 1983658 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:14 1983662 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:14 1983662 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:15 1983659 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:15 1983659 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:15 1983664 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:15 1983664 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:15 1983660 dinov2 loaders.py:93] # of dataset samples: 162,127
I20241203 07:40:15 1983660 dinov2 loaders.py:88] using dataset: "CelebAOriginalVal"
I20241203 07:40:15 1983658 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:15 1983658 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:15 1983658 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:15 1983658 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:15 1983658 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:15 1983658 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:17 1983662 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:17 1983662 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:17 1983662 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:17 1983662 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:17 1983662 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:17 1983662 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:18 1983659 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:18 1983659 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:18 1983659 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:18 1983659 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:18 1983659 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:18 1983659 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:19 1983664 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:19 1983664 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:19 1983664 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:19 1983664 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:19 1983664 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:19 1983664 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:19 1983660 dinov2 loaders.py:93] # of dataset samples: 19,792
I20241203 07:40:19 1983660 dinov2 knn.py:260] Extracting features for train set...
I20241203 07:40:19 1983660 dinov2 loaders.py:151] sampler: distributed
I20241203 07:40:19 1983660 dinov2 loaders.py:210] using PyTorch data loader
W20241203 07:40:19 1983660 py.warnings warnings.py:109] /opt/miniconda3/envs/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241203 07:40:19 1983660 dinov2 loaders.py:223] # of batches: 634
I20241203 07:40:42 1983661 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:40:42 1983661 dinov2 helpers.py:102]   [  0/634]  eta: 5:51:52    time: 33.300415  data: 16.900663  max mem: 3463
I20241203 07:40:46 1983661 dinov2 helpers.py:102]   [ 10/634]  eta: 0:35:36    time: 3.424170  data: 1.536794  max mem: 4109
I20241203 07:40:47 1983665 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:40:47 1983665 dinov2 helpers.py:102]   [  0/634]  eta: 6:13:14    time: 35.322475  data: 11.619547  max mem: 3463
I20241203 07:40:52 1983663 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:40:55 1983665 dinov2 helpers.py:102]   [ 10/634]  eta: 0:41:47    time: 4.019159  data: 1.060436  max mem: 4109
I20241203 07:40:56 1983663 dinov2 helpers.py:102]   [  0/634]  eta: 7:49:28    time: 44.429382  data: 12.934300  max mem: 3463
I20241203 07:40:57 1983658 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:40:57 1983658 dinov2 helpers.py:102]   [  0/634]  eta: 7:18:26    time: 41.492168  data: 15.018486  max mem: 3463
I20241203 07:40:58 1983661 dinov2 helpers.py:102]   [ 20/634]  eta: 0:23:58    time: 0.795407  data: 0.000368  max mem: 4109
I20241203 07:41:00 1983662 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:41:00 1983662 dinov2 helpers.py:102]   [  0/634]  eta: 7:34:36    time: 43.022659  data: 14.155947  max mem: 3463
I20241203 07:41:02 1983659 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:41:02 1983659 dinov2 helpers.py:102]   [  0/634]  eta: 7:46:03    time: 44.106415  data: 14.486715  max mem: 3463
I20241203 07:41:08 1983664 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:41:08 1983664 dinov2 helpers.py:102]   [  0/634]  eta: 8:41:37    time: 49.364937  data: 19.721922  max mem: 3463
I20241203 07:41:10 1983660 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241203 07:41:10 1983660 dinov2 helpers.py:102]   [  0/634]  eta: 8:50:26    time: 50.200153  data: 19.987682  max mem: 3463
I20241203 07:41:18 1983663 dinov2 helpers.py:102]   [ 10/634]  eta: 1:02:28    time: 6.006802  data: 1.180099  max mem: 4109
I20241203 07:41:23 1983658 dinov2 helpers.py:102]   [ 10/634]  eta: 1:04:14    time: 6.177166  data: 1.367357  max mem: 4109
I20241203 07:41:26 1983665 dinov2 helpers.py:102]   [ 20/634]  eta: 0:36:14    time: 1.952705  data: 0.002492  max mem: 4109
I20241203 07:41:28 1983662 dinov2 helpers.py:102]   [ 10/634]  eta: 1:07:40    time: 6.507947  data: 1.289554  max mem: 4109
I20241203 07:41:32 1983659 dinov2 helpers.py:102]   [ 10/634]  eta: 1:09:55    time: 6.724230  data: 1.319361  max mem: 4109
I20241203 07:41:32 1983661 dinov2 helpers.py:102]   [ 30/634]  eta: 0:27:04    time: 2.284359  data: 0.000800  max mem: 4109
I20241203 07:41:40 1983664 dinov2 helpers.py:102]   [ 10/634]  eta: 1:16:39    time: 7.371559  data: 1.795428  max mem: 4109
I20241203 07:41:41 1983660 dinov2 helpers.py:102]   [ 10/634]  eta: 1:17:33    time: 7.457112  data: 1.818033  max mem: 4109
I20241203 07:41:57 1983663 dinov2 helpers.py:102]   [ 20/634]  eta: 0:51:08    time: 3.025911  data: 0.002950  max mem: 4109
I20241203 07:42:02 1983658 dinov2 helpers.py:102]   [ 20/634]  eta: 0:52:02    time: 3.264779  data: 0.002113  max mem: 4109
I20241203 07:42:05 1983665 dinov2 helpers.py:102]   [ 30/634]  eta: 0:36:45    time: 3.450413  data: 0.003082  max mem: 4109
I20241203 07:42:07 1983662 dinov2 helpers.py:102]   [ 20/634]  eta: 0:53:49    time: 3.372329  data: 0.001797  max mem: 4109
I20241203 07:42:11 1983659 dinov2 helpers.py:102]   [ 20/634]  eta: 0:55:02    time: 3.441629  data: 0.001626  max mem: 4109
I20241203 07:42:11 1983661 dinov2 helpers.py:102]   [ 40/634]  eta: 0:29:32    time: 3.655207  data: 0.001074  max mem: 4109
I20241203 07:42:19 1983664 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:32    time: 3.538451  data: 0.001867  max mem: 4109
I20241203 07:42:20 1983660 dinov2 helpers.py:102]   [ 20/634]  eta: 0:58:58    time: 3.541436  data: 0.001653  max mem: 4109
I20241203 07:42:36 1983663 dinov2 helpers.py:102]   [ 30/634]  eta: 0:46:49    time: 3.906825  data: 0.001107  max mem: 4109
I20241203 07:42:41 1983658 dinov2 helpers.py:102]   [ 30/634]  eta: 0:47:24    time: 3.900906  data: 0.001397  max mem: 4109
I20241203 07:42:44 1983665 dinov2 helpers.py:102]   [ 40/634]  eta: 0:36:44    time: 3.890985  data: 0.003398  max mem: 4109
I20241203 07:42:46 1983662 dinov2 helpers.py:102]   [ 30/634]  eta: 0:48:36    time: 3.905893  data: 0.000595  max mem: 4109
I20241203 07:42:50 1983659 dinov2 helpers.py:102]   [ 30/634]  eta: 0:49:26    time: 3.913167  data: 0.000909  max mem: 4109
I20241203 07:42:50 1983661 dinov2 helpers.py:102]   [ 50/634]  eta: 0:30:50    time: 3.912515  data: 0.000898  max mem: 4109
I20241203 07:42:58 1983664 dinov2 helpers.py:102]   [ 30/634]  eta: 0:51:47    time: 3.920887  data: 0.000825  max mem: 4109
I20241203 07:43:00 1983660 dinov2 helpers.py:102]   [ 30/634]  eta: 0:52:04    time: 3.917778  data: 0.001820  max mem: 4109
I20241203 07:43:15 1983663 dinov2 helpers.py:102]   [ 40/634]  eta: 0:44:22    time: 3.942691  data: 0.001281  max mem: 4109
I20241203 07:43:21 1983658 dinov2 helpers.py:102]   [ 40/634]  eta: 0:44:47    time: 3.933972  data: 0.001046  max mem: 4109
I20241203 07:43:24 1983665 dinov2 helpers.py:102]   [ 50/634]  eta: 0:36:35    time: 3.924790  data: 0.001228  max mem: 4109
I20241203 07:43:26 1983662 dinov2 helpers.py:102]   [ 40/634]  eta: 0:45:40    time: 3.935024  data: 0.000946  max mem: 4109
I20241203 07:43:30 1983659 dinov2 helpers.py:102]   [ 40/634]  eta: 0:46:17    time: 3.938562  data: 0.000897  max mem: 4109
I20241203 07:43:30 1983661 dinov2 helpers.py:102]   [ 60/634]  eta: 0:31:32    time: 3.941156  data: 0.000880  max mem: 4109
I20241203 07:43:38 1983664 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:03    time: 3.944955  data: 0.000961  max mem: 4109
I20241203 07:43:39 1983660 dinov2 helpers.py:102]   [ 40/634]  eta: 0:48:16    time: 3.945878  data: 0.001169  max mem: 4109
I20241203 07:43:55 1983663 dinov2 helpers.py:102]   [ 50/634]  eta: 0:42:37    time: 3.958199  data: 0.001132  max mem: 4109
I20241203 07:44:00 1983658 dinov2 helpers.py:102]   [ 50/634]  eta: 0:42:56    time: 3.951869  data: 0.001025  max mem: 4109
I20241203 07:44:03 1983665 dinov2 helpers.py:102]   [ 60/634]  eta: 0:36:16    time: 3.954544  data: 0.002212  max mem: 4109
I20241203 07:44:05 1983662 dinov2 helpers.py:102]   [ 50/634]  eta: 0:43:39    time: 3.950773  data: 0.001318  max mem: 4109
I20241203 07:44:09 1983659 dinov2 helpers.py:102]   [ 50/634]  eta: 0:44:08    time: 3.950919  data: 0.000869  max mem: 4109
I20241203 07:44:09 1983661 dinov2 helpers.py:102]   [ 70/634]  eta: 0:31:51    time: 3.954310  data: 0.000708  max mem: 4109
I20241203 07:44:17 1983664 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:31    time: 3.953337  data: 0.000973  max mem: 4109
I20241203 07:44:19 1983660 dinov2 helpers.py:102]   [ 50/634]  eta: 0:45:42    time: 3.956548  data: 0.000993  max mem: 4109
I20241203 07:44:35 1983663 dinov2 helpers.py:102]   [ 60/634]  eta: 0:41:15    time: 3.964370  data: 0.001111  max mem: 4109
I20241203 07:44:40 1983658 dinov2 helpers.py:102]   [ 60/634]  eta: 0:41:30    time: 3.957912  data: 0.000704  max mem: 4109
I20241203 07:44:43 1983665 dinov2 helpers.py:102]   [ 70/634]  eta: 0:35:51    time: 3.955228  data: 0.002192  max mem: 4109
I20241203 07:44:45 1983662 dinov2 helpers.py:102]   [ 60/634]  eta: 0:42:05    time: 3.959612  data: 0.001189  max mem: 4109
I20241203 07:44:49 1983659 dinov2 helpers.py:102]   [ 60/634]  eta: 0:42:28    time: 3.956132  data: 0.000992  max mem: 4109
I20241203 07:44:49 1983661 dinov2 helpers.py:102]   [ 80/634]  eta: 0:31:56    time: 3.954306  data: 0.001029  max mem: 4109
I20241203 07:44:57 1983664 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:37    time: 3.955072  data: 0.001474  max mem: 4109
I20241203 07:44:59 1983660 dinov2 helpers.py:102]   [ 60/634]  eta: 0:43:46    time: 3.959592  data: 0.001291  max mem: 4109
I20241203 07:45:14 1983663 dinov2 helpers.py:102]   [ 70/634]  eta: 0:40:06    time: 3.975912  data: 0.001137  max mem: 4109
I20241203 07:45:20 1983658 dinov2 helpers.py:102]   [ 70/634]  eta: 0:40:16    time: 3.959608  data: 0.000783  max mem: 4109
I20241203 07:45:22 1983665 dinov2 helpers.py:102]   [ 80/634]  eta: 0:35:23    time: 3.956031  data: 0.001198  max mem: 4109
I20241203 07:45:24 1983662 dinov2 helpers.py:102]   [ 70/634]  eta: 0:40:46    time: 3.960635  data: 0.002043  max mem: 4109
I20241203 07:45:28 1983659 dinov2 helpers.py:102]   [ 70/634]  eta: 0:41:05    time: 3.959257  data: 0.002012  max mem: 4109
I20241203 07:45:29 1983661 dinov2 helpers.py:102]   [ 90/634]  eta: 0:31:51    time: 3.956956  data: 0.001184  max mem: 4109
I20241203 07:45:36 1983664 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:04    time: 3.959403  data: 0.001406  max mem: 4109
I20241203 07:45:38 1983660 dinov2 helpers.py:102]   [ 70/634]  eta: 0:42:12    time: 3.967119  data: 0.001099  max mem: 4109
I20241203 07:45:54 1983663 dinov2 helpers.py:102]   [ 80/634]  eta: 0:39:03    time: 3.980946  data: 0.000900  max mem: 4109
I20241203 07:45:59 1983658 dinov2 helpers.py:102]   [ 80/634]  eta: 0:39:11    time: 3.962209  data: 0.001034  max mem: 4109
I20241203 07:46:02 1983665 dinov2 helpers.py:102]   [ 90/634]  eta: 0:34:52    time: 3.964085  data: 0.000948  max mem: 4109
I20241203 07:46:04 1983662 dinov2 helpers.py:102]   [ 80/634]  eta: 0:39:37    time: 3.964180  data: 0.001875  max mem: 4109
I20241203 07:46:08 1983659 dinov2 helpers.py:102]   [ 80/634]  eta: 0:39:54    time: 3.964885  data: 0.002370  max mem: 4109
I20241203 07:46:08 1983661 dinov2 helpers.py:102]   [100/634]  eta: 0:31:40    time: 3.965159  data: 0.001348  max mem: 4109
I20241203 07:46:16 1983664 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:45    time: 3.968182  data: 0.000558  max mem: 4109
I20241203 07:46:18 1983660 dinov2 helpers.py:102]   [ 80/634]  eta: 0:40:52    time: 3.972800  data: 0.001145  max mem: 4109
I20241203 07:46:34 1983663 dinov2 helpers.py:102]   [ 90/634]  eta: 0:38:07    time: 3.987755  data: 0.000940  max mem: 4109
I20241203 07:46:39 1983658 dinov2 helpers.py:102]   [ 90/634]  eta: 0:38:13    time: 3.970972  data: 0.000897  max mem: 4109
I20241203 07:46:42 1983665 dinov2 helpers.py:102]   [100/634]  eta: 0:34:21    time: 3.973672  data: 0.000746  max mem: 4109
I20241203 07:46:44 1983662 dinov2 helpers.py:102]   [ 90/634]  eta: 0:38:35    time: 3.972774  data: 0.000668  max mem: 4109
I20241203 07:46:48 1983659 dinov2 helpers.py:102]   [ 90/634]  eta: 0:38:50    time: 3.973418  data: 0.001497  max mem: 4109
I20241203 07:46:48 1983661 dinov2 helpers.py:102]   [110/634]  eta: 0:31:24    time: 3.972052  data: 0.002155  max mem: 4109
I20241203 07:46:56 1983664 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:34    time: 3.974107  data: 0.001028  max mem: 4109
I20241203 07:46:58 1983660 dinov2 helpers.py:102]   [ 90/634]  eta: 0:39:41    time: 3.976784  data: 0.002708  max mem: 4109
I20241203 07:47:14 1983663 dinov2 helpers.py:102]   [100/634]  eta: 0:37:14    time: 3.993245  data: 0.001134  max mem: 4109
I20241203 07:47:19 1983658 dinov2 helpers.py:102]   [100/634]  eta: 0:37:18    time: 3.977191  data: 0.001025  max mem: 4109
I20241203 07:47:22 1983665 dinov2 helpers.py:102]   [110/634]  eta: 0:33:48    time: 3.977204  data: 0.001661  max mem: 4109
I20241203 07:47:24 1983662 dinov2 helpers.py:102]   [100/634]  eta: 0:37:38    time: 3.974387  data: 0.000684  max mem: 4109
I20241203 07:47:28 1983659 dinov2 helpers.py:102]   [100/634]  eta: 0:37:51    time: 3.975779  data: 0.001163  max mem: 4109
I20241203 07:47:28 1983661 dinov2 helpers.py:102]   [120/634]  eta: 0:31:04    time: 3.974028  data: 0.003105  max mem: 4109
I20241203 07:47:36 1983664 dinov2 helpers.py:102]   [100/634]  eta: 0:38:30    time: 3.974370  data: 0.001370  max mem: 4109
I20241203 07:47:38 1983660 dinov2 helpers.py:102]   [100/634]  eta: 0:38:36    time: 3.977087  data: 0.003361  max mem: 4109
I20241203 07:47:54 1983663 dinov2 helpers.py:102]   [110/634]  eta: 0:36:23    time: 3.992537  data: 0.001109  max mem: 4109
I20241203 07:47:59 1983658 dinov2 helpers.py:102]   [110/634]  eta: 0:36:26    time: 3.976931  data: 0.001418  max mem: 4109
I20241203 07:48:01 1983665 dinov2 helpers.py:102]   [120/634]  eta: 0:33:13    time: 3.975246  data: 0.001916  max mem: 4109
I20241203 07:48:03 1983662 dinov2 helpers.py:102]   [110/634]  eta: 0:36:43    time: 3.974377  data: 0.000704  max mem: 4109
I20241203 07:48:07 1983661 dinov2 helpers.py:102]   [130/634]  eta: 0:30:41    time: 3.973950  data: 0.002149  max mem: 4109
I20241203 07:48:08 1983659 dinov2 helpers.py:102]   [110/634]  eta: 0:36:56    time: 3.977065  data: 0.001715  max mem: 4109
I20241203 07:48:15 1983664 dinov2 helpers.py:102]   [110/634]  eta: 0:37:30    time: 3.974433  data: 0.001262  max mem: 4109
I20241203 07:48:17 1983660 dinov2 helpers.py:102]   [110/634]  eta: 0:37:36    time: 3.976141  data: 0.002230  max mem: 4109
I20241203 07:48:34 1983663 dinov2 helpers.py:102]   [120/634]  eta: 0:35:34    time: 3.991382  data: 0.000760  max mem: 4109
I20241203 07:48:38 1983658 dinov2 helpers.py:102]   [120/634]  eta: 0:35:36    time: 3.974797  data: 0.001178  max mem: 4109
I20241203 07:48:41 1983665 dinov2 helpers.py:102]   [130/634]  eta: 0:32:38    time: 3.974097  data: 0.000920  max mem: 4109
I20241203 07:48:43 1983662 dinov2 helpers.py:102]   [120/634]  eta: 0:35:51    time: 3.973266  data: 0.000889  max mem: 4109
I20241203 07:48:47 1983661 dinov2 helpers.py:102]   [140/634]  eta: 0:30:16    time: 3.974160  data: 0.000579  max mem: 4109
I20241203 07:48:47 1983659 dinov2 helpers.py:102]   [120/634]  eta: 0:36:03    time: 3.977203  data: 0.002569  max mem: 4109
I20241203 07:48:55 1983664 dinov2 helpers.py:102]   [120/634]  eta: 0:36:33    time: 3.974990  data: 0.001675  max mem: 4109
I20241203 07:48:57 1983660 dinov2 helpers.py:102]   [120/634]  eta: 0:36:38    time: 3.975811  data: 0.001616  max mem: 4109
I20241203 07:49:14 1983663 dinov2 helpers.py:102]   [130/634]  eta: 0:34:46    time: 3.988132  data: 0.000626  max mem: 4109
I20241203 07:49:18 1983658 dinov2 helpers.py:102]   [130/634]  eta: 0:34:47    time: 3.972918  data: 0.001177  max mem: 4109
I20241203 07:49:21 1983665 dinov2 helpers.py:102]   [140/634]  eta: 0:32:03    time: 3.974684  data: 0.000815  max mem: 4109
I20241203 07:49:23 1983662 dinov2 helpers.py:102]   [130/634]  eta: 0:35:01    time: 3.972852  data: 0.001264  max mem: 4109
I20241203 07:49:27 1983661 dinov2 helpers.py:102]   [150/634]  eta: 0:29:49    time: 3.972976  data: 0.000877  max mem: 4109
I20241203 07:49:27 1983659 dinov2 helpers.py:102]   [130/634]  eta: 0:35:11    time: 3.973908  data: 0.001942  max mem: 4109
I20241203 07:49:35 1983664 dinov2 helpers.py:102]   [130/634]  eta: 0:35:39    time: 3.974360  data: 0.001660  max mem: 4109
I20241203 07:49:37 1983660 dinov2 helpers.py:102]   [130/634]  eta: 0:35:44    time: 3.973882  data: 0.001377  max mem: 4109
I20241203 07:49:54 1983663 dinov2 helpers.py:102]   [140/634]  eta: 0:33:59    time: 3.980378  data: 0.000573  max mem: 4109
I20241203 07:49:58 1983658 dinov2 helpers.py:102]   [140/634]  eta: 0:34:00    time: 3.971587  data: 0.001276  max mem: 4109
I20241203 07:50:01 1983665 dinov2 helpers.py:102]   [150/634]  eta: 0:31:26    time: 3.973144  data: 0.001093  max mem: 4109
I20241203 07:50:03 1983662 dinov2 helpers.py:102]   [140/634]  eta: 0:34:13    time: 3.973150  data: 0.001107  max mem: 4109
I20241203 07:50:07 1983661 dinov2 helpers.py:102]   [160/634]  eta: 0:29:20    time: 3.971302  data: 0.001007  max mem: 4109
I20241203 07:50:07 1983659 dinov2 helpers.py:102]   [140/634]  eta: 0:34:22    time: 3.970944  data: 0.001033  max mem: 4109
I20241203 07:50:15 1983664 dinov2 helpers.py:102]   [140/634]  eta: 0:34:47    time: 3.972023  data: 0.001770  max mem: 4109
I20241203 07:50:16 1983660 dinov2 helpers.py:102]   [140/634]  eta: 0:34:51    time: 3.972022  data: 0.000869  max mem: 4109
I20241203 07:50:33 1983663 dinov2 helpers.py:102]   [150/634]  eta: 0:33:13    time: 3.977009  data: 0.000752  max mem: 4109
I20241203 07:50:37 1983658 dinov2 helpers.py:102]   [150/634]  eta: 0:33:13    time: 3.968073  data: 0.001099  max mem: 4109
I20241203 07:50:40 1983665 dinov2 helpers.py:102]   [160/634]  eta: 0:30:49    time: 3.967116  data: 0.001756  max mem: 4109
I20241203 07:50:42 1983662 dinov2 helpers.py:102]   [150/634]  eta: 0:33:25    time: 3.968009  data: 0.000854  max mem: 4109
I20241203 07:50:46 1983661 dinov2 helpers.py:102]   [170/634]  eta: 0:28:50    time: 3.968661  data: 0.000908  max mem: 4109
I20241203 07:50:46 1983659 dinov2 helpers.py:102]   [150/634]  eta: 0:33:33    time: 3.966890  data: 0.001920  max mem: 4109
I20241203 07:50:54 1983664 dinov2 helpers.py:102]   [150/634]  eta: 0:33:57    time: 3.968732  data: 0.001589  max mem: 4109
I20241203 07:50:56 1983660 dinov2 helpers.py:102]   [150/634]  eta: 0:34:01    time: 3.969211  data: 0.000901  max mem: 4109
I20241203 07:51:13 1983663 dinov2 helpers.py:102]   [160/634]  eta: 0:32:27    time: 3.976691  data: 0.000841  max mem: 4109
I20241203 07:51:17 1983658 dinov2 helpers.py:102]   [160/634]  eta: 0:32:27    time: 3.963167  data: 0.000804  max mem: 4109
I20241203 07:51:20 1983665 dinov2 helpers.py:102]   [170/634]  eta: 0:30:12    time: 3.963092  data: 0.001544  max mem: 4109
I20241203 07:51:22 1983662 dinov2 helpers.py:102]   [160/634]  eta: 0:32:38    time: 3.962145  data: 0.001227  max mem: 4109
I20241203 07:51:26 1983661 dinov2 helpers.py:102]   [180/634]  eta: 0:28:18    time: 3.964760  data: 0.000923  max mem: 4109
I20241203 07:51:26 1983659 dinov2 helpers.py:102]   [160/634]  eta: 0:32:46    time: 3.963031  data: 0.001921  max mem: 4109
I20241203 07:51:34 1983664 dinov2 helpers.py:102]   [160/634]  eta: 0:33:08    time: 3.966455  data: 0.001076  max mem: 4109
I20241203 07:51:36 1983660 dinov2 helpers.py:102]   [160/634]  eta: 0:33:11    time: 3.967513  data: 0.001424  max mem: 4109
I20241203 07:51:53 1983663 dinov2 helpers.py:102]   [170/634]  eta: 0:31:42    time: 3.973621  data: 0.002187  max mem: 4109
I20241203 07:51:57 1983658 dinov2 helpers.py:102]   [170/634]  eta: 0:31:42    time: 3.963658  data: 0.001736  max mem: 4109
I20241203 07:52:00 1983665 dinov2 helpers.py:102]   [180/634]  eta: 0:29:34    time: 3.962689  data: 0.000871  max mem: 4109
I20241203 07:52:01 1983662 dinov2 helpers.py:102]   [170/634]  eta: 0:31:52    time: 3.957353  data: 0.001257  max mem: 4109
I20241203 07:52:05 1983659 dinov2 helpers.py:102]   [170/634]  eta: 0:31:59    time: 3.957182  data: 0.000652  max mem: 4109
I20241203 07:52:06 1983661 dinov2 helpers.py:102]   [190/634]  eta: 0:27:46    time: 3.960847  data: 0.000861  max mem: 4109
I20241203 07:52:14 1983664 dinov2 helpers.py:102]   [170/634]  eta: 0:32:19    time: 3.965339  data: 0.001384  max mem: 4109
I20241203 07:52:15 1983660 dinov2 helpers.py:102]   [170/634]  eta: 0:32:22    time: 3.962828  data: 0.001320  max mem: 4109
I20241203 07:52:33 1983663 dinov2 helpers.py:102]   [180/634]  eta: 0:30:58    time: 3.975885  data: 0.002219  max mem: 4109
I20241203 07:52:36 1983658 dinov2 helpers.py:102]   [180/634]  eta: 0:30:58    time: 3.961633  data: 0.002028  max mem: 4109
I20241203 07:52:39 1983665 dinov2 helpers.py:102]   [190/634]  eta: 0:28:56    time: 3.962535  data: 0.002147  max mem: 4109
I20241203 07:52:41 1983662 dinov2 helpers.py:102]   [180/634]  eta: 0:31:07    time: 3.956182  data: 0.000878  max mem: 4109
I20241203 07:52:45 1983661 dinov2 helpers.py:102]   [200/634]  eta: 0:27:13    time: 3.957997  data: 0.001652  max mem: 4109
I20241203 07:52:45 1983659 dinov2 helpers.py:102]   [180/634]  eta: 0:31:13    time: 3.957968  data: 0.000548  max mem: 4109
I20241203 07:52:53 1983664 dinov2 helpers.py:102]   [180/634]  eta: 0:31:32    time: 3.966264  data: 0.001246  max mem: 4109
I20241203 07:52:55 1983660 dinov2 helpers.py:102]   [180/634]  eta: 0:31:35    time: 3.959056  data: 0.001307  max mem: 4109
I20241203 07:53:12 1983663 dinov2 helpers.py:102]   [190/634]  eta: 0:30:15    time: 3.975244  data: 0.000725  max mem: 4109
I20241203 07:53:16 1983658 dinov2 helpers.py:102]   [190/634]  eta: 0:30:14    time: 3.960079  data: 0.001057  max mem: 4109
I20241203 07:53:19 1983665 dinov2 helpers.py:102]   [200/634]  eta: 0:28:18    time: 3.960772  data: 0.002385  max mem: 4109
I20241203 07:53:21 1983662 dinov2 helpers.py:102]   [190/634]  eta: 0:30:22    time: 3.959129  data: 0.000812  max mem: 4109
I20241203 07:53:25 1983661 dinov2 helpers.py:102]   [210/634]  eta: 0:26:39    time: 3.962857  data: 0.001771  max mem: 4109
I20241203 07:53:25 1983659 dinov2 helpers.py:102]   [190/634]  eta: 0:30:28    time: 3.965587  data: 0.000925  max mem: 4109
I20241203 07:53:33 1983664 dinov2 helpers.py:102]   [190/634]  eta: 0:30:46    time: 3.968280  data: 0.000817  max mem: 4109
I20241203 07:53:35 1983660 dinov2 helpers.py:102]   [190/634]  eta: 0:30:48    time: 3.962776  data: 0.001873  max mem: 4109
I20241203 07:53:52 1983663 dinov2 helpers.py:102]   [200/634]  eta: 0:29:31    time: 3.973136  data: 0.001246  max mem: 4109
I20241203 07:53:56 1983658 dinov2 helpers.py:102]   [200/634]  eta: 0:29:30    time: 3.965901  data: 0.000850  max mem: 4109
I20241203 07:53:58 1983665 dinov2 helpers.py:102]   [210/634]  eta: 0:27:40    time: 3.963897  data: 0.001042  max mem: 4109
I20241203 07:54:00 1983662 dinov2 helpers.py:102]   [200/634]  eta: 0:29:38    time: 3.962440  data: 0.000708  max mem: 4109
I20241203 07:54:04 1983661 dinov2 helpers.py:102]   [220/634]  eta: 0:26:05    time: 3.969688  data: 0.001112  max mem: 4109
I20241203 07:54:04 1983659 dinov2 helpers.py:102]   [200/634]  eta: 0:29:44    time: 3.969697  data: 0.001106  max mem: 4109
I20241203 07:54:13 1983664 dinov2 helpers.py:102]   [200/634]  eta: 0:30:00    time: 3.969656  data: 0.000762  max mem: 4109
I20241203 07:54:14 1983660 dinov2 helpers.py:102]   [200/634]  eta: 0:30:02    time: 3.966888  data: 0.001585  max mem: 4109
I20241203 07:54:32 1983663 dinov2 helpers.py:102]   [210/634]  eta: 0:28:48    time: 3.974456  data: 0.001272  max mem: 4109
I20241203 07:54:35 1983658 dinov2 helpers.py:102]   [210/634]  eta: 0:28:47    time: 3.972306  data: 0.000690  max mem: 4109
I20241203 07:54:38 1983665 dinov2 helpers.py:102]   [220/634]  eta: 0:27:02    time: 3.969977  data: 0.000719  max mem: 4109
I20241203 07:54:40 1983662 dinov2 helpers.py:102]   [210/634]  eta: 0:28:54    time: 3.968256  data: 0.000906  max mem: 4109
I20241203 07:54:44 1983661 dinov2 helpers.py:102]   [230/634]  eta: 0:25:31    time: 3.970962  data: 0.001108  max mem: 4109
I20241203 07:54:44 1983659 dinov2 helpers.py:102]   [210/634]  eta: 0:29:00    time: 3.971826  data: 0.000926  max mem: 4109
I20241203 07:54:52 1983664 dinov2 helpers.py:102]   [210/634]  eta: 0:29:15    time: 3.971974  data: 0.000702  max mem: 4109
I20241203 07:54:54 1983660 dinov2 helpers.py:102]   [210/634]  eta: 0:29:17    time: 3.969266  data: 0.001039  max mem: 4109
I20241203 07:55:12 1983663 dinov2 helpers.py:102]   [220/634]  eta: 0:28:06    time: 3.974741  data: 0.000605  max mem: 4109
I20241203 07:55:15 1983658 dinov2 helpers.py:102]   [220/634]  eta: 0:28:05    time: 3.973038  data: 0.001026  max mem: 4109
I20241203 07:55:18 1983665 dinov2 helpers.py:102]   [230/634]  eta: 0:26:24    time: 3.972137  data: 0.001011  max mem: 4109
I20241203 07:55:20 1983662 dinov2 helpers.py:102]   [220/634]  eta: 0:28:11    time: 3.972147  data: 0.000942  max mem: 4109
I20241203 07:55:24 1983661 dinov2 helpers.py:102]   [240/634]  eta: 0:24:56    time: 3.972524  data: 0.000815  max mem: 4109
I20241203 07:55:24 1983659 dinov2 helpers.py:102]   [220/634]  eta: 0:28:16    time: 3.973075  data: 0.000954  max mem: 4109
I20241203 07:55:32 1983664 dinov2 helpers.py:102]   [220/634]  eta: 0:28:31    time: 3.973123  data: 0.000754  max mem: 4109
I20241203 07:55:34 1983660 dinov2 helpers.py:102]   [220/634]  eta: 0:28:32    time: 3.972435  data: 0.001265  max mem: 4109
I20241203 07:55:51 1983663 dinov2 helpers.py:102]   [230/634]  eta: 0:27:23    time: 3.976871  data: 0.000598  max mem: 4109
I20241203 07:55:55 1983658 dinov2 helpers.py:102]   [230/634]  eta: 0:27:22    time: 3.972816  data: 0.001174  max mem: 4109
I20241203 07:55:58 1983665 dinov2 helpers.py:102]   [240/634]  eta: 0:25:45    time: 3.973399  data: 0.001479  max mem: 4109
I20241203 07:55:59 1983662 dinov2 helpers.py:102]   [230/634]  eta: 0:27:28    time: 3.973391  data: 0.000894  max mem: 4109
I20241203 07:56:04 1983661 dinov2 helpers.py:102]   [250/634]  eta: 0:24:20    time: 3.973418  data: 0.000752  max mem: 4109
I20241203 07:56:04 1983659 dinov2 helpers.py:102]   [230/634]  eta: 0:27:33    time: 3.973449  data: 0.000924  max mem: 4109
I20241203 07:56:12 1983664 dinov2 helpers.py:102]   [230/634]  eta: 0:27:47    time: 3.973311  data: 0.001411  max mem: 4109
I20241203 07:56:14 1983660 dinov2 helpers.py:102]   [230/634]  eta: 0:27:48    time: 3.973427  data: 0.001158  max mem: 4109
I20241203 07:56:31 1983663 dinov2 helpers.py:102]   [240/634]  eta: 0:26:41    time: 3.979800  data: 0.000744  max mem: 4109
I20241203 07:56:35 1983658 dinov2 helpers.py:102]   [240/634]  eta: 0:26:40    time: 3.973835  data: 0.000870  max mem: 4109
I20241203 07:56:37 1983665 dinov2 helpers.py:102]   [250/634]  eta: 0:25:07    time: 3.973467  data: 0.001512  max mem: 4109
I20241203 07:56:39 1983662 dinov2 helpers.py:102]   [240/634]  eta: 0:26:46    time: 3.973508  data: 0.000844  max mem: 4109
I20241203 07:56:43 1983661 dinov2 helpers.py:102]   [260/634]  eta: 0:23:45    time: 3.973241  data: 0.000842  max mem: 4109
I20241203 07:56:43 1983659 dinov2 helpers.py:102]   [240/634]  eta: 0:26:50    time: 3.973438  data: 0.001932  max mem: 4109
I20241203 07:56:52 1983664 dinov2 helpers.py:102]   [240/634]  eta: 0:27:03    time: 3.973659  data: 0.001603  max mem: 4109
I20241203 07:56:53 1983660 dinov2 helpers.py:102]   [240/634]  eta: 0:27:04    time: 3.973368  data: 0.001321  max mem: 4109
I20241203 07:57:11 1983663 dinov2 helpers.py:102]   [250/634]  eta: 0:25:59    time: 3.979877  data: 0.001444  max mem: 4109
I20241203 07:57:14 1983658 dinov2 helpers.py:102]   [250/634]  eta: 0:25:58    time: 3.973528  data: 0.000682  max mem: 4109
I20241203 07:57:17 1983665 dinov2 helpers.py:102]   [260/634]  eta: 0:24:28    time: 3.973886  data: 0.001057  max mem: 4109
I20241203 07:57:19 1983662 dinov2 helpers.py:102]   [250/634]  eta: 0:26:04    time: 3.973510  data: 0.000619  max mem: 4109
I20241203 07:57:23 1983661 dinov2 helpers.py:102]   [270/634]  eta: 0:23:09    time: 3.973641  data: 0.000637  max mem: 4109
I20241203 07:57:23 1983659 dinov2 helpers.py:102]   [250/634]  eta: 0:26:08    time: 3.973527  data: 0.002764  max mem: 4109
I20241203 07:57:31 1983664 dinov2 helpers.py:102]   [250/634]  eta: 0:26:19    time: 3.973565  data: 0.000982  max mem: 4109
I20241203 07:57:33 1983660 dinov2 helpers.py:102]   [250/634]  eta: 0:26:21    time: 3.973607  data: 0.001322  max mem: 4109
I20241203 07:57:51 1983663 dinov2 helpers.py:102]   [260/634]  eta: 0:25:17    time: 3.980816  data: 0.001232  max mem: 4109
I20241203 07:57:54 1983658 dinov2 helpers.py:102]   [260/634]  eta: 0:25:16    time: 3.973300  data: 0.000709  max mem: 4109
I20241203 07:57:57 1983665 dinov2 helpers.py:102]   [270/634]  eta: 0:23:50    time: 3.973681  data: 0.000969  max mem: 4109
I20241203 07:57:59 1983662 dinov2 helpers.py:102]   [260/634]  eta: 0:25:21    time: 3.973700  data: 0.001011  max mem: 4109
I20241203 07:58:03 1983661 dinov2 helpers.py:102]   [280/634]  eta: 0:22:33    time: 3.973602  data: 0.000651  max mem: 4109
I20241203 07:58:03 1983659 dinov2 helpers.py:102]   [260/634]  eta: 0:25:25    time: 3.973711  data: 0.001665  max mem: 4109
I20241203 07:58:11 1983664 dinov2 helpers.py:102]   [260/634]  eta: 0:25:36    time: 3.973589  data: 0.000762  max mem: 4109
I20241203 07:58:13 1983660 dinov2 helpers.py:102]   [260/634]  eta: 0:25:38    time: 3.973896  data: 0.000649  max mem: 4109
I20241203 07:58:31 1983663 dinov2 helpers.py:102]   [270/634]  eta: 0:24:36    time: 3.982673  data: 0.000516  max mem: 4109
I20241203 07:58:34 1983658 dinov2 helpers.py:102]   [270/634]  eta: 0:24:35    time: 3.973629  data: 0.001098  max mem: 4109
I20241203 07:58:37 1983665 dinov2 helpers.py:102]   [280/634]  eta: 0:23:11    time: 3.973281  data: 0.002351  max mem: 4109
I20241203 07:58:38 1983662 dinov2 helpers.py:102]   [270/634]  eta: 0:24:39    time: 3.973644  data: 0.001649  max mem: 4109
I20241203 07:58:43 1983661 dinov2 helpers.py:102]   [290/634]  eta: 0:21:56    time: 3.973528  data: 0.000881  max mem: 4109
I20241203 07:58:43 1983659 dinov2 helpers.py:102]   [270/634]  eta: 0:24:43    time: 3.973632  data: 0.001551  max mem: 4109
I20241203 07:58:51 1983664 dinov2 helpers.py:102]   [270/634]  eta: 0:24:53    time: 3.973749  data: 0.000842  max mem: 4109
I20241203 07:58:52 1983660 dinov2 helpers.py:102]   [270/634]  eta: 0:24:55    time: 3.973572  data: 0.000639  max mem: 4109
I20241203 07:59:10 1983663 dinov2 helpers.py:102]   [280/634]  eta: 0:23:54    time: 3.982628  data: 0.000572  max mem: 4109
I20241203 07:59:14 1983658 dinov2 helpers.py:102]   [280/634]  eta: 0:23:53    time: 3.973716  data: 0.001316  max mem: 4109
I20241203 07:59:16 1983665 dinov2 helpers.py:102]   [290/634]  eta: 0:22:32    time: 3.973611  data: 0.002228  max mem: 4109
I20241203 07:59:18 1983662 dinov2 helpers.py:102]   [280/634]  eta: 0:23:58    time: 3.973571  data: 0.001358  max mem: 4109
I20241203 07:59:22 1983661 dinov2 helpers.py:102]   [300/634]  eta: 0:21:20    time: 3.972771  data: 0.000900  max mem: 4109
I20241203 07:59:22 1983659 dinov2 helpers.py:102]   [280/634]  eta: 0:24:01    time: 3.973601  data: 0.001566  max mem: 4109
I20241203 07:59:31 1983664 dinov2 helpers.py:102]   [280/634]  eta: 0:24:11    time: 3.973520  data: 0.000944  max mem: 4109
I20241203 07:59:32 1983660 dinov2 helpers.py:102]   [280/634]  eta: 0:24:12    time: 3.974423  data: 0.001094  max mem: 4109
I20241203 07:59:50 1983663 dinov2 helpers.py:102]   [290/634]  eta: 0:23:13    time: 3.981712  data: 0.003134  max mem: 4109
I20241203 07:59:53 1983658 dinov2 helpers.py:102]   [290/634]  eta: 0:23:12    time: 3.974719  data: 0.001026  max mem: 4109
I20241203 07:59:56 1983665 dinov2 helpers.py:102]   [300/634]  eta: 0:21:53    time: 3.974629  data: 0.000905  max mem: 4109
I20241203 07:59:58 1983662 dinov2 helpers.py:102]   [290/634]  eta: 0:23:16    time: 3.974608  data: 0.001248  max mem: 4109
I20241203 08:00:02 1983661 dinov2 helpers.py:102]   [310/634]  eta: 0:20:43    time: 3.971926  data: 0.001019  max mem: 4109
I20241203 08:00:02 1983659 dinov2 helpers.py:102]   [290/634]  eta: 0:23:19    time: 3.973732  data: 0.000962  max mem: 4109
I20241203 08:00:10 1983664 dinov2 helpers.py:102]   [290/634]  eta: 0:23:28    time: 3.975443  data: 0.000941  max mem: 4109
I20241203 08:00:12 1983660 dinov2 helpers.py:102]   [290/634]  eta: 0:23:29    time: 3.975720  data: 0.001201  max mem: 4109
I20241203 08:00:30 1983663 dinov2 helpers.py:102]   [300/634]  eta: 0:22:32    time: 3.981232  data: 0.003301  max mem: 4109
I20241203 08:00:33 1983658 dinov2 helpers.py:102]   [300/634]  eta: 0:22:31    time: 3.975536  data: 0.001322  max mem: 4109
I20241203 08:00:36 1983665 dinov2 helpers.py:102]   [310/634]  eta: 0:21:14    time: 3.974775  data: 0.001003  max mem: 4109
I20241203 08:00:38 1983662 dinov2 helpers.py:102]   [300/634]  eta: 0:22:34    time: 3.974780  data: 0.001127  max mem: 4109
I20241203 08:00:42 1983661 dinov2 helpers.py:102]   [320/634]  eta: 0:20:06    time: 3.972860  data: 0.001895  max mem: 4109
I20241203 08:00:42 1983659 dinov2 helpers.py:102]   [300/634]  eta: 0:22:37    time: 3.974756  data: 0.001007  max mem: 4109
I20241203 08:00:50 1983664 dinov2 helpers.py:102]   [300/634]  eta: 0:22:46    time: 3.975698  data: 0.001698  max mem: 4109
I20241203 08:00:52 1983660 dinov2 helpers.py:102]   [300/634]  eta: 0:22:47    time: 3.974724  data: 0.000762  max mem: 4109
I20241203 08:01:10 1983663 dinov2 helpers.py:102]   [310/634]  eta: 0:21:50    time: 3.977463  data: 0.000775  max mem: 4109
I20241203 08:01:13 1983658 dinov2 helpers.py:102]   [310/634]  eta: 0:21:49    time: 3.975519  data: 0.001657  max mem: 4109
I20241203 08:01:16 1983665 dinov2 helpers.py:102]   [320/634]  eta: 0:20:35    time: 3.973893  data: 0.002016  max mem: 4109
I20241203 08:01:17 1983662 dinov2 helpers.py:102]   [310/634]  eta: 0:21:53    time: 3.974729  data: 0.000780  max mem: 4109
I20241203 08:01:22 1983661 dinov2 helpers.py:102]   [330/634]  eta: 0:19:29    time: 3.975599  data: 0.001675  max mem: 4109
I20241203 08:01:22 1983659 dinov2 helpers.py:102]   [310/634]  eta: 0:21:56    time: 3.975662  data: 0.001066  max mem: 4109
I20241203 08:01:30 1983664 dinov2 helpers.py:102]   [310/634]  eta: 0:22:04    time: 3.974709  data: 0.001789  max mem: 4109
I20241203 08:01:31 1983660 dinov2 helpers.py:102]   [310/634]  eta: 0:22:05    time: 3.973652  data: 0.000647  max mem: 4109
I20241203 08:01:50 1983663 dinov2 helpers.py:102]   [320/634]  eta: 0:21:09    time: 3.982643  data: 0.000619  max mem: 4109
I20241203 08:01:53 1983658 dinov2 helpers.py:102]   [320/634]  eta: 0:21:08    time: 3.974716  data: 0.001238  max mem: 4109
I20241203 08:01:55 1983665 dinov2 helpers.py:102]   [330/634]  eta: 0:19:56    time: 3.973795  data: 0.002055  max mem: 4109
I20241203 08:01:57 1983662 dinov2 helpers.py:102]   [320/634]  eta: 0:21:12    time: 3.974729  data: 0.000806  max mem: 4109
I20241203 08:02:01 1983661 dinov2 helpers.py:102]   [340/634]  eta: 0:18:51    time: 3.975653  data: 0.000841  max mem: 4109
I20241203 08:02:01 1983659 dinov2 helpers.py:102]   [320/634]  eta: 0:21:14    time: 3.976632  data: 0.000993  max mem: 4109
I20241203 08:02:10 1983664 dinov2 helpers.py:102]   [320/634]  eta: 0:21:22    time: 3.975677  data: 0.001008  max mem: 4109
I20241203 08:02:11 1983660 dinov2 helpers.py:102]   [320/634]  eta: 0:21:23    time: 3.973909  data: 0.000633  max mem: 4109
I20241203 08:02:30 1983663 dinov2 helpers.py:102]   [330/634]  eta: 0:20:28    time: 3.990226  data: 0.000786  max mem: 4109
I20241203 08:02:32 1983658 dinov2 helpers.py:102]   [330/634]  eta: 0:20:27    time: 3.975856  data: 0.000954  max mem: 4109
I20241203 08:02:35 1983665 dinov2 helpers.py:102]   [340/634]  eta: 0:19:17    time: 3.975802  data: 0.001083  max mem: 4109
I20241203 08:02:37 1983662 dinov2 helpers.py:102]   [330/634]  eta: 0:20:30    time: 3.974105  data: 0.000800  max mem: 4109
I20241203 08:02:41 1983661 dinov2 helpers.py:102]   [350/634]  eta: 0:18:14    time: 3.974161  data: 0.000949  max mem: 4109
I20241203 08:02:41 1983659 dinov2 helpers.py:102]   [330/634]  eta: 0:20:33    time: 3.975889  data: 0.000759  max mem: 4109
I20241203 08:02:49 1983664 dinov2 helpers.py:102]   [330/634]  eta: 0:20:40    time: 3.976914  data: 0.000967  max mem: 4109
I20241203 08:02:51 1983660 dinov2 helpers.py:102]   [330/634]  eta: 0:20:41    time: 3.976025  data: 0.000542  max mem: 4109
I20241203 08:03:10 1983663 dinov2 helpers.py:102]   [340/634]  eta: 0:19:48    time: 3.991481  data: 0.000832  max mem: 4109
I20241203 08:03:12 1983658 dinov2 helpers.py:102]   [340/634]  eta: 0:19:46    time: 3.976163  data: 0.001133  max mem: 4109
I20241203 08:03:15 1983665 dinov2 helpers.py:102]   [350/634]  eta: 0:18:38    time: 3.976270  data: 0.000765  max mem: 4109
I20241203 08:03:17 1983662 dinov2 helpers.py:102]   [340/634]  eta: 0:19:49    time: 3.974360  data: 0.001021  max mem: 4109
I20241203 08:03:21 1983661 dinov2 helpers.py:102]   [360/634]  eta: 0:17:36    time: 3.976277  data: 0.001055  max mem: 4109
I20241203 08:03:21 1983659 dinov2 helpers.py:102]   [340/634]  eta: 0:19:52    time: 3.974274  data: 0.000726  max mem: 4109
I20241203 08:03:29 1983664 dinov2 helpers.py:102]   [340/634]  eta: 0:19:58    time: 3.976165  data: 0.001299  max mem: 4109
I20241203 08:03:31 1983660 dinov2 helpers.py:102]   [340/634]  eta: 0:19:59    time: 3.978793  data: 0.000665  max mem: 4109
I20241203 08:03:49 1983663 dinov2 helpers.py:102]   [350/634]  eta: 0:19:07    time: 3.992699  data: 0.000702  max mem: 4109
I20241203 08:03:52 1983658 dinov2 helpers.py:102]   [350/634]  eta: 0:19:05    time: 3.976044  data: 0.001524  max mem: 4109
I20241203 08:03:55 1983665 dinov2 helpers.py:102]   [360/634]  eta: 0:17:59    time: 3.974236  data: 0.000553  max mem: 4109
I20241203 08:03:56 1983662 dinov2 helpers.py:102]   [350/634]  eta: 0:19:08    time: 3.974269  data: 0.001463  max mem: 4109
I20241203 08:04:01 1983661 dinov2 helpers.py:102]   [370/634]  eta: 0:16:58    time: 3.976067  data: 0.000949  max mem: 4109
I20241203 08:04:01 1983659 dinov2 helpers.py:102]   [350/634]  eta: 0:19:11    time: 3.976087  data: 0.000695  max mem: 4109
I20241203 08:04:09 1983664 dinov2 helpers.py:102]   [350/634]  eta: 0:19:17    time: 3.974226  data: 0.001975  max mem: 4109
I20241203 08:04:11 1983660 dinov2 helpers.py:102]   [350/634]  eta: 0:19:17    time: 3.977046  data: 0.000686  max mem: 4109
I20241203 08:04:29 1983663 dinov2 helpers.py:102]   [360/634]  eta: 0:18:26    time: 3.989305  data: 0.000698  max mem: 4109
I20241203 08:04:32 1983658 dinov2 helpers.py:102]   [360/634]  eta: 0:18:25    time: 3.975919  data: 0.001454  max mem: 4109
I20241203 08:04:34 1983665 dinov2 helpers.py:102]   [370/634]  eta: 0:17:20    time: 3.975780  data: 0.000944  max mem: 4109
I20241203 08:04:36 1983662 dinov2 helpers.py:102]   [360/634]  eta: 0:18:27    time: 3.975901  data: 0.001385  max mem: 4109
I20241203 08:04:40 1983661 dinov2 helpers.py:102]   [380/634]  eta: 0:16:21    time: 3.973991  data: 0.000753  max mem: 4109
I20241203 08:04:40 1983659 dinov2 helpers.py:102]   [360/634]  eta: 0:18:29    time: 3.975969  data: 0.000762  max mem: 4109
I20241203 08:04:49 1983664 dinov2 helpers.py:102]   [360/634]  eta: 0:18:35    time: 3.975948  data: 0.001666  max mem: 4109
I20241203 08:04:50 1983660 dinov2 helpers.py:102]   [360/634]  eta: 0:18:36    time: 3.975959  data: 0.000664  max mem: 4109
I20241203 08:05:09 1983663 dinov2 helpers.py:102]   [370/634]  eta: 0:17:45    time: 3.989115  data: 0.000770  max mem: 4109
I20241203 08:05:11 1983658 dinov2 helpers.py:102]   [370/634]  eta: 0:17:44    time: 3.976997  data: 0.001832  max mem: 4109
I20241203 08:05:14 1983665 dinov2 helpers.py:102]   [380/634]  eta: 0:16:41    time: 3.976073  data: 0.001081  max mem: 4109
I20241203 08:05:16 1983662 dinov2 helpers.py:102]   [370/634]  eta: 0:17:46    time: 3.977962  data: 0.000904  max mem: 4109
I20241203 08:05:20 1983661 dinov2 helpers.py:102]   [390/634]  eta: 0:15:43    time: 3.975238  data: 0.000675  max mem: 4109
I20241203 08:05:20 1983659 dinov2 helpers.py:102]   [370/634]  eta: 0:17:48    time: 3.974249  data: 0.000707  max mem: 4109
I20241203 08:05:28 1983664 dinov2 helpers.py:102]   [370/634]  eta: 0:17:54    time: 3.976064  data: 0.000945  max mem: 4109
I20241203 08:05:30 1983660 dinov2 helpers.py:102]   [370/634]  eta: 0:17:54    time: 3.976059  data: 0.000654  max mem: 4109
I20241203 08:05:49 1983663 dinov2 helpers.py:102]   [380/634]  eta: 0:17:05    time: 3.993347  data: 0.000856  max mem: 4109
I20241203 08:05:51 1983658 dinov2 helpers.py:102]   [380/634]  eta: 0:17:03    time: 3.977056  data: 0.001512  max mem: 4109
I20241203 08:05:54 1983665 dinov2 helpers.py:102]   [390/634]  eta: 0:16:02    time: 3.974511  data: 0.001440  max mem: 4109
I20241203 08:05:56 1983662 dinov2 helpers.py:102]   [380/634]  eta: 0:17:06    time: 3.976195  data: 0.001541  max mem: 4109
I20241203 08:06:00 1983661 dinov2 helpers.py:102]   [400/634]  eta: 0:15:05    time: 3.976282  data: 0.001142  max mem: 4109
I20241203 08:06:00 1983659 dinov2 helpers.py:102]   [380/634]  eta: 0:17:07    time: 3.977123  data: 0.001044  max mem: 4109
I20241203 08:06:08 1983664 dinov2 helpers.py:102]   [380/634]  eta: 0:17:12    time: 3.974551  data: 0.000951  max mem: 4109
I20241203 08:06:10 1983660 dinov2 helpers.py:102]   [380/634]  eta: 0:17:13    time: 3.974494  data: 0.000633  max mem: 4109
I20241203 08:06:29 1983663 dinov2 helpers.py:102]   [390/634]  eta: 0:16:24    time: 3.990600  data: 0.000803  max mem: 4109
I20241203 08:06:31 1983658 dinov2 helpers.py:102]   [390/634]  eta: 0:16:23    time: 3.974433  data: 0.000654  max mem: 4109
I20241203 08:06:34 1983665 dinov2 helpers.py:102]   [400/634]  eta: 0:15:22    time: 3.974574  data: 0.001528  max mem: 4109
I20241203 08:06:35 1983662 dinov2 helpers.py:102]   [390/634]  eta: 0:16:25    time: 3.975247  data: 0.001365  max mem: 4109
I20241203 08:06:40 1983661 dinov2 helpers.py:102]   [410/634]  eta: 0:14:27    time: 3.977957  data: 0.001088  max mem: 4109
I20241203 08:06:40 1983659 dinov2 helpers.py:102]   [390/634]  eta: 0:16:27    time: 3.981729  data: 0.001270  max mem: 4109
I20241203 08:06:48 1983664 dinov2 helpers.py:102]   [390/634]  eta: 0:16:31    time: 3.974458  data: 0.001734  max mem: 4109
I20241203 08:06:50 1983660 dinov2 helpers.py:102]   [390/634]  eta: 0:16:32    time: 3.976138  data: 0.001168  max mem: 4109
I20241203 08:07:09 1983663 dinov2 helpers.py:102]   [400/634]  eta: 0:15:43    time: 3.987865  data: 0.000750  max mem: 4109
I20241203 08:07:11 1983658 dinov2 helpers.py:102]   [400/634]  eta: 0:15:42    time: 3.976306  data: 0.000878  max mem: 4109
I20241203 08:07:13 1983665 dinov2 helpers.py:102]   [410/634]  eta: 0:14:43    time: 3.974488  data: 0.001136  max mem: 4109
I20241203 08:07:15 1983662 dinov2 helpers.py:102]   [400/634]  eta: 0:15:44    time: 3.976342  data: 0.000853  max mem: 4109
I20241203 08:07:19 1983661 dinov2 helpers.py:102]   [420/634]  eta: 0:13:48    time: 3.977132  data: 0.000710  max mem: 4109
I20241203 08:07:20 1983659 dinov2 helpers.py:102]   [400/634]  eta: 0:15:46    time: 3.978944  data: 0.001217  max mem: 4109
I20241203 08:07:28 1983664 dinov2 helpers.py:102]   [400/634]  eta: 0:15:50    time: 3.977041  data: 0.001803  max mem: 4109
I20241203 08:07:29 1983660 dinov2 helpers.py:102]   [400/634]  eta: 0:15:51    time: 3.977052  data: 0.001368  max mem: 4109
I20241203 08:07:49 1983663 dinov2 helpers.py:102]   [410/634]  eta: 0:15:03    time: 3.990735  data: 0.000667  max mem: 4109
I20241203 08:07:50 1983658 dinov2 helpers.py:102]   [410/634]  eta: 0:15:01    time: 3.977100  data: 0.001614  max mem: 4109
I20241203 08:07:53 1983665 dinov2 helpers.py:102]   [420/634]  eta: 0:14:04    time: 3.976108  data: 0.001430  max mem: 4109
I20241203 08:07:55 1983662 dinov2 helpers.py:102]   [410/634]  eta: 0:15:03    time: 3.977988  data: 0.001108  max mem: 4109
I20241203 08:07:59 1983661 dinov2 helpers.py:102]   [430/634]  eta: 0:13:10    time: 3.974402  data: 0.000895  max mem: 4109
I20241203 08:07:59 1983659 dinov2 helpers.py:102]   [410/634]  eta: 0:15:05    time: 3.977006  data: 0.000998  max mem: 4109
I20241203 08:08:07 1983664 dinov2 helpers.py:102]   [410/634]  eta: 0:15:09    time: 3.977121  data: 0.001704  max mem: 4109
I20241203 08:08:09 1983660 dinov2 helpers.py:102]   [410/634]  eta: 0:15:09    time: 3.975322  data: 0.001136  max mem: 4109
I20241203 08:08:29 1983663 dinov2 helpers.py:102]   [420/634]  eta: 0:14:22    time: 3.990531  data: 0.001250  max mem: 4109
I20241203 08:08:30 1983658 dinov2 helpers.py:102]   [420/634]  eta: 0:14:21    time: 3.977262  data: 0.001452  max mem: 4109
I20241203 08:08:33 1983665 dinov2 helpers.py:102]   [430/634]  eta: 0:13:24    time: 3.975978  data: 0.001263  max mem: 4109
I20241203 08:08:35 1983662 dinov2 helpers.py:102]   [420/634]  eta: 0:14:23    time: 3.977835  data: 0.001465  max mem: 4109
I20241203 08:08:39 1983661 dinov2 helpers.py:102]   [440/634]  eta: 0:12:32    time: 3.974340  data: 0.001358  max mem: 4109
I20241203 08:08:39 1983659 dinov2 helpers.py:102]   [420/634]  eta: 0:14:24    time: 3.977383  data: 0.000899  max mem: 4109
I20241203 08:08:47 1983664 dinov2 helpers.py:102]   [420/634]  eta: 0:14:28    time: 3.976156  data: 0.001433  max mem: 4109
I20241203 08:08:49 1983660 dinov2 helpers.py:102]   [420/634]  eta: 0:14:28    time: 3.976086  data: 0.000884  max mem: 4109
I20241203 08:09:09 1983663 dinov2 helpers.py:102]   [430/634]  eta: 0:13:42    time: 3.992284  data: 0.001248  max mem: 4109
I20241203 08:09:10 1983658 dinov2 helpers.py:102]   [430/634]  eta: 0:13:40    time: 3.976213  data: 0.000652  max mem: 4109
I20241203 08:09:13 1983665 dinov2 helpers.py:102]   [440/634]  eta: 0:12:45    time: 3.977078  data: 0.000876  max mem: 4109
I20241203 08:09:14 1983662 dinov2 helpers.py:102]   [430/634]  eta: 0:13:42    time: 3.975335  data: 0.001255  max mem: 4109
I20241203 08:09:19 1983661 dinov2 helpers.py:102]   [450/634]  eta: 0:11:53    time: 3.974489  data: 0.001310  max mem: 4109
I20241203 08:09:19 1983659 dinov2 helpers.py:102]   [430/634]  eta: 0:13:43    time: 3.977171  data: 0.000918  max mem: 4109
I20241203 08:09:27 1983664 dinov2 helpers.py:102]   [430/634]  eta: 0:13:47    time: 3.976233  data: 0.000795  max mem: 4109
I20241203 08:09:29 1983660 dinov2 helpers.py:102]   [430/634]  eta: 0:13:47    time: 3.978077  data: 0.000882  max mem: 4109
I20241203 08:09:49 1983663 dinov2 helpers.py:102]   [440/634]  eta: 0:13:01    time: 3.994366  data: 0.000835  max mem: 4109
I20241203 08:09:50 1983658 dinov2 helpers.py:102]   [440/634]  eta: 0:13:00    time: 3.974323  data: 0.001239  max mem: 4109
I20241203 08:09:52 1983665 dinov2 helpers.py:102]   [450/634]  eta: 0:12:06    time: 3.977385  data: 0.000858  max mem: 4109
I20241203 08:09:54 1983662 dinov2 helpers.py:102]   [440/634]  eta: 0:13:01    time: 3.974905  data: 0.000766  max mem: 4109
I20241203 08:09:58 1983661 dinov2 helpers.py:102]   [460/634]  eta: 0:11:15    time: 3.974502  data: 0.001005  max mem: 4109
I20241203 08:09:59 1983659 dinov2 helpers.py:102]   [440/634]  eta: 0:13:03    time: 3.978634  data: 0.000782  max mem: 4109
I20241203 08:10:07 1983664 dinov2 helpers.py:102]   [440/634]  eta: 0:13:06    time: 3.977136  data: 0.000903  max mem: 4109
I20241203 08:10:08 1983660 dinov2 helpers.py:102]   [440/634]  eta: 0:13:07    time: 3.977220  data: 0.001272  max mem: 4109
I20241203 08:10:29 1983663 dinov2 helpers.py:102]   [450/634]  eta: 0:12:21    time: 3.993228  data: 0.000775  max mem: 4109
I20241203 08:10:29 1983658 dinov2 helpers.py:102]   [450/634]  eta: 0:12:20    time: 3.976177  data: 0.001425  max mem: 4109
I20241203 08:10:32 1983665 dinov2 helpers.py:102]   [460/634]  eta: 0:11:26    time: 3.976179  data: 0.001617  max mem: 4109
I20241203 08:10:34 1983662 dinov2 helpers.py:102]   [450/634]  eta: 0:12:21    time: 3.976165  data: 0.000983  max mem: 4109
I20241203 08:10:38 1983661 dinov2 helpers.py:102]   [470/634]  eta: 0:10:36    time: 3.976100  data: 0.000987  max mem: 4109
I20241203 08:10:38 1983659 dinov2 helpers.py:102]   [450/634]  eta: 0:12:22    time: 3.976211  data: 0.000921  max mem: 4109
I20241203 08:10:47 1983664 dinov2 helpers.py:102]   [450/634]  eta: 0:12:25    time: 3.978845  data: 0.000759  max mem: 4109
I20241203 08:10:48 1983660 dinov2 helpers.py:102]   [450/634]  eta: 0:12:26    time: 3.976180  data: 0.001063  max mem: 4109
I20241203 08:11:09 1983663 dinov2 helpers.py:102]   [460/634]  eta: 0:11:40    time: 3.994052  data: 0.000692  max mem: 4109
I20241203 08:11:09 1983658 dinov2 helpers.py:102]   [460/634]  eta: 0:11:39    time: 3.976953  data: 0.001113  max mem: 4109
I20241203 08:11:12 1983665 dinov2 helpers.py:102]   [470/634]  eta: 0:10:47    time: 3.975926  data: 0.001605  max mem: 4109
I20241203 08:11:14 1983662 dinov2 helpers.py:102]   [460/634]  eta: 0:11:40    time: 3.975725  data: 0.000924  max mem: 4109
I20241203 08:11:18 1983661 dinov2 helpers.py:102]   [480/634]  eta: 0:09:58    time: 3.977886  data: 0.000878  max mem: 4109
I20241203 08:11:18 1983659 dinov2 helpers.py:102]   [460/634]  eta: 0:11:42    time: 3.976051  data: 0.000790  max mem: 4109
I20241203 08:11:26 1983664 dinov2 helpers.py:102]   [460/634]  eta: 0:11:44    time: 3.975984  data: 0.001529  max mem: 4109
I20241203 08:11:28 1983660 dinov2 helpers.py:102]   [460/634]  eta: 0:11:45    time: 3.976046  data: 0.001872  max mem: 4109
I20241203 08:11:49 1983663 dinov2 helpers.py:102]   [470/634]  eta: 0:11:00    time: 3.995038  data: 0.001362  max mem: 4109
I20241203 08:11:49 1983658 dinov2 helpers.py:102]   [470/634]  eta: 0:10:59    time: 3.976983  data: 0.001719  max mem: 4109
I20241203 08:11:52 1983665 dinov2 helpers.py:102]   [480/634]  eta: 0:10:08    time: 3.976063  data: 0.000965  max mem: 4109
I20241203 08:11:54 1983662 dinov2 helpers.py:102]   [470/634]  eta: 0:11:00    time: 3.976071  data: 0.000878  max mem: 4109
I20241203 08:11:58 1983661 dinov2 helpers.py:102]   [490/634]  eta: 0:09:19    time: 3.977906  data: 0.001121  max mem: 4109
I20241203 08:11:58 1983659 dinov2 helpers.py:102]   [470/634]  eta: 0:11:01    time: 3.977743  data: 0.000894  max mem: 4109
I20241203 08:12:06 1983664 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.975970  data: 0.002015  max mem: 4109
I20241203 08:12:08 1983660 dinov2 helpers.py:102]   [470/634]  eta: 0:11:04    time: 3.976780  data: 0.001982  max mem: 4109
I20241203 08:12:28 1983663 dinov2 helpers.py:102]   [480/634]  eta: 0:10:20    time: 3.991154  data: 0.001812  max mem: 4109
I20241203 08:12:29 1983658 dinov2 helpers.py:102]   [480/634]  eta: 0:10:18    time: 3.976803  data: 0.002211  max mem: 4109
I20241203 08:12:31 1983665 dinov2 helpers.py:102]   [490/634]  eta: 0:09:28    time: 3.977731  data: 0.000913  max mem: 4109
I20241203 08:12:33 1983662 dinov2 helpers.py:102]   [480/634]  eta: 0:10:20    time: 3.977766  data: 0.000878  max mem: 4109
I20241203 08:12:37 1983661 dinov2 helpers.py:102]   [500/634]  eta: 0:08:41    time: 3.975972  data: 0.001662  max mem: 4109
I20241203 08:12:38 1983659 dinov2 helpers.py:102]   [480/634]  eta: 0:10:20    time: 3.975919  data: 0.001302  max mem: 4109
I20241203 08:12:46 1983664 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.977759  data: 0.001084  max mem: 4109
I20241203 08:12:47 1983660 dinov2 helpers.py:102]   [480/634]  eta: 0:10:23    time: 3.977834  data: 0.001038  max mem: 4109
I20241203 08:13:08 1983663 dinov2 helpers.py:102]   [490/634]  eta: 0:09:39    time: 3.991177  data: 0.001155  max mem: 4109
I20241203 08:13:09 1983658 dinov2 helpers.py:102]   [490/634]  eta: 0:09:38    time: 3.975093  data: 0.001440  max mem: 4109
I20241203 08:13:11 1983665 dinov2 helpers.py:102]   [500/634]  eta: 0:08:49    time: 3.976125  data: 0.000913  max mem: 4109
I20241203 08:13:13 1983662 dinov2 helpers.py:102]   [490/634]  eta: 0:09:39    time: 3.976014  data: 0.000849  max mem: 4109
I20241203 08:13:17 1983661 dinov2 helpers.py:102]   [510/634]  eta: 0:08:02    time: 3.975971  data: 0.001561  max mem: 4109
I20241203 08:13:17 1983659 dinov2 helpers.py:102]   [490/634]  eta: 0:09:40    time: 3.976043  data: 0.001119  max mem: 4109
I20241203 08:13:26 1983664 dinov2 helpers.py:102]   [490/634]  eta: 0:09:42    time: 3.976094  data: 0.001048  max mem: 4109
I20241203 08:13:27 1983660 dinov2 helpers.py:102]   [490/634]  eta: 0:09:42    time: 3.976131  data: 0.000975  max mem: 4109
I20241203 08:13:48 1983663 dinov2 helpers.py:102]   [500/634]  eta: 0:08:59    time: 3.993271  data: 0.000478  max mem: 4109
I20241203 08:13:48 1983658 dinov2 helpers.py:102]   [500/634]  eta: 0:08:58    time: 3.976119  data: 0.000969  max mem: 4109
I20241203 08:13:51 1983665 dinov2 helpers.py:102]   [510/634]  eta: 0:08:09    time: 3.976132  data: 0.001047  max mem: 4109
I20241203 08:13:53 1983662 dinov2 helpers.py:102]   [500/634]  eta: 0:08:59    time: 3.976092  data: 0.001595  max mem: 4109
I20241203 08:13:57 1983661 dinov2 helpers.py:102]   [520/634]  eta: 0:07:23    time: 3.976070  data: 0.000817  max mem: 4109
I20241203 08:13:57 1983659 dinov2 helpers.py:102]   [500/634]  eta: 0:09:00    time: 3.976172  data: 0.000613  max mem: 4109
I20241203 08:14:05 1983664 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.976170  data: 0.001868  max mem: 4109
I20241203 08:14:07 1983660 dinov2 helpers.py:102]   [500/634]  eta: 0:09:02    time: 3.976082  data: 0.001018  max mem: 4109
I20241203 08:14:28 1983658 dinov2 helpers.py:102]   [510/634]  eta: 0:08:18    time: 3.978766  data: 0.001052  max mem: 4109
I20241203 08:14:28 1983663 dinov2 helpers.py:102]   [510/634]  eta: 0:08:19    time: 3.994121  data: 0.000617  max mem: 4109
I20241203 08:14:31 1983665 dinov2 helpers.py:102]   [520/634]  eta: 0:07:30    time: 3.976002  data: 0.001070  max mem: 4109
I20241203 08:14:33 1983662 dinov2 helpers.py:102]   [510/634]  eta: 0:08:18    time: 3.976096  data: 0.001484  max mem: 4109
I20241203 08:14:37 1983661 dinov2 helpers.py:102]   [530/634]  eta: 0:06:45    time: 3.976101  data: 0.000646  max mem: 4109
I20241203 08:14:37 1983659 dinov2 helpers.py:102]   [510/634]  eta: 0:08:19    time: 3.976474  data: 0.001751  max mem: 4109
I20241203 08:14:45 1983664 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.976064  data: 0.001710  max mem: 4109
I20241203 08:14:47 1983660 dinov2 helpers.py:102]   [510/634]  eta: 0:08:21    time: 3.978009  data: 0.001603  max mem: 4109
I20241203 08:15:08 1983658 dinov2 helpers.py:102]   [520/634]  eta: 0:07:37    time: 3.978740  data: 0.000768  max mem: 4109
I20241203 08:15:08 1983663 dinov2 helpers.py:102]   [520/634]  eta: 0:07:38    time: 3.993993  data: 0.000936  max mem: 4109
I20241203 08:15:10 1983665 dinov2 helpers.py:102]   [530/634]  eta: 0:06:50    time: 3.976074  data: 0.000933  max mem: 4109
I20241203 08:15:12 1983662 dinov2 helpers.py:102]   [520/634]  eta: 0:07:38    time: 3.976111  data: 0.000792  max mem: 4109
I20241203 08:15:17 1983661 dinov2 helpers.py:102]   [540/634]  eta: 0:06:06    time: 3.977824  data: 0.000862  max mem: 4109
I20241203 08:15:17 1983659 dinov2 helpers.py:102]   [520/634]  eta: 0:07:39    time: 3.976023  data: 0.002234  max mem: 4109
I20241203 08:15:25 1983664 dinov2 helpers.py:102]   [520/634]  eta: 0:07:40    time: 3.976057  data: 0.001055  max mem: 4109
I20241203 08:15:27 1983660 dinov2 helpers.py:102]   [520/634]  eta: 0:07:41    time: 3.978688  data: 0.001520  max mem: 4109
I20241203 08:15:48 1983658 dinov2 helpers.py:102]   [530/634]  eta: 0:06:57    time: 3.977885  data: 0.001483  max mem: 4109
I20241203 08:15:48 1983663 dinov2 helpers.py:102]   [530/634]  eta: 0:06:58    time: 3.992266  data: 0.000906  max mem: 4109
I20241203 08:15:50 1983665 dinov2 helpers.py:102]   [540/634]  eta: 0:06:11    time: 3.977852  data: 0.000658  max mem: 4109
I20241203 08:15:52 1983662 dinov2 helpers.py:102]   [530/634]  eta: 0:06:58    time: 3.977865  data: 0.001430  max mem: 4109
I20241203 08:15:56 1983661 dinov2 helpers.py:102]   [550/634]  eta: 0:05:27    time: 3.978829  data: 0.001738  max mem: 4109
I20241203 08:15:57 1983659 dinov2 helpers.py:102]   [530/634]  eta: 0:06:58    time: 3.975927  data: 0.002359  max mem: 4109
I20241203 08:16:05 1983664 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.977865  data: 0.000929  max mem: 4109
I20241203 08:16:06 1983660 dinov2 helpers.py:102]   [530/634]  eta: 0:07:00    time: 3.978601  data: 0.001281  max mem: 4109
I20241203 08:16:27 1983658 dinov2 helpers.py:102]   [540/634]  eta: 0:06:17    time: 3.976191  data: 0.001406  max mem: 4109
I20241203 08:16:28 1983663 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.993227  data: 0.000698  max mem: 4109
I20241203 08:16:30 1983665 dinov2 helpers.py:102]   [550/634]  eta: 0:05:32    time: 3.978810  data: 0.000712  max mem: 4109
I20241203 08:16:32 1983662 dinov2 helpers.py:102]   [540/634]  eta: 0:06:17    time: 3.977768  data: 0.002498  max mem: 4109
I20241203 08:16:36 1983661 dinov2 helpers.py:102]   [560/634]  eta: 0:04:48    time: 3.977970  data: 0.001534  max mem: 4109
I20241203 08:16:36 1983659 dinov2 helpers.py:102]   [540/634]  eta: 0:06:18    time: 3.976136  data: 0.002056  max mem: 4109
I20241203 08:16:44 1983664 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.978757  data: 0.001110  max mem: 4109
I20241203 08:16:46 1983660 dinov2 helpers.py:102]   [540/634]  eta: 0:06:19    time: 3.976111  data: 0.001196  max mem: 4109
I20241203 08:17:07 1983658 dinov2 helpers.py:102]   [550/634]  eta: 0:05:37    time: 3.976063  data: 0.000554  max mem: 4109
I20241203 08:17:08 1983663 dinov2 helpers.py:102]   [550/634]  eta: 0:05:37    time: 3.994040  data: 0.000815  max mem: 4109
I20241203 08:17:10 1983665 dinov2 helpers.py:102]   [560/634]  eta: 0:04:52    time: 3.978905  data: 0.000884  max mem: 4109
I20241203 08:17:12 1983662 dinov2 helpers.py:102]   [550/634]  eta: 0:05:37    time: 3.975999  data: 0.001922  max mem: 4109
I20241203 08:17:16 1983661 dinov2 helpers.py:102]   [570/634]  eta: 0:04:09    time: 3.977816  data: 0.000642  max mem: 4109
I20241203 08:17:16 1983659 dinov2 helpers.py:102]   [550/634]  eta: 0:05:38    time: 3.975877  data: 0.000953  max mem: 4109
I20241203 08:17:24 1983664 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.978869  data: 0.001333  max mem: 4109
I20241203 08:17:26 1983660 dinov2 helpers.py:102]   [550/634]  eta: 0:05:39    time: 3.976252  data: 0.000809  max mem: 4109
I20241203 08:17:47 1983658 dinov2 helpers.py:102]   [560/634]  eta: 0:04:56    time: 3.978806  data: 0.000575  max mem: 4109
I20241203 08:17:48 1983663 dinov2 helpers.py:102]   [560/634]  eta: 0:04:57    time: 3.993218  data: 0.001216  max mem: 4109
I20241203 08:17:50 1983665 dinov2 helpers.py:102]   [570/634]  eta: 0:04:13    time: 3.977938  data: 0.001725  max mem: 4109
I20241203 08:17:51 1983662 dinov2 helpers.py:102]   [560/634]  eta: 0:04:57    time: 3.976116  data: 0.000998  max mem: 4109
I20241203 08:17:56 1983661 dinov2 helpers.py:102]   [580/634]  eta: 0:03:30    time: 3.977011  data: 0.000840  max mem: 4109
I20241203 08:17:56 1983659 dinov2 helpers.py:102]   [560/634]  eta: 0:04:57    time: 3.980648  data: 0.000811  max mem: 4109
I20241203 08:18:04 1983664 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.977176  data: 0.001109  max mem: 4109
I20241203 08:18:06 1983660 dinov2 helpers.py:102]   [560/634]  eta: 0:04:58    time: 3.978900  data: 0.002189  max mem: 4109
I20241203 08:18:27 1983658 dinov2 helpers.py:102]   [570/634]  eta: 0:04:16    time: 3.978989  data: 0.000709  max mem: 4109
I20241203 08:18:28 1983663 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.992458  data: 0.001315  max mem: 4109
I20241203 08:18:29 1983665 dinov2 helpers.py:102]   [580/634]  eta: 0:03:33    time: 3.976110  data: 0.002140  max mem: 4109
I20241203 08:18:31 1983662 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.976265  data: 0.000929  max mem: 4109
I20241203 08:18:35 1983661 dinov2 helpers.py:102]   [590/634]  eta: 0:02:51    time: 3.976181  data: 0.001116  max mem: 4109
I20241203 08:18:36 1983659 dinov2 helpers.py:102]   [570/634]  eta: 0:04:17    time: 3.978974  data: 0.000782  max mem: 4109
I20241203 08:18:44 1983664 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.978797  data: 0.000710  max mem: 4109
I20241203 08:18:45 1983660 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.978828  data: 0.002337  max mem: 4109
I20241203 08:19:06 1983658 dinov2 helpers.py:102]   [580/634]  eta: 0:03:36    time: 3.976135  data: 0.000672  max mem: 4109
I20241203 08:19:08 1983663 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.991392  data: 0.000920  max mem: 4109
I20241203 08:19:09 1983665 dinov2 helpers.py:102]   [590/634]  eta: 0:02:53    time: 3.974270  data: 0.001620  max mem: 4109
I20241203 08:19:11 1983662 dinov2 helpers.py:102]   [580/634]  eta: 0:03:36    time: 3.974290  data: 0.000647  max mem: 4109
I20241203 08:19:15 1983661 dinov2 helpers.py:102]   [600/634]  eta: 0:02:12    time: 3.976005  data: 0.001680  max mem: 4109
I20241203 08:19:15 1983659 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.974320  data: 0.000956  max mem: 4109
I20241203 08:19:24 1983664 dinov2 helpers.py:102]   [580/634]  eta: 0:03:37    time: 3.977685  data: 0.000856  max mem: 4109
I20241203 08:19:25 1983660 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.975964  data: 0.001761  max mem: 4109
I20241203 08:19:46 1983658 dinov2 helpers.py:102]   [590/634]  eta: 0:02:56    time: 3.973872  data: 0.000605  max mem: 4109
I20241203 08:19:48 1983663 dinov2 helpers.py:102]   [590/634]  eta: 0:02:56    time: 3.989100  data: 0.001374  max mem: 4109
I20241203 08:19:49 1983665 dinov2 helpers.py:102]   [600/634]  eta: 0:02:14    time: 3.972914  data: 0.001277  max mem: 4109
I20241203 08:19:51 1983662 dinov2 helpers.py:102]   [590/634]  eta: 0:02:56    time: 3.972870  data: 0.000735  max mem: 4109
I20241203 08:19:55 1983661 dinov2 helpers.py:102]   [610/634]  eta: 0:01:33    time: 3.972862  data: 0.002158  max mem: 4109
I20241203 08:19:55 1983659 dinov2 helpers.py:102]   [590/634]  eta: 0:02:56    time: 3.973658  data: 0.001225  max mem: 4109
I20241203 08:20:03 1983664 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.972789  data: 0.001118  max mem: 4109
I20241203 08:20:05 1983660 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.973572  data: 0.002916  max mem: 4109
I20241203 08:20:26 1983658 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.973335  data: 0.000878  max mem: 4109
I20241203 08:20:27 1983663 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.981426  data: 0.001374  max mem: 4109
I20241203 08:20:29 1983665 dinov2 helpers.py:102]   [610/634]  eta: 0:01:34    time: 3.972457  data: 0.001946  max mem: 4109
I20241203 08:20:30 1983662 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.970760  data: 0.000883  max mem: 4109
I20241203 08:20:35 1983661 dinov2 helpers.py:102]   [620/634]  eta: 0:00:54    time: 3.972358  data: 0.001702  max mem: 4109
I20241203 08:20:35 1983659 dinov2 helpers.py:102]   [600/634]  eta: 0:02:16    time: 3.973176  data: 0.001665  max mem: 4109
I20241203 08:20:43 1983664 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.972247  data: 0.000953  max mem: 4109
I20241203 08:20:45 1983660 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.971318  data: 0.002147  max mem: 4109
I20241203 08:21:06 1983658 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.972148  data: 0.001077  max mem: 4109
I20241203 08:21:07 1983663 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.976751  data: 0.000771  max mem: 4109
I20241203 08:21:08 1983665 dinov2 helpers.py:102]   [620/634]  eta: 0:00:55    time: 3.972160  data: 0.002087  max mem: 4109
I20241203 08:21:10 1983662 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.971271  data: 0.000843  max mem: 4109
I20241203 08:21:14 1983661 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.973027  data: 0.001321  max mem: 4109
I20241203 08:21:15 1983659 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.972152  data: 0.001261  max mem: 4109
I20241203 08:21:23 1983664 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.972132  data: 0.001004  max mem: 4109
I20241203 08:21:24 1983660 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.970569  data: 0.001116  max mem: 4109
I20241203 08:21:34 1983661 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.351031  data: 0.001123  max mem: 4109
I20241203 08:21:34 1983661 dinov2 helpers.py:130]  Total time: 0:41:25 (3.920232 s / it)
I20241203 08:21:34 1983661 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:21:34 1983661 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:21:35 1983661 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:21:35 1983661 dinov2 loaders.py:151] sampler: distributed
I20241203 08:21:35 1983661 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:21:35 1983661 dinov2 loaders.py:223] # of batches: 78
I20241203 08:21:44 1983658 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.908865  data: 0.000824  max mem: 4109
I20241203 08:21:45 1983663 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.904752  data: 0.001000  max mem: 4109
I20241203 08:21:46 1983665 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.892575  data: 0.001434  max mem: 4109
I20241203 08:21:48 1983662 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.881994  data: 0.000765  max mem: 4109
I20241203 08:21:52 1983659 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.854394  data: 0.000678  max mem: 4109
I20241203 08:21:59 1983664 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.807227  data: 0.001098  max mem: 4109
I20241203 08:22:01 1983660 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.796850  data: 0.000948  max mem: 4109
I20241203 08:22:03 1983665 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.150450  data: 0.001085  max mem: 4109
I20241203 08:22:04 1983665 dinov2 helpers.py:130]  Total time: 0:41:52 (3.962869 s / it)
I20241203 08:22:04 1983665 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:04 1983665 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:05 1983665 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:05 1983665 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:05 1983665 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:05 1983665 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:17 1983658 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.570033  data: 0.000685  max mem: 4109
I20241203 08:22:18 1983663 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.558726  data: 0.001688  max mem: 4109
I20241203 08:22:20 1983662 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.516737  data: 0.000674  max mem: 4109
I20241203 08:22:24 1983659 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.464392  data: 0.000596  max mem: 4109
I20241203 08:22:30 1983664 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.366199  data: 0.001044  max mem: 4109
I20241203 08:22:31 1983660 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.347420  data: 0.000598  max mem: 4109
I20241203 08:22:32 1983658 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.711690  data: 0.000608  max mem: 4109
I20241203 08:22:32 1983658 dinov2 helpers.py:130]  Total time: 0:42:16 (4.000888 s / it)
I20241203 08:22:32 1983658 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:32 1983658 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:33 1983658 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:33 1983658 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:33 1983658 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:33 1983658 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:33 1983663 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.701361  data: 0.001609  max mem: 4109
I20241203 08:22:33 1983663 dinov2 helpers.py:130]  Total time: 0:42:21 (4.009004 s / it)
I20241203 08:22:33 1983663 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:33 1983663 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:34 1983663 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:34 1983663 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:34 1983663 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:34 1983663 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:35 1983662 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.630545  data: 0.000626  max mem: 4109
I20241203 08:22:35 1983662 dinov2 helpers.py:130]  Total time: 0:42:18 (4.003528 s / it)
I20241203 08:22:35 1983662 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:35 1983662 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:35 1983662 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:35 1983662 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:35 1983662 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:35 1983662 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:37 1983659 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.502174  data: 0.000476  max mem: 4109
I20241203 08:22:37 1983659 dinov2 helpers.py:130]  Total time: 0:42:18 (4.004312 s / it)
I20241203 08:22:37 1983659 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:37 1983659 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:37 1983659 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:37 1983659 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:37 1983659 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:37 1983659 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:39 1983664 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.212859  data: 0.000757  max mem: 4109
I20241203 08:22:39 1983664 dinov2 helpers.py:130]  Total time: 0:42:20 (4.006947 s / it)
I20241203 08:22:39 1983664 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:39 1983664 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:39 1983664 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:39 1983664 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:39 1983664 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:39 1983664 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:39 1983660 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 3.156980  data: 0.000519  max mem: 4109
I20241203 08:22:40 1983660 dinov2 helpers.py:130]  Total time: 0:42:20 (4.006557 s / it)
I20241203 08:22:40 1983660 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241203 08:22:40 1983660 dinov2 utils.py:142] Labels shape: (162127,)
I20241203 08:22:40 1983660 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241203 08:22:40 1983660 dinov2 loaders.py:151] sampler: distributed
I20241203 08:22:40 1983660 dinov2 loaders.py:210] using PyTorch data loader
I20241203 08:22:40 1983660 dinov2 loaders.py:223] # of batches: 78
I20241203 08:22:43 1983661 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:44 1983665 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983659 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983658 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983662 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983663 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983664 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:46 1983660 dinov2 knn.py:299] Start the k-NN classification.
I20241203 08:22:49 1983661 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:08:11    time: 6.305489  data: 5.672287  max mem: 8496
I20241203 08:22:56 1983665 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:15:44    time: 12.105674  data: 11.478812  max mem: 8496
E20241203 08:22:57 1983664 submitit submission.py:68] Submitted job triggered an exception
E20241203 08:22:58 1983658 submitit submission.py:68] Submitted job triggered an exception
E20241203 08:22:58 1983659 submitit submission.py:68] Submitted job triggered an exception
E20241203 08:22:59 1983660 submitit submission.py:68] Submitted job triggered an exception
E20241203 08:23:00 1983662 submitit submission.py:68] Submitted job triggered an exception
E20241203 08:23:01 1983663 submitit submission.py:68] Submitted job triggered an exception
I20241203 08:23:08 1983661 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:02:31    time: 2.225355  data: 1.599151  max mem: 8536
I20241203 08:23:10 1983665 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:02:40    time: 2.358572  data: 1.646876  max mem: 8536
I20241203 08:23:17 1983661 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:01:33    time: 1.379610  data: 0.636773  max mem: 8536
I20241203 08:23:20 1983665 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:01:39    time: 1.188739  data: 0.334764  max mem: 8536
I20241203 08:23:27 1983661 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:01:08    time: 0.986085  data: 0.042724  max mem: 8536
I20241203 08:23:31 1983665 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:01:11    time: 1.016978  data: 0.003587  max mem: 8536
I20241203 08:23:38 1983661 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:50    time: 1.037393  data: 0.003230  max mem: 8536
I20241203 08:23:41 1983665 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:00:52    time: 1.040553  data: 0.000945  max mem: 8536
I20241203 08:23:48 1983661 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:35    time: 1.042904  data: 0.001457  max mem: 8536
I20241203 08:23:51 1983665 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:00:36    time: 1.041677  data: 0.000374  max mem: 8536
I20241203 08:23:59 1983661 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:22    time: 1.041962  data: 0.000194  max mem: 8536
I20241203 08:24:02 1983665 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:00:22    time: 1.042982  data: 0.000183  max mem: 8536
I20241203 08:24:09 1983661 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:09    time: 1.043213  data: 0.000203  max mem: 8536
I20241203 08:24:12 1983665 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:09    time: 1.043754  data: 0.000196  max mem: 8536
I20241203 08:24:16 1983661 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:01    time: 1.015405  data: 0.000170  max mem: 8536
I20241203 08:24:16 1983661 dinov2 helpers.py:130] Test: Total time: 0:01:32 (1.188045 s / it)
I20241203 08:24:16 1983661 dinov2 utils.py:79] Averaged stats: 
I20241203 08:24:16 1983661 dinov2 knn.py:367] ('full', 10) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:16 1983661 dinov2 knn.py:367] ('full', 20) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:16 1983661 dinov2 knn.py:367] ('full', 100) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:16 1983661 dinov2 knn.py:367] ('full', 200) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:16 1983661 submitit submission.py:56] Job completed successfully
I20241203 08:24:16 1983661 submitit submission.py:61] Exiting after successful completion
I20241203 08:24:17 1983665 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:01    time: 0.928455  data: 0.000169  max mem: 8536
I20241203 08:24:17 1983665 dinov2 helpers.py:130] Test: Total time: 0:01:33 (1.193210 s / it)
I20241203 08:24:17 1983665 dinov2 utils.py:79] Averaged stats: 
I20241203 08:24:17 1983665 dinov2 knn.py:367] ('full', 10) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:17 1983665 dinov2 knn.py:367] ('full', 20) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:17 1983665 dinov2 knn.py:367] ('full', 100) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:17 1983665 dinov2 knn.py:367] ('full', 200) classifier result: Top1: 0.00 Top5: 0.00
I20241203 08:24:17 1983665 submitit submission.py:56] Job completed successfully
I20241203 08:24:17 1983665 submitit submission.py:61] Exiting after successful completion

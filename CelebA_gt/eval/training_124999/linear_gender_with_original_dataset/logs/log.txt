I20250215 11:20:22 3089994 dinov2 config.py:59] git:
  sha: b6e9010bb34d082e5aa136aba99cb1ecb692a4b4, status: has uncommitted changes, branch: main

I20250215 11:20:22 3089994 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: CelebA_gt/config.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: CelebAOriginalTrain
val_class_mapping_fpath: None
val_dataset_str: CelebAOriginalVal
val_metric_type: mean_accuracy
I20250215 11:20:22 3089994 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250215 11:20:22 3089994 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250215 11:20:22 3089994 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250215 11:20:25 3089994 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250215 11:20:25 3089994 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250215 11:20:25 3089994 dinov2 loaders.py:134] using dataset: "CelebAOriginalTrain"
I20250215 11:20:27 3089994 dinov2 loaders.py:139] # of dataset samples: 162,127
I20250215 11:20:28 3089994 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250215 11:20:28 3089994 dinov2 loaders.py:172] sampler: sharded infinite
I20250215 11:20:28 3089994 dinov2 loaders.py:256] using PyTorch data loader
W20250215 11:20:28 3089994 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250215 11:20:28 3089994 dinov2 loaders.py:271] infinite data loader
I20250215 11:20:28 3089994 dinov2 loaders.py:134] using dataset: "CelebAOriginalVal"
I20250215 11:20:29 3089994 dinov2 loaders.py:139] # of dataset samples: 19,792
I20250215 11:20:29 3089994 dinov2 loaders.py:197] sampler: distributed
I20250215 11:20:29 3089994 dinov2 loaders.py:256] using PyTorch data loader
W20250215 11:20:29 3089994 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250215 11:20:29 3089994 dinov2 loaders.py:269] # of batches: 155
I20250215 11:20:29 3089994 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250215 11:20:29 3089994 dinov2 linear.py:338] Starting training from iteration 0
I20250215 11:20:33 3089994 dinov2 helpers.py:102] Training  [    0/12500]  eta: 13:52:51  loss: 35.0071 (35.0071)  lr: 0.0000 (0.0000)  time: 3.997690  data: 3.445595  max mem: 2706
I20250215 11:20:33 3089994 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20250215 11:20:35 3089994 dinov2 helpers.py:102] Training  [   10/12500]  eta: 1:51:45  loss: 28.3533 (31.6802)  lr: 0.0000 (0.0000)  time: 0.536890  data: 0.313675  max mem: 3115
I20250215 11:20:36 3089994 dinov2 helpers.py:102] Training  [   20/12500]  eta: 1:16:07  loss: 28.3533 (28.9271)  lr: 0.0000 (0.0000)  time: 0.184395  data: 0.000461  max mem: 3115
I20250215 11:20:38 3089994 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:03:31  loss: 23.4210 (26.6114)  lr: 0.0000 (0.0000)  time: 0.178436  data: 0.000485  max mem: 3115
I20250215 11:20:40 3089994 dinov2 helpers.py:102] Training  [   40/12500]  eta: 0:57:04  loss: 23.4210 (25.7554)  lr: 0.0000 (0.0000)  time: 0.179089  data: 0.000459  max mem: 3115
I20250215 11:20:42 3089994 dinov2 helpers.py:102] Training  [   50/12500]  eta: 0:53:09  loss: 23.4210 (25.5186)  lr: 0.0000 (0.0000)  time: 0.179459  data: 0.000447  max mem: 3115
I20250215 11:20:43 3089994 dinov2 helpers.py:102] Training  [   60/12500]  eta: 0:50:31  loss: 23.4210 (24.9989)  lr: 0.0000 (0.0000)  time: 0.179793  data: 0.000502  max mem: 3115
I20250215 11:20:45 3089994 dinov2 helpers.py:102] Training  [   70/12500]  eta: 0:48:37  loss: 22.4402 (24.6791)  lr: 0.0000 (0.0000)  time: 0.180083  data: 0.000497  max mem: 3115
I20250215 11:20:47 3089994 dinov2 helpers.py:102] Training  [   80/12500]  eta: 0:47:12  loss: 22.7967 (24.4699)  lr: 0.0000 (0.0000)  time: 0.180394  data: 0.000504  max mem: 3115
I20250215 11:20:49 3089994 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:46:06  loss: 22.4402 (24.0480)  lr: 0.0000 (0.0000)  time: 0.180890  data: 0.000476  max mem: 3115
I20250215 11:20:51 3089994 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:45:13  loss: 22.4402 (23.2667)  lr: 0.0000 (0.0000)  time: 0.181475  data: 0.000430  max mem: 3115
I20250215 11:20:53 3089994 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:44:29  loss: 22.4402 (23.4675)  lr: 0.0000 (0.0000)  time: 0.181749  data: 0.000441  max mem: 3115
I20250215 11:20:54 3089994 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:43:53  loss: 22.4402 (23.0126)  lr: 0.0000 (0.0000)  time: 0.181826  data: 0.000465  max mem: 3115
I20250215 11:20:56 3089994 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:43:23  loss: 22.3315 (22.9425)  lr: 0.0000 (0.0000)  time: 0.182414  data: 0.000482  max mem: 3115
I20250215 11:20:58 3089994 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:42:57  loss: 22.4402 (22.9368)  lr: 0.0000 (0.0000)  time: 0.183113  data: 0.000458  max mem: 3115
I20250215 11:21:00 3089994 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:42:34  loss: 22.3315 (22.6942)  lr: 0.0000 (0.0000)  time: 0.183272  data: 0.000444  max mem: 3115
I20250215 11:21:02 3089994 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:42:14  loss: 22.3315 (22.4769)  lr: 0.0000 (0.0000)  time: 0.183300  data: 0.000447  max mem: 3115
I20250215 11:21:04 3089994 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:41:56  loss: 22.0318 (22.2321)  lr: 0.0000 (0.0000)  time: 0.183569  data: 0.000471  max mem: 3115
I20250215 11:21:05 3089994 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:41:41  loss: 22.0318 (22.0259)  lr: 0.0000 (0.0000)  time: 0.184013  data: 0.000482  max mem: 3115
I20250215 11:21:07 3089994 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:41:27  loss: 21.8807 (21.8607)  lr: 0.0000 (0.0000)  time: 0.184403  data: 0.000465  max mem: 3115
I20250215 11:21:09 3089994 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:41:14  loss: 20.2507 (21.6656)  lr: 0.0000 (0.0000)  time: 0.184519  data: 0.000444  max mem: 3115
I20250215 11:21:11 3089994 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:41:03  loss: 19.6641 (21.3701)  lr: 0.0000 (0.0000)  time: 0.184843  data: 0.000423  max mem: 3115
I20250215 11:21:13 3089994 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:40:52  loss: 19.2210 (21.2766)  lr: 0.0000 (0.0000)  time: 0.185366  data: 0.000468  max mem: 3115
I20250215 11:21:15 3089994 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:40:43  loss: 19.0553 (21.1400)  lr: 0.0000 (0.0000)  time: 0.185610  data: 0.000474  max mem: 3115
I20250215 11:21:16 3089994 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:40:34  loss: 19.0553 (21.2794)  lr: 0.0000 (0.0000)  time: 0.185856  data: 0.000447  max mem: 3115
I20250215 11:21:18 3089994 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:40:26  loss: 19.0008 (21.1434)  lr: 0.0000 (0.0000)  time: 0.186351  data: 0.000448  max mem: 3115
I20250215 11:21:20 3089994 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:40:19  loss: 18.7221 (21.0302)  lr: 0.0000 (0.0000)  time: 0.186891  data: 0.000463  max mem: 3115
I20250215 11:21:22 3089994 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:40:13  loss: 18.3134 (20.9124)  lr: 0.0000 (0.0000)  time: 0.187173  data: 0.000469  max mem: 3115
I20250215 11:21:24 3089994 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:40:06  loss: 18.3134 (20.8617)  lr: 0.0000 (0.0000)  time: 0.187526  data: 0.000455  max mem: 3115
I20250215 11:21:26 3089994 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:40:01  loss: 18.0851 (20.7678)  lr: 0.0000 (0.0000)  time: 0.187925  data: 0.000438  max mem: 3115
I20250215 11:21:28 3089994 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:39:55  loss: 18.0851 (20.6120)  lr: 0.0000 (0.0000)  time: 0.188271  data: 0.000445  max mem: 3115
I20250215 11:21:30 3089994 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:39:51  loss: 18.0851 (20.5954)  lr: 0.0000 (0.0000)  time: 0.188741  data: 0.000458  max mem: 3115
I20250215 11:21:32 3089994 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:39:46  loss: 18.0851 (20.3997)  lr: 0.0000 (0.0000)  time: 0.189295  data: 0.000402  max mem: 3115
I20250215 11:21:33 3089994 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:39:42  loss: 18.0706 (20.2733)  lr: 0.0000 (0.0000)  time: 0.189730  data: 0.000406  max mem: 3115
I20250215 11:21:35 3089994 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:39:38  loss: 18.0441 (20.1098)  lr: 0.0000 (0.0000)  time: 0.189826  data: 0.000434  max mem: 3115
I20250215 11:21:37 3089994 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:39:34  loss: 17.9970 (20.0374)  lr: 0.0000 (0.0000)  time: 0.190012  data: 0.000358  max mem: 3115
I20250215 11:21:39 3089994 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:39:30  loss: 17.8824 (19.9791)  lr: 0.0000 (0.0000)  time: 0.190213  data: 0.000350  max mem: 3115
I20250215 11:21:41 3089994 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:39:27  loss: 17.7647 (19.8769)  lr: 0.0000 (0.0000)  time: 0.190450  data: 0.000391  max mem: 3115
I20250215 11:21:43 3089994 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:39:24  loss: 17.7444 (19.7575)  lr: 0.0000 (0.0000)  time: 0.190862  data: 0.000430  max mem: 3115
I20250215 11:21:45 3089994 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:39:21  loss: 17.7444 (19.7632)  lr: 0.0000 (0.0000)  time: 0.191313  data: 0.000426  max mem: 3115
I20250215 11:21:47 3089994 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:39:18  loss: 17.7444 (19.7652)  lr: 0.0000 (0.0000)  time: 0.191624  data: 0.000409  max mem: 3115
I20250215 11:21:49 3089994 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:39:15  loss: 17.7444 (19.6207)  lr: 0.0000 (0.0000)  time: 0.191772  data: 0.000438  max mem: 3115
I20250215 11:21:51 3089994 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:39:12  loss: 17.7319 (19.5235)  lr: 0.0000 (0.0000)  time: 0.192022  data: 0.000401  max mem: 3115
I20250215 11:21:53 3089994 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:39:10  loss: 17.6894 (19.4818)  lr: 0.0000 (0.0000)  time: 0.192343  data: 0.000375  max mem: 3115
I20250215 11:21:54 3089994 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:39:07  loss: 17.6894 (19.4789)  lr: 0.0000 (0.0000)  time: 0.192554  data: 0.000409  max mem: 3115
I20250215 11:21:56 3089994 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:39:05  loss: 17.6894 (19.4742)  lr: 0.0000 (0.0000)  time: 0.192935  data: 0.000414  max mem: 3115
I20250215 11:21:58 3089994 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:39:02  loss: 17.6894 (19.4527)  lr: 0.0000 (0.0000)  time: 0.193255  data: 0.000438  max mem: 3115
I20250215 11:22:00 3089994 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:39:00  loss: 17.5016 (19.3402)  lr: 0.0000 (0.0000)  time: 0.193382  data: 0.000424  max mem: 3115
I20250215 11:22:02 3089994 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:38:58  loss: 16.1035 (19.2574)  lr: 0.0000 (0.0000)  time: 0.193514  data: 0.000411  max mem: 3115
I20250215 11:22:04 3089994 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:38:56  loss: 16.1035 (19.1995)  lr: 0.0000 (0.0000)  time: 0.193704  data: 0.000398  max mem: 3115
I20250215 11:22:06 3089994 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:38:54  loss: 16.3624 (19.1974)  lr: 0.0000 (0.0000)  time: 0.194092  data: 0.000381  max mem: 3115
I20250215 11:22:08 3089994 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:38:52  loss: 16.3624 (19.2247)  lr: 0.0000 (0.0000)  time: 0.194373  data: 0.000382  max mem: 3115
I20250215 11:22:10 3089994 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:38:50  loss: 17.5016 (19.2485)  lr: 0.0000 (0.0000)  time: 0.194525  data: 0.000411  max mem: 3115
I20250215 11:22:12 3089994 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:38:48  loss: 17.6732 (19.2193)  lr: 0.0000 (0.0000)  time: 0.194717  data: 0.000425  max mem: 3115
I20250215 11:22:14 3089994 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:38:46  loss: 17.6894 (19.2422)  lr: 0.0000 (0.0000)  time: 0.194878  data: 0.000390  max mem: 3115
I20250215 11:22:16 3089994 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:38:44  loss: 17.6894 (19.1543)  lr: 0.0000 (0.0000)  time: 0.194867  data: 0.000409  max mem: 3115
I20250215 11:22:18 3089994 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:38:43  loss: 17.6894 (19.1671)  lr: 0.0000 (0.0000)  time: 0.194965  data: 0.000418  max mem: 3115
I20250215 11:22:20 3089994 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:38:41  loss: 18.4633 (19.2836)  lr: 0.0000 (0.0000)  time: 0.195055  data: 0.000418  max mem: 3115
I20250215 11:22:22 3089994 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:38:39  loss: 18.4633 (19.2653)  lr: 0.0000 (0.0000)  time: 0.195168  data: 0.000434  max mem: 3115
I20250215 11:22:24 3089994 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:38:37  loss: 18.2058 (19.2299)  lr: 0.0000 (0.0000)  time: 0.195224  data: 0.000393  max mem: 3115
I20250215 11:22:26 3089994 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:38:35  loss: 18.2058 (19.2924)  lr: 0.0000 (0.0000)  time: 0.195264  data: 0.000377  max mem: 3115
I20250215 11:22:28 3089994 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:38:34  loss: 18.2058 (19.2254)  lr: 0.0000 (0.0000)  time: 0.195534  data: 0.000432  max mem: 3115
I20250215 11:22:30 3089994 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:38:32  loss: 18.4633 (19.2388)  lr: 0.0000 (0.0000)  time: 0.195742  data: 0.000407  max mem: 3115
I20250215 11:22:31 3089994 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:38:30  loss: 19.0931 (19.2648)  lr: 0.0000 (0.0000)  time: 0.195834  data: 0.000428  max mem: 3115
I20250215 11:22:33 3089994 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:38:28  loss: 18.4633 (19.2509)  lr: 0.0000 (0.0000)  time: 0.195941  data: 0.000469  max mem: 3115
I20250215 11:22:35 3089994 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:38:27  loss: 18.4633 (19.2854)  lr: 0.0000 (0.0000)  time: 0.196068  data: 0.000423  max mem: 3115
I20250215 11:22:37 3089994 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:38:25  loss: 18.6606 (19.2760)  lr: 0.0000 (0.0000)  time: 0.196231  data: 0.000422  max mem: 3115
I20250215 11:22:39 3089994 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:38:23  loss: 19.0931 (19.2801)  lr: 0.0000 (0.0000)  time: 0.196328  data: 0.000412  max mem: 3115
I20250215 11:22:41 3089994 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:38:22  loss: 19.0931 (19.1778)  lr: 0.0000 (0.0000)  time: 0.196583  data: 0.000401  max mem: 3115
I20250215 11:22:43 3089994 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:38:20  loss: 19.0931 (19.1367)  lr: 0.0000 (0.0000)  time: 0.196817  data: 0.000435  max mem: 3115
I20250215 11:22:45 3089994 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:38:19  loss: 18.6606 (19.0698)  lr: 0.0000 (0.0000)  time: 0.196787  data: 0.000387  max mem: 3115
I20250215 11:22:47 3089994 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:38:17  loss: 18.3591 (19.0223)  lr: 0.0000 (0.0000)  time: 0.196909  data: 0.000385  max mem: 3115
I20250215 11:22:49 3089994 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:38:15  loss: 18.3591 (19.0205)  lr: 0.0000 (0.0000)  time: 0.196983  data: 0.000436  max mem: 3115
I20250215 11:22:51 3089994 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:38:14  loss: 18.3591 (18.9595)  lr: 0.0000 (0.0000)  time: 0.196896  data: 0.000409  max mem: 3115
I20250215 11:22:53 3089994 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:38:12  loss: 18.2058 (18.9393)  lr: 0.0000 (0.0000)  time: 0.196832  data: 0.000398  max mem: 3115
I20250215 11:22:55 3089994 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:38:11  loss: 18.2058 (18.8640)  lr: 0.0000 (0.0000)  time: 0.197041  data: 0.000436  max mem: 3115
I20250215 11:22:57 3089994 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:38:09  loss: 17.7059 (18.8490)  lr: 0.0000 (0.0000)  time: 0.197128  data: 0.000475  max mem: 3115
I20250215 11:22:59 3089994 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:38:07  loss: 17.4451 (18.7924)  lr: 0.0000 (0.0000)  time: 0.196868  data: 0.000455  max mem: 3115
I20250215 11:23:01 3089994 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:38:06  loss: 17.4451 (18.8405)  lr: 0.0000 (0.0000)  time: 0.196794  data: 0.000422  max mem: 3115
I20250215 11:23:03 3089994 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:38:04  loss: 17.7059 (18.8895)  lr: 0.0000 (0.0000)  time: 0.196997  data: 0.000401  max mem: 3115
I20250215 11:23:05 3089994 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:38:02  loss: 17.4451 (18.8565)  lr: 0.0000 (0.0000)  time: 0.197220  data: 0.000405  max mem: 3115
I20250215 11:23:07 3089994 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:38:01  loss: 17.7059 (18.8523)  lr: 0.0000 (0.0000)  time: 0.197295  data: 0.000417  max mem: 3115
I20250215 11:23:09 3089994 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:37:59  loss: 17.4451 (18.8344)  lr: 0.0000 (0.0000)  time: 0.197399  data: 0.000412  max mem: 3115
I20250215 11:23:11 3089994 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:37:57  loss: 17.4451 (18.8530)  lr: 0.0000 (0.0000)  time: 0.197402  data: 0.000439  max mem: 3115
I20250215 11:23:13 3089994 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:37:56  loss: 17.4451 (18.8693)  lr: 0.0000 (0.0000)  time: 0.197301  data: 0.000415  max mem: 3115
I20250215 11:23:15 3089994 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:37:54  loss: 17.3665 (18.8427)  lr: 0.0000 (0.0000)  time: 0.197334  data: 0.000400  max mem: 3115
I20250215 11:23:17 3089994 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:37:52  loss: 16.7900 (18.8191)  lr: 0.0000 (0.0000)  time: 0.197578  data: 0.000434  max mem: 3115
I20250215 11:23:19 3089994 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:37:51  loss: 16.5791 (18.7531)  lr: 0.0000 (0.0000)  time: 0.197656  data: 0.000430  max mem: 3115
I20250215 11:23:21 3089994 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:37:49  loss: 16.5791 (18.6811)  lr: 0.0000 (0.0000)  time: 0.197502  data: 0.000390  max mem: 3115
I20250215 11:23:23 3089994 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:37:47  loss: 16.7900 (18.7006)  lr: 0.0000 (0.0000)  time: 0.197550  data: 0.000384  max mem: 3115
I20250215 11:23:25 3089994 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:37:46  loss: 17.3665 (18.7135)  lr: 0.0000 (0.0000)  time: 0.197621  data: 0.000386  max mem: 3115
I20250215 11:23:27 3089994 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:37:44  loss: 17.4451 (18.7050)  lr: 0.0000 (0.0000)  time: 0.197434  data: 0.000380  max mem: 3115
I20250215 11:23:29 3089994 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:37:42  loss: 17.3665 (18.6299)  lr: 0.0000 (0.0000)  time: 0.197492  data: 0.000426  max mem: 3115
I20250215 11:23:31 3089994 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:37:41  loss: 17.3665 (18.5940)  lr: 0.0000 (0.0000)  time: 0.197638  data: 0.000477  max mem: 3115
I20250215 11:23:33 3089994 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:37:39  loss: 17.1657 (18.5789)  lr: 0.0000 (0.0000)  time: 0.197647  data: 0.000435  max mem: 3115
I20250215 11:23:35 3089994 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:37:37  loss: 17.1657 (18.5422)  lr: 0.0000 (0.0000)  time: 0.197611  data: 0.000411  max mem: 3115
I20250215 11:23:37 3089994 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:37:36  loss: 16.7900 (18.5134)  lr: 0.0000 (0.0000)  time: 0.197533  data: 0.000423  max mem: 3115
I20250215 11:23:39 3089994 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:37:34  loss: 17.1657 (18.5643)  lr: 0.0000 (0.0000)  time: 0.197508  data: 0.000422  max mem: 3115
I20250215 11:23:41 3089994 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:37:32  loss: 16.7900 (18.5196)  lr: 0.0000 (0.0000)  time: 0.197513  data: 0.000425  max mem: 3115
I20250215 11:23:42 3089994 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:37:30  loss: 16.5791 (18.4958)  lr: 0.0000 (0.0000)  time: 0.197393  data: 0.000383  max mem: 3115
I20250215 11:23:44 3089994 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:37:29  loss: 16.7900 (18.4888)  lr: 0.0000 (0.0000)  time: 0.197289  data: 0.000396  max mem: 3115
I20250215 11:23:46 3089994 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:37:27  loss: 16.7900 (18.4787)  lr: 0.0000 (0.0000)  time: 0.197502  data: 0.000422  max mem: 3115
I20250215 11:23:48 3089994 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:37:25  loss: 16.5791 (18.4554)  lr: 0.0000 (0.0000)  time: 0.197718  data: 0.000411  max mem: 3115
I20250215 11:23:50 3089994 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:37:24  loss: 16.1401 (18.3996)  lr: 0.0000 (0.0000)  time: 0.197997  data: 0.000373  max mem: 3115
I20250215 11:23:52 3089994 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:37:22  loss: 16.0797 (18.3741)  lr: 0.0000 (0.0000)  time: 0.198039  data: 0.000337  max mem: 3115
I20250215 11:23:54 3089994 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:37:20  loss: 15.7510 (18.3391)  lr: 0.0000 (0.0000)  time: 0.197895  data: 0.000385  max mem: 3115
I20250215 11:23:56 3089994 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:37:18  loss: 15.7192 (18.3128)  lr: 0.0000 (0.0000)  time: 0.197804  data: 0.000435  max mem: 3115
I20250215 11:23:58 3089994 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:37:17  loss: 15.7192 (18.2755)  lr: 0.0000 (0.0000)  time: 0.197813  data: 0.000403  max mem: 3115
I20250215 11:24:00 3089994 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:37:15  loss: 15.7510 (18.2947)  lr: 0.0000 (0.0000)  time: 0.197997  data: 0.000407  max mem: 3115
I20250215 11:24:02 3089994 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:37:13  loss: 15.7510 (18.2818)  lr: 0.0000 (0.0000)  time: 0.198035  data: 0.000423  max mem: 3115
I20250215 11:24:04 3089994 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:37:12  loss: 15.7192 (18.2486)  lr: 0.0000 (0.0000)  time: 0.198037  data: 0.000408  max mem: 3115
I20250215 11:24:06 3089994 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:37:10  loss: 15.7192 (18.2569)  lr: 0.0000 (0.0000)  time: 0.197950  data: 0.000409  max mem: 3115
I20250215 11:24:08 3089994 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:37:08  loss: 15.7192 (18.2268)  lr: 0.0000 (0.0000)  time: 0.197921  data: 0.000404  max mem: 3115
I20250215 11:24:10 3089994 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:37:06  loss: 15.7510 (18.2233)  lr: 0.0000 (0.0000)  time: 0.198081  data: 0.000432  max mem: 3115
I20250215 11:24:12 3089994 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:37:05  loss: 15.7510 (18.2492)  lr: 0.0000 (0.0000)  time: 0.198157  data: 0.000414  max mem: 3115
I20250215 11:24:14 3089994 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:37:03  loss: 15.7510 (18.2209)  lr: 0.0000 (0.0000)  time: 0.198124  data: 0.000384  max mem: 3115
I20250215 11:24:16 3089994 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:37:01  loss: 15.7192 (18.1935)  lr: 0.0000 (0.0000)  time: 0.197901  data: 0.000375  max mem: 3115
I20250215 11:24:18 3089994 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:36:59  loss: 15.7192 (18.1924)  lr: 0.0000 (0.0000)  time: 0.197988  data: 0.000380  max mem: 3115
I20250215 11:24:20 3089994 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:36:58  loss: 15.7192 (18.1408)  lr: 0.0000 (0.0000)  time: 0.198260  data: 0.000404  max mem: 3115
I20250215 11:24:22 3089994 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:36:56  loss: 15.7192 (18.1479)  lr: 0.0000 (0.0000)  time: 0.198190  data: 0.000372  max mem: 3115
I20250215 11:24:24 3089994 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:36:54  loss: 15.5240 (18.1258)  lr: 0.0000 (0.0000)  time: 0.198091  data: 0.000366  max mem: 3115
I20250215 11:24:26 3089994 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:36:52  loss: 15.5240 (18.1248)  lr: 0.0000 (0.0000)  time: 0.197970  data: 0.000387  max mem: 3115
I20250215 11:24:28 3089994 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:36:51  loss: 15.5240 (18.1057)  lr: 0.0000 (0.0000)  time: 0.197923  data: 0.000389  max mem: 3115
I20250215 11:24:30 3089994 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:36:49  loss: 15.7192 (18.1216)  lr: 0.0000 (0.0000)  time: 0.198093  data: 0.000367  max mem: 3115
I20250215 11:24:32 3089994 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:36:47  loss: 15.7819 (18.1306)  lr: 0.0000 (0.0000)  time: 0.198375  data: 0.000415  max mem: 3115
I20250215 11:24:34 3089994 dinov2 linear.py:272] running validation !
I20250215 11:24:37 3089994 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:07:05    time: 2.747038  data: 2.418739  max mem: 3190
I20250215 11:24:39 3089994 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:01:04    time: 0.444283  data: 0.220157  max mem: 3586
I20250215 11:24:41 3089994 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:44    time: 0.206951  data: 0.000268  max mem: 3586
I20250215 11:24:43 3089994 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:35    time: 0.199953  data: 0.000212  max mem: 3586
I20250215 11:24:45 3089994 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:30    time: 0.199918  data: 0.000204  max mem: 3586
I20250215 11:24:47 3089994 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:26    time: 0.199905  data: 0.000257  max mem: 3586
I20250215 11:24:49 3089994 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:23    time: 0.199927  data: 0.000258  max mem: 3586
I20250215 11:24:51 3089994 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:20    time: 0.199884  data: 0.000227  max mem: 3586
I20250215 11:24:53 3089994 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.199890  data: 0.000258  max mem: 3586
I20250215 11:24:55 3089994 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.199788  data: 0.000240  max mem: 3586
I20250215 11:24:57 3089994 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.199941  data: 0.000206  max mem: 3586
I20250215 11:24:59 3089994 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.200041  data: 0.000200  max mem: 3586
I20250215 11:25:01 3089994 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199789  data: 0.000208  max mem: 3586
I20250215 11:25:03 3089994 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199931  data: 0.000239  max mem: 3586
I20250215 11:25:05 3089994 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199826  data: 0.000218  max mem: 3586
I20250215 11:25:07 3089994 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199632  data: 0.000142  max mem: 3586
I20250215 11:25:07 3089994 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.200355  data: 0.000124  max mem: 3586
I20250215 11:25:08 3089994 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218373 s / it)
I20250215 11:25:08 3089994 dinov2 utils.py:79] Averaged stats: 
I20250215 11:25:08 3089994 dinov2 linear.py:287] 
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8995, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9114, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9155, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9227, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9271, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9306, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9324, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9336, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9327, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9300, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.9202, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.9124, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8960, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9109, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9169, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9239, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9293, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9328, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9342, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9353, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9341, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9333, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.9218, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.9020, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.9154, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9224, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9268, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9302, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9339, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9350, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9348, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9313, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9291, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9157, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8991, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8999, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.9122, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9212, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9282, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9322, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9348, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9352, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9352, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9331, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9306, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9132, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8982, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8998, device='cuda:0')}
I20250215 11:25:08 3089994 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.9352768659591675}
I20250215 11:25:08 3089994 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250215 11:25:08 3089994 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset/running_checkpoint_linear_eval.pth
I20250215 11:25:08 3089994 dinov2 helpers.py:102] Training  [ 1250/12500]  eta: 0:41:55  loss: 16.8784 (18.1243)  lr: 0.0000 (0.0000)  time: 1.922168  data: 0.027107  max mem: 3586
I20250215 11:25:10 3089994 dinov2 helpers.py:102] Training  [ 1260/12500]  eta: 0:41:51  loss: 17.3458 (18.1190)  lr: 0.0000 (0.0000)  time: 1.920794  data: 0.027038  max mem: 3586
I20250215 11:25:12 3089994 dinov2 helpers.py:102] Training  [ 1270/12500]  eta: 0:41:46  loss: 17.3458 (18.0987)  lr: 0.0000 (0.0000)  time: 0.196503  data: 0.000381  max mem: 3586
I20250215 11:25:14 3089994 dinov2 helpers.py:102] Training  [ 1280/12500]  eta: 0:41:42  loss: 16.8784 (18.0765)  lr: 0.0000 (0.0000)  time: 0.197338  data: 0.000422  max mem: 3586
I20250215 11:25:16 3089994 dinov2 helpers.py:102] Training  [ 1290/12500]  eta: 0:41:37  loss: 17.3458 (18.0877)  lr: 0.0000 (0.0000)  time: 0.197441  data: 0.000407  max mem: 3586
I20250215 11:25:18 3089994 dinov2 helpers.py:102] Training  [ 1300/12500]  eta: 0:41:33  loss: 17.4477 (18.0897)  lr: 0.0000 (0.0000)  time: 0.197469  data: 0.000383  max mem: 3586
I20250215 11:25:20 3089994 dinov2 helpers.py:102] Training  [ 1310/12500]  eta: 0:41:28  loss: 17.3458 (18.0776)  lr: 0.0000 (0.0000)  time: 0.197597  data: 0.000352  max mem: 3586
I20250215 11:25:22 3089994 dinov2 helpers.py:102] Training  [ 1320/12500]  eta: 0:41:24  loss: 17.4477 (18.0982)  lr: 0.0000 (0.0000)  time: 0.197536  data: 0.000318  max mem: 3586
I20250215 11:25:24 3089994 dinov2 helpers.py:102] Training  [ 1330/12500]  eta: 0:41:20  loss: 17.3595 (18.0927)  lr: 0.0000 (0.0000)  time: 0.197306  data: 0.000369  max mem: 3586
I20250215 11:25:26 3089994 dinov2 helpers.py:102] Training  [ 1340/12500]  eta: 0:41:15  loss: 17.3458 (18.0519)  lr: 0.0000 (0.0000)  time: 0.197319  data: 0.000425  max mem: 3586
I20250215 11:25:28 3089994 dinov2 helpers.py:102] Training  [ 1350/12500]  eta: 0:41:11  loss: 17.3595 (18.0731)  lr: 0.0000 (0.0000)  time: 0.197381  data: 0.000434  max mem: 3586
I20250215 11:25:30 3089994 dinov2 helpers.py:102] Training  [ 1360/12500]  eta: 0:41:07  loss: 17.3595 (18.0426)  lr: 0.0000 (0.0000)  time: 0.197442  data: 0.000435  max mem: 3586
I20250215 11:25:32 3089994 dinov2 helpers.py:102] Training  [ 1370/12500]  eta: 0:41:03  loss: 17.3595 (18.0597)  lr: 0.0000 (0.0000)  time: 0.197592  data: 0.000428  max mem: 3586
I20250215 11:25:34 3089994 dinov2 helpers.py:102] Training  [ 1380/12500]  eta: 0:40:59  loss: 17.3595 (18.0381)  lr: 0.0000 (0.0000)  time: 0.197564  data: 0.000473  max mem: 3586
I20250215 11:25:36 3089994 dinov2 helpers.py:102] Training  [ 1390/12500]  eta: 0:40:55  loss: 17.3595 (18.0517)  lr: 0.0000 (0.0000)  time: 0.197701  data: 0.000476  max mem: 3586
I20250215 11:25:38 3089994 dinov2 helpers.py:102] Training  [ 1400/12500]  eta: 0:40:51  loss: 17.3595 (18.0467)  lr: 0.0000 (0.0000)  time: 0.198095  data: 0.000417  max mem: 3586
I20250215 11:25:40 3089994 dinov2 helpers.py:102] Training  [ 1410/12500]  eta: 0:40:47  loss: 17.3519 (18.0365)  lr: 0.0000 (0.0000)  time: 0.198179  data: 0.000445  max mem: 3586
I20250215 11:25:42 3089994 dinov2 helpers.py:102] Training  [ 1420/12500]  eta: 0:40:43  loss: 17.3595 (18.0508)  lr: 0.0000 (0.0000)  time: 0.198040  data: 0.000455  max mem: 3586
I20250215 11:25:44 3089994 dinov2 helpers.py:102] Training  [ 1430/12500]  eta: 0:40:39  loss: 17.3595 (18.0526)  lr: 0.0000 (0.0000)  time: 0.197964  data: 0.000431  max mem: 3586
I20250215 11:25:46 3089994 dinov2 helpers.py:102] Training  [ 1440/12500]  eta: 0:40:35  loss: 17.3519 (18.0392)  lr: 0.0000 (0.0000)  time: 0.197851  data: 0.000438  max mem: 3586
I20250215 11:25:48 3089994 dinov2 helpers.py:102] Training  [ 1450/12500]  eta: 0:40:31  loss: 17.3519 (18.0229)  lr: 0.0000 (0.0000)  time: 0.197710  data: 0.000444  max mem: 3586
I20250215 11:25:50 3089994 dinov2 helpers.py:102] Training  [ 1460/12500]  eta: 0:40:27  loss: 17.3519 (18.0190)  lr: 0.0000 (0.0000)  time: 0.197639  data: 0.000416  max mem: 3586
I20250215 11:25:52 3089994 dinov2 helpers.py:102] Training  [ 1470/12500]  eta: 0:40:23  loss: 17.3519 (17.9991)  lr: 0.0000 (0.0000)  time: 0.197724  data: 0.000387  max mem: 3586
I20250215 11:25:54 3089994 dinov2 helpers.py:102] Training  [ 1480/12500]  eta: 0:40:19  loss: 17.3519 (17.9921)  lr: 0.0000 (0.0000)  time: 0.197721  data: 0.000423  max mem: 3586
I20250215 11:25:56 3089994 dinov2 helpers.py:102] Training  [ 1490/12500]  eta: 0:40:15  loss: 16.9626 (17.9470)  lr: 0.0000 (0.0000)  time: 0.197598  data: 0.000425  max mem: 3586
I20250215 11:25:58 3089994 dinov2 helpers.py:102] Training  [ 1500/12500]  eta: 0:40:12  loss: 16.9626 (17.9751)  lr: 0.0000 (0.0000)  time: 0.197694  data: 0.000393  max mem: 3586
I20250215 11:26:00 3089994 dinov2 helpers.py:102] Training  [ 1510/12500]  eta: 0:40:08  loss: 16.9626 (17.9402)  lr: 0.0000 (0.0000)  time: 0.197849  data: 0.000429  max mem: 3586
I20250215 11:26:02 3089994 dinov2 helpers.py:102] Training  [ 1520/12500]  eta: 0:40:04  loss: 16.5937 (17.9245)  lr: 0.0000 (0.0000)  time: 0.197940  data: 0.000445  max mem: 3586
I20250215 11:26:04 3089994 dinov2 helpers.py:102] Training  [ 1530/12500]  eta: 0:40:01  loss: 16.1054 (17.8989)  lr: 0.0000 (0.0000)  time: 0.198074  data: 0.000413  max mem: 3586
I20250215 11:26:06 3089994 dinov2 helpers.py:102] Training  [ 1540/12500]  eta: 0:39:57  loss: 16.1054 (17.8833)  lr: 0.0000 (0.0000)  time: 0.198362  data: 0.000442  max mem: 3586
I20250215 11:26:08 3089994 dinov2 helpers.py:102] Training  [ 1550/12500]  eta: 0:39:53  loss: 15.6597 (17.8514)  lr: 0.0000 (0.0000)  time: 0.198301  data: 0.000443  max mem: 3586
I20250215 11:26:10 3089994 dinov2 helpers.py:102] Training  [ 1560/12500]  eta: 0:39:50  loss: 15.6597 (17.8256)  lr: 0.0000 (0.0000)  time: 0.198162  data: 0.000428  max mem: 3586
I20250215 11:26:12 3089994 dinov2 helpers.py:102] Training  [ 1570/12500]  eta: 0:39:46  loss: 15.6597 (17.8704)  lr: 0.0000 (0.0000)  time: 0.198298  data: 0.000388  max mem: 3586
I20250215 11:26:14 3089994 dinov2 helpers.py:102] Training  [ 1580/12500]  eta: 0:39:42  loss: 16.1054 (17.8824)  lr: 0.0000 (0.0000)  time: 0.198258  data: 0.000365  max mem: 3586
I20250215 11:26:16 3089994 dinov2 helpers.py:102] Training  [ 1590/12500]  eta: 0:39:39  loss: 15.6597 (17.8576)  lr: 0.0000 (0.0000)  time: 0.198220  data: 0.000427  max mem: 3586
I20250215 11:26:18 3089994 dinov2 helpers.py:102] Training  [ 1600/12500]  eta: 0:39:35  loss: 15.5457 (17.8294)  lr: 0.0000 (0.0000)  time: 0.198278  data: 0.000469  max mem: 3586
I20250215 11:26:20 3089994 dinov2 helpers.py:102] Training  [ 1610/12500]  eta: 0:39:32  loss: 15.4707 (17.7957)  lr: 0.0000 (0.0000)  time: 0.198118  data: 0.000430  max mem: 3586
I20250215 11:26:22 3089994 dinov2 helpers.py:102] Training  [ 1620/12500]  eta: 0:39:28  loss: 15.0750 (17.7736)  lr: 0.0000 (0.0000)  time: 0.198041  data: 0.000386  max mem: 3586
I20250215 11:26:24 3089994 dinov2 helpers.py:102] Training  [ 1630/12500]  eta: 0:39:25  loss: 14.1908 (17.7222)  lr: 0.0000 (0.0000)  time: 0.198184  data: 0.000391  max mem: 3586
I20250215 11:26:26 3089994 dinov2 helpers.py:102] Training  [ 1640/12500]  eta: 0:39:21  loss: 14.1908 (17.7054)  lr: 0.0000 (0.0000)  time: 0.198528  data: 0.000391  max mem: 3586
I20250215 11:26:28 3089994 dinov2 helpers.py:102] Training  [ 1650/12500]  eta: 0:39:18  loss: 13.9853 (17.6776)  lr: 0.0000 (0.0000)  time: 0.198620  data: 0.000425  max mem: 3586
I20250215 11:26:30 3089994 dinov2 helpers.py:102] Training  [ 1660/12500]  eta: 0:39:15  loss: 13.9853 (17.6763)  lr: 0.0000 (0.0000)  time: 0.198434  data: 0.000434  max mem: 3586
I20250215 11:26:32 3089994 dinov2 helpers.py:102] Training  [ 1670/12500]  eta: 0:39:11  loss: 13.9853 (17.6599)  lr: 0.0000 (0.0000)  time: 0.198628  data: 0.000397  max mem: 3586
I20250215 11:26:34 3089994 dinov2 helpers.py:102] Training  [ 1680/12500]  eta: 0:39:08  loss: 13.9853 (17.6594)  lr: 0.0000 (0.0000)  time: 0.198643  data: 0.000410  max mem: 3586
I20250215 11:26:36 3089994 dinov2 helpers.py:102] Training  [ 1690/12500]  eta: 0:39:05  loss: 14.1908 (17.6513)  lr: 0.0000 (0.0000)  time: 0.198532  data: 0.000402  max mem: 3586
I20250215 11:26:38 3089994 dinov2 helpers.py:102] Training  [ 1700/12500]  eta: 0:39:01  loss: 13.9853 (17.6257)  lr: 0.0000 (0.0000)  time: 0.198646  data: 0.000378  max mem: 3586
I20250215 11:26:40 3089994 dinov2 helpers.py:102] Training  [ 1710/12500]  eta: 0:38:58  loss: 14.1908 (17.6075)  lr: 0.0000 (0.0000)  time: 0.198559  data: 0.000398  max mem: 3586
I20250215 11:26:42 3089994 dinov2 helpers.py:102] Training  [ 1720/12500]  eta: 0:38:55  loss: 13.9853 (17.5820)  lr: 0.0000 (0.0000)  time: 0.198388  data: 0.000389  max mem: 3586
I20250215 11:26:43 3089994 dinov2 helpers.py:102] Training  [ 1730/12500]  eta: 0:38:51  loss: 13.9114 (17.5599)  lr: 0.0000 (0.0000)  time: 0.198669  data: 0.000405  max mem: 3586
I20250215 11:26:45 3089994 dinov2 helpers.py:102] Training  [ 1740/12500]  eta: 0:38:48  loss: 13.8119 (17.5321)  lr: 0.0000 (0.0000)  time: 0.198769  data: 0.000411  max mem: 3586
I20250215 11:26:47 3089994 dinov2 helpers.py:102] Training  [ 1750/12500]  eta: 0:38:45  loss: 13.9114 (17.5213)  lr: 0.0000 (0.0000)  time: 0.198768  data: 0.000400  max mem: 3586
I20250215 11:26:49 3089994 dinov2 helpers.py:102] Training  [ 1760/12500]  eta: 0:38:42  loss: 14.1908 (17.5358)  lr: 0.0000 (0.0000)  time: 0.198830  data: 0.000435  max mem: 3586
I20250215 11:26:51 3089994 dinov2 helpers.py:102] Training  [ 1770/12500]  eta: 0:38:38  loss: 14.1908 (17.5249)  lr: 0.0000 (0.0000)  time: 0.198822  data: 0.000471  max mem: 3586
I20250215 11:26:53 3089994 dinov2 helpers.py:102] Training  [ 1780/12500]  eta: 0:38:35  loss: 13.9114 (17.4942)  lr: 0.0000 (0.0000)  time: 0.198952  data: 0.000483  max mem: 3586
I20250215 11:26:55 3089994 dinov2 helpers.py:102] Training  [ 1790/12500]  eta: 0:38:32  loss: 14.1908 (17.4991)  lr: 0.0000 (0.0000)  time: 0.198955  data: 0.000446  max mem: 3586
I20250215 11:26:57 3089994 dinov2 helpers.py:102] Training  [ 1800/12500]  eta: 0:38:29  loss: 14.5018 (17.4910)  lr: 0.0000 (0.0000)  time: 0.198794  data: 0.000372  max mem: 3586
I20250215 11:26:59 3089994 dinov2 helpers.py:102] Training  [ 1810/12500]  eta: 0:38:26  loss: 14.9057 (17.4909)  lr: 0.0000 (0.0000)  time: 0.198791  data: 0.000400  max mem: 3586
I20250215 11:27:01 3089994 dinov2 helpers.py:102] Training  [ 1820/12500]  eta: 0:38:22  loss: 14.9057 (17.4495)  lr: 0.0000 (0.0000)  time: 0.198750  data: 0.000459  max mem: 3586
I20250215 11:27:03 3089994 dinov2 helpers.py:102] Training  [ 1830/12500]  eta: 0:38:19  loss: 14.9576 (17.4426)  lr: 0.0000 (0.0000)  time: 0.198579  data: 0.000457  max mem: 3586
I20250215 11:27:05 3089994 dinov2 helpers.py:102] Training  [ 1840/12500]  eta: 0:38:16  loss: 15.5914 (17.4564)  lr: 0.0000 (0.0000)  time: 0.198757  data: 0.000464  max mem: 3586
I20250215 11:27:07 3089994 dinov2 helpers.py:102] Training  [ 1850/12500]  eta: 0:38:13  loss: 15.5914 (17.4460)  lr: 0.0000 (0.0000)  time: 0.198727  data: 0.000444  max mem: 3586
I20250215 11:27:09 3089994 dinov2 helpers.py:102] Training  [ 1860/12500]  eta: 0:38:10  loss: 15.5265 (17.4264)  lr: 0.0000 (0.0000)  time: 0.198749  data: 0.000396  max mem: 3586
I20250215 11:27:11 3089994 dinov2 helpers.py:102] Training  [ 1870/12500]  eta: 0:38:07  loss: 15.5265 (17.3943)  lr: 0.0000 (0.0000)  time: 0.198843  data: 0.000375  max mem: 3586
I20250215 11:27:13 3089994 dinov2 helpers.py:102] Training  [ 1880/12500]  eta: 0:38:04  loss: 15.5265 (17.3900)  lr: 0.0000 (0.0000)  time: 0.198802  data: 0.000393  max mem: 3586
I20250215 11:27:15 3089994 dinov2 helpers.py:102] Training  [ 1890/12500]  eta: 0:38:01  loss: 14.8787 (17.3768)  lr: 0.0000 (0.0000)  time: 0.198730  data: 0.000375  max mem: 3586
I20250215 11:27:17 3089994 dinov2 helpers.py:102] Training  [ 1900/12500]  eta: 0:37:58  loss: 14.8787 (17.3363)  lr: 0.0000 (0.0000)  time: 0.198729  data: 0.000368  max mem: 3586
I20250215 11:27:19 3089994 dinov2 helpers.py:102] Training  [ 1910/12500]  eta: 0:37:55  loss: 15.5265 (17.3707)  lr: 0.0000 (0.0000)  time: 0.198789  data: 0.000405  max mem: 3586
I20250215 11:27:21 3089994 dinov2 helpers.py:102] Training  [ 1920/12500]  eta: 0:37:52  loss: 15.5914 (17.3749)  lr: 0.0000 (0.0000)  time: 0.198758  data: 0.000403  max mem: 3586
I20250215 11:27:23 3089994 dinov2 helpers.py:102] Training  [ 1930/12500]  eta: 0:37:49  loss: 15.5914 (17.3513)  lr: 0.0000 (0.0000)  time: 0.198780  data: 0.000354  max mem: 3586
I20250215 11:27:25 3089994 dinov2 helpers.py:102] Training  [ 1940/12500]  eta: 0:37:46  loss: 15.6372 (17.3773)  lr: 0.0000 (0.0000)  time: 0.198707  data: 0.000371  max mem: 3586
I20250215 11:27:27 3089994 dinov2 helpers.py:102] Training  [ 1950/12500]  eta: 0:37:43  loss: 16.0188 (17.3938)  lr: 0.0000 (0.0000)  time: 0.198829  data: 0.000395  max mem: 3586
I20250215 11:27:29 3089994 dinov2 helpers.py:102] Training  [ 1960/12500]  eta: 0:37:40  loss: 15.9348 (17.3864)  lr: 0.0000 (0.0000)  time: 0.198671  data: 0.000401  max mem: 3586
I20250215 11:27:31 3089994 dinov2 helpers.py:102] Training  [ 1970/12500]  eta: 0:37:37  loss: 16.0188 (17.3879)  lr: 0.0000 (0.0000)  time: 0.198562  data: 0.000446  max mem: 3586
I20250215 11:27:33 3089994 dinov2 helpers.py:102] Training  [ 1980/12500]  eta: 0:37:34  loss: 16.0188 (17.3785)  lr: 0.0000 (0.0000)  time: 0.198610  data: 0.000456  max mem: 3586
I20250215 11:27:35 3089994 dinov2 helpers.py:102] Training  [ 1990/12500]  eta: 0:37:31  loss: 15.9348 (17.3614)  lr: 0.0000 (0.0000)  time: 0.198406  data: 0.000443  max mem: 3586
I20250215 11:27:37 3089994 dinov2 helpers.py:102] Training  [ 2000/12500]  eta: 0:37:28  loss: 15.5265 (17.3237)  lr: 0.0000 (0.0000)  time: 0.198427  data: 0.000421  max mem: 3586
I20250215 11:27:39 3089994 dinov2 helpers.py:102] Training  [ 2010/12500]  eta: 0:37:25  loss: 15.5265 (17.3232)  lr: 0.0000 (0.0000)  time: 0.198564  data: 0.000407  max mem: 3586
I20250215 11:27:41 3089994 dinov2 helpers.py:102] Training  [ 2020/12500]  eta: 0:37:22  loss: 15.5265 (17.3082)  lr: 0.0000 (0.0000)  time: 0.198556  data: 0.000391  max mem: 3586
I20250215 11:27:43 3089994 dinov2 helpers.py:102] Training  [ 2030/12500]  eta: 0:37:19  loss: 15.5265 (17.3118)  lr: 0.0000 (0.0000)  time: 0.198593  data: 0.000395  max mem: 3586
I20250215 11:27:45 3089994 dinov2 helpers.py:102] Training  [ 2040/12500]  eta: 0:37:16  loss: 15.5182 (17.3019)  lr: 0.0000 (0.0000)  time: 0.198738  data: 0.000393  max mem: 3586
I20250215 11:27:47 3089994 dinov2 helpers.py:102] Training  [ 2050/12500]  eta: 0:37:13  loss: 15.2809 (17.2849)  lr: 0.0000 (0.0000)  time: 0.198619  data: 0.000372  max mem: 3586
I20250215 11:27:49 3089994 dinov2 helpers.py:102] Training  [ 2060/12500]  eta: 0:37:10  loss: 15.2809 (17.2557)  lr: 0.0000 (0.0000)  time: 0.198549  data: 0.000424  max mem: 3586
I20250215 11:27:51 3089994 dinov2 helpers.py:102] Training  [ 2070/12500]  eta: 0:37:07  loss: 15.5182 (17.2558)  lr: 0.0000 (0.0000)  time: 0.198530  data: 0.000428  max mem: 3586
I20250215 11:27:53 3089994 dinov2 helpers.py:102] Training  [ 2080/12500]  eta: 0:37:04  loss: 15.5182 (17.2667)  lr: 0.0000 (0.0000)  time: 0.198478  data: 0.000431  max mem: 3586
I20250215 11:27:55 3089994 dinov2 helpers.py:102] Training  [ 2090/12500]  eta: 0:37:01  loss: 15.9348 (17.2651)  lr: 0.0000 (0.0000)  time: 0.198736  data: 0.000454  max mem: 3586
I20250215 11:27:57 3089994 dinov2 helpers.py:102] Training  [ 2100/12500]  eta: 0:36:59  loss: 15.9348 (17.2454)  lr: 0.0000 (0.0000)  time: 0.198676  data: 0.000437  max mem: 3586
I20250215 11:27:59 3089994 dinov2 helpers.py:102] Training  [ 2110/12500]  eta: 0:36:56  loss: 15.9348 (17.2529)  lr: 0.0000 (0.0000)  time: 0.198593  data: 0.000467  max mem: 3586
I20250215 11:28:01 3089994 dinov2 helpers.py:102] Training  [ 2120/12500]  eta: 0:36:53  loss: 15.9348 (17.2574)  lr: 0.0000 (0.0000)  time: 0.198793  data: 0.000451  max mem: 3586
I20250215 11:28:03 3089994 dinov2 helpers.py:102] Training  [ 2130/12500]  eta: 0:36:50  loss: 15.9348 (17.2477)  lr: 0.0000 (0.0000)  time: 0.198743  data: 0.000430  max mem: 3586
I20250215 11:28:05 3089994 dinov2 helpers.py:102] Training  [ 2140/12500]  eta: 0:36:47  loss: 15.8538 (17.2412)  lr: 0.0000 (0.0000)  time: 0.198851  data: 0.000422  max mem: 3586
I20250215 11:28:07 3089994 dinov2 helpers.py:102] Training  [ 2150/12500]  eta: 0:36:44  loss: 15.5182 (17.2316)  lr: 0.0000 (0.0000)  time: 0.198815  data: 0.000414  max mem: 3586
I20250215 11:28:09 3089994 dinov2 helpers.py:102] Training  [ 2160/12500]  eta: 0:36:42  loss: 15.5182 (17.2508)  lr: 0.0000 (0.0000)  time: 0.198609  data: 0.000397  max mem: 3586
I20250215 11:28:11 3089994 dinov2 helpers.py:102] Training  [ 2170/12500]  eta: 0:36:39  loss: 15.5182 (17.2573)  lr: 0.0000 (0.0000)  time: 0.198571  data: 0.000425  max mem: 3586
I20250215 11:28:13 3089994 dinov2 helpers.py:102] Training  [ 2180/12500]  eta: 0:36:36  loss: 15.2809 (17.2166)  lr: 0.0000 (0.0000)  time: 0.198358  data: 0.000467  max mem: 3586
I20250215 11:28:15 3089994 dinov2 helpers.py:102] Training  [ 2190/12500]  eta: 0:36:33  loss: 15.2809 (17.2022)  lr: 0.0000 (0.0000)  time: 0.198368  data: 0.000483  max mem: 3586
I20250215 11:28:17 3089994 dinov2 helpers.py:102] Training  [ 2200/12500]  eta: 0:36:30  loss: 15.2809 (17.1772)  lr: 0.0000 (0.0000)  time: 0.198530  data: 0.000499  max mem: 3586
I20250215 11:28:19 3089994 dinov2 helpers.py:102] Training  [ 2210/12500]  eta: 0:36:28  loss: 15.2809 (17.1720)  lr: 0.0000 (0.0000)  time: 0.198397  data: 0.000406  max mem: 3586
I20250215 11:28:21 3089994 dinov2 helpers.py:102] Training  [ 2220/12500]  eta: 0:36:25  loss: 15.2809 (17.1462)  lr: 0.0000 (0.0000)  time: 0.198277  data: 0.000391  max mem: 3586
I20250215 11:28:23 3089994 dinov2 helpers.py:102] Training  [ 2230/12500]  eta: 0:36:22  loss: 15.2809 (17.1561)  lr: 0.0000 (0.0000)  time: 0.198277  data: 0.000425  max mem: 3586
I20250215 11:28:25 3089994 dinov2 helpers.py:102] Training  [ 2240/12500]  eta: 0:36:19  loss: 15.8538 (17.1637)  lr: 0.0000 (0.0000)  time: 0.198449  data: 0.000405  max mem: 3586
I20250215 11:28:27 3089994 dinov2 helpers.py:102] Training  [ 2250/12500]  eta: 0:36:16  loss: 15.8538 (17.1446)  lr: 0.0000 (0.0000)  time: 0.198532  data: 0.000432  max mem: 3586
I20250215 11:28:29 3089994 dinov2 helpers.py:102] Training  [ 2260/12500]  eta: 0:36:14  loss: 16.0130 (17.1422)  lr: 0.0000 (0.0000)  time: 0.198496  data: 0.000445  max mem: 3586
I20250215 11:28:31 3089994 dinov2 helpers.py:102] Training  [ 2270/12500]  eta: 0:36:11  loss: 15.8538 (17.1221)  lr: 0.0000 (0.0000)  time: 0.198569  data: 0.000434  max mem: 3586
I20250215 11:28:33 3089994 dinov2 helpers.py:102] Training  [ 2280/12500]  eta: 0:36:08  loss: 15.8538 (17.1208)  lr: 0.0000 (0.0000)  time: 0.198533  data: 0.000442  max mem: 3586
I20250215 11:28:35 3089994 dinov2 helpers.py:102] Training  [ 2290/12500]  eta: 0:36:05  loss: 15.8538 (17.1330)  lr: 0.0000 (0.0000)  time: 0.198778  data: 0.000460  max mem: 3586
I20250215 11:28:37 3089994 dinov2 helpers.py:102] Training  [ 2300/12500]  eta: 0:36:03  loss: 15.8989 (17.1276)  lr: 0.0000 (0.0000)  time: 0.198873  data: 0.000464  max mem: 3586
I20250215 11:28:39 3089994 dinov2 helpers.py:102] Training  [ 2310/12500]  eta: 0:36:00  loss: 15.8989 (17.1328)  lr: 0.0000 (0.0000)  time: 0.198822  data: 0.000484  max mem: 3586
I20250215 11:28:41 3089994 dinov2 helpers.py:102] Training  [ 2320/12500]  eta: 0:35:57  loss: 15.8989 (17.1460)  lr: 0.0000 (0.0000)  time: 0.198830  data: 0.000439  max mem: 3586
I20250215 11:28:43 3089994 dinov2 helpers.py:102] Training  [ 2330/12500]  eta: 0:35:55  loss: 15.8989 (17.1254)  lr: 0.0000 (0.0000)  time: 0.198879  data: 0.000357  max mem: 3586
I20250215 11:28:45 3089994 dinov2 helpers.py:102] Training  [ 2340/12500]  eta: 0:35:52  loss: 15.8989 (17.1124)  lr: 0.0000 (0.0000)  time: 0.198938  data: 0.000391  max mem: 3586
I20250215 11:28:47 3089994 dinov2 helpers.py:102] Training  [ 2350/12500]  eta: 0:35:49  loss: 16.0130 (17.1087)  lr: 0.0000 (0.0000)  time: 0.198933  data: 0.000445  max mem: 3586
I20250215 11:28:49 3089994 dinov2 helpers.py:102] Training  [ 2360/12500]  eta: 0:35:47  loss: 16.0130 (17.1090)  lr: 0.0000 (0.0000)  time: 0.198927  data: 0.000450  max mem: 3586
I20250215 11:28:51 3089994 dinov2 helpers.py:102] Training  [ 2370/12500]  eta: 0:35:44  loss: 16.0130 (17.1080)  lr: 0.0000 (0.0000)  time: 0.198865  data: 0.000416  max mem: 3586
I20250215 11:28:53 3089994 dinov2 helpers.py:102] Training  [ 2380/12500]  eta: 0:35:41  loss: 16.0130 (17.0965)  lr: 0.0000 (0.0000)  time: 0.198759  data: 0.000408  max mem: 3586
I20250215 11:28:55 3089994 dinov2 helpers.py:102] Training  [ 2390/12500]  eta: 0:35:39  loss: 16.2433 (17.0946)  lr: 0.0000 (0.0000)  time: 0.198744  data: 0.000427  max mem: 3586
I20250215 11:28:57 3089994 dinov2 helpers.py:102] Training  [ 2400/12500]  eta: 0:35:36  loss: 16.2433 (17.0674)  lr: 0.0000 (0.0000)  time: 0.198886  data: 0.000442  max mem: 3586
I20250215 11:28:59 3089994 dinov2 helpers.py:102] Training  [ 2410/12500]  eta: 0:35:33  loss: 16.2433 (17.0567)  lr: 0.0000 (0.0000)  time: 0.198708  data: 0.000473  max mem: 3586
I20250215 11:29:01 3089994 dinov2 helpers.py:102] Training  [ 2420/12500]  eta: 0:35:31  loss: 16.2433 (17.0486)  lr: 0.0000 (0.0000)  time: 0.198648  data: 0.000437  max mem: 3586
I20250215 11:29:03 3089994 dinov2 helpers.py:102] Training  [ 2430/12500]  eta: 0:35:28  loss: 15.8989 (17.0438)  lr: 0.0000 (0.0000)  time: 0.198658  data: 0.000401  max mem: 3586
I20250215 11:29:05 3089994 dinov2 helpers.py:102] Training  [ 2440/12500]  eta: 0:35:25  loss: 15.8625 (17.0275)  lr: 0.0000 (0.0000)  time: 0.198746  data: 0.000384  max mem: 3586
I20250215 11:29:07 3089994 dinov2 helpers.py:102] Training  [ 2450/12500]  eta: 0:35:23  loss: 15.8625 (17.0188)  lr: 0.0000 (0.0000)  time: 0.198694  data: 0.000385  max mem: 3586
I20250215 11:29:09 3089994 dinov2 helpers.py:102] Training  [ 2460/12500]  eta: 0:35:20  loss: 15.8453 (17.0140)  lr: 0.0000 (0.0000)  time: 0.198562  data: 0.000396  max mem: 3586
I20250215 11:29:11 3089994 dinov2 helpers.py:102] Training  [ 2470/12500]  eta: 0:35:18  loss: 15.8625 (17.0240)  lr: 0.0000 (0.0000)  time: 0.198533  data: 0.000384  max mem: 3586
I20250215 11:29:13 3089994 dinov2 helpers.py:102] Training  [ 2480/12500]  eta: 0:35:15  loss: 15.8625 (17.0320)  lr: 0.0000 (0.0000)  time: 0.198344  data: 0.000413  max mem: 3586
I20250215 11:29:15 3089994 dinov2 helpers.py:102] Training  [ 2490/12500]  eta: 0:35:12  loss: 15.8625 (17.0482)  lr: 0.0000 (0.0000)  time: 0.198385  data: 0.000474  max mem: 3586
I20250215 11:29:16 3089994 dinov2 linear.py:272] running validation !
I20250215 11:29:18 3089994 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:10    time: 1.618574  data: 1.420285  max mem: 3586
I20250215 11:29:20 3089994 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.330233  data: 0.129362  max mem: 3586
I20250215 11:29:22 3089994 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.201753  data: 0.000450  max mem: 3586
I20250215 11:29:24 3089994 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:30    time: 0.200839  data: 0.000435  max mem: 3586
I20250215 11:29:26 3089994 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.199818  data: 0.000245  max mem: 3586
I20250215 11:29:28 3089994 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:23    time: 0.199997  data: 0.000215  max mem: 3586
I20250215 11:29:30 3089994 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.199772  data: 0.000185  max mem: 3586
I20250215 11:29:32 3089994 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199965  data: 0.000189  max mem: 3586
I20250215 11:29:34 3089994 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199945  data: 0.000195  max mem: 3586
I20250215 11:29:36 3089994 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.199880  data: 0.000219  max mem: 3586
I20250215 11:29:38 3089994 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.199987  data: 0.000208  max mem: 3586
I20250215 11:29:40 3089994 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199851  data: 0.000189  max mem: 3586
I20250215 11:29:42 3089994 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199731  data: 0.000217  max mem: 3586
I20250215 11:29:44 3089994 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199923  data: 0.000225  max mem: 3586
I20250215 11:29:46 3089994 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199881  data: 0.000238  max mem: 3586
I20250215 11:29:48 3089994 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199572  data: 0.000195  max mem: 3586
I20250215 11:29:49 3089994 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195988  data: 0.000166  max mem: 3586
I20250215 11:29:49 3089994 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.209801 s / it)
I20250215 11:29:49 3089994 dinov2 utils.py:79] Averaged stats: 
I20250215 11:29:49 3089994 dinov2 linear.py:287] 
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.9103, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9174, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9221, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9272, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9306, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9329, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9346, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9361, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9360, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9345, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.9286, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.9243, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.9052, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9183, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9231, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9282, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9325, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9348, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9370, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9388, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9378, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9374, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.9308, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.9263, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.9211, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9274, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9308, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9336, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9349, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9362, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9365, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9362, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9333, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9311, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.9261, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.9202, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.9198, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9255, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9310, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9341, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9358, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9373, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9374, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9371, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9344, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9333, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.9248, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.9206, device='cuda:0')}
I20250215 11:29:49 3089994 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.9387631416320801}
I20250215 11:29:49 3089994 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250215 11:29:49 3089994 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset/running_checkpoint_linear_eval.pth
I20250215 11:29:49 3089994 dinov2 helpers.py:102] Training  [ 2500/12500]  eta: 0:37:20  loss: 15.8453 (17.0425)  lr: 0.0000 (0.0000)  time: 1.829157  data: 0.000493  max mem: 3586
I20250215 11:29:51 3089994 dinov2 helpers.py:102] Training  [ 2510/12500]  eta: 0:37:17  loss: 15.6090 (17.0237)  lr: 0.0000 (0.0000)  time: 1.827842  data: 0.000424  max mem: 3586
I20250215 11:29:54 3089994 dinov2 helpers.py:102] Training  [ 2520/12500]  eta: 0:37:15  loss: 15.6090 (17.0194)  lr: 0.0000 (0.0000)  time: 0.221394  data: 0.028773  max mem: 3586
I20250215 11:29:56 3089994 dinov2 helpers.py:102] Training  [ 2530/12500]  eta: 0:37:12  loss: 15.8207 (17.0147)  lr: 0.0000 (0.0000)  time: 0.222138  data: 0.028783  max mem: 3586
I20250215 11:29:58 3089994 dinov2 helpers.py:102] Training  [ 2540/12500]  eta: 0:37:09  loss: 15.8207 (17.0022)  lr: 0.0000 (0.0000)  time: 0.197372  data: 0.000422  max mem: 3586
I20250215 11:29:59 3089994 dinov2 helpers.py:102] Training  [ 2550/12500]  eta: 0:37:06  loss: 15.8207 (16.9996)  lr: 0.0000 (0.0000)  time: 0.197463  data: 0.000463  max mem: 3586
I20250215 11:30:01 3089994 dinov2 helpers.py:102] Training  [ 2560/12500]  eta: 0:37:02  loss: 15.6090 (16.9817)  lr: 0.0000 (0.0000)  time: 0.197594  data: 0.000452  max mem: 3586
I20250215 11:30:03 3089994 dinov2 helpers.py:102] Training  [ 2570/12500]  eta: 0:36:59  loss: 15.6090 (16.9876)  lr: 0.0000 (0.0000)  time: 0.197563  data: 0.000419  max mem: 3586
I20250215 11:30:05 3089994 dinov2 helpers.py:102] Training  [ 2580/12500]  eta: 0:36:56  loss: 15.6090 (16.9800)  lr: 0.0000 (0.0000)  time: 0.197567  data: 0.000390  max mem: 3586
I20250215 11:30:07 3089994 dinov2 helpers.py:102] Training  [ 2590/12500]  eta: 0:36:53  loss: 15.0870 (16.9476)  lr: 0.0000 (0.0000)  time: 0.197639  data: 0.000402  max mem: 3586
I20250215 11:30:09 3089994 dinov2 helpers.py:102] Training  [ 2600/12500]  eta: 0:36:49  loss: 15.6090 (16.9489)  lr: 0.0000 (0.0000)  time: 0.197719  data: 0.000410  max mem: 3586
I20250215 11:30:11 3089994 dinov2 helpers.py:102] Training  [ 2610/12500]  eta: 0:36:46  loss: 15.8207 (16.9449)  lr: 0.0000 (0.0000)  time: 0.197790  data: 0.000379  max mem: 3586
I20250215 11:30:13 3089994 dinov2 helpers.py:102] Training  [ 2620/12500]  eta: 0:36:43  loss: 15.8207 (16.9348)  lr: 0.0000 (0.0000)  time: 0.197714  data: 0.000376  max mem: 3586
I20250215 11:30:15 3089994 dinov2 helpers.py:102] Training  [ 2630/12500]  eta: 0:36:40  loss: 15.6090 (16.9243)  lr: 0.0000 (0.0000)  time: 0.197763  data: 0.000436  max mem: 3586
I20250215 11:30:17 3089994 dinov2 helpers.py:102] Training  [ 2640/12500]  eta: 0:36:37  loss: 15.8207 (16.9361)  lr: 0.0000 (0.0000)  time: 0.197940  data: 0.000458  max mem: 3586
I20250215 11:30:19 3089994 dinov2 helpers.py:102] Training  [ 2650/12500]  eta: 0:36:34  loss: 15.8207 (16.9099)  lr: 0.0000 (0.0000)  time: 0.197951  data: 0.000458  max mem: 3586
I20250215 11:30:21 3089994 dinov2 helpers.py:102] Training  [ 2660/12500]  eta: 0:36:30  loss: 15.6090 (16.9015)  lr: 0.0000 (0.0000)  time: 0.197908  data: 0.000452  max mem: 3586
I20250215 11:30:23 3089994 dinov2 helpers.py:102] Training  [ 2670/12500]  eta: 0:36:27  loss: 15.0102 (16.8791)  lr: 0.0000 (0.0000)  time: 0.198035  data: 0.000410  max mem: 3586
I20250215 11:30:25 3089994 dinov2 helpers.py:102] Training  [ 2680/12500]  eta: 0:36:24  loss: 14.6627 (16.8541)  lr: 0.0000 (0.0000)  time: 0.197986  data: 0.000387  max mem: 3586
I20250215 11:30:27 3089994 dinov2 helpers.py:102] Training  [ 2690/12500]  eta: 0:36:21  loss: 14.6627 (16.8743)  lr: 0.0000 (0.0000)  time: 0.198155  data: 0.000394  max mem: 3586
I20250215 11:30:29 3089994 dinov2 helpers.py:102] Training  [ 2700/12500]  eta: 0:36:18  loss: 14.6627 (16.8746)  lr: 0.0000 (0.0000)  time: 0.198321  data: 0.000429  max mem: 3586
I20250215 11:30:31 3089994 dinov2 helpers.py:102] Training  [ 2710/12500]  eta: 0:36:15  loss: 15.0102 (16.8723)  lr: 0.0000 (0.0000)  time: 0.198138  data: 0.000418  max mem: 3586
I20250215 11:30:33 3089994 dinov2 helpers.py:102] Training  [ 2720/12500]  eta: 0:36:12  loss: 14.6627 (16.8567)  lr: 0.0000 (0.0000)  time: 0.198068  data: 0.000406  max mem: 3586
I20250215 11:30:35 3089994 dinov2 helpers.py:102] Training  [ 2730/12500]  eta: 0:36:09  loss: 14.2881 (16.8392)  lr: 0.0000 (0.0000)  time: 0.197995  data: 0.000420  max mem: 3586
I20250215 11:30:37 3089994 dinov2 helpers.py:102] Training  [ 2740/12500]  eta: 0:36:06  loss: 14.6627 (16.8549)  lr: 0.0000 (0.0000)  time: 0.198064  data: 0.000420  max mem: 3586
I20250215 11:30:39 3089994 dinov2 helpers.py:102] Training  [ 2750/12500]  eta: 0:36:02  loss: 14.2881 (16.8414)  lr: 0.0000 (0.0000)  time: 0.198198  data: 0.000423  max mem: 3586
I20250215 11:30:41 3089994 dinov2 helpers.py:102] Training  [ 2760/12500]  eta: 0:35:59  loss: 14.6627 (16.8357)  lr: 0.0000 (0.0000)  time: 0.198246  data: 0.000417  max mem: 3586
I20250215 11:30:43 3089994 dinov2 helpers.py:102] Training  [ 2770/12500]  eta: 0:35:56  loss: 14.6627 (16.8352)  lr: 0.0000 (0.0000)  time: 0.198382  data: 0.000386  max mem: 3586
I20250215 11:30:45 3089994 dinov2 helpers.py:102] Training  [ 2780/12500]  eta: 0:35:53  loss: 14.3901 (16.8265)  lr: 0.0000 (0.0000)  time: 0.198378  data: 0.000375  max mem: 3586
I20250215 11:30:47 3089994 dinov2 helpers.py:102] Training  [ 2790/12500]  eta: 0:35:50  loss: 14.3901 (16.8177)  lr: 0.0000 (0.0000)  time: 0.198312  data: 0.000392  max mem: 3586
I20250215 11:30:49 3089994 dinov2 helpers.py:102] Training  [ 2800/12500]  eta: 0:35:47  loss: 14.3803 (16.7921)  lr: 0.0000 (0.0000)  time: 0.198133  data: 0.000380  max mem: 3586
I20250215 11:30:51 3089994 dinov2 helpers.py:102] Training  [ 2810/12500]  eta: 0:35:44  loss: 14.2881 (16.7686)  lr: 0.0000 (0.0000)  time: 0.198083  data: 0.000418  max mem: 3586
I20250215 11:30:53 3089994 dinov2 helpers.py:102] Training  [ 2820/12500]  eta: 0:35:41  loss: 14.3803 (16.7812)  lr: 0.0000 (0.0000)  time: 0.198162  data: 0.000415  max mem: 3586
I20250215 11:30:55 3089994 dinov2 helpers.py:102] Training  [ 2830/12500]  eta: 0:35:38  loss: 14.3803 (16.7650)  lr: 0.0000 (0.0000)  time: 0.198133  data: 0.000381  max mem: 3586
I20250215 11:30:57 3089994 dinov2 helpers.py:102] Training  [ 2840/12500]  eta: 0:35:35  loss: 14.3803 (16.7584)  lr: 0.0000 (0.0000)  time: 0.198273  data: 0.000421  max mem: 3586
I20250215 11:30:59 3089994 dinov2 helpers.py:102] Training  [ 2850/12500]  eta: 0:35:32  loss: 14.3901 (16.7549)  lr: 0.0000 (0.0000)  time: 0.198365  data: 0.000387  max mem: 3586
I20250215 11:31:01 3089994 dinov2 helpers.py:102] Training  [ 2860/12500]  eta: 0:35:29  loss: 14.3901 (16.7726)  lr: 0.0000 (0.0000)  time: 0.198349  data: 0.000371  max mem: 3586
I20250215 11:31:03 3089994 dinov2 helpers.py:102] Training  [ 2870/12500]  eta: 0:35:26  loss: 14.3901 (16.7629)  lr: 0.0000 (0.0000)  time: 0.198361  data: 0.000400  max mem: 3586
I20250215 11:31:05 3089994 dinov2 helpers.py:102] Training  [ 2880/12500]  eta: 0:35:23  loss: 14.3901 (16.7506)  lr: 0.0000 (0.0000)  time: 0.198340  data: 0.000482  max mem: 3586
I20250215 11:31:07 3089994 dinov2 helpers.py:102] Training  [ 2890/12500]  eta: 0:35:20  loss: 14.3803 (16.7420)  lr: 0.0000 (0.0000)  time: 0.198229  data: 0.000511  max mem: 3586
I20250215 11:31:09 3089994 dinov2 helpers.py:102] Training  [ 2900/12500]  eta: 0:35:18  loss: 14.2650 (16.7313)  lr: 0.0000 (0.0000)  time: 0.198342  data: 0.000427  max mem: 3586
I20250215 11:31:11 3089994 dinov2 helpers.py:102] Training  [ 2910/12500]  eta: 0:35:15  loss: 14.2650 (16.7559)  lr: 0.0000 (0.0000)  time: 0.198669  data: 0.000407  max mem: 3586
I20250215 11:31:13 3089994 dinov2 helpers.py:102] Training  [ 2920/12500]  eta: 0:35:12  loss: 14.2650 (16.7416)  lr: 0.0000 (0.0000)  time: 0.198564  data: 0.000444  max mem: 3586
I20250215 11:31:15 3089994 dinov2 helpers.py:102] Training  [ 2930/12500]  eta: 0:35:09  loss: 14.3803 (16.7350)  lr: 0.0000 (0.0000)  time: 0.198412  data: 0.000419  max mem: 3586
I20250215 11:31:17 3089994 dinov2 helpers.py:102] Training  [ 2940/12500]  eta: 0:35:06  loss: 14.2650 (16.7264)  lr: 0.0000 (0.0000)  time: 0.198465  data: 0.000385  max mem: 3586
I20250215 11:31:19 3089994 dinov2 helpers.py:102] Training  [ 2950/12500]  eta: 0:35:03  loss: 14.3803 (16.7336)  lr: 0.0000 (0.0000)  time: 0.198498  data: 0.000398  max mem: 3586
I20250215 11:31:21 3089994 dinov2 helpers.py:102] Training  [ 2960/12500]  eta: 0:35:00  loss: 14.2650 (16.7221)  lr: 0.0000 (0.0000)  time: 0.198418  data: 0.000392  max mem: 3586
I20250215 11:31:23 3089994 dinov2 helpers.py:102] Training  [ 2970/12500]  eta: 0:34:57  loss: 14.1803 (16.7081)  lr: 0.0000 (0.0000)  time: 0.198309  data: 0.000422  max mem: 3586
I20250215 11:31:25 3089994 dinov2 helpers.py:102] Training  [ 2980/12500]  eta: 0:34:54  loss: 14.1803 (16.7116)  lr: 0.0000 (0.0000)  time: 0.198575  data: 0.000453  max mem: 3586
I20250215 11:31:27 3089994 dinov2 helpers.py:102] Training  [ 2990/12500]  eta: 0:34:51  loss: 14.1803 (16.7227)  lr: 0.0000 (0.0000)  time: 0.198603  data: 0.000457  max mem: 3586
I20250215 11:31:29 3089994 dinov2 helpers.py:102] Training  [ 3000/12500]  eta: 0:34:48  loss: 14.1803 (16.7098)  lr: 0.0000 (0.0000)  time: 0.198550  data: 0.000452  max mem: 3586
I20250215 11:31:31 3089994 dinov2 helpers.py:102] Training  [ 3010/12500]  eta: 0:34:46  loss: 14.1803 (16.6980)  lr: 0.0000 (0.0000)  time: 0.198627  data: 0.000424  max mem: 3586
I20250215 11:31:33 3089994 dinov2 helpers.py:102] Training  [ 3020/12500]  eta: 0:34:43  loss: 13.9877 (16.6880)  lr: 0.0000 (0.0000)  time: 0.198480  data: 0.000393  max mem: 3586
I20250215 11:31:35 3089994 dinov2 helpers.py:102] Training  [ 3030/12500]  eta: 0:34:40  loss: 13.9877 (16.6774)  lr: 0.0000 (0.0000)  time: 0.198421  data: 0.000399  max mem: 3586
I20250215 11:31:37 3089994 dinov2 helpers.py:102] Training  [ 3040/12500]  eta: 0:34:37  loss: 13.6696 (16.6621)  lr: 0.0000 (0.0000)  time: 0.198369  data: 0.000394  max mem: 3586
I20250215 11:31:39 3089994 dinov2 helpers.py:102] Training  [ 3050/12500]  eta: 0:34:34  loss: 13.6696 (16.6584)  lr: 0.0000 (0.0000)  time: 0.198404  data: 0.000427  max mem: 3586
I20250215 11:31:41 3089994 dinov2 helpers.py:102] Training  [ 3060/12500]  eta: 0:34:31  loss: 13.6696 (16.6569)  lr: 0.0000 (0.0000)  time: 0.198560  data: 0.000428  max mem: 3586
I20250215 11:31:43 3089994 dinov2 helpers.py:102] Training  [ 3070/12500]  eta: 0:34:28  loss: 13.6696 (16.6487)  lr: 0.0000 (0.0000)  time: 0.198696  data: 0.000415  max mem: 3586
I20250215 11:31:45 3089994 dinov2 helpers.py:102] Training  [ 3080/12500]  eta: 0:34:26  loss: 14.1136 (16.6540)  lr: 0.0000 (0.0000)  time: 0.198730  data: 0.000376  max mem: 3586
I20250215 11:31:47 3089994 dinov2 helpers.py:102] Training  [ 3090/12500]  eta: 0:34:23  loss: 13.6696 (16.6409)  lr: 0.0000 (0.0000)  time: 0.198553  data: 0.000364  max mem: 3586
I20250215 11:31:49 3089994 dinov2 helpers.py:102] Training  [ 3100/12500]  eta: 0:34:20  loss: 13.6696 (16.6179)  lr: 0.0000 (0.0000)  time: 0.198617  data: 0.000372  max mem: 3586
I20250215 11:31:51 3089994 dinov2 helpers.py:102] Training  [ 3110/12500]  eta: 0:34:17  loss: 13.4834 (16.6068)  lr: 0.0000 (0.0000)  time: 0.198635  data: 0.000380  max mem: 3586
I20250215 11:31:53 3089994 dinov2 helpers.py:102] Training  [ 3120/12500]  eta: 0:34:14  loss: 13.6696 (16.6013)  lr: 0.0000 (0.0000)  time: 0.198561  data: 0.000453  max mem: 3586
I20250215 11:31:55 3089994 dinov2 helpers.py:102] Training  [ 3130/12500]  eta: 0:34:12  loss: 13.4834 (16.5864)  lr: 0.0000 (0.0000)  time: 0.198681  data: 0.000465  max mem: 3586
I20250215 11:31:57 3089994 dinov2 helpers.py:102] Training  [ 3140/12500]  eta: 0:34:09  loss: 13.4834 (16.5992)  lr: 0.0000 (0.0000)  time: 0.198499  data: 0.000437  max mem: 3586
I20250215 11:31:58 3089994 dinov2 helpers.py:102] Training  [ 3150/12500]  eta: 0:34:06  loss: 13.3084 (16.5834)  lr: 0.0000 (0.0000)  time: 0.198460  data: 0.000387  max mem: 3586
I20250215 11:32:00 3089994 dinov2 helpers.py:102] Training  [ 3160/12500]  eta: 0:34:03  loss: 13.4834 (16.5855)  lr: 0.0000 (0.0000)  time: 0.198582  data: 0.000386  max mem: 3586
I20250215 11:32:02 3089994 dinov2 helpers.py:102] Training  [ 3170/12500]  eta: 0:34:00  loss: 13.6696 (16.5910)  lr: 0.0000 (0.0000)  time: 0.198376  data: 0.000405  max mem: 3586
I20250215 11:32:04 3089994 dinov2 helpers.py:102] Training  [ 3180/12500]  eta: 0:33:58  loss: 13.4834 (16.5806)  lr: 0.0000 (0.0000)  time: 0.198216  data: 0.000423  max mem: 3586
I20250215 11:32:06 3089994 dinov2 helpers.py:102] Training  [ 3190/12500]  eta: 0:33:55  loss: 13.4834 (16.5794)  lr: 0.0000 (0.0000)  time: 0.198291  data: 0.000404  max mem: 3586
I20250215 11:32:08 3089994 dinov2 helpers.py:102] Training  [ 3200/12500]  eta: 0:33:52  loss: 13.6696 (16.5781)  lr: 0.0000 (0.0000)  time: 0.198339  data: 0.000402  max mem: 3586
I20250215 11:32:10 3089994 dinov2 helpers.py:102] Training  [ 3210/12500]  eta: 0:33:49  loss: 14.1136 (16.5738)  lr: 0.0000 (0.0000)  time: 0.198283  data: 0.000412  max mem: 3586
I20250215 11:32:12 3089994 dinov2 helpers.py:102] Training  [ 3220/12500]  eta: 0:33:47  loss: 14.8834 (16.5719)  lr: 0.0000 (0.0000)  time: 0.198195  data: 0.000388  max mem: 3586
I20250215 11:32:14 3089994 dinov2 helpers.py:102] Training  [ 3230/12500]  eta: 0:33:44  loss: 15.2205 (16.5772)  lr: 0.0000 (0.0000)  time: 0.198144  data: 0.000363  max mem: 3586
I20250215 11:32:16 3089994 dinov2 helpers.py:102] Training  [ 3240/12500]  eta: 0:33:41  loss: 15.4463 (16.5737)  lr: 0.0000 (0.0000)  time: 0.198237  data: 0.000332  max mem: 3586
I20250215 11:32:18 3089994 dinov2 helpers.py:102] Training  [ 3250/12500]  eta: 0:33:38  loss: 15.2205 (16.5591)  lr: 0.0000 (0.0000)  time: 0.198252  data: 0.000384  max mem: 3586
I20250215 11:32:20 3089994 dinov2 helpers.py:102] Training  [ 3260/12500]  eta: 0:33:35  loss: 15.2205 (16.5668)  lr: 0.0000 (0.0000)  time: 0.198243  data: 0.000420  max mem: 3586
I20250215 11:32:22 3089994 dinov2 helpers.py:102] Training  [ 3270/12500]  eta: 0:33:33  loss: 15.2205 (16.5516)  lr: 0.0000 (0.0000)  time: 0.198292  data: 0.000412  max mem: 3586
I20250215 11:32:24 3089994 dinov2 helpers.py:102] Training  [ 3280/12500]  eta: 0:33:30  loss: 15.2205 (16.5504)  lr: 0.0000 (0.0000)  time: 0.198290  data: 0.000418  max mem: 3586
I20250215 11:32:26 3089994 dinov2 helpers.py:102] Training  [ 3290/12500]  eta: 0:33:27  loss: 15.2205 (16.5292)  lr: 0.0000 (0.0000)  time: 0.198320  data: 0.000395  max mem: 3586
I20250215 11:32:28 3089994 dinov2 helpers.py:102] Training  [ 3300/12500]  eta: 0:33:25  loss: 15.2205 (16.5065)  lr: 0.0000 (0.0000)  time: 0.198299  data: 0.000383  max mem: 3586
I20250215 11:32:30 3089994 dinov2 helpers.py:102] Training  [ 3310/12500]  eta: 0:33:22  loss: 15.2205 (16.4923)  lr: 0.0000 (0.0000)  time: 0.198156  data: 0.000389  max mem: 3586
I20250215 11:32:32 3089994 dinov2 helpers.py:102] Training  [ 3320/12500]  eta: 0:33:19  loss: 15.2205 (16.4841)  lr: 0.0000 (0.0000)  time: 0.198229  data: 0.000398  max mem: 3586
I20250215 11:32:34 3089994 dinov2 helpers.py:102] Training  [ 3330/12500]  eta: 0:33:16  loss: 15.2205 (16.4698)  lr: 0.0000 (0.0000)  time: 0.198330  data: 0.000390  max mem: 3586
I20250215 11:32:36 3089994 dinov2 helpers.py:102] Training  [ 3340/12500]  eta: 0:33:14  loss: 13.8702 (16.4620)  lr: 0.0000 (0.0000)  time: 0.198365  data: 0.000419  max mem: 3586
I20250215 11:32:38 3089994 dinov2 helpers.py:102] Training  [ 3350/12500]  eta: 0:33:11  loss: 15.1227 (16.4581)  lr: 0.0000 (0.0000)  time: 0.198568  data: 0.000421  max mem: 3586
I20250215 11:32:40 3089994 dinov2 helpers.py:102] Training  [ 3360/12500]  eta: 0:33:08  loss: 13.8702 (16.4428)  lr: 0.0000 (0.0000)  time: 0.198519  data: 0.000389  max mem: 3586
I20250215 11:32:42 3089994 dinov2 helpers.py:102] Training  [ 3370/12500]  eta: 0:33:06  loss: 13.8702 (16.4402)  lr: 0.0000 (0.0000)  time: 0.198213  data: 0.000399  max mem: 3586
I20250215 11:32:44 3089994 dinov2 helpers.py:102] Training  [ 3380/12500]  eta: 0:33:03  loss: 14.7776 (16.4353)  lr: 0.0000 (0.0000)  time: 0.198159  data: 0.000418  max mem: 3586
I20250215 11:32:46 3089994 dinov2 helpers.py:102] Training  [ 3390/12500]  eta: 0:33:00  loss: 13.8702 (16.4186)  lr: 0.0000 (0.0000)  time: 0.198395  data: 0.000459  max mem: 3586
I20250215 11:32:48 3089994 dinov2 helpers.py:102] Training  [ 3400/12500]  eta: 0:32:58  loss: 13.7686 (16.4041)  lr: 0.0000 (0.0000)  time: 0.198477  data: 0.000493  max mem: 3586
I20250215 11:32:50 3089994 dinov2 helpers.py:102] Training  [ 3410/12500]  eta: 0:32:55  loss: 13.7686 (16.3991)  lr: 0.0000 (0.0000)  time: 0.198348  data: 0.000446  max mem: 3586
I20250215 11:32:52 3089994 dinov2 helpers.py:102] Training  [ 3420/12500]  eta: 0:32:52  loss: 12.3397 (16.3873)  lr: 0.0000 (0.0000)  time: 0.198221  data: 0.000419  max mem: 3586
I20250215 11:32:54 3089994 dinov2 helpers.py:102] Training  [ 3430/12500]  eta: 0:32:49  loss: 11.8261 (16.3740)  lr: 0.0000 (0.0000)  time: 0.198249  data: 0.000416  max mem: 3586
I20250215 11:32:56 3089994 dinov2 helpers.py:102] Training  [ 3440/12500]  eta: 0:32:47  loss: 11.8261 (16.3664)  lr: 0.0000 (0.0000)  time: 0.198329  data: 0.000390  max mem: 3586
I20250215 11:32:58 3089994 dinov2 helpers.py:102] Training  [ 3450/12500]  eta: 0:32:44  loss: 12.3397 (16.3737)  lr: 0.0000 (0.0000)  time: 0.198187  data: 0.000435  max mem: 3586
I20250215 11:33:00 3089994 dinov2 helpers.py:102] Training  [ 3460/12500]  eta: 0:32:41  loss: 12.3397 (16.3758)  lr: 0.0000 (0.0000)  time: 0.198096  data: 0.000435  max mem: 3586
I20250215 11:33:02 3089994 dinov2 helpers.py:102] Training  [ 3470/12500]  eta: 0:32:39  loss: 12.3397 (16.3598)  lr: 0.0000 (0.0000)  time: 0.198114  data: 0.000370  max mem: 3586
I20250215 11:33:04 3089994 dinov2 helpers.py:102] Training  [ 3480/12500]  eta: 0:32:36  loss: 12.3397 (16.3628)  lr: 0.0000 (0.0000)  time: 0.198174  data: 0.000364  max mem: 3586
I20250215 11:33:06 3089994 dinov2 helpers.py:102] Training  [ 3490/12500]  eta: 0:32:33  loss: 13.7284 (16.3653)  lr: 0.0000 (0.0000)  time: 0.198066  data: 0.000439  max mem: 3586
I20250215 11:33:08 3089994 dinov2 helpers.py:102] Training  [ 3500/12500]  eta: 0:32:31  loss: 13.7686 (16.3604)  lr: 0.0000 (0.0000)  time: 0.197870  data: 0.000486  max mem: 3586
I20250215 11:33:10 3089994 dinov2 helpers.py:102] Training  [ 3510/12500]  eta: 0:32:28  loss: 13.7686 (16.3496)  lr: 0.0000 (0.0000)  time: 0.197854  data: 0.000436  max mem: 3586
I20250215 11:33:12 3089994 dinov2 helpers.py:102] Training  [ 3520/12500]  eta: 0:32:26  loss: 13.7284 (16.3402)  lr: 0.0000 (0.0000)  time: 0.197969  data: 0.000440  max mem: 3586
I20250215 11:33:14 3089994 dinov2 helpers.py:102] Training  [ 3530/12500]  eta: 0:32:23  loss: 13.8702 (16.3464)  lr: 0.0000 (0.0000)  time: 0.198048  data: 0.000454  max mem: 3586
I20250215 11:33:16 3089994 dinov2 helpers.py:102] Training  [ 3540/12500]  eta: 0:32:20  loss: 14.3304 (16.3407)  lr: 0.0000 (0.0000)  time: 0.197950  data: 0.000395  max mem: 3586
I20250215 11:33:18 3089994 dinov2 helpers.py:102] Training  [ 3550/12500]  eta: 0:32:18  loss: 14.3304 (16.3415)  lr: 0.0000 (0.0000)  time: 0.198143  data: 0.000394  max mem: 3586
I20250215 11:33:20 3089994 dinov2 helpers.py:102] Training  [ 3560/12500]  eta: 0:32:15  loss: 14.6319 (16.3410)  lr: 0.0000 (0.0000)  time: 0.198202  data: 0.000380  max mem: 3586
I20250215 11:33:22 3089994 dinov2 helpers.py:102] Training  [ 3570/12500]  eta: 0:32:12  loss: 14.3304 (16.3281)  lr: 0.0000 (0.0000)  time: 0.197861  data: 0.000405  max mem: 3586
I20250215 11:33:24 3089994 dinov2 helpers.py:102] Training  [ 3580/12500]  eta: 0:32:10  loss: 13.7284 (16.3200)  lr: 0.0000 (0.0000)  time: 0.197913  data: 0.000456  max mem: 3586
I20250215 11:33:26 3089994 dinov2 helpers.py:102] Training  [ 3590/12500]  eta: 0:32:07  loss: 13.7284 (16.3056)  lr: 0.0000 (0.0000)  time: 0.197869  data: 0.000434  max mem: 3586
I20250215 11:33:28 3089994 dinov2 helpers.py:102] Training  [ 3600/12500]  eta: 0:32:04  loss: 13.7284 (16.2958)  lr: 0.0000 (0.0000)  time: 0.197839  data: 0.000450  max mem: 3586
I20250215 11:33:30 3089994 dinov2 helpers.py:102] Training  [ 3610/12500]  eta: 0:32:02  loss: 13.7284 (16.2951)  lr: 0.0000 (0.0000)  time: 0.197987  data: 0.000456  max mem: 3586
I20250215 11:33:32 3089994 dinov2 helpers.py:102] Training  [ 3620/12500]  eta: 0:31:59  loss: 13.7284 (16.2857)  lr: 0.0000 (0.0000)  time: 0.197925  data: 0.000434  max mem: 3586
I20250215 11:33:34 3089994 dinov2 helpers.py:102] Training  [ 3630/12500]  eta: 0:31:57  loss: 14.3304 (16.2870)  lr: 0.0000 (0.0000)  time: 0.197865  data: 0.000428  max mem: 3586
I20250215 11:33:36 3089994 dinov2 helpers.py:102] Training  [ 3640/12500]  eta: 0:31:54  loss: 14.6319 (16.2870)  lr: 0.0000 (0.0000)  time: 0.197819  data: 0.000397  max mem: 3586
I20250215 11:33:38 3089994 dinov2 helpers.py:102] Training  [ 3650/12500]  eta: 0:31:51  loss: 14.3304 (16.2698)  lr: 0.0000 (0.0000)  time: 0.197986  data: 0.000376  max mem: 3586
I20250215 11:33:40 3089994 dinov2 helpers.py:102] Training  [ 3660/12500]  eta: 0:31:49  loss: 14.3304 (16.2693)  lr: 0.0000 (0.0000)  time: 0.198078  data: 0.000405  max mem: 3586
I20250215 11:33:42 3089994 dinov2 helpers.py:102] Training  [ 3670/12500]  eta: 0:31:46  loss: 14.3304 (16.2609)  lr: 0.0000 (0.0000)  time: 0.198029  data: 0.000406  max mem: 3586
I20250215 11:33:44 3089994 dinov2 helpers.py:102] Training  [ 3680/12500]  eta: 0:31:44  loss: 14.0727 (16.2550)  lr: 0.0000 (0.0000)  time: 0.198199  data: 0.000409  max mem: 3586
I20250215 11:33:46 3089994 dinov2 helpers.py:102] Training  [ 3690/12500]  eta: 0:31:41  loss: 14.0727 (16.2558)  lr: 0.0000 (0.0000)  time: 0.198284  data: 0.000454  max mem: 3586
I20250215 11:33:48 3089994 dinov2 helpers.py:102] Training  [ 3700/12500]  eta: 0:31:39  loss: 13.4025 (16.2470)  lr: 0.0000 (0.0000)  time: 0.198109  data: 0.000437  max mem: 3586
I20250215 11:33:50 3089994 dinov2 helpers.py:102] Training  [ 3710/12500]  eta: 0:31:36  loss: 14.0727 (16.2491)  lr: 0.0000 (0.0000)  time: 0.198048  data: 0.000398  max mem: 3586
I20250215 11:33:51 3089994 dinov2 helpers.py:102] Training  [ 3720/12500]  eta: 0:31:33  loss: 14.3304 (16.2470)  lr: 0.0000 (0.0000)  time: 0.197959  data: 0.000363  max mem: 3586
I20250215 11:33:53 3089994 dinov2 helpers.py:102] Training  [ 3730/12500]  eta: 0:31:31  loss: 14.0727 (16.2344)  lr: 0.0000 (0.0000)  time: 0.197992  data: 0.000384  max mem: 3586
I20250215 11:33:55 3089994 dinov2 helpers.py:102] Training  [ 3740/12500]  eta: 0:31:28  loss: 13.4025 (16.2182)  lr: 0.0000 (0.0000)  time: 0.198057  data: 0.000446  max mem: 3586
I20250215 11:33:57 3089994 dinov2 linear.py:272] running validation !
I20250215 11:33:59 3089994 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:18    time: 1.670101  data: 1.472459  max mem: 3586
I20250215 11:34:01 3089994 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.336397  data: 0.134468  max mem: 3586
I20250215 11:34:03 3089994 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.201776  data: 0.000499  max mem: 3586
I20250215 11:34:05 3089994 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.199994  data: 0.000266  max mem: 3586
I20250215 11:34:07 3089994 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.199779  data: 0.000210  max mem: 3586
I20250215 11:34:09 3089994 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.199959  data: 0.000222  max mem: 3586
I20250215 11:34:11 3089994 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.199869  data: 0.000224  max mem: 3586
I20250215 11:34:13 3089994 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:18    time: 0.199986  data: 0.000296  max mem: 3586
I20250215 11:34:15 3089994 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.199809  data: 0.000291  max mem: 3586
I20250215 11:34:17 3089994 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.199767  data: 0.000218  max mem: 3586
I20250215 11:34:19 3089994 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:11    time: 0.200003  data: 0.000222  max mem: 3586
I20250215 11:34:21 3089994 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.199868  data: 0.000227  max mem: 3586
I20250215 11:34:23 3089994 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.199937  data: 0.000221  max mem: 3586
I20250215 11:34:25 3089994 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.199960  data: 0.000219  max mem: 3586
I20250215 11:34:27 3089994 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.199650  data: 0.000235  max mem: 3586
I20250215 11:34:29 3089994 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.199678  data: 0.000178  max mem: 3586
I20250215 11:34:30 3089994 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.195909  data: 0.000138  max mem: 3586
I20250215 11:34:30 3089994 dinov2 helpers.py:130] Test: Total time: 0:00:32 (0.210119 s / it)
I20250215 11:34:30 3089994 dinov2 utils.py:79] Averaged stats: 
I20250215 11:34:30 3089994 dinov2 linear.py:287] 
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.9125, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9205, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9244, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9292, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9323, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9340, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9352, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9364, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9369, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9366, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.9319, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.9251, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.9091, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9207, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9254, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9302, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9336, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9359, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9377, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9393, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9407, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9377, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.9285, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.9177, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.9238, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.9289, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.9322, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.9344, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.9360, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.9376, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.9385, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.9383, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.9343, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.9267, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.9088, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.9021, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.9234, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.9283, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.9327, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.9351, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.9369, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.9387, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.9389, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.9374, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.9335, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.9249, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.9118, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.9079, device='cuda:0')}
I20250215 11:34:30 3089994 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.940683126449585}
I20250215 11:34:30 3089994 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250215 11:34:30 3089994 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/linear_gender_with_original_dataset/running_checkpoint_linear_eval.pth
I20250215 11:34:30 3089994 dinov2 helpers.py:102] Training  [ 3750/12500]  eta: 0:32:42  loss: 13.1910 (16.2010)  lr: 0.0000 (0.0000)  time: 1.831149  data: 0.000426  max mem: 3586
I20250215 11:34:32 3089994 dinov2 helpers.py:102] Training  [ 3760/12500]  eta: 0:32:39  loss: 13.1910 (16.2166)  lr: 0.0000 (0.0000)  time: 1.830452  data: 0.000389  max mem: 3586
I20250215 11:34:34 3089994 dinov2 helpers.py:102] Training  [ 3770/12500]  eta: 0:32:36  loss: 13.1910 (16.1983)  lr: 0.0000 (0.0000)  time: 0.197196  data: 0.000380  max mem: 3586
I20250215 11:34:36 3089994 dinov2 helpers.py:102] Training  [ 3780/12500]  eta: 0:32:33  loss: 12.9916 (16.1803)  lr: 0.0000 (0.0000)  time: 0.197773  data: 0.000423  max mem: 3586
I20250215 11:34:38 3089994 dinov2 helpers.py:102] Training  [ 3790/12500]  eta: 0:32:31  loss: 13.1910 (16.1790)  lr: 0.0000 (0.0000)  time: 0.220904  data: 0.027292  max mem: 3586
I20250215 11:34:40 3089994 dinov2 helpers.py:102] Training  [ 3800/12500]  eta: 0:32:29  loss: 13.1910 (16.1709)  lr: 0.0000 (0.0000)  time: 0.220789  data: 0.027305  max mem: 3586
I20250215 11:34:42 3089994 dinov2 helpers.py:102] Training  [ 3810/12500]  eta: 0:32:26  loss: 13.0977 (16.1556)  lr: 0.0000 (0.0000)  time: 0.197496  data: 0.000483  max mem: 3586
I20250215 11:34:44 3089994 dinov2 helpers.py:102] Training  [ 3820/12500]  eta: 0:32:23  loss: 13.1910 (16.1525)  lr: 0.0000 (0.0000)  time: 0.197406  data: 0.000456  max mem: 3586
I20250215 11:34:46 3089994 dinov2 helpers.py:102] Training  [ 3830/12500]  eta: 0:32:20  loss: 13.0977 (16.1382)  lr: 0.0000 (0.0000)  time: 0.197463  data: 0.000398  max mem: 3586
I20250215 11:34:48 3089994 dinov2 helpers.py:102] Training  [ 3840/12500]  eta: 0:32:17  loss: 13.0977 (16.1438)  lr: 0.0000 (0.0000)  time: 0.197593  data: 0.000394  max mem: 3586
I20250215 11:34:50 3089994 dinov2 helpers.py:102] Training  [ 3850/12500]  eta: 0:32:14  loss: 13.1910 (16.1438)  lr: 0.0000 (0.0000)  time: 0.197696  data: 0.000396  max mem: 3586
I20250215 11:34:52 3089994 dinov2 helpers.py:102] Training  [ 3860/12500]  eta: 0:32:12  loss: 13.1910 (16.1440)  lr: 0.0000 (0.0000)  time: 0.197739  data: 0.000415  max mem: 3586
I20250215 11:34:54 3089994 dinov2 helpers.py:102] Training  [ 3870/12500]  eta: 0:32:09  loss: 14.0727 (16.1452)  lr: 0.0000 (0.0000)  time: 0.197764  data: 0.000447  max mem: 3586
I20250215 11:34:56 3089994 dinov2 helpers.py:102] Training  [ 3880/12500]  eta: 0:32:06  loss: 13.0977 (16.1299)  lr: 0.0000 (0.0000)  time: 0.197786  data: 0.000465  max mem: 3586
I20250215 11:34:58 3089994 dinov2 helpers.py:102] Training  [ 3890/12500]  eta: 0:32:03  loss: 13.0977 (16.1283)  lr: 0.0000 (0.0000)  time: 0.197855  data: 0.000470  max mem: 3586
I20250215 11:35:00 3089994 dinov2 helpers.py:102] Training  [ 3900/12500]  eta: 0:32:00  loss: 14.9867 (16.1268)  lr: 0.0000 (0.0000)  time: 0.197978  data: 0.000389  max mem: 3586
I20250215 11:35:02 3089994 dinov2 helpers.py:102] Training  [ 3910/12500]  eta: 0:31:58  loss: 13.0977 (16.1145)  lr: 0.0000 (0.0000)  time: 0.197863  data: 0.000361  max mem: 3586
I20250215 11:35:04 3089994 dinov2 helpers.py:102] Training  [ 3920/12500]  eta: 0:31:55  loss: 13.0977 (16.1209)  lr: 0.0000 (0.0000)  time: 0.197968  data: 0.000419  max mem: 3586
I20250215 11:35:06 3089994 dinov2 helpers.py:102] Training  [ 3930/12500]  eta: 0:31:52  loss: 13.0977 (16.1113)  lr: 0.0000 (0.0000)  time: 0.198041  data: 0.000458  max mem: 3586
I20250215 11:35:08 3089994 dinov2 helpers.py:102] Training  [ 3940/12500]  eta: 0:31:49  loss: 13.0977 (16.0991)  lr: 0.0000 (0.0000)  time: 0.197863  data: 0.000410  max mem: 3586
I20250215 11:35:10 3089994 dinov2 helpers.py:102] Training  [ 3950/12500]  eta: 0:31:46  loss: 14.9867 (16.0964)  lr: 0.0000 (0.0000)  time: 0.197793  data: 0.000396  max mem: 3586
I20250215 11:35:12 3089994 dinov2 helpers.py:102] Training  [ 3960/12500]  eta: 0:31:44  loss: 13.2104 (16.0891)  lr: 0.0000 (0.0000)  time: 0.197801  data: 0.000413  max mem: 3586
I20250215 11:35:14 3089994 dinov2 helpers.py:102] Training  [ 3970/12500]  eta: 0:31:41  loss: 13.2104 (16.0797)  lr: 0.0000 (0.0000)  time: 0.197869  data: 0.000411  max mem: 3586
I20250215 11:35:16 3089994 dinov2 helpers.py:102] Training  [ 3980/12500]  eta: 0:31:38  loss: 14.9867 (16.0832)  lr: 0.0000 (0.0000)  time: 0.197780  data: 0.000442  max mem: 3586
I20250215 11:35:18 3089994 dinov2 helpers.py:102] Training  [ 3990/12500]  eta: 0:31:35  loss: 14.9867 (16.0848)  lr: 0.0000 (0.0000)  time: 0.197634  data: 0.000448  max mem: 3586
I20250215 11:35:20 3089994 dinov2 helpers.py:102] Training  [ 4000/12500]  eta: 0:31:33  loss: 15.0561 (16.0913)  lr: 0.0000 (0.0000)  time: 0.197506  data: 0.000416  max mem: 3586
I20250215 11:35:22 3089994 dinov2 helpers.py:102] Training  [ 4010/12500]  eta: 0:31:30  loss: 15.4976 (16.0971)  lr: 0.0000 (0.0000)  time: 0.197473  data: 0.000443  max mem: 3586
I20250215 11:35:24 3089994 dinov2 helpers.py:102] Training  [ 4020/12500]  eta: 0:31:27  loss: 15.4976 (16.0824)  lr: 0.0000 (0.0000)  time: 0.197515  data: 0.000457  max mem: 3586
I20250215 11:35:26 3089994 dinov2 helpers.py:102] Training  [ 4030/12500]  eta: 0:31:24  loss: 15.4976 (16.0789)  lr: 0.0000 (0.0000)  time: 0.197619  data: 0.000397  max mem: 3586
I20250215 11:35:28 3089994 dinov2 helpers.py:102] Training  [ 4040/12500]  eta: 0:31:22  loss: 15.4976 (16.0795)  lr: 0.0000 (0.0000)  time: 0.197653  data: 0.000378  max mem: 3586
I20250215 11:35:30 3089994 dinov2 helpers.py:102] Training  [ 4050/12500]  eta: 0:31:19  loss: 15.0561 (16.0742)  lr: 0.0000 (0.0000)  time: 0.197603  data: 0.000418  max mem: 3586
I20250215 11:35:32 3089994 dinov2 helpers.py:102] Training  [ 4060/12500]  eta: 0:31:16  loss: 15.0561 (16.0757)  lr: 0.0000 (0.0000)  time: 0.197609  data: 0.000462  max mem: 3586
I20250215 11:35:34 3089994 dinov2 helpers.py:102] Training  [ 4070/12500]  eta: 0:31:13  loss: 15.0561 (16.0747)  lr: 0.0000 (0.0000)  time: 0.197407  data: 0.000403  max mem: 3586
I20250215 11:35:36 3089994 dinov2 helpers.py:102] Training  [ 4080/12500]  eta: 0:31:11  loss: 15.0561 (16.0689)  lr: 0.0000 (0.0000)  time: 0.197394  data: 0.000409  max mem: 3586
I20250215 11:35:38 3089994 dinov2 helpers.py:102] Training  [ 4090/12500]  eta: 0:31:08  loss: 15.0561 (16.0727)  lr: 0.0000 (0.0000)  time: 0.197619  data: 0.000473  max mem: 3586
I20250215 11:35:40 3089994 dinov2 helpers.py:102] Training  [ 4100/12500]  eta: 0:31:05  loss: 14.6584 (16.0683)  lr: 0.0000 (0.0000)  time: 0.197662  data: 0.000415  max mem: 3586
I20250215 11:35:42 3089994 dinov2 helpers.py:102] Training  [ 4110/12500]  eta: 0:31:02  loss: 14.6584 (16.0647)  lr: 0.0000 (0.0000)  time: 0.197631  data: 0.000392  max mem: 3586
I20250215 11:35:44 3089994 dinov2 helpers.py:102] Training  [ 4120/12500]  eta: 0:31:00  loss: 14.6584 (16.0718)  lr: 0.0000 (0.0000)  time: 0.197699  data: 0.000420  max mem: 3586
I20250215 11:35:46 3089994 dinov2 helpers.py:102] Training  [ 4130/12500]  eta: 0:30:57  loss: 15.0561 (16.0695)  lr: 0.0000 (0.0000)  time: 0.197765  data: 0.000422  max mem: 3586
I20250215 11:35:48 3089994 dinov2 helpers.py:102] Training  [ 4140/12500]  eta: 0:30:54  loss: 15.1136 (16.0779)  lr: 0.0000 (0.0000)  time: 0.197782  data: 0.000415  max mem: 3586
I20250215 11:35:50 3089994 dinov2 helpers.py:102] Training  [ 4150/12500]  eta: 0:30:52  loss: 15.1136 (16.0677)  lr: 0.0000 (0.0000)  time: 0.197775  data: 0.000413  max mem: 3586
I20250215 11:35:52 3089994 dinov2 helpers.py:102] Training  [ 4160/12500]  eta: 0:30:49  loss: 15.6853 (16.0725)  lr: 0.0000 (0.0000)  time: 0.197674  data: 0.000438  max mem: 3586
I20250215 11:35:54 3089994 dinov2 helpers.py:102] Training  [ 4170/12500]  eta: 0:30:46  loss: 16.3234 (16.0775)  lr: 0.0000 (0.0000)  time: 0.197708  data: 0.000427  max mem: 3586
I20250215 11:35:56 3089994 dinov2 helpers.py:102] Training  [ 4180/12500]  eta: 0:30:44  loss: 15.6853 (16.0624)  lr: 0.0000 (0.0000)  time: 0.197783  data: 0.000391  max mem: 3586
I20250215 11:35:58 3089994 dinov2 helpers.py:102] Training  [ 4190/12500]  eta: 0:30:41  loss: 15.1136 (16.0529)  lr: 0.0000 (0.0000)  time: 0.198025  data: 0.000377  max mem: 3586
I20250215 11:36:00 3089994 dinov2 helpers.py:102] Training  [ 4200/12500]  eta: 0:30:38  loss: 14.6584 (16.0440)  lr: 0.0000 (0.0000)  time: 0.198073  data: 0.000413  max mem: 3586
I20250215 11:36:02 3089994 dinov2 helpers.py:102] Training  [ 4210/12500]  eta: 0:30:36  loss: 14.6584 (16.0483)  lr: 0.0000 (0.0000)  time: 0.197875  data: 0.000448  max mem: 3586
I20250215 11:36:03 3089994 dinov2 helpers.py:102] Training  [ 4220/12500]  eta: 0:30:33  loss: 14.6584 (16.0400)  lr: 0.0000 (0.0000)  time: 0.197830  data: 0.000438  max mem: 3586
I20250215 11:36:05 3089994 dinov2 helpers.py:102] Training  [ 4230/12500]  eta: 0:30:30  loss: 15.1136 (16.0444)  lr: 0.0000 (0.0000)  time: 0.197831  data: 0.000401  max mem: 3586
I20250215 11:36:07 3089994 dinov2 helpers.py:102] Training  [ 4240/12500]  eta: 0:30:28  loss: 14.6116 (16.0347)  lr: 0.0000 (0.0000)  time: 0.198071  data: 0.000353  max mem: 3586
I20250215 11:36:09 3089994 dinov2 helpers.py:102] Training  [ 4250/12500]  eta: 0:30:25  loss: 14.6116 (16.0221)  lr: 0.0000 (0.0000)  time: 0.198163  data: 0.000411  max mem: 3586
I20250215 11:36:11 3089994 dinov2 helpers.py:102] Training  [ 4260/12500]  eta: 0:30:22  loss: 14.2639 (16.0171)  lr: 0.0000 (0.0000)  time: 0.198102  data: 0.000493  max mem: 3586
I20250215 11:36:13 3089994 dinov2 helpers.py:102] Training  [ 4270/12500]  eta: 0:30:20  loss: 14.2639 (16.0227)  lr: 0.0000 (0.0000)  time: 0.198124  data: 0.000476  max mem: 3586
I20250215 11:36:15 3089994 dinov2 helpers.py:102] Training  [ 4280/12500]  eta: 0:30:17  loss: 14.6116 (16.0232)  lr: 0.0000 (0.0000)  time: 0.198320  data: 0.000442  max mem: 3586
I20250215 11:36:17 3089994 dinov2 helpers.py:102] Training  [ 4290/12500]  eta: 0:30:14  loss: 14.2639 (16.0151)  lr: 0.0000 (0.0000)  time: 0.198360  data: 0.000444  max mem: 3586
I20250215 11:36:19 3089994 dinov2 helpers.py:102] Training  [ 4300/12500]  eta: 0:30:12  loss: 14.6116 (16.0188)  lr: 0.0000 (0.0000)  time: 0.198161  data: 0.000417  max mem: 3586
I20250215 11:36:21 3089994 dinov2 helpers.py:102] Training  [ 4310/12500]  eta: 0:30:09  loss: 14.1873 (16.0146)  lr: 0.0000 (0.0000)  time: 0.198123  data: 0.000412  max mem: 3586
I20250215 11:36:23 3089994 dinov2 helpers.py:102] Training  [ 4320/12500]  eta: 0:30:06  loss: 14.1873 (16.0157)  lr: 0.0000 (0.0000)  time: 0.198043  data: 0.000424  max mem: 3586
I20250215 11:36:25 3089994 dinov2 helpers.py:102] Training  [ 4330/12500]  eta: 0:30:04  loss: 13.8811 (16.0064)  lr: 0.0000 (0.0000)  time: 0.197867  data: 0.000439  max mem: 3586
I20250215 11:36:27 3089994 dinov2 helpers.py:102] Training  [ 4340/12500]  eta: 0:30:01  loss: 13.8071 (16.0013)  lr: 0.0000 (0.0000)  time: 0.197814  data: 0.000448  max mem: 3586
I20250215 11:36:29 3089994 dinov2 helpers.py:102] Training  [ 4350/12500]  eta: 0:29:58  loss: 13.8071 (15.9902)  lr: 0.0000 (0.0000)  time: 0.197957  data: 0.000464  max mem: 3586
I20250215 11:36:31 3089994 dinov2 helpers.py:102] Training  [ 4360/12500]  eta: 0:29:56  loss: 13.0151 (15.9834)  lr: 0.0000 (0.0000)  time: 0.198122  data: 0.000464  max mem: 3586
I20250215 11:36:33 3089994 dinov2 helpers.py:102] Training  [ 4370/12500]  eta: 0:29:53  loss: 13.0151 (15.9799)  lr: 0.0000 (0.0000)  time: 0.197977  data: 0.000423  max mem: 3586
I20250215 11:36:35 3089994 dinov2 helpers.py:102] Training  [ 4380/12500]  eta: 0:29:50  loss: 13.0151 (15.9683)  lr: 0.0000 (0.0000)  time: 0.198009  data: 0.000448  max mem: 3586
I20250215 11:36:37 3089994 dinov2 helpers.py:102] Training  [ 4390/12500]  eta: 0:29:48  loss: 13.0151 (15.9598)  lr: 0.0000 (0.0000)  time: 0.198164  data: 0.000443  max mem: 3586
I20250215 11:36:39 3089994 dinov2 helpers.py:102] Training  [ 4400/12500]  eta: 0:29:45  loss: 13.3038 (15.9537)  lr: 0.0000 (0.0000)  time: 0.197890  data: 0.000427  max mem: 3586
I20250215 11:36:41 3089994 dinov2 helpers.py:102] Training  [ 4410/12500]  eta: 0:29:43  loss: 13.3038 (15.9482)  lr: 0.0000 (0.0000)  time: 0.197663  data: 0.000453  max mem: 3586
I20250215 11:36:43 3089994 dinov2 helpers.py:102] Training  [ 4420/12500]  eta: 0:29:40  loss: 13.3038 (15.9335)  lr: 0.0000 (0.0000)  time: 0.197811  data: 0.000432  max mem: 3586
I20250215 11:36:45 3089994 dinov2 helpers.py:102] Training  [ 4430/12500]  eta: 0:29:37  loss: 13.3038 (15.9312)  lr: 0.0000 (0.0000)  time: 0.197957  data: 0.000451  max mem: 3586

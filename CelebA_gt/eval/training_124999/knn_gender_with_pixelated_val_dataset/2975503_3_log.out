submitit INFO (2024-12-05 07:22:37,862) - Starting with JobEnvironment(job_id=2975503, hostname=tars, local_rank=3(8), node=0(1), global_rank=3(8))
submitit INFO (2024-12-05 07:22:37,862) - Loading pickle: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset/2975503_submitted.pkl
I20241205 07:22:47 2975509 dinov2 config.py:59] git:
  sha: 1514d8883ab0f94a8e16e2f31e7880cd543d6e95, status: has uncommitted changes, branch: main

I20241205 07:22:47 2975509 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAPixelatedVal
I20241205 07:22:47 2975509 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241205 07:22:47 2975509 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241205 07:22:48 2975509 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241205 07:23:26 2975509 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241205 07:23:32 2975509 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241205 07:23:33 2975509 dinov2 loaders.py:94] using dataset: "CelebAOriginalTrain"
Load image list
I20241205 07:23:47 2975509 dinov2 loaders.py:99] # of dataset samples: 162,127
I20241205 07:23:47 2975509 dinov2 loaders.py:94] using dataset: "CelebAPixelatedVal"
Load image list
I20241205 07:23:51 2975509 dinov2 loaders.py:99] # of dataset samples: 19,792
I20241205 07:23:51 2975509 dinov2 knn.py:260] Extracting features for train set...
I20241205 07:23:51 2975509 dinov2 loaders.py:157] sampler: distributed
I20241205 07:23:51 2975509 dinov2 loaders.py:216] using PyTorch data loader
W20241205 07:23:51 2975509 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241205 07:23:51 2975509 dinov2 loaders.py:229] # of batches: 634
I20241205 07:24:52 2975509 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241205 07:24:52 2975509 dinov2 helpers.py:102]   [  0/634]  eta: 10:47:03    time: 61.236149  data: 13.364747  max mem: 3463
I20241205 07:25:25 2975509 dinov2 helpers.py:102]   [ 10/634]  eta: 1:28:26    time: 8.503314  data: 1.218590  max mem: 4109
I20241205 07:26:04 2975509 dinov2 helpers.py:102]   [ 20/634]  eta: 1:04:50    time: 3.590853  data: 0.003817  max mem: 4109
I20241205 07:26:44 2975509 dinov2 helpers.py:102]   [ 30/634]  eta: 0:56:03    time: 3.955692  data: 0.002390  max mem: 4109
I20241205 07:27:23 2975509 dinov2 helpers.py:102]   [ 40/634]  eta: 0:51:15    time: 3.960768  data: 0.000864  max mem: 4109
I20241205 07:28:03 2975509 dinov2 helpers.py:102]   [ 50/634]  eta: 0:48:04    time: 3.961033  data: 0.001709  max mem: 4109
I20241205 07:28:43 2975509 dinov2 helpers.py:102]   [ 60/634]  eta: 0:45:42    time: 3.960128  data: 0.001951  max mem: 4109
I20241205 07:29:22 2975509 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:49    time: 3.959936  data: 0.001222  max mem: 4109
I20241205 07:30:02 2975509 dinov2 helpers.py:102]   [ 80/634]  eta: 0:42:15    time: 3.958800  data: 0.001210  max mem: 4109
I20241205 07:30:41 2975509 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:52    time: 3.959666  data: 0.001122  max mem: 4109
I20241205 07:31:21 2975509 dinov2 helpers.py:102]   [100/634]  eta: 0:39:38    time: 3.957714  data: 0.001146  max mem: 4109
I20241205 07:32:01 2975509 dinov2 helpers.py:102]   [110/634]  eta: 0:38:30    time: 3.957687  data: 0.001343  max mem: 4109
I20241205 07:32:40 2975509 dinov2 helpers.py:102]   [120/634]  eta: 0:37:27    time: 3.961377  data: 0.001285  max mem: 4109
I20241205 07:33:20 2975509 dinov2 helpers.py:102]   [130/634]  eta: 0:36:27    time: 3.959679  data: 0.001114  max mem: 4109
I20241205 07:33:59 2975509 dinov2 helpers.py:102]   [140/634]  eta: 0:35:30    time: 3.955034  data: 0.001601  max mem: 4109
I20241205 07:34:39 2975509 dinov2 helpers.py:102]   [150/634]  eta: 0:34:36    time: 3.954097  data: 0.001704  max mem: 4109
I20241205 07:35:18 2975509 dinov2 helpers.py:102]   [160/634]  eta: 0:33:43    time: 3.954390  data: 0.001261  max mem: 4109
I20241205 07:35:58 2975509 dinov2 helpers.py:102]   [170/634]  eta: 0:32:52    time: 3.954370  data: 0.000955  max mem: 4109
I20241205 07:36:37 2975509 dinov2 helpers.py:102]   [180/634]  eta: 0:32:02    time: 3.954462  data: 0.001388  max mem: 4109
I20241205 07:37:17 2975509 dinov2 helpers.py:102]   [190/634]  eta: 0:31:13    time: 3.952605  data: 0.001529  max mem: 4109
I20241205 07:37:57 2975509 dinov2 helpers.py:102]   [200/634]  eta: 0:30:25    time: 3.952420  data: 0.001239  max mem: 4109
I20241205 07:38:36 2975509 dinov2 helpers.py:102]   [210/634]  eta: 0:29:38    time: 3.952406  data: 0.001026  max mem: 4109
I20241205 07:39:16 2975509 dinov2 helpers.py:102]   [220/634]  eta: 0:28:51    time: 3.952489  data: 0.000716  max mem: 4109
I20241205 07:39:55 2975509 dinov2 helpers.py:102]   [230/634]  eta: 0:28:05    time: 3.954328  data: 0.001185  max mem: 4109
I20241205 07:40:35 2975509 dinov2 helpers.py:102]   [240/634]  eta: 0:27:20    time: 3.954413  data: 0.001099  max mem: 4109
I20241205 07:41:14 2975509 dinov2 helpers.py:102]   [250/634]  eta: 0:26:35    time: 3.952542  data: 0.003266  max mem: 4109
I20241205 07:41:54 2975509 dinov2 helpers.py:102]   [260/634]  eta: 0:25:51    time: 3.952660  data: 0.003446  max mem: 4109
I20241205 07:42:33 2975509 dinov2 helpers.py:102]   [270/634]  eta: 0:25:07    time: 3.952396  data: 0.000736  max mem: 4109
I20241205 07:43:13 2975509 dinov2 helpers.py:102]   [280/634]  eta: 0:24:23    time: 3.953152  data: 0.000881  max mem: 4109
I20241205 07:43:52 2975509 dinov2 helpers.py:102]   [290/634]  eta: 0:23:39    time: 3.954530  data: 0.000969  max mem: 4109
I20241205 07:44:32 2975509 dinov2 helpers.py:102]   [300/634]  eta: 0:22:56    time: 3.956573  data: 0.002188  max mem: 4109
I20241205 07:45:11 2975509 dinov2 helpers.py:102]   [310/634]  eta: 0:22:13    time: 3.955720  data: 0.002416  max mem: 4109
I20241205 07:45:51 2975509 dinov2 helpers.py:102]   [320/634]  eta: 0:21:31    time: 3.955842  data: 0.001224  max mem: 4109
I20241205 07:46:31 2975509 dinov2 helpers.py:102]   [330/634]  eta: 0:20:48    time: 3.958282  data: 0.001130  max mem: 4109
I20241205 07:47:10 2975509 dinov2 helpers.py:102]   [340/634]  eta: 0:20:06    time: 3.956998  data: 0.001235  max mem: 4109
I20241205 07:47:50 2975509 dinov2 helpers.py:102]   [350/634]  eta: 0:19:23    time: 3.954213  data: 0.001298  max mem: 4109
I20241205 07:48:29 2975509 dinov2 helpers.py:102]   [360/634]  eta: 0:18:41    time: 3.952023  data: 0.001205  max mem: 4109
I20241205 07:49:09 2975509 dinov2 helpers.py:102]   [370/634]  eta: 0:17:59    time: 3.953677  data: 0.001157  max mem: 4109
I20241205 07:49:48 2975509 dinov2 helpers.py:102]   [380/634]  eta: 0:17:18    time: 3.953821  data: 0.001109  max mem: 4109
I20241205 07:50:28 2975509 dinov2 helpers.py:102]   [390/634]  eta: 0:16:36    time: 3.953210  data: 0.001416  max mem: 4109
I20241205 07:51:07 2975509 dinov2 helpers.py:102]   [400/634]  eta: 0:15:54    time: 3.955189  data: 0.002573  max mem: 4109
I20241205 07:51:47 2975509 dinov2 helpers.py:102]   [410/634]  eta: 0:15:13    time: 3.955070  data: 0.002138  max mem: 4109
I20241205 07:52:26 2975509 dinov2 helpers.py:102]   [420/634]  eta: 0:14:31    time: 3.954159  data: 0.002282  max mem: 4109
I20241205 07:53:06 2975509 dinov2 helpers.py:102]   [430/634]  eta: 0:13:50    time: 3.956233  data: 0.002614  max mem: 4109
I20241205 07:53:46 2975509 dinov2 helpers.py:102]   [440/634]  eta: 0:13:09    time: 3.964917  data: 0.001335  max mem: 4109
I20241205 07:54:25 2975509 dinov2 helpers.py:102]   [450/634]  eta: 0:12:28    time: 3.970826  data: 0.001178  max mem: 4109
I20241205 07:55:05 2975509 dinov2 helpers.py:102]   [460/634]  eta: 0:11:47    time: 3.969251  data: 0.001621  max mem: 4109
I20241205 07:55:45 2975509 dinov2 helpers.py:102]   [470/634]  eta: 0:11:06    time: 3.967297  data: 0.001616  max mem: 4109
I20241205 07:56:25 2975509 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.968880  data: 0.001054  max mem: 4109
I20241205 07:57:04 2975509 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.970453  data: 0.001028  max mem: 4109
I20241205 07:57:44 2975509 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.969631  data: 0.001240  max mem: 4109
I20241205 07:58:24 2975509 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.969060  data: 0.001181  max mem: 4109
I20241205 07:59:03 2975509 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.969116  data: 0.001405  max mem: 4109
I20241205 07:59:43 2975509 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.971462  data: 0.001237  max mem: 4109
I20241205 08:00:23 2975509 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.972373  data: 0.000794  max mem: 4109
I20241205 08:01:03 2975509 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.972474  data: 0.001040  max mem: 4109
I20241205 08:01:42 2975509 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.972664  data: 0.000776  max mem: 4109
I20241205 08:02:22 2975509 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.972189  data: 0.000837  max mem: 4109
I20241205 08:03:02 2975509 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.971418  data: 0.001741  max mem: 4109
I20241205 08:03:41 2975509 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.970731  data: 0.001648  max mem: 4109
I20241205 08:04:19 2975509 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.860973  data: 0.000927  max mem: 4109
I20241205 08:04:57 2975509 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.792042  data: 0.000925  max mem: 4109
I20241205 08:05:36 2975509 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.878432  data: 0.000860  max mem: 4109
I20241205 08:06:16 2975509 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.927203  data: 0.000654  max mem: 4109
I20241205 08:06:34 2975509 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.263975  data: 0.000596  max mem: 4109
I20241205 08:06:35 2975509 dinov2 helpers.py:130]  Total time: 0:42:43 (4.043281 s / it)
I20241205 08:06:35 2975509 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241205 08:06:35 2975509 dinov2 utils.py:142] Labels shape: (162127,)
I20241205 08:06:35 2975509 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241205 08:06:35 2975509 dinov2 loaders.py:157] sampler: distributed
I20241205 08:06:35 2975509 dinov2 loaders.py:216] using PyTorch data loader
I20241205 08:06:35 2975509 dinov2 loaders.py:229] # of batches: 78
I20241205 08:06:35 2975509 dinov2 knn.py:299] Start the k-NN classification.
I20241205 08:06:48 2975509 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:15:57    time: 12.273630  data: 9.160618  max mem: 4109
I20241205 08:07:28 2975509 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:21    time: 4.722430  data: 0.838646  max mem: 4109
I20241205 08:08:08 2975509 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:13    time: 3.981515  data: 0.006845  max mem: 4109
I20241205 08:08:48 2975509 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:24    time: 3.998349  data: 0.005418  max mem: 4109
I20241205 08:09:21 2975509 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:32    time: 3.631404  data: 0.005092  max mem: 4109
I20241205 08:09:49 2975509 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:46    time: 3.065839  data: 0.004790  max mem: 4109
I20241205 08:10:14 2975509 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:04    time: 2.685175  data: 0.007007  max mem: 4109
I20241205 08:10:39 2975509 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:27    time: 2.480619  data: 0.006261  max mem: 4109
I20241205 08:10:52 2975509 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.235987  data: 0.002503  max mem: 4109
I20241205 08:10:52 2975509 dinov2 helpers.py:130] Test: Total time: 0:04:15 (3.276440 s / it)
I20241205 08:10:52 2975509 dinov2 utils.py:79] Averaged stats: 
I20241205 08:10:52 2975509 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 75.06
I20241205 08:10:52 2975509 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 75.91
I20241205 08:10:52 2975509 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 77.50
I20241205 08:10:52 2975509 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 78.01
submitit INFO (2024-12-05 08:10:52,634) - Job completed successfully
I20241205 08:10:52 2975509 submitit submission.py:56] Job completed successfully
submitit INFO (2024-12-05 08:10:52,636) - Exiting after successful completion
I20241205 08:10:52 2975509 submitit submission.py:61] Exiting after successful completion

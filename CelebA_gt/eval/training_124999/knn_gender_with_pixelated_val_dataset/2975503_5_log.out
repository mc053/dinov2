submitit INFO (2024-12-05 07:22:37,808) - Starting with JobEnvironment(job_id=2975503, hostname=tars, local_rank=5(8), node=0(1), global_rank=5(8))
submitit INFO (2024-12-05 07:22:37,808) - Loading pickle: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset/2975503_submitted.pkl
I20241205 07:22:47 2975511 dinov2 config.py:59] git:
  sha: 1514d8883ab0f94a8e16e2f31e7880cd543d6e95, status: has uncommitted changes, branch: main

I20241205 07:22:47 2975511 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAPixelatedVal
I20241205 07:22:47 2975511 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241205 07:22:47 2975511 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241205 07:22:47 2975511 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241205 07:23:13 2975511 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241205 07:23:17 2975511 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241205 07:23:17 2975511 dinov2 loaders.py:94] using dataset: "CelebAOriginalTrain"
Load image list
I20241205 07:23:25 2975511 dinov2 loaders.py:99] # of dataset samples: 162,127
I20241205 07:23:25 2975511 dinov2 loaders.py:94] using dataset: "CelebAPixelatedVal"
Creating image list
I20241205 07:23:28 2975511 dinov2 loaders.py:99] # of dataset samples: 19,792
I20241205 07:23:28 2975511 dinov2 knn.py:260] Extracting features for train set...
I20241205 07:23:28 2975511 dinov2 loaders.py:157] sampler: distributed
I20241205 07:23:28 2975511 dinov2 loaders.py:216] using PyTorch data loader
W20241205 07:23:28 2975511 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241205 07:23:28 2975511 dinov2 loaders.py:229] # of batches: 634
I20241205 07:23:58 2975511 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241205 07:23:58 2975511 dinov2 helpers.py:102]   [  0/634]  eta: 5:22:56    time: 30.561743  data: 11.007779  max mem: 3463
I20241205 07:24:04 2975511 dinov2 helpers.py:102]   [ 10/634]  eta: 0:34:38    time: 3.331525  data: 1.004641  max mem: 4109
I20241205 07:24:16 2975511 dinov2 helpers.py:102]   [ 20/634]  eta: 0:23:36    time: 0.894583  data: 0.502905  max mem: 4109
I20241205 07:24:31 2975511 dinov2 helpers.py:102]   [ 30/634]  eta: 0:20:34    time: 1.336713  data: 0.688495  max mem: 4109
I20241205 07:24:47 2975511 dinov2 helpers.py:102]   [ 40/634]  eta: 0:19:13    time: 1.558829  data: 0.187964  max mem: 4109
I20241205 07:25:22 2975511 dinov2 helpers.py:102]   [ 50/634]  eta: 0:21:53    time: 2.567373  data: 0.001801  max mem: 4109
I20241205 07:26:02 2975511 dinov2 helpers.py:102]   [ 60/634]  eta: 0:24:11    time: 3.730692  data: 0.002131  max mem: 4109
I20241205 07:26:42 2975511 dinov2 helpers.py:102]   [ 70/634]  eta: 0:25:39    time: 3.954733  data: 0.001146  max mem: 4109
I20241205 07:27:21 2975511 dinov2 helpers.py:102]   [ 80/634]  eta: 0:26:36    time: 3.959032  data: 0.001089  max mem: 4109
I20241205 07:28:01 2975511 dinov2 helpers.py:102]   [ 90/634]  eta: 0:27:12    time: 3.961091  data: 0.001692  max mem: 4109
I20241205 07:28:40 2975511 dinov2 helpers.py:102]   [100/634]  eta: 0:27:32    time: 3.958366  data: 0.001714  max mem: 4109
I20241205 07:29:20 2975511 dinov2 helpers.py:102]   [110/634]  eta: 0:27:42    time: 3.955479  data: 0.001124  max mem: 4109
I20241205 07:29:59 2975511 dinov2 helpers.py:102]   [120/634]  eta: 0:27:43    time: 3.956060  data: 0.001069  max mem: 4109
I20241205 07:30:39 2975511 dinov2 helpers.py:102]   [130/634]  eta: 0:27:39    time: 3.954280  data: 0.001077  max mem: 4109
I20241205 07:31:18 2975511 dinov2 helpers.py:102]   [140/634]  eta: 0:27:29    time: 3.953351  data: 0.001087  max mem: 4109
I20241205 07:31:58 2975511 dinov2 helpers.py:102]   [150/634]  eta: 0:27:15    time: 3.953043  data: 0.000755  max mem: 4109
I20241205 07:32:38 2975511 dinov2 helpers.py:102]   [160/634]  eta: 0:26:58    time: 3.953215  data: 0.000558  max mem: 4109
I20241205 07:33:17 2975511 dinov2 helpers.py:102]   [170/634]  eta: 0:26:39    time: 3.955293  data: 0.000667  max mem: 4109
I20241205 07:33:57 2975511 dinov2 helpers.py:102]   [180/634]  eta: 0:26:17    time: 3.955307  data: 0.001057  max mem: 4109
I20241205 07:34:36 2975511 dinov2 helpers.py:102]   [190/634]  eta: 0:25:53    time: 3.954109  data: 0.001490  max mem: 4109
I20241205 07:35:16 2975511 dinov2 helpers.py:102]   [200/634]  eta: 0:25:28    time: 3.954952  data: 0.001144  max mem: 4109
I20241205 07:35:55 2975511 dinov2 helpers.py:102]   [210/634]  eta: 0:25:02    time: 3.954402  data: 0.000576  max mem: 4109
I20241205 07:36:35 2975511 dinov2 helpers.py:102]   [220/634]  eta: 0:24:34    time: 3.953651  data: 0.000535  max mem: 4109
I20241205 07:37:14 2975511 dinov2 helpers.py:102]   [230/634]  eta: 0:24:05    time: 3.954424  data: 0.001144  max mem: 4109
I20241205 07:37:54 2975511 dinov2 helpers.py:102]   [240/634]  eta: 0:23:36    time: 3.953292  data: 0.001484  max mem: 4109
I20241205 07:38:33 2975511 dinov2 helpers.py:102]   [250/634]  eta: 0:23:05    time: 3.952385  data: 0.001009  max mem: 4109
I20241205 07:39:13 2975511 dinov2 helpers.py:102]   [260/634]  eta: 0:22:34    time: 3.953286  data: 0.000987  max mem: 4109
I20241205 07:39:53 2975511 dinov2 helpers.py:102]   [270/634]  eta: 0:22:02    time: 3.954406  data: 0.001515  max mem: 4109
I20241205 07:40:32 2975511 dinov2 helpers.py:102]   [280/634]  eta: 0:21:30    time: 3.953640  data: 0.002009  max mem: 4109
I20241205 07:41:12 2975511 dinov2 helpers.py:102]   [290/634]  eta: 0:20:57    time: 3.952479  data: 0.002130  max mem: 4109
I20241205 07:41:51 2975511 dinov2 helpers.py:102]   [300/634]  eta: 0:20:24    time: 3.952469  data: 0.002425  max mem: 4109
I20241205 07:42:31 2975511 dinov2 helpers.py:102]   [310/634]  eta: 0:19:50    time: 3.952408  data: 0.001754  max mem: 4109
I20241205 07:43:10 2975511 dinov2 helpers.py:102]   [320/634]  eta: 0:19:16    time: 3.952270  data: 0.001326  max mem: 4109
I20241205 07:43:50 2975511 dinov2 helpers.py:102]   [330/634]  eta: 0:18:42    time: 3.954406  data: 0.001497  max mem: 4109
I20241205 07:44:29 2975511 dinov2 helpers.py:102]   [340/634]  eta: 0:18:07    time: 3.955839  data: 0.001391  max mem: 4109
I20241205 07:45:09 2975511 dinov2 helpers.py:102]   [350/634]  eta: 0:17:32    time: 3.954293  data: 0.001385  max mem: 4109
I20241205 07:45:48 2975511 dinov2 helpers.py:102]   [360/634]  eta: 0:16:57    time: 3.955788  data: 0.002083  max mem: 4109
I20241205 07:46:28 2975511 dinov2 helpers.py:102]   [370/634]  eta: 0:16:22    time: 3.955236  data: 0.001882  max mem: 4109
I20241205 07:47:07 2975511 dinov2 helpers.py:102]   [380/634]  eta: 0:15:46    time: 3.954310  data: 0.000767  max mem: 4109
I20241205 07:47:47 2975511 dinov2 helpers.py:102]   [390/634]  eta: 0:15:10    time: 3.954297  data: 0.000829  max mem: 4109
I20241205 07:48:27 2975511 dinov2 helpers.py:102]   [400/634]  eta: 0:14:34    time: 3.952073  data: 0.000964  max mem: 4109
I20241205 07:49:06 2975511 dinov2 helpers.py:102]   [410/634]  eta: 0:13:58    time: 3.951887  data: 0.001165  max mem: 4109
I20241205 07:49:46 2975511 dinov2 helpers.py:102]   [420/634]  eta: 0:13:22    time: 3.952059  data: 0.001154  max mem: 4109
I20241205 07:50:25 2975511 dinov2 helpers.py:102]   [430/634]  eta: 0:12:45    time: 3.954091  data: 0.001224  max mem: 4109
I20241205 07:51:05 2975511 dinov2 helpers.py:102]   [440/634]  eta: 0:12:08    time: 3.955905  data: 0.001972  max mem: 4109
I20241205 07:51:44 2975511 dinov2 helpers.py:102]   [450/634]  eta: 0:11:32    time: 3.956009  data: 0.001595  max mem: 4109
I20241205 07:52:24 2975511 dinov2 helpers.py:102]   [460/634]  eta: 0:10:55    time: 3.957929  data: 0.000574  max mem: 4109
I20241205 07:53:03 2975511 dinov2 helpers.py:102]   [470/634]  eta: 0:10:18    time: 3.958886  data: 0.000552  max mem: 4109
I20241205 07:53:43 2975511 dinov2 helpers.py:102]   [480/634]  eta: 0:09:41    time: 3.958574  data: 0.000755  max mem: 4109
I20241205 07:54:23 2975511 dinov2 helpers.py:102]   [490/634]  eta: 0:09:04    time: 3.962716  data: 0.000911  max mem: 4109
I20241205 07:55:02 2975511 dinov2 helpers.py:102]   [500/634]  eta: 0:08:26    time: 3.967467  data: 0.000728  max mem: 4109
I20241205 07:55:42 2975511 dinov2 helpers.py:102]   [510/634]  eta: 0:07:49    time: 3.965521  data: 0.001005  max mem: 4109
I20241205 07:56:22 2975511 dinov2 helpers.py:102]   [520/634]  eta: 0:07:11    time: 3.966656  data: 0.001111  max mem: 4109
I20241205 07:57:01 2975511 dinov2 helpers.py:102]   [530/634]  eta: 0:06:34    time: 3.970431  data: 0.000698  max mem: 4109
I20241205 07:57:41 2975511 dinov2 helpers.py:102]   [540/634]  eta: 0:05:56    time: 3.968276  data: 0.000581  max mem: 4109
I20241205 07:58:21 2975511 dinov2 helpers.py:102]   [550/634]  eta: 0:05:19    time: 3.965402  data: 0.001762  max mem: 4109
I20241205 07:59:00 2975511 dinov2 helpers.py:102]   [560/634]  eta: 0:04:41    time: 3.967283  data: 0.001993  max mem: 4109
I20241205 07:59:40 2975511 dinov2 helpers.py:102]   [570/634]  eta: 0:04:03    time: 3.969513  data: 0.001572  max mem: 4109
I20241205 08:00:20 2975511 dinov2 helpers.py:102]   [580/634]  eta: 0:03:25    time: 3.969640  data: 0.003109  max mem: 4109
I20241205 08:01:00 2975511 dinov2 helpers.py:102]   [590/634]  eta: 0:02:47    time: 3.971616  data: 0.002673  max mem: 4109
I20241205 08:01:39 2975511 dinov2 helpers.py:102]   [600/634]  eta: 0:02:09    time: 3.972572  data: 0.001328  max mem: 4109
I20241205 08:02:19 2975511 dinov2 helpers.py:102]   [610/634]  eta: 0:01:31    time: 3.972332  data: 0.001226  max mem: 4109
I20241205 08:02:59 2975511 dinov2 helpers.py:102]   [620/634]  eta: 0:00:53    time: 3.972308  data: 0.000898  max mem: 4109
I20241205 08:03:38 2975511 dinov2 helpers.py:102]   [630/634]  eta: 0:00:15    time: 3.971647  data: 0.001648  max mem: 4109
I20241205 08:03:57 2975511 dinov2 helpers.py:102]   [633/634]  eta: 0:00:03    time: 4.292352  data: 0.001486  max mem: 4109
I20241205 08:03:57 2975511 dinov2 helpers.py:130]  Total time: 0:40:29 (3.831849 s / it)
I20241205 08:03:57 2975511 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241205 08:03:57 2975511 dinov2 utils.py:142] Labels shape: (162127,)
I20241205 08:03:58 2975511 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241205 08:03:58 2975511 dinov2 loaders.py:157] sampler: distributed
I20241205 08:03:58 2975511 dinov2 loaders.py:216] using PyTorch data loader
I20241205 08:03:58 2975511 dinov2 loaders.py:229] # of batches: 78
I20241205 08:03:58 2975511 dinov2 knn.py:299] Start the k-NN classification.
I20241205 08:04:08 2975511 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:12:11    time: 9.381402  data: 5.278734  max mem: 4109
I20241205 08:04:49 2975511 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:10    time: 4.563715  data: 0.486086  max mem: 4109
I20241205 08:05:29 2975511 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:09    time: 4.043848  data: 0.005958  max mem: 4109
I20241205 08:06:10 2975511 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:22    time: 4.037110  data: 0.004870  max mem: 4109
I20241205 08:06:42 2975511 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:31    time: 3.677903  data: 0.004606  max mem: 4109
I20241205 08:07:20 2975511 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:50    time: 3.514580  data: 0.004692  max mem: 4109
I20241205 08:08:00 2975511 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:11    time: 3.867654  data: 0.005642  max mem: 4109
I20241205 08:08:40 2975511 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:31    time: 3.992924  data: 0.005569  max mem: 4109
I20241205 08:09:04 2975511 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 3.807679  data: 0.003490  max mem: 4109
I20241205 08:09:04 2975511 dinov2 helpers.py:130] Test: Total time: 0:05:05 (3.914607 s / it)
I20241205 08:09:04 2975511 dinov2 utils.py:79] Averaged stats: 
I20241205 08:09:05 2975511 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 75.06
I20241205 08:09:05 2975511 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 75.91
I20241205 08:09:05 2975511 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 77.50
I20241205 08:09:05 2975511 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 78.01
submitit INFO (2024-12-05 08:09:06,111) - Job completed successfully
I20241205 08:09:06 2975511 submitit submission.py:56] Job completed successfully
submitit INFO (2024-12-05 08:09:06,137) - Exiting after successful completion
I20241205 08:09:06 2975511 submitit submission.py:61] Exiting after successful completion

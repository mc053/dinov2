submitit INFO (2024-12-05 07:22:37,879) - Starting with JobEnvironment(job_id=2975503, hostname=tars, local_rank=7(8), node=0(1), global_rank=7(8))
submitit INFO (2024-12-05 07:22:37,879) - Loading pickle: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset/2975503_submitted.pkl
I20241205 07:22:47 2975514 dinov2 config.py:59] git:
  sha: 1514d8883ab0f94a8e16e2f31e7880cd543d6e95, status: has uncommitted changes, branch: main

I20241205 07:22:47 2975514 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAPixelatedVal
I20241205 07:22:47 2975514 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241205 07:22:47 2975514 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241205 07:22:48 2975514 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241205 07:23:27 2975514 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241205 07:23:33 2975514 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241205 07:23:33 2975514 dinov2 loaders.py:94] using dataset: "CelebAOriginalTrain"
Load image list
I20241205 07:23:47 2975514 dinov2 loaders.py:99] # of dataset samples: 162,127
I20241205 07:23:47 2975514 dinov2 loaders.py:94] using dataset: "CelebAPixelatedVal"
Load image list
I20241205 07:23:51 2975514 dinov2 loaders.py:99] # of dataset samples: 19,792
I20241205 07:23:51 2975514 dinov2 knn.py:260] Extracting features for train set...
I20241205 07:23:51 2975514 dinov2 loaders.py:157] sampler: distributed
I20241205 07:23:51 2975514 dinov2 loaders.py:216] using PyTorch data loader
W20241205 07:23:51 2975514 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241205 07:23:51 2975514 dinov2 loaders.py:229] # of batches: 634
I20241205 07:24:55 2975514 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241205 07:24:55 2975514 dinov2 helpers.py:102]   [  0/634]  eta: 11:09:14    time: 63.334702  data: 19.531212  max mem: 3463
I20241205 07:25:27 2975514 dinov2 helpers.py:102]   [ 10/634]  eta: 1:30:34    time: 8.708767  data: 1.779624  max mem: 4109
I20241205 07:26:07 2975514 dinov2 helpers.py:102]   [ 20/634]  eta: 1:05:56    time: 3.599054  data: 0.002666  max mem: 4109
I20241205 07:26:46 2975514 dinov2 helpers.py:102]   [ 30/634]  eta: 0:56:48    time: 3.956464  data: 0.001232  max mem: 4109
I20241205 07:27:26 2975514 dinov2 helpers.py:102]   [ 40/634]  eta: 0:51:48    time: 3.960576  data: 0.001442  max mem: 4109
I20241205 07:28:05 2975514 dinov2 helpers.py:102]   [ 50/634]  eta: 0:48:30    time: 3.960250  data: 0.001031  max mem: 4109
I20241205 07:28:45 2975514 dinov2 helpers.py:102]   [ 60/634]  eta: 0:46:04    time: 3.961955  data: 0.001782  max mem: 4109
I20241205 07:29:25 2975514 dinov2 helpers.py:102]   [ 70/634]  eta: 0:44:08    time: 3.963515  data: 0.001691  max mem: 4109
I20241205 07:30:04 2975514 dinov2 helpers.py:102]   [ 80/634]  eta: 0:42:30    time: 3.958770  data: 0.000900  max mem: 4109
I20241205 07:30:44 2975514 dinov2 helpers.py:102]   [ 90/634]  eta: 0:41:05    time: 3.955123  data: 0.000926  max mem: 4109
I20241205 07:31:23 2975514 dinov2 helpers.py:102]   [100/634]  eta: 0:39:50    time: 3.955973  data: 0.001343  max mem: 4109
I20241205 07:32:03 2975514 dinov2 helpers.py:102]   [110/634]  eta: 0:38:40    time: 3.954029  data: 0.001609  max mem: 4109
I20241205 07:32:43 2975514 dinov2 helpers.py:102]   [120/634]  eta: 0:37:36    time: 3.955055  data: 0.001495  max mem: 4109
I20241205 07:33:22 2975514 dinov2 helpers.py:102]   [130/634]  eta: 0:36:35    time: 3.957584  data: 0.001440  max mem: 4109
I20241205 07:34:02 2975514 dinov2 helpers.py:102]   [140/634]  eta: 0:35:38    time: 3.954124  data: 0.000851  max mem: 4109
I20241205 07:34:41 2975514 dinov2 helpers.py:102]   [150/634]  eta: 0:34:42    time: 3.953539  data: 0.001109  max mem: 4109
I20241205 07:35:21 2975514 dinov2 helpers.py:102]   [160/634]  eta: 0:33:49    time: 3.955208  data: 0.002073  max mem: 4109
I20241205 07:36:00 2975514 dinov2 helpers.py:102]   [170/634]  eta: 0:32:57    time: 3.955333  data: 0.001900  max mem: 4109
I20241205 07:36:40 2975514 dinov2 helpers.py:102]   [180/634]  eta: 0:32:07    time: 3.954615  data: 0.001047  max mem: 4109
I20241205 07:37:19 2975514 dinov2 helpers.py:102]   [190/634]  eta: 0:31:18    time: 3.952615  data: 0.000904  max mem: 4109
I20241205 07:37:59 2975514 dinov2 helpers.py:102]   [200/634]  eta: 0:30:29    time: 3.952331  data: 0.001056  max mem: 4109
I20241205 07:38:38 2975514 dinov2 helpers.py:102]   [210/634]  eta: 0:29:42    time: 3.952382  data: 0.001544  max mem: 4109
I20241205 07:39:18 2975514 dinov2 helpers.py:102]   [220/634]  eta: 0:28:55    time: 3.954264  data: 0.001549  max mem: 4109
I20241205 07:39:57 2975514 dinov2 helpers.py:102]   [230/634]  eta: 0:28:09    time: 3.954407  data: 0.000855  max mem: 4109
I20241205 07:40:37 2975514 dinov2 helpers.py:102]   [240/634]  eta: 0:27:24    time: 3.952718  data: 0.000571  max mem: 4109
I20241205 07:41:17 2975514 dinov2 helpers.py:102]   [250/634]  eta: 0:26:38    time: 3.952494  data: 0.001258  max mem: 4109
I20241205 07:41:56 2975514 dinov2 helpers.py:102]   [260/634]  eta: 0:25:54    time: 3.952438  data: 0.001752  max mem: 4109
I20241205 07:42:36 2975514 dinov2 helpers.py:102]   [270/634]  eta: 0:25:09    time: 3.952482  data: 0.001464  max mem: 4109
I20241205 07:43:15 2975514 dinov2 helpers.py:102]   [280/634]  eta: 0:24:26    time: 3.954229  data: 0.001462  max mem: 4109
I20241205 07:43:55 2975514 dinov2 helpers.py:102]   [290/634]  eta: 0:23:42    time: 3.954335  data: 0.001429  max mem: 4109
I20241205 07:44:34 2975514 dinov2 helpers.py:102]   [300/634]  eta: 0:22:59    time: 3.954835  data: 0.000905  max mem: 4109
I20241205 07:45:14 2975514 dinov2 helpers.py:102]   [310/634]  eta: 0:22:16    time: 3.955840  data: 0.001317  max mem: 4109
I20241205 07:45:53 2975514 dinov2 helpers.py:102]   [320/634]  eta: 0:21:33    time: 3.953948  data: 0.001651  max mem: 4109
I20241205 07:46:33 2975514 dinov2 helpers.py:102]   [330/634]  eta: 0:20:50    time: 3.954542  data: 0.001276  max mem: 4109
I20241205 07:47:12 2975514 dinov2 helpers.py:102]   [340/634]  eta: 0:20:07    time: 3.954428  data: 0.002213  max mem: 4109
I20241205 07:47:52 2975514 dinov2 helpers.py:102]   [350/634]  eta: 0:19:25    time: 3.952490  data: 0.002629  max mem: 4109
I20241205 07:48:31 2975514 dinov2 helpers.py:102]   [360/634]  eta: 0:18:43    time: 3.951914  data: 0.001619  max mem: 4109
I20241205 07:49:11 2975514 dinov2 helpers.py:102]   [370/634]  eta: 0:18:01    time: 3.951899  data: 0.001032  max mem: 4109
I20241205 07:49:50 2975514 dinov2 helpers.py:102]   [380/634]  eta: 0:17:19    time: 3.952042  data: 0.001080  max mem: 4109
I20241205 07:50:30 2975514 dinov2 helpers.py:102]   [390/634]  eta: 0:16:37    time: 3.954093  data: 0.001529  max mem: 4109
I20241205 07:51:10 2975514 dinov2 helpers.py:102]   [400/634]  eta: 0:15:55    time: 3.956005  data: 0.001412  max mem: 4109
I20241205 07:51:49 2975514 dinov2 helpers.py:102]   [410/634]  eta: 0:15:14    time: 3.954202  data: 0.000821  max mem: 4109
I20241205 07:52:29 2975514 dinov2 helpers.py:102]   [420/634]  eta: 0:14:32    time: 3.953360  data: 0.000800  max mem: 4109
I20241205 07:53:08 2975514 dinov2 helpers.py:102]   [430/634]  eta: 0:13:51    time: 3.960747  data: 0.000838  max mem: 4109
I20241205 07:53:48 2975514 dinov2 helpers.py:102]   [440/634]  eta: 0:13:10    time: 3.965832  data: 0.001555  max mem: 4109
I20241205 07:54:28 2975514 dinov2 helpers.py:102]   [450/634]  eta: 0:12:29    time: 3.965473  data: 0.002187  max mem: 4109
I20241205 07:55:07 2975514 dinov2 helpers.py:102]   [460/634]  eta: 0:11:48    time: 3.969583  data: 0.001863  max mem: 4109
I20241205 07:55:47 2975514 dinov2 helpers.py:102]   [470/634]  eta: 0:11:07    time: 3.971895  data: 0.001357  max mem: 4109
I20241205 07:56:27 2975514 dinov2 helpers.py:102]   [480/634]  eta: 0:10:26    time: 3.971874  data: 0.001341  max mem: 4109
I20241205 07:57:07 2975514 dinov2 helpers.py:102]   [490/634]  eta: 0:09:45    time: 3.970351  data: 0.001728  max mem: 4109
I20241205 07:57:46 2975514 dinov2 helpers.py:102]   [500/634]  eta: 0:09:04    time: 3.968992  data: 0.002121  max mem: 4109
I20241205 07:58:26 2975514 dinov2 helpers.py:102]   [510/634]  eta: 0:08:23    time: 3.967265  data: 0.002266  max mem: 4109
I20241205 07:59:06 2975514 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.968251  data: 0.001495  max mem: 4109
I20241205 07:59:45 2975514 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.972121  data: 0.000752  max mem: 4109
I20241205 08:00:25 2975514 dinov2 helpers.py:102]   [540/634]  eta: 0:06:21    time: 3.972357  data: 0.000775  max mem: 4109
I20241205 08:01:05 2975514 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.972620  data: 0.000976  max mem: 4109
I20241205 08:01:44 2975514 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.970779  data: 0.000936  max mem: 4109
I20241205 08:02:24 2975514 dinov2 helpers.py:102]   [570/634]  eta: 0:04:19    time: 3.968694  data: 0.001056  max mem: 4109
I20241205 08:03:04 2975514 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.970571  data: 0.001081  max mem: 4109
I20241205 08:03:44 2975514 dinov2 helpers.py:102]   [590/634]  eta: 0:02:58    time: 3.970017  data: 0.000809  max mem: 4109
I20241205 08:04:21 2975514 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.857901  data: 0.000760  max mem: 4109
I20241205 08:04:59 2975514 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.789109  data: 0.000933  max mem: 4109
I20241205 08:05:38 2975514 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.873290  data: 0.000948  max mem: 4109
I20241205 08:06:18 2975514 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.918590  data: 0.000687  max mem: 4109
I20241205 08:06:36 2975514 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.240778  data: 0.000589  max mem: 4109
I20241205 08:06:36 2975514 dinov2 helpers.py:130]  Total time: 0:42:44 (4.045684 s / it)
I20241205 08:06:36 2975514 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241205 08:06:36 2975514 dinov2 utils.py:142] Labels shape: (162127,)
I20241205 08:06:37 2975514 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241205 08:06:37 2975514 dinov2 loaders.py:157] sampler: distributed
I20241205 08:06:37 2975514 dinov2 loaders.py:216] using PyTorch data loader
I20241205 08:06:37 2975514 dinov2 loaders.py:229] # of batches: 78
I20241205 08:06:37 2975514 dinov2 knn.py:299] Start the k-NN classification.
I20241205 08:06:53 2975514 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:20:32    time: 15.804076  data: 11.776560  max mem: 4109
I20241205 08:07:33 2975514 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:43    time: 5.047987  data: 1.078784  max mem: 4109
I20241205 08:08:13 2975514 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:23    time: 3.988526  data: 0.008694  max mem: 4109
I20241205 08:08:53 2975514 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:30    time: 4.006067  data: 0.008280  max mem: 4109
I20241205 08:09:24 2975514 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:34    time: 3.574291  data: 0.008292  max mem: 4109
I20241205 08:09:53 2975514 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:47    time: 2.979662  data: 0.008655  max mem: 4109
I20241205 08:10:18 2975514 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:05    time: 2.662908  data: 0.007526  max mem: 4109
I20241205 08:10:42 2975514 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:27    time: 2.448853  data: 0.003538  max mem: 4109
I20241205 08:10:53 2975514 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.114053  data: 0.001250  max mem: 4109
I20241205 08:10:53 2975514 dinov2 helpers.py:130] Test: Total time: 0:04:15 (3.271335 s / it)
I20241205 08:10:53 2975514 dinov2 utils.py:79] Averaged stats: 
I20241205 08:10:53 2975514 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 75.06
I20241205 08:10:53 2975514 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 75.91
I20241205 08:10:53 2975514 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 77.50
I20241205 08:10:53 2975514 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 78.01
submitit INFO (2024-12-05 08:10:53,402) - Job completed successfully
I20241205 08:10:53 2975514 submitit submission.py:56] Job completed successfully
submitit INFO (2024-12-05 08:10:53,403) - Exiting after successful completion
I20241205 08:10:53 2975514 submitit submission.py:61] Exiting after successful completion

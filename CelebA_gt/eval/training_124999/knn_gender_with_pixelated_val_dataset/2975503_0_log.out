submitit INFO (2024-12-05 07:22:37,825) - Starting with JobEnvironment(job_id=2975503, hostname=tars, local_rank=0(8), node=0(1), global_rank=0(8))
submitit INFO (2024-12-05 07:22:37,825) - Loading pickle: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset/2975503_submitted.pkl
I20241205 07:22:47 2975506 dinov2 config.py:59] git:
  sha: 1514d8883ab0f94a8e16e2f31e7880cd543d6e95, status: has uncommitted changes, branch: main

I20241205 07:22:47 2975506 dinov2 config.py:60] batch_size: 256
comment: 
config_file: CelebA_gt/config.yaml
exclude: 
gather_on_cpu: False
n_per_class_list: [-1]
n_tries: 1
nb_knn: [10, 20, 100, 200]
ngpus: 8
nodes: 1
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
partition: learnlab
pretrained_weights: CelebA_gt/eval/training_124999/teacher_checkpoint.pth
temperature: 0.07
timeout: 2800
train_dataset_str: CelebAOriginalTrain
use_volta32: False
val_dataset_str: CelebAPixelatedVal
I20241205 07:22:47 2975506 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20241205 07:22:47 2975506 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAOriginalTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_gt/eval/training_124999/knn_gender_with_pixelated_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20241205 07:22:48 2975506 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20241205 07:23:27 2975506 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20241205 07:23:33 2975506 dinov2 utils.py:33] Pretrained weights found at CelebA_gt/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20241205 07:23:33 2975506 dinov2 loaders.py:94] using dataset: "CelebAOriginalTrain"
Load image list
I20241205 07:23:47 2975506 dinov2 loaders.py:99] # of dataset samples: 162,127
I20241205 07:23:47 2975506 dinov2 loaders.py:94] using dataset: "CelebAPixelatedVal"
Load image list
I20241205 07:23:53 2975506 dinov2 loaders.py:99] # of dataset samples: 19,792
I20241205 07:23:53 2975506 dinov2 knn.py:260] Extracting features for train set...
I20241205 07:23:53 2975506 dinov2 loaders.py:157] sampler: distributed
I20241205 07:23:53 2975506 dinov2 loaders.py:216] using PyTorch data loader
W20241205 07:23:53 2975506 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20241205 07:23:53 2975506 dinov2 loaders.py:229] # of batches: 634
I20241205 07:24:53 2975506 dinov2 utils.py:129] Storing features into tensor of shape torch.Size([162127, 1024])
I20241205 07:24:53 2975506 dinov2 helpers.py:102]   [  0/634]  eta: 10:41:39    time: 60.724548  data: 14.504234  max mem: 3463
I20241205 07:25:26 2975506 dinov2 helpers.py:102]   [ 10/634]  eta: 1:28:07    time: 8.473327  data: 1.322576  max mem: 4109
I20241205 07:26:05 2975506 dinov2 helpers.py:102]   [ 20/634]  eta: 1:04:40    time: 3.599794  data: 0.003208  max mem: 4109
I20241205 07:26:45 2975506 dinov2 helpers.py:102]   [ 30/634]  eta: 0:55:58    time: 3.957414  data: 0.001953  max mem: 4109
I20241205 07:27:25 2975506 dinov2 helpers.py:102]   [ 40/634]  eta: 0:51:11    time: 3.962775  data: 0.001480  max mem: 4109
I20241205 07:28:04 2975506 dinov2 helpers.py:102]   [ 50/634]  eta: 0:48:01    time: 3.962961  data: 0.001963  max mem: 4109
I20241205 07:28:44 2975506 dinov2 helpers.py:102]   [ 60/634]  eta: 0:45:40    time: 3.961864  data: 0.002117  max mem: 4109
I20241205 07:29:23 2975506 dinov2 helpers.py:102]   [ 70/634]  eta: 0:43:47    time: 3.958069  data: 0.001139  max mem: 4109
I20241205 07:30:03 2975506 dinov2 helpers.py:102]   [ 80/634]  eta: 0:42:13    time: 3.959705  data: 0.000950  max mem: 4109
I20241205 07:30:43 2975506 dinov2 helpers.py:102]   [ 90/634]  eta: 0:40:50    time: 3.959862  data: 0.001112  max mem: 4109
I20241205 07:31:22 2975506 dinov2 helpers.py:102]   [100/634]  eta: 0:39:36    time: 3.954983  data: 0.001173  max mem: 4109
I20241205 07:32:02 2975506 dinov2 helpers.py:102]   [110/634]  eta: 0:38:28    time: 3.955924  data: 0.001003  max mem: 4109
I20241205 07:32:41 2975506 dinov2 helpers.py:102]   [120/634]  eta: 0:37:25    time: 3.955100  data: 0.001729  max mem: 4109
I20241205 07:33:21 2975506 dinov2 helpers.py:102]   [130/634]  eta: 0:36:26    time: 3.954950  data: 0.001900  max mem: 4109
I20241205 07:34:00 2975506 dinov2 helpers.py:102]   [140/634]  eta: 0:35:29    time: 3.956811  data: 0.002850  max mem: 4109
I20241205 07:34:40 2975506 dinov2 helpers.py:102]   [150/634]  eta: 0:34:34    time: 3.954038  data: 0.002918  max mem: 4109
I20241205 07:35:19 2975506 dinov2 helpers.py:102]   [160/634]  eta: 0:33:42    time: 3.954314  data: 0.003298  max mem: 4109
I20241205 07:35:59 2975506 dinov2 helpers.py:102]   [170/634]  eta: 0:32:50    time: 3.954539  data: 0.003490  max mem: 4109
I20241205 07:36:39 2975506 dinov2 helpers.py:102]   [180/634]  eta: 0:32:01    time: 3.952785  data: 0.001878  max mem: 4109
I20241205 07:37:18 2975506 dinov2 helpers.py:102]   [190/634]  eta: 0:31:12    time: 3.954317  data: 0.001649  max mem: 4109
I20241205 07:37:58 2975506 dinov2 helpers.py:102]   [200/634]  eta: 0:30:24    time: 3.954193  data: 0.001232  max mem: 4109
I20241205 07:38:37 2975506 dinov2 helpers.py:102]   [210/634]  eta: 0:29:37    time: 3.952369  data: 0.000984  max mem: 4109
I20241205 07:39:17 2975506 dinov2 helpers.py:102]   [220/634]  eta: 0:28:50    time: 3.952427  data: 0.001517  max mem: 4109
I20241205 07:39:56 2975506 dinov2 helpers.py:102]   [230/634]  eta: 0:28:05    time: 3.952570  data: 0.001576  max mem: 4109
I20241205 07:40:36 2975506 dinov2 helpers.py:102]   [240/634]  eta: 0:27:19    time: 3.954530  data: 0.001399  max mem: 4109
I20241205 07:41:15 2975506 dinov2 helpers.py:102]   [250/634]  eta: 0:26:35    time: 3.954318  data: 0.001810  max mem: 4109
I20241205 07:41:55 2975506 dinov2 helpers.py:102]   [260/634]  eta: 0:25:50    time: 3.952420  data: 0.001339  max mem: 4109
I20241205 07:42:34 2975506 dinov2 helpers.py:102]   [270/634]  eta: 0:25:06    time: 3.952419  data: 0.001099  max mem: 4109
I20241205 07:43:14 2975506 dinov2 helpers.py:102]   [280/634]  eta: 0:24:22    time: 3.952316  data: 0.001308  max mem: 4109
I20241205 07:43:53 2975506 dinov2 helpers.py:102]   [290/634]  eta: 0:23:39    time: 3.952591  data: 0.001374  max mem: 4109
I20241205 07:44:33 2975506 dinov2 helpers.py:102]   [300/634]  eta: 0:22:56    time: 3.958501  data: 0.001309  max mem: 4109
I20241205 07:45:13 2975506 dinov2 helpers.py:102]   [310/634]  eta: 0:22:13    time: 3.962096  data: 0.003901  max mem: 4109
I20241205 07:45:52 2975506 dinov2 helpers.py:102]   [320/634]  eta: 0:21:30    time: 3.958537  data: 0.004569  max mem: 4109
I20241205 07:46:32 2975506 dinov2 helpers.py:102]   [330/634]  eta: 0:20:48    time: 3.956364  data: 0.002885  max mem: 4109
I20241205 07:47:11 2975506 dinov2 helpers.py:102]   [340/634]  eta: 0:20:05    time: 3.954385  data: 0.002143  max mem: 4109
I20241205 07:47:51 2975506 dinov2 helpers.py:102]   [350/634]  eta: 0:19:23    time: 3.952521  data: 0.002006  max mem: 4109
I20241205 07:48:30 2975506 dinov2 helpers.py:102]   [360/634]  eta: 0:18:41    time: 3.951890  data: 0.002769  max mem: 4109
I20241205 07:49:10 2975506 dinov2 helpers.py:102]   [370/634]  eta: 0:17:59    time: 3.953695  data: 0.001566  max mem: 4109
I20241205 07:49:49 2975506 dinov2 helpers.py:102]   [380/634]  eta: 0:17:17    time: 3.954262  data: 0.000542  max mem: 4109
I20241205 07:50:29 2975506 dinov2 helpers.py:102]   [390/634]  eta: 0:16:36    time: 3.952347  data: 0.000851  max mem: 4109
I20241205 07:51:08 2975506 dinov2 helpers.py:102]   [400/634]  eta: 0:15:54    time: 3.952956  data: 0.000824  max mem: 4109
I20241205 07:51:48 2975506 dinov2 helpers.py:102]   [410/634]  eta: 0:15:13    time: 3.958633  data: 0.001003  max mem: 4109
I20241205 07:52:28 2975506 dinov2 helpers.py:102]   [420/634]  eta: 0:14:31    time: 3.961438  data: 0.001328  max mem: 4109
I20241205 07:53:07 2975506 dinov2 helpers.py:102]   [430/634]  eta: 0:13:50    time: 3.958932  data: 0.001769  max mem: 4109
I20241205 07:53:47 2975506 dinov2 helpers.py:102]   [440/634]  eta: 0:13:09    time: 3.959445  data: 0.001807  max mem: 4109
I20241205 07:54:27 2975506 dinov2 helpers.py:102]   [450/634]  eta: 0:12:28    time: 3.964548  data: 0.001387  max mem: 4109
I20241205 07:55:06 2975506 dinov2 helpers.py:102]   [460/634]  eta: 0:11:47    time: 3.969282  data: 0.001875  max mem: 4109
I20241205 07:55:46 2975506 dinov2 helpers.py:102]   [470/634]  eta: 0:11:06    time: 3.967276  data: 0.002375  max mem: 4109
I20241205 07:56:26 2975506 dinov2 helpers.py:102]   [480/634]  eta: 0:10:25    time: 3.966775  data: 0.001757  max mem: 4109
I20241205 07:57:05 2975506 dinov2 helpers.py:102]   [490/634]  eta: 0:09:44    time: 3.966910  data: 0.001294  max mem: 4109
I20241205 07:57:45 2975506 dinov2 helpers.py:102]   [500/634]  eta: 0:09:03    time: 3.966319  data: 0.001355  max mem: 4109
I20241205 07:58:25 2975506 dinov2 helpers.py:102]   [510/634]  eta: 0:08:22    time: 3.969049  data: 0.001110  max mem: 4109
I20241205 07:59:04 2975506 dinov2 helpers.py:102]   [520/634]  eta: 0:07:42    time: 3.970027  data: 0.001177  max mem: 4109
I20241205 07:59:44 2975506 dinov2 helpers.py:102]   [530/634]  eta: 0:07:01    time: 3.971186  data: 0.001056  max mem: 4109
I20241205 08:00:24 2975506 dinov2 helpers.py:102]   [540/634]  eta: 0:06:20    time: 3.970469  data: 0.002351  max mem: 4109
I20241205 08:01:03 2975506 dinov2 helpers.py:102]   [550/634]  eta: 0:05:40    time: 3.970712  data: 0.002219  max mem: 4109
I20241205 08:01:43 2975506 dinov2 helpers.py:102]   [560/634]  eta: 0:04:59    time: 3.971675  data: 0.001011  max mem: 4109
I20241205 08:02:23 2975506 dinov2 helpers.py:102]   [570/634]  eta: 0:04:18    time: 3.970466  data: 0.001242  max mem: 4109
I20241205 08:03:03 2975506 dinov2 helpers.py:102]   [580/634]  eta: 0:03:38    time: 3.969626  data: 0.000905  max mem: 4109
I20241205 08:03:42 2975506 dinov2 helpers.py:102]   [590/634]  eta: 0:02:57    time: 3.970451  data: 0.001001  max mem: 4109
I20241205 08:04:20 2975506 dinov2 helpers.py:102]   [600/634]  eta: 0:02:17    time: 3.861206  data: 0.002095  max mem: 4109
I20241205 08:04:58 2975506 dinov2 helpers.py:102]   [610/634]  eta: 0:01:36    time: 3.791307  data: 0.001742  max mem: 4109
I20241205 08:05:37 2975506 dinov2 helpers.py:102]   [620/634]  eta: 0:00:56    time: 3.875245  data: 0.000520  max mem: 4109
I20241205 08:06:17 2975506 dinov2 helpers.py:102]   [630/634]  eta: 0:00:16    time: 3.923746  data: 0.000654  max mem: 4109
I20241205 08:06:35 2975506 dinov2 helpers.py:102]   [633/634]  eta: 0:00:04    time: 4.251563  data: 0.000602  max mem: 4109
I20241205 08:06:35 2975506 dinov2 helpers.py:130]  Total time: 0:42:42 (4.042052 s / it)
I20241205 08:06:35 2975506 dinov2 utils.py:141] Features shape: (162127, 1024)
I20241205 08:06:35 2975506 dinov2 utils.py:142] Labels shape: (162127,)
I20241205 08:06:36 2975506 dinov2 knn.py:264] Train features created, shape torch.Size([162127, 1024]).
I20241205 08:06:36 2975506 dinov2 loaders.py:157] sampler: distributed
I20241205 08:06:36 2975506 dinov2 loaders.py:216] using PyTorch data loader
I20241205 08:06:36 2975506 dinov2 loaders.py:229] # of batches: 78
I20241205 08:06:36 2975506 dinov2 knn.py:299] Start the k-NN classification.
I20241205 08:06:50 2975506 dinov2 helpers.py:102] Test:  [ 0/78]  eta: 0:18:04    time: 13.902790  data: 10.417771  max mem: 4109
I20241205 08:07:30 2975506 dinov2 helpers.py:102] Test:  [10/78]  eta: 0:05:32    time: 4.891590  data: 0.951251  max mem: 4109
I20241205 08:08:10 2975506 dinov2 helpers.py:102] Test:  [20/78]  eta: 0:04:19    time: 3.994220  data: 0.005393  max mem: 4109
I20241205 08:08:50 2975506 dinov2 helpers.py:102] Test:  [30/78]  eta: 0:03:27    time: 4.000343  data: 0.006498  max mem: 4109
I20241205 08:09:23 2975506 dinov2 helpers.py:102] Test:  [40/78]  eta: 0:02:34    time: 3.624411  data: 0.007517  max mem: 4109
I20241205 08:09:51 2975506 dinov2 helpers.py:102] Test:  [50/78]  eta: 0:01:46    time: 3.045305  data: 0.005204  max mem: 4109
I20241205 08:10:16 2975506 dinov2 helpers.py:102] Test:  [60/78]  eta: 0:01:04    time: 2.665854  data: 0.004251  max mem: 4109
I20241205 08:10:40 2975506 dinov2 helpers.py:102] Test:  [70/78]  eta: 0:00:27    time: 2.453753  data: 0.003415  max mem: 4109
I20241205 08:10:52 2975506 dinov2 helpers.py:102] Test:  [77/78]  eta: 0:00:03    time: 2.179636  data: 0.000869  max mem: 4109
I20241205 08:10:52 2975506 dinov2 helpers.py:130] Test: Total time: 0:04:15 (3.279044 s / it)
I20241205 08:10:52 2975506 dinov2 utils.py:79] Averaged stats: 
I20241205 08:10:53 2975506 dinov2 knn.py:368] ('full', 10) classifier result: Top1: 75.06
I20241205 08:10:53 2975506 dinov2 knn.py:368] ('full', 20) classifier result: Top1: 75.91
I20241205 08:10:53 2975506 dinov2 knn.py:368] ('full', 100) classifier result: Top1: 77.50
I20241205 08:10:53 2975506 dinov2 knn.py:368] ('full', 200) classifier result: Top1: 78.01
submitit INFO (2024-12-05 08:10:53,317) - Job completed successfully
I20241205 08:10:53 2975506 submitit submission.py:56] Job completed successfully
submitit INFO (2024-12-05 08:10:53,318) - Exiting after successful completion
I20241205 08:10:53 2975506 submitit submission.py:61] Exiting after successful completion

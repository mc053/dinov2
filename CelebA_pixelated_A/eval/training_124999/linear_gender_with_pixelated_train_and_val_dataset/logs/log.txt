I20250120 11:52:32 3545703 dinov2 config.py:59] git:
  sha: 3ded4e34eb54a7264c5d718f22ec7b24d73ba04c, status: has uncommitted changes, branch: main

I20250120 11:52:32 3545703 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: CelebA_pixelated_A/config.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
pretrained_weights: CelebA_pixelated_A/eval/training_124999/teacher_checkpoint.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: CelebAPixelatedTrain
val_class_mapping_fpath: None
val_dataset_str: CelebAPixelatedVal
val_metric_type: mean_accuracy
I20250120 11:52:32 3545703 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250120 11:52:32 3545703 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAPixelatedABTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
  a_b_training: A
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250120 11:52:32 3545703 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250120 11:52:50 3545703 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250120 11:52:50 3545703 dinov2 utils.py:33] Pretrained weights found at CelebA_pixelated_A/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250120 11:52:50 3545703 dinov2 loaders.py:116] using dataset: "CelebAPixelatedTrain"
I20250120 11:52:52 3545703 dinov2 loaders.py:121] # of dataset samples: 162,127
I20250120 11:52:53 3545703 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:52:53 3545703 dinov2 loaders.py:154] sampler: sharded infinite
I20250120 11:52:53 3545703 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:52:53 3545703 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:52:53 3545703 dinov2 loaders.py:253] infinite data loader
I20250120 11:52:53 3545703 dinov2 loaders.py:116] using dataset: "CelebAPixelatedVal"
I20250120 11:52:54 3545703 dinov2 loaders.py:121] # of dataset samples: 19,792
I20250120 11:52:54 3545703 dinov2 loaders.py:179] sampler: distributed
I20250120 11:52:54 3545703 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:52:54 3545703 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:52:54 3545703 dinov2 loaders.py:251] # of batches: 155
I20250120 11:52:54 3545703 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:52:54 3545703 dinov2 linear.py:338] Starting training from iteration 0
I20250120 11:52:59 3545703 dinov2 helpers.py:102] Training  [    0/12500]  eta: 16:12:47  loss: 35.3044 (35.3044)  lr: 0.0000 (0.0000)  time: 4.669375  data: 4.368509  max mem: 2706
I20250120 11:52:59 3545703 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20250120 11:53:01 3545703 dinov2 helpers.py:102] Training  [   10/12500]  eta: 2:06:29  loss: 31.9666 (33.6355)  lr: 0.0000 (0.0000)  time: 0.607647  data: 0.397993  max mem: 3115
I20250120 11:53:03 3545703 dinov2 helpers.py:102] Training  [   20/12500]  eta: 1:25:29  loss: 31.9666 (31.1541)  lr: 0.0000 (0.0000)  time: 0.198127  data: 0.000783  max mem: 3115
I20250120 11:53:04 3545703 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:10:54  loss: 26.1911 (29.5527)  lr: 0.0000 (0.0000)  time: 0.194680  data: 0.000581  max mem: 3115
I20250120 11:53:06 3545703 dinov2 helpers.py:102] Training  [   40/12500]  eta: 1:03:27  loss: 29.7441 (29.5910)  lr: 0.0000 (0.0000)  time: 0.194815  data: 0.000591  max mem: 3115
I20250120 11:53:08 3545703 dinov2 helpers.py:102] Training  [   50/12500]  eta: 0:58:56  loss: 26.1911 (28.8561)  lr: 0.0000 (0.0000)  time: 0.195401  data: 0.000607  max mem: 3115
I20250120 11:53:10 3545703 dinov2 helpers.py:102] Training  [   60/12500]  eta: 0:55:56  loss: 29.7441 (29.2944)  lr: 0.0000 (0.0000)  time: 0.196468  data: 0.000580  max mem: 3115
I20250120 11:53:12 3545703 dinov2 helpers.py:102] Training  [   70/12500]  eta: 0:53:45  loss: 27.8419 (29.1129)  lr: 0.0000 (0.0000)  time: 0.196861  data: 0.000604  max mem: 3115
I20250120 11:53:14 3545703 dinov2 helpers.py:102] Training  [   80/12500]  eta: 0:52:08  loss: 29.7441 (29.4461)  lr: 0.0000 (0.0000)  time: 0.197214  data: 0.000690  max mem: 3115
I20250120 11:53:16 3545703 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:50:52  loss: 29.7441 (29.6813)  lr: 0.0000 (0.0000)  time: 0.198021  data: 0.000646  max mem: 3115
I20250120 11:53:18 3545703 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:49:51  loss: 29.7441 (29.1589)  lr: 0.0000 (0.0000)  time: 0.198091  data: 0.000495  max mem: 3115
I20250120 11:53:20 3545703 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:49:01  loss: 29.7441 (29.2145)  lr: 0.0000 (0.0000)  time: 0.198432  data: 0.000419  max mem: 3115
I20250120 11:53:28 3545703 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:57:59  loss: 29.7441 (29.0134)  lr: 0.0000 (0.0000)  time: 0.482075  data: 0.288888  max mem: 3115
I20250120 11:53:30 3545703 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:56:37  loss: 27.8419 (28.7581)  lr: 0.0000 (0.0000)  time: 0.481405  data: 0.289849  max mem: 3115
I20250120 11:53:32 3545703 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:55:27  loss: 29.7441 (29.2045)  lr: 0.0000 (0.0000)  time: 0.197885  data: 0.001428  max mem: 3115
I20250120 11:53:34 3545703 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:54:27  loss: 27.8419 (29.0313)  lr: 0.0000 (0.0000)  time: 0.198572  data: 0.000538  max mem: 3115
I20250120 11:53:36 3545703 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:53:35  loss: 27.9921 (28.9702)  lr: 0.0000 (0.0000)  time: 0.199347  data: 0.000509  max mem: 3115
I20250120 11:53:38 3545703 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:52:49  loss: 27.8419 (28.8476)  lr: 0.0000 (0.0000)  time: 0.199986  data: 0.000527  max mem: 3115
I20250120 11:53:40 3545703 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:52:07  loss: 27.9921 (28.9040)  lr: 0.0000 (0.0000)  time: 0.200194  data: 0.000568  max mem: 3115
I20250120 11:53:42 3545703 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:51:30  loss: 27.9921 (28.9156)  lr: 0.0000 (0.0000)  time: 0.200373  data: 0.000532  max mem: 3115
I20250120 11:53:44 3545703 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:50:57  loss: 27.9921 (28.9324)  lr: 0.0000 (0.0000)  time: 0.200800  data: 0.000494  max mem: 3115
I20250120 11:53:46 3545703 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:50:27  loss: 27.8419 (28.5573)  lr: 0.0000 (0.0000)  time: 0.201181  data: 0.000491  max mem: 3115
I20250120 11:53:48 3545703 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:50:00  loss: 27.8419 (28.4572)  lr: 0.0000 (0.0000)  time: 0.201443  data: 0.000495  max mem: 3115
I20250120 11:53:50 3545703 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:49:35  loss: 27.8419 (28.3022)  lr: 0.0000 (0.0000)  time: 0.201733  data: 0.000494  max mem: 3115
I20250120 11:53:52 3545703 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:49:12  loss: 27.8419 (28.3375)  lr: 0.0000 (0.0000)  time: 0.202017  data: 0.000561  max mem: 3115
I20250120 11:53:54 3545703 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:48:51  loss: 27.9921 (28.3409)  lr: 0.0000 (0.0000)  time: 0.202424  data: 0.000581  max mem: 3115
I20250120 11:53:56 3545703 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:48:32  loss: 27.8419 (28.2371)  lr: 0.0000 (0.0000)  time: 0.202942  data: 0.000514  max mem: 3115
I20250120 11:53:58 3545703 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:48:14  loss: 26.7641 (28.1816)  lr: 0.0000 (0.0000)  time: 0.203104  data: 0.000500  max mem: 3115
I20250120 11:54:00 3545703 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:47:57  loss: 26.7641 (28.1798)  lr: 0.0000 (0.0000)  time: 0.203330  data: 0.000488  max mem: 3115
I20250120 11:54:02 3545703 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:47:41  loss: 26.6842 (28.1228)  lr: 0.0000 (0.0000)  time: 0.203660  data: 0.000478  max mem: 3115
I20250120 11:54:04 3545703 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:47:26  loss: 26.6842 (27.9342)  lr: 0.0000 (0.0000)  time: 0.203758  data: 0.000506  max mem: 3115
I20250120 11:54:06 3545703 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:47:13  loss: 26.6842 (27.9989)  lr: 0.0000 (0.0000)  time: 0.203949  data: 0.000883  max mem: 3115
I20250120 11:54:08 3545703 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:46:59  loss: 26.6842 (27.8141)  lr: 0.0000 (0.0000)  time: 0.203985  data: 0.000872  max mem: 3115
I20250120 11:54:10 3545703 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:46:47  loss: 26.6842 (27.7168)  lr: 0.0000 (0.0000)  time: 0.204595  data: 0.000513  max mem: 3115
I20250120 11:54:12 3545703 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:46:36  loss: 26.6842 (27.7652)  lr: 0.0000 (0.0000)  time: 0.205062  data: 0.000541  max mem: 3115
I20250120 11:54:14 3545703 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:46:25  loss: 26.6842 (27.6573)  lr: 0.0000 (0.0000)  time: 0.205030  data: 0.000569  max mem: 3115
I20250120 11:54:16 3545703 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:46:15  loss: 26.4708 (27.5688)  lr: 0.0000 (0.0000)  time: 0.205269  data: 0.000555  max mem: 3115
I20250120 11:54:19 3545703 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:46:05  loss: 26.4708 (27.5582)  lr: 0.0000 (0.0000)  time: 0.205362  data: 0.000542  max mem: 3115
I20250120 11:54:21 3545703 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:45:55  loss: 26.2538 (27.4845)  lr: 0.0000 (0.0000)  time: 0.205348  data: 0.000485  max mem: 3115
I20250120 11:54:23 3545703 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:45:46  loss: 26.2538 (27.6075)  lr: 0.0000 (0.0000)  time: 0.205537  data: 0.000461  max mem: 3115
I20250120 11:54:25 3545703 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:45:38  loss: 26.2538 (27.6076)  lr: 0.0000 (0.0000)  time: 0.206077  data: 0.000505  max mem: 3115
I20250120 11:54:27 3545703 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:45:30  loss: 26.2538 (27.5191)  lr: 0.0000 (0.0000)  time: 0.206229  data: 0.000475  max mem: 3115
I20250120 11:54:29 3545703 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:45:22  loss: 25.5375 (27.4395)  lr: 0.0000 (0.0000)  time: 0.206154  data: 0.000473  max mem: 3115
I20250120 11:54:31 3545703 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:45:14  loss: 26.4708 (27.4249)  lr: 0.0000 (0.0000)  time: 0.206157  data: 0.000489  max mem: 3115
I20250120 11:54:33 3545703 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:45:07  loss: 26.4708 (27.4842)  lr: 0.0000 (0.0000)  time: 0.206264  data: 0.000476  max mem: 3115
I20250120 11:54:35 3545703 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:45:00  loss: 25.6180 (27.4436)  lr: 0.0000 (0.0000)  time: 0.206391  data: 0.000517  max mem: 3115
I20250120 11:54:37 3545703 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:44:53  loss: 26.4708 (27.4445)  lr: 0.0000 (0.0000)  time: 0.206316  data: 0.000500  max mem: 3115
I20250120 11:54:39 3545703 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:44:46  loss: 25.6180 (27.3501)  lr: 0.0000 (0.0000)  time: 0.206343  data: 0.000486  max mem: 3115
I20250120 11:54:41 3545703 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:44:40  loss: 24.6866 (27.2825)  lr: 0.0000 (0.0000)  time: 0.206327  data: 0.000513  max mem: 3115
I20250120 11:54:43 3545703 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:44:34  loss: 24.5083 (27.1742)  lr: 0.0000 (0.0000)  time: 0.206466  data: 0.000479  max mem: 3115
I20250120 11:54:45 3545703 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:44:28  loss: 24.5083 (27.1083)  lr: 0.0000 (0.0000)  time: 0.206751  data: 0.000457  max mem: 3115
I20250120 11:54:47 3545703 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:44:22  loss: 24.5083 (27.0958)  lr: 0.0000 (0.0000)  time: 0.207063  data: 0.000492  max mem: 3115
I20250120 11:54:49 3545703 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:44:16  loss: 24.6866 (27.0980)  lr: 0.0000 (0.0000)  time: 0.207107  data: 0.000486  max mem: 3115
I20250120 11:54:52 3545703 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:44:11  loss: 25.6180 (27.0891)  lr: 0.0000 (0.0000)  time: 0.207056  data: 0.000489  max mem: 3115
I20250120 11:54:54 3545703 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:44:05  loss: 25.6180 (27.2202)  lr: 0.0000 (0.0000)  time: 0.207056  data: 0.000537  max mem: 3115
I20250120 11:54:56 3545703 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:44:00  loss: 25.6180 (27.1903)  lr: 0.0000 (0.0000)  time: 0.207133  data: 0.000495  max mem: 3115
I20250120 11:54:58 3545703 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:43:55  loss: 26.4574 (27.2172)  lr: 0.0000 (0.0000)  time: 0.207336  data: 0.000498  max mem: 3115
I20250120 11:55:00 3545703 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:43:50  loss: 26.4574 (27.4079)  lr: 0.0000 (0.0000)  time: 0.207014  data: 0.000495  max mem: 3115
I20250120 11:55:02 3545703 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:43:45  loss: 26.6203 (27.4734)  lr: 0.0000 (0.0000)  time: 0.207083  data: 0.000449  max mem: 3115
I20250120 11:55:04 3545703 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:43:40  loss: 26.4574 (27.3861)  lr: 0.0000 (0.0000)  time: 0.207207  data: 0.000477  max mem: 3115
I20250120 11:55:06 3545703 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:43:35  loss: 26.4574 (27.4713)  lr: 0.0000 (0.0000)  time: 0.207016  data: 0.000515  max mem: 3115
I20250120 11:55:08 3545703 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:43:31  loss: 26.4574 (27.3952)  lr: 0.0000 (0.0000)  time: 0.207317  data: 0.000560  max mem: 3115
I20250120 11:55:10 3545703 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:43:26  loss: 26.4574 (27.3641)  lr: 0.0000 (0.0000)  time: 0.207461  data: 0.000548  max mem: 3115
I20250120 11:55:12 3545703 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:43:22  loss: 26.2687 (27.3470)  lr: 0.0000 (0.0000)  time: 0.207574  data: 0.000480  max mem: 3115
I20250120 11:55:14 3545703 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:43:17  loss: 26.2687 (27.3363)  lr: 0.0000 (0.0000)  time: 0.207498  data: 0.000489  max mem: 3115
I20250120 11:55:16 3545703 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:43:13  loss: 26.4574 (27.3677)  lr: 0.0000 (0.0000)  time: 0.207268  data: 0.000514  max mem: 3115
I20250120 11:55:19 3545703 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:43:09  loss: 26.2687 (27.3086)  lr: 0.0000 (0.0000)  time: 0.207572  data: 0.000515  max mem: 3115
I20250120 11:55:21 3545703 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:43:05  loss: 26.4574 (27.3176)  lr: 0.0000 (0.0000)  time: 0.207809  data: 0.000490  max mem: 3115
I20250120 11:55:23 3545703 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:43:01  loss: 26.4574 (27.1729)  lr: 0.0000 (0.0000)  time: 0.207745  data: 0.000478  max mem: 3115
I20250120 11:55:25 3545703 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:42:57  loss: 26.4574 (27.1395)  lr: 0.0000 (0.0000)  time: 0.207661  data: 0.000498  max mem: 3115
I20250120 11:55:27 3545703 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:42:53  loss: 26.4574 (27.0814)  lr: 0.0000 (0.0000)  time: 0.207633  data: 0.000477  max mem: 3115
I20250120 11:55:29 3545703 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:42:49  loss: 26.2687 (27.0337)  lr: 0.0000 (0.0000)  time: 0.207795  data: 0.000510  max mem: 3115
I20250120 11:55:31 3545703 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:42:45  loss: 26.2668 (27.0232)  lr: 0.0000 (0.0000)  time: 0.207953  data: 0.000494  max mem: 3115
I20250120 11:55:33 3545703 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:42:41  loss: 26.2668 (27.0250)  lr: 0.0000 (0.0000)  time: 0.207853  data: 0.000465  max mem: 3115
I20250120 11:55:35 3545703 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:42:37  loss: 25.5441 (26.9650)  lr: 0.0000 (0.0000)  time: 0.207806  data: 0.000464  max mem: 3115
I20250120 11:55:37 3545703 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:42:34  loss: 25.4345 (26.9395)  lr: 0.0000 (0.0000)  time: 0.207837  data: 0.000473  max mem: 3115
I20250120 11:55:39 3545703 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:42:30  loss: 25.0309 (26.9073)  lr: 0.0000 (0.0000)  time: 0.207802  data: 0.000453  max mem: 3115
I20250120 11:55:41 3545703 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:42:26  loss: 25.0309 (26.8987)  lr: 0.0000 (0.0000)  time: 0.207846  data: 0.000431  max mem: 3115
I20250120 11:55:43 3545703 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:42:23  loss: 25.0309 (26.9452)  lr: 0.0000 (0.0000)  time: 0.207921  data: 0.000478  max mem: 3115
I20250120 11:55:46 3545703 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:42:19  loss: 25.4345 (27.0991)  lr: 0.0000 (0.0000)  time: 0.207840  data: 0.000468  max mem: 3115
I20250120 11:55:48 3545703 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:42:16  loss: 25.4345 (27.1204)  lr: 0.0000 (0.0000)  time: 0.207804  data: 0.000477  max mem: 3115
I20250120 11:55:50 3545703 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:42:12  loss: 26.2371 (27.1506)  lr: 0.0000 (0.0000)  time: 0.207923  data: 0.000500  max mem: 3115
I20250120 11:55:52 3545703 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:42:09  loss: 26.2668 (27.1495)  lr: 0.0000 (0.0000)  time: 0.207844  data: 0.000511  max mem: 3115
I20250120 11:55:54 3545703 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:42:06  loss: 26.2668 (27.1474)  lr: 0.0000 (0.0000)  time: 0.207735  data: 0.000527  max mem: 3115
I20250120 11:55:56 3545703 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:42:02  loss: 26.2668 (27.1396)  lr: 0.0000 (0.0000)  time: 0.207686  data: 0.000505  max mem: 3115
I20250120 11:55:58 3545703 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:41:59  loss: 26.2668 (27.1401)  lr: 0.0000 (0.0000)  time: 0.207654  data: 0.000470  max mem: 3115
I20250120 11:56:00 3545703 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:41:56  loss: 26.4816 (27.1849)  lr: 0.0000 (0.0000)  time: 0.207676  data: 0.000473  max mem: 3115
I20250120 11:56:02 3545703 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:41:52  loss: 26.2668 (27.1339)  lr: 0.0000 (0.0000)  time: 0.207717  data: 0.000452  max mem: 3115
I20250120 11:56:04 3545703 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:41:49  loss: 26.2668 (27.0955)  lr: 0.0000 (0.0000)  time: 0.207850  data: 0.000419  max mem: 3115
I20250120 11:56:06 3545703 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:41:46  loss: 26.2668 (27.0495)  lr: 0.0000 (0.0000)  time: 0.207923  data: 0.000420  max mem: 3115
I20250120 11:56:08 3545703 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:41:43  loss: 26.2668 (27.0264)  lr: 0.0000 (0.0000)  time: 0.207932  data: 0.000442  max mem: 3115
I20250120 11:56:10 3545703 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:41:39  loss: 26.4816 (27.0932)  lr: 0.0000 (0.0000)  time: 0.207934  data: 0.000489  max mem: 3115
I20250120 11:56:13 3545703 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:41:36  loss: 26.4816 (27.0085)  lr: 0.0000 (0.0000)  time: 0.207785  data: 0.000476  max mem: 3115
I20250120 11:56:15 3545703 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:41:33  loss: 26.2371 (26.9896)  lr: 0.0000 (0.0000)  time: 0.207956  data: 0.000467  max mem: 3115
I20250120 11:56:17 3545703 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:41:30  loss: 26.4816 (26.9977)  lr: 0.0000 (0.0000)  time: 0.208053  data: 0.000493  max mem: 3115
I20250120 11:56:19 3545703 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:41:27  loss: 26.4816 (26.9803)  lr: 0.0000 (0.0000)  time: 0.208121  data: 0.000492  max mem: 3115
I20250120 11:56:21 3545703 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:41:24  loss: 26.9756 (26.9947)  lr: 0.0000 (0.0000)  time: 0.208495  data: 0.000474  max mem: 3115
I20250120 11:56:23 3545703 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:41:21  loss: 27.0614 (27.0624)  lr: 0.0000 (0.0000)  time: 0.208323  data: 0.000515  max mem: 3115
I20250120 11:56:25 3545703 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:41:18  loss: 26.9756 (27.0201)  lr: 0.0000 (0.0000)  time: 0.208248  data: 0.000510  max mem: 3115
I20250120 11:56:27 3545703 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:41:15  loss: 26.4816 (26.9734)  lr: 0.0000 (0.0000)  time: 0.208288  data: 0.000475  max mem: 3115
I20250120 11:56:29 3545703 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:41:12  loss: 26.4816 (26.9846)  lr: 0.0000 (0.0000)  time: 0.208205  data: 0.000487  max mem: 3115
I20250120 11:56:31 3545703 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:41:09  loss: 26.4816 (27.0089)  lr: 0.0000 (0.0000)  time: 0.208343  data: 0.000512  max mem: 3115
I20250120 11:56:33 3545703 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:41:07  loss: 26.4816 (27.0157)  lr: 0.0000 (0.0000)  time: 0.208405  data: 0.000544  max mem: 3115
I20250120 11:56:35 3545703 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:41:04  loss: 25.3313 (26.9445)  lr: 0.0000 (0.0000)  time: 0.208605  data: 0.000491  max mem: 3115
I20250120 11:56:38 3545703 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:41:01  loss: 25.2391 (26.8657)  lr: 0.0000 (0.0000)  time: 0.208520  data: 0.000516  max mem: 3115
I20250120 11:56:40 3545703 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:40:58  loss: 25.2391 (26.8506)  lr: 0.0000 (0.0000)  time: 0.208287  data: 0.000481  max mem: 3115
I20250120 11:56:42 3545703 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:40:55  loss: 24.9452 (26.8102)  lr: 0.0000 (0.0000)  time: 0.208412  data: 0.000434  max mem: 3115
I20250120 11:56:44 3545703 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:40:52  loss: 24.9452 (26.7568)  lr: 0.0000 (0.0000)  time: 0.208425  data: 0.000483  max mem: 3115
I20250120 11:56:46 3545703 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:40:50  loss: 24.9452 (26.6932)  lr: 0.0000 (0.0000)  time: 0.208474  data: 0.000523  max mem: 3115
I20250120 11:56:48 3545703 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:40:47  loss: 25.2391 (26.6871)  lr: 0.0000 (0.0000)  time: 0.208728  data: 0.000548  max mem: 3115
I20250120 11:56:50 3545703 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:40:44  loss: 25.2391 (26.6526)  lr: 0.0000 (0.0000)  time: 0.208811  data: 0.000532  max mem: 3115
I20250120 11:56:52 3545703 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:40:41  loss: 25.2391 (26.6832)  lr: 0.0000 (0.0000)  time: 0.208714  data: 0.000533  max mem: 3115
I20250120 11:56:54 3545703 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:40:39  loss: 25.2391 (26.6486)  lr: 0.0000 (0.0000)  time: 0.208599  data: 0.000508  max mem: 3115
I20250120 11:56:56 3545703 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:40:36  loss: 25.2697 (26.6404)  lr: 0.0000 (0.0000)  time: 0.208524  data: 0.000535  max mem: 3115
I20250120 11:56:58 3545703 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:40:33  loss: 25.2697 (26.6368)  lr: 0.0000 (0.0000)  time: 0.208807  data: 0.000523  max mem: 3115
I20250120 11:57:01 3545703 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:40:31  loss: 25.2697 (26.6280)  lr: 0.0000 (0.0000)  time: 0.208882  data: 0.000452  max mem: 3115
I20250120 11:57:03 3545703 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:40:28  loss: 25.2697 (26.6561)  lr: 0.0000 (0.0000)  time: 0.208476  data: 0.000450  max mem: 3115
I20250120 11:57:05 3545703 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:40:25  loss: 25.2697 (26.6667)  lr: 0.0000 (0.0000)  time: 0.208902  data: 0.000497  max mem: 3115
I20250120 11:57:07 3545703 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:40:23  loss: 25.2697 (26.6219)  lr: 0.0000 (0.0000)  time: 0.209119  data: 0.000482  max mem: 3115
I20250120 11:57:09 3545703 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:40:20  loss: 25.6123 (26.6602)  lr: 0.0000 (0.0000)  time: 0.208719  data: 0.000514  max mem: 3115
I20250120 11:57:11 3545703 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:40:17  loss: 25.6123 (26.6706)  lr: 0.0000 (0.0000)  time: 0.208580  data: 0.000501  max mem: 3115
I20250120 11:57:13 3545703 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:40:15  loss: 25.6123 (26.7147)  lr: 0.0000 (0.0000)  time: 0.208473  data: 0.000472  max mem: 3115
I20250120 11:57:15 3545703 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:40:12  loss: 25.2697 (26.6978)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000548  max mem: 3115
I20250120 11:57:17 3545703 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:40:09  loss: 25.6123 (26.6995)  lr: 0.0000 (0.0000)  time: 0.208183  data: 0.000545  max mem: 3115
I20250120 11:57:19 3545703 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:40:07  loss: 25.7109 (26.7103)  lr: 0.0000 (0.0000)  time: 0.208308  data: 0.000533  max mem: 3115
I20250120 11:57:21 3545703 dinov2 linear.py:272] running validation !
I20250120 11:57:23 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:05:46    time: 2.234083  data: 1.963048  max mem: 3190
I20250120 11:57:26 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:59    time: 0.410785  data: 0.178701  max mem: 3586
I20250120 11:57:28 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:43    time: 0.224336  data: 0.000262  max mem: 3586
I20250120 11:57:30 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:35    time: 0.215030  data: 0.000277  max mem: 3586
I20250120 11:57:32 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:30    time: 0.212841  data: 0.000255  max mem: 3586
I20250120 11:57:34 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:26    time: 0.213075  data: 0.000228  max mem: 3586
I20250120 11:57:36 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:23    time: 0.210609  data: 0.000237  max mem: 3586
I20250120 11:57:38 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:20    time: 0.210597  data: 0.000268  max mem: 3586
I20250120 11:57:41 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210250  data: 0.000281  max mem: 3586
I20250120 11:57:43 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:15    time: 0.210481  data: 0.000231  max mem: 3586
I20250120 11:57:45 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210453  data: 0.000255  max mem: 3586
I20250120 11:57:47 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.209406  data: 0.000283  max mem: 3586
I20250120 11:57:49 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:08    time: 0.209720  data: 0.000232  max mem: 3586
I20250120 11:57:51 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210502  data: 0.000207  max mem: 3586
I20250120 11:57:53 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210531  data: 0.000268  max mem: 3586
I20250120 11:57:55 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210305  data: 0.000224  max mem: 3586
I20250120 11:57:56 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.210501  data: 0.000179  max mem: 3586
I20250120 11:57:56 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:35 (0.226440 s / it)
I20250120 11:57:56 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 11:57:56 3545703 dinov2 linear.py:287] 
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8204, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8450, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8515, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8626, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8675, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8712, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8729, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8725, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8683, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8618, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8551, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8472, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8337, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8445, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8567, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8734, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8771, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8626, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8559, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8447, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8580, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8657, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8753, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8751, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8695, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8608, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8511, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8469, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8526, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8544, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8612, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8690, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8708, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8756, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8759, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8731, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8712, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8632, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8566, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8509, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8414, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8770715594291687}
I20250120 11:57:57 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:57:57 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:57:57 3545703 dinov2 helpers.py:102] Training  [ 1250/12500]  eta: 0:45:25  loss: 26.0156 (26.7164)  lr: 0.0000 (0.0000)  time: 1.994699  data: 0.027359  max mem: 3586
I20250120 11:57:59 3545703 dinov2 helpers.py:102] Training  [ 1260/12500]  eta: 0:45:20  loss: 26.2280 (26.7362)  lr: 0.0000 (0.0000)  time: 1.993421  data: 0.027303  max mem: 3586
I20250120 11:58:01 3545703 dinov2 helpers.py:102] Training  [ 1270/12500]  eta: 0:45:14  loss: 26.2280 (26.7146)  lr: 0.0000 (0.0000)  time: 0.206270  data: 0.000400  max mem: 3586
I20250120 11:58:03 3545703 dinov2 helpers.py:102] Training  [ 1280/12500]  eta: 0:45:09  loss: 26.9061 (26.7241)  lr: 0.0000 (0.0000)  time: 0.206721  data: 0.000396  max mem: 3586
I20250120 11:58:05 3545703 dinov2 helpers.py:102] Training  [ 1290/12500]  eta: 0:45:03  loss: 26.9061 (26.6695)  lr: 0.0000 (0.0000)  time: 0.206695  data: 0.000372  max mem: 3586
I20250120 11:58:07 3545703 dinov2 helpers.py:102] Training  [ 1300/12500]  eta: 0:44:58  loss: 27.1965 (26.6735)  lr: 0.0000 (0.0000)  time: 0.206744  data: 0.000390  max mem: 3586
I20250120 11:58:10 3545703 dinov2 helpers.py:102] Training  [ 1310/12500]  eta: 0:44:52  loss: 26.9061 (26.6060)  lr: 0.0000 (0.0000)  time: 0.206887  data: 0.000468  max mem: 3586
I20250120 11:58:12 3545703 dinov2 helpers.py:102] Training  [ 1320/12500]  eta: 0:44:47  loss: 27.1965 (26.6160)  lr: 0.0000 (0.0000)  time: 0.206988  data: 0.000470  max mem: 3586
I20250120 11:58:14 3545703 dinov2 helpers.py:102] Training  [ 1330/12500]  eta: 0:44:42  loss: 27.1965 (26.5663)  lr: 0.0000 (0.0000)  time: 0.207374  data: 0.000447  max mem: 3586
I20250120 11:58:16 3545703 dinov2 helpers.py:102] Training  [ 1340/12500]  eta: 0:44:37  loss: 27.1965 (26.5426)  lr: 0.0000 (0.0000)  time: 0.207568  data: 0.000461  max mem: 3586
I20250120 11:58:18 3545703 dinov2 helpers.py:102] Training  [ 1350/12500]  eta: 0:44:32  loss: 27.4726 (26.5795)  lr: 0.0000 (0.0000)  time: 0.207327  data: 0.000494  max mem: 3586
I20250120 11:58:20 3545703 dinov2 helpers.py:102] Training  [ 1360/12500]  eta: 0:44:27  loss: 27.1965 (26.5531)  lr: 0.0000 (0.0000)  time: 0.207248  data: 0.000457  max mem: 3586
I20250120 11:58:22 3545703 dinov2 helpers.py:102] Training  [ 1370/12500]  eta: 0:44:22  loss: 26.9061 (26.5472)  lr: 0.0000 (0.0000)  time: 0.207416  data: 0.000443  max mem: 3586
I20250120 11:58:24 3545703 dinov2 helpers.py:102] Training  [ 1380/12500]  eta: 0:44:17  loss: 26.9061 (26.5215)  lr: 0.0000 (0.0000)  time: 0.207522  data: 0.000467  max mem: 3586
I20250120 11:58:26 3545703 dinov2 helpers.py:102] Training  [ 1390/12500]  eta: 0:44:12  loss: 25.9925 (26.5177)  lr: 0.0000 (0.0000)  time: 0.207454  data: 0.000464  max mem: 3586
I20250120 11:58:28 3545703 dinov2 helpers.py:102] Training  [ 1400/12500]  eta: 0:44:07  loss: 25.7274 (26.5118)  lr: 0.0000 (0.0000)  time: 0.207289  data: 0.000471  max mem: 3586
I20250120 11:58:30 3545703 dinov2 helpers.py:102] Training  [ 1410/12500]  eta: 0:44:02  loss: 25.6863 (26.4853)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000477  max mem: 3586
I20250120 11:58:32 3545703 dinov2 helpers.py:102] Training  [ 1420/12500]  eta: 0:43:57  loss: 25.7274 (26.5006)  lr: 0.0000 (0.0000)  time: 0.207687  data: 0.000465  max mem: 3586
I20250120 11:58:34 3545703 dinov2 helpers.py:102] Training  [ 1430/12500]  eta: 0:43:53  loss: 25.7274 (26.5127)  lr: 0.0000 (0.0000)  time: 0.207568  data: 0.000447  max mem: 3586
I20250120 11:58:36 3545703 dinov2 helpers.py:102] Training  [ 1440/12500]  eta: 0:43:48  loss: 25.7274 (26.5101)  lr: 0.0000 (0.0000)  time: 0.207563  data: 0.000450  max mem: 3586
I20250120 11:58:39 3545703 dinov2 helpers.py:102] Training  [ 1450/12500]  eta: 0:43:43  loss: 25.6863 (26.4630)  lr: 0.0000 (0.0000)  time: 0.207596  data: 0.000454  max mem: 3586
I20250120 11:58:41 3545703 dinov2 helpers.py:102] Training  [ 1460/12500]  eta: 0:43:39  loss: 25.6863 (26.4761)  lr: 0.0000 (0.0000)  time: 0.207340  data: 0.000457  max mem: 3586
I20250120 11:58:43 3545703 dinov2 helpers.py:102] Training  [ 1470/12500]  eta: 0:43:34  loss: 25.6863 (26.4314)  lr: 0.0000 (0.0000)  time: 0.206982  data: 0.000478  max mem: 3586
I20250120 11:58:45 3545703 dinov2 helpers.py:102] Training  [ 1480/12500]  eta: 0:43:29  loss: 23.3628 (26.4081)  lr: 0.0000 (0.0000)  time: 0.207010  data: 0.000464  max mem: 3586
I20250120 11:58:47 3545703 dinov2 helpers.py:102] Training  [ 1490/12500]  eta: 0:43:25  loss: 23.3628 (26.3731)  lr: 0.0000 (0.0000)  time: 0.207343  data: 0.000455  max mem: 3586
I20250120 11:58:49 3545703 dinov2 helpers.py:102] Training  [ 1500/12500]  eta: 0:43:20  loss: 23.3628 (26.3618)  lr: 0.0000 (0.0000)  time: 0.207290  data: 0.000466  max mem: 3586
I20250120 11:58:51 3545703 dinov2 helpers.py:102] Training  [ 1510/12500]  eta: 0:43:16  loss: 23.3628 (26.3210)  lr: 0.0000 (0.0000)  time: 0.207311  data: 0.000473  max mem: 3586
I20250120 11:58:53 3545703 dinov2 helpers.py:102] Training  [ 1520/12500]  eta: 0:43:11  loss: 23.3628 (26.3104)  lr: 0.0000 (0.0000)  time: 0.207488  data: 0.000492  max mem: 3586
I20250120 11:58:55 3545703 dinov2 helpers.py:102] Training  [ 1530/12500]  eta: 0:43:07  loss: 23.3628 (26.2893)  lr: 0.0000 (0.0000)  time: 0.207264  data: 0.000485  max mem: 3586
I20250120 11:58:57 3545703 dinov2 helpers.py:102] Training  [ 1540/12500]  eta: 0:43:03  loss: 24.6630 (26.2877)  lr: 0.0000 (0.0000)  time: 0.207288  data: 0.000436  max mem: 3586
I20250120 11:58:59 3545703 dinov2 helpers.py:102] Training  [ 1550/12500]  eta: 0:42:58  loss: 24.6630 (26.2982)  lr: 0.0000 (0.0000)  time: 0.207284  data: 0.000419  max mem: 3586
I20250120 11:59:01 3545703 dinov2 helpers.py:102] Training  [ 1560/12500]  eta: 0:42:54  loss: 24.6630 (26.2464)  lr: 0.0000 (0.0000)  time: 0.207298  data: 0.000433  max mem: 3586
I20250120 11:59:03 3545703 dinov2 helpers.py:102] Training  [ 1570/12500]  eta: 0:42:50  loss: 24.6630 (26.3141)  lr: 0.0000 (0.0000)  time: 0.207612  data: 0.000440  max mem: 3586
I20250120 11:59:06 3545703 dinov2 helpers.py:102] Training  [ 1580/12500]  eta: 0:42:45  loss: 24.6969 (26.3433)  lr: 0.0000 (0.0000)  time: 0.207581  data: 0.000423  max mem: 3586
I20250120 11:59:08 3545703 dinov2 helpers.py:102] Training  [ 1590/12500]  eta: 0:42:41  loss: 24.6630 (26.3301)  lr: 0.0000 (0.0000)  time: 0.207704  data: 0.000426  max mem: 3586
I20250120 11:59:10 3545703 dinov2 helpers.py:102] Training  [ 1600/12500]  eta: 0:42:37  loss: 24.2223 (26.2773)  lr: 0.0000 (0.0000)  time: 0.207805  data: 0.000479  max mem: 3586
I20250120 11:59:12 3545703 dinov2 helpers.py:102] Training  [ 1610/12500]  eta: 0:42:33  loss: 24.2223 (26.2433)  lr: 0.0000 (0.0000)  time: 0.207450  data: 0.000476  max mem: 3586
I20250120 11:59:14 3545703 dinov2 helpers.py:102] Training  [ 1620/12500]  eta: 0:42:29  loss: 24.2223 (26.2407)  lr: 0.0000 (0.0000)  time: 0.207426  data: 0.000446  max mem: 3586
I20250120 11:59:16 3545703 dinov2 helpers.py:102] Training  [ 1630/12500]  eta: 0:42:25  loss: 23.0537 (26.1959)  lr: 0.0000 (0.0000)  time: 0.207596  data: 0.000449  max mem: 3586
I20250120 11:59:18 3545703 dinov2 helpers.py:102] Training  [ 1640/12500]  eta: 0:42:20  loss: 23.0537 (26.2035)  lr: 0.0000 (0.0000)  time: 0.207720  data: 0.000451  max mem: 3586
I20250120 11:59:20 3545703 dinov2 helpers.py:102] Training  [ 1650/12500]  eta: 0:42:16  loss: 24.2223 (26.2386)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000399  max mem: 3586
I20250120 11:59:22 3545703 dinov2 helpers.py:102] Training  [ 1660/12500]  eta: 0:42:12  loss: 24.2223 (26.2971)  lr: 0.0000 (0.0000)  time: 0.207474  data: 0.000409  max mem: 3586
I20250120 11:59:24 3545703 dinov2 helpers.py:102] Training  [ 1670/12500]  eta: 0:42:08  loss: 24.2223 (26.2817)  lr: 0.0000 (0.0000)  time: 0.207510  data: 0.000452  max mem: 3586
I20250120 11:59:26 3545703 dinov2 helpers.py:102] Training  [ 1680/12500]  eta: 0:42:04  loss: 24.6630 (26.2761)  lr: 0.0000 (0.0000)  time: 0.207455  data: 0.000435  max mem: 3586
I20250120 11:59:28 3545703 dinov2 helpers.py:102] Training  [ 1690/12500]  eta: 0:42:00  loss: 24.6969 (26.2801)  lr: 0.0000 (0.0000)  time: 0.207484  data: 0.000442  max mem: 3586
I20250120 11:59:30 3545703 dinov2 helpers.py:102] Training  [ 1700/12500]  eta: 0:41:56  loss: 24.6969 (26.2637)  lr: 0.0000 (0.0000)  time: 0.207869  data: 0.000469  max mem: 3586
I20250120 11:59:33 3545703 dinov2 helpers.py:102] Training  [ 1710/12500]  eta: 0:41:53  loss: 24.6969 (26.2141)  lr: 0.0000 (0.0000)  time: 0.208157  data: 0.000504  max mem: 3586
I20250120 11:59:35 3545703 dinov2 helpers.py:102] Training  [ 1720/12500]  eta: 0:41:49  loss: 25.3392 (26.2189)  lr: 0.0000 (0.0000)  time: 0.207993  data: 0.000479  max mem: 3586
I20250120 11:59:37 3545703 dinov2 helpers.py:102] Training  [ 1730/12500]  eta: 0:41:45  loss: 25.3392 (26.1949)  lr: 0.0000 (0.0000)  time: 0.207564  data: 0.000450  max mem: 3586
I20250120 11:59:39 3545703 dinov2 helpers.py:102] Training  [ 1740/12500]  eta: 0:41:41  loss: 24.2223 (26.1384)  lr: 0.0000 (0.0000)  time: 0.207403  data: 0.000435  max mem: 3586
I20250120 11:59:41 3545703 dinov2 helpers.py:102] Training  [ 1750/12500]  eta: 0:41:37  loss: 24.2223 (26.1332)  lr: 0.0000 (0.0000)  time: 0.207763  data: 0.000441  max mem: 3586
I20250120 11:59:43 3545703 dinov2 helpers.py:102] Training  [ 1760/12500]  eta: 0:41:33  loss: 25.2109 (26.1587)  lr: 0.0000 (0.0000)  time: 0.207827  data: 0.000453  max mem: 3586
I20250120 11:59:45 3545703 dinov2 helpers.py:102] Training  [ 1770/12500]  eta: 0:41:29  loss: 25.2109 (26.1647)  lr: 0.0000 (0.0000)  time: 0.207812  data: 0.000475  max mem: 3586
I20250120 11:59:47 3545703 dinov2 helpers.py:102] Training  [ 1780/12500]  eta: 0:41:26  loss: 24.2223 (26.1377)  lr: 0.0000 (0.0000)  time: 0.207847  data: 0.000484  max mem: 3586
I20250120 11:59:49 3545703 dinov2 helpers.py:102] Training  [ 1790/12500]  eta: 0:41:22  loss: 25.2109 (26.1451)  lr: 0.0000 (0.0000)  time: 0.207603  data: 0.000436  max mem: 3586
I20250120 11:59:51 3545703 dinov2 helpers.py:102] Training  [ 1800/12500]  eta: 0:41:18  loss: 25.2109 (26.1385)  lr: 0.0000 (0.0000)  time: 0.207816  data: 0.000452  max mem: 3586
I20250120 11:59:53 3545703 dinov2 helpers.py:102] Training  [ 1810/12500]  eta: 0:41:14  loss: 25.3392 (26.1352)  lr: 0.0000 (0.0000)  time: 0.208003  data: 0.000468  max mem: 3586
I20250120 11:59:55 3545703 dinov2 helpers.py:102] Training  [ 1820/12500]  eta: 0:41:11  loss: 25.2109 (26.1042)  lr: 0.0000 (0.0000)  time: 0.207743  data: 0.000469  max mem: 3586
I20250120 11:59:57 3545703 dinov2 helpers.py:102] Training  [ 1830/12500]  eta: 0:41:07  loss: 25.2109 (26.0963)  lr: 0.0000 (0.0000)  time: 0.207609  data: 0.000468  max mem: 3586
I20250120 12:00:00 3545703 dinov2 helpers.py:102] Training  [ 1840/12500]  eta: 0:41:03  loss: 25.2109 (26.1300)  lr: 0.0000 (0.0000)  time: 0.207566  data: 0.000459  max mem: 3586
I20250120 12:00:02 3545703 dinov2 helpers.py:102] Training  [ 1850/12500]  eta: 0:41:00  loss: 25.2109 (26.1418)  lr: 0.0000 (0.0000)  time: 0.207695  data: 0.000451  max mem: 3586
I20250120 12:00:04 3545703 dinov2 helpers.py:102] Training  [ 1860/12500]  eta: 0:40:56  loss: 24.9663 (26.1332)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000398  max mem: 3586
I20250120 12:00:06 3545703 dinov2 helpers.py:102] Training  [ 1870/12500]  eta: 0:40:52  loss: 24.9663 (26.1101)  lr: 0.0000 (0.0000)  time: 0.207626  data: 0.000413  max mem: 3586
I20250120 12:00:08 3545703 dinov2 helpers.py:102] Training  [ 1880/12500]  eta: 0:40:49  loss: 24.9663 (26.1104)  lr: 0.0000 (0.0000)  time: 0.207815  data: 0.000443  max mem: 3586
I20250120 12:00:10 3545703 dinov2 helpers.py:102] Training  [ 1890/12500]  eta: 0:40:45  loss: 24.6491 (26.0991)  lr: 0.0000 (0.0000)  time: 0.207678  data: 0.000435  max mem: 3586
I20250120 12:00:12 3545703 dinov2 helpers.py:102] Training  [ 1900/12500]  eta: 0:40:42  loss: 24.6491 (26.0714)  lr: 0.0000 (0.0000)  time: 0.207641  data: 0.000448  max mem: 3586
I20250120 12:00:14 3545703 dinov2 helpers.py:102] Training  [ 1910/12500]  eta: 0:40:38  loss: 24.9663 (26.1033)  lr: 0.0000 (0.0000)  time: 0.207631  data: 0.000448  max mem: 3586
I20250120 12:00:16 3545703 dinov2 helpers.py:102] Training  [ 1920/12500]  eta: 0:40:34  loss: 24.9663 (26.1238)  lr: 0.0000 (0.0000)  time: 0.207677  data: 0.000460  max mem: 3586
I20250120 12:00:18 3545703 dinov2 helpers.py:102] Training  [ 1930/12500]  eta: 0:40:31  loss: 24.9663 (26.0957)  lr: 0.0000 (0.0000)  time: 0.207808  data: 0.000467  max mem: 3586
I20250120 12:00:20 3545703 dinov2 helpers.py:102] Training  [ 1940/12500]  eta: 0:40:27  loss: 25.2109 (26.1105)  lr: 0.0000 (0.0000)  time: 0.207531  data: 0.000488  max mem: 3586
I20250120 12:00:22 3545703 dinov2 helpers.py:102] Training  [ 1950/12500]  eta: 0:40:24  loss: 25.5376 (26.1496)  lr: 0.0000 (0.0000)  time: 0.207246  data: 0.000499  max mem: 3586
I20250120 12:00:24 3545703 dinov2 helpers.py:102] Training  [ 1960/12500]  eta: 0:40:20  loss: 25.0007 (26.1437)  lr: 0.0000 (0.0000)  time: 0.207471  data: 0.000489  max mem: 3586
I20250120 12:00:27 3545703 dinov2 helpers.py:102] Training  [ 1970/12500]  eta: 0:40:17  loss: 25.0007 (26.1722)  lr: 0.0000 (0.0000)  time: 0.207541  data: 0.000439  max mem: 3586
I20250120 12:00:29 3545703 dinov2 helpers.py:102] Training  [ 1980/12500]  eta: 0:40:13  loss: 25.5376 (26.1799)  lr: 0.0000 (0.0000)  time: 0.207627  data: 0.000432  max mem: 3586
I20250120 12:00:31 3545703 dinov2 helpers.py:102] Training  [ 1990/12500]  eta: 0:40:10  loss: 25.0007 (26.1386)  lr: 0.0000 (0.0000)  time: 0.207665  data: 0.000484  max mem: 3586
I20250120 12:00:33 3545703 dinov2 helpers.py:102] Training  [ 2000/12500]  eta: 0:40:07  loss: 25.5376 (26.1387)  lr: 0.0000 (0.0000)  time: 0.207474  data: 0.000495  max mem: 3586
I20250120 12:00:35 3545703 dinov2 helpers.py:102] Training  [ 2010/12500]  eta: 0:40:03  loss: 26.1614 (26.1792)  lr: 0.0000 (0.0000)  time: 0.207563  data: 0.000502  max mem: 3586
I20250120 12:00:37 3545703 dinov2 helpers.py:102] Training  [ 2020/12500]  eta: 0:40:00  loss: 26.1663 (26.2056)  lr: 0.0000 (0.0000)  time: 0.207636  data: 0.000507  max mem: 3586
I20250120 12:00:39 3545703 dinov2 helpers.py:102] Training  [ 2030/12500]  eta: 0:39:56  loss: 26.1663 (26.1980)  lr: 0.0000 (0.0000)  time: 0.207631  data: 0.000492  max mem: 3586
I20250120 12:00:41 3545703 dinov2 helpers.py:102] Training  [ 2040/12500]  eta: 0:39:53  loss: 26.1614 (26.1807)  lr: 0.0000 (0.0000)  time: 0.207690  data: 0.000441  max mem: 3586
I20250120 12:00:43 3545703 dinov2 helpers.py:102] Training  [ 2050/12500]  eta: 0:39:50  loss: 25.0007 (26.1633)  lr: 0.0000 (0.0000)  time: 0.207573  data: 0.000411  max mem: 3586
I20250120 12:00:45 3545703 dinov2 helpers.py:102] Training  [ 2060/12500]  eta: 0:39:46  loss: 25.0007 (26.1248)  lr: 0.0000 (0.0000)  time: 0.207512  data: 0.000443  max mem: 3586
I20250120 12:00:47 3545703 dinov2 helpers.py:102] Training  [ 2070/12500]  eta: 0:39:43  loss: 26.1614 (26.1310)  lr: 0.0000 (0.0000)  time: 0.207687  data: 0.000466  max mem: 3586
I20250120 12:00:49 3545703 dinov2 helpers.py:102] Training  [ 2080/12500]  eta: 0:39:40  loss: 26.1614 (26.1484)  lr: 0.0000 (0.0000)  time: 0.207908  data: 0.000458  max mem: 3586
I20250120 12:00:51 3545703 dinov2 helpers.py:102] Training  [ 2090/12500]  eta: 0:39:36  loss: 26.1614 (26.1362)  lr: 0.0000 (0.0000)  time: 0.207767  data: 0.000450  max mem: 3586
I20250120 12:00:54 3545703 dinov2 helpers.py:102] Training  [ 2100/12500]  eta: 0:39:33  loss: 26.1614 (26.1169)  lr: 0.0000 (0.0000)  time: 0.207302  data: 0.000421  max mem: 3586
I20250120 12:00:56 3545703 dinov2 helpers.py:102] Training  [ 2110/12500]  eta: 0:39:30  loss: 25.7189 (26.1150)  lr: 0.0000 (0.0000)  time: 0.207452  data: 0.000401  max mem: 3586
I20250120 12:00:58 3545703 dinov2 helpers.py:102] Training  [ 2120/12500]  eta: 0:39:26  loss: 25.7189 (26.1234)  lr: 0.0000 (0.0000)  time: 0.207610  data: 0.000430  max mem: 3586
I20250120 12:01:00 3545703 dinov2 helpers.py:102] Training  [ 2130/12500]  eta: 0:39:23  loss: 26.1614 (26.1496)  lr: 0.0000 (0.0000)  time: 0.207619  data: 0.000466  max mem: 3586
I20250120 12:01:02 3545703 dinov2 helpers.py:102] Training  [ 2140/12500]  eta: 0:39:20  loss: 26.1614 (26.1749)  lr: 0.0000 (0.0000)  time: 0.207692  data: 0.000466  max mem: 3586
I20250120 12:01:04 3545703 dinov2 helpers.py:102] Training  [ 2150/12500]  eta: 0:39:17  loss: 25.7189 (26.1654)  lr: 0.0000 (0.0000)  time: 0.207601  data: 0.000471  max mem: 3586
I20250120 12:01:06 3545703 dinov2 helpers.py:102] Training  [ 2160/12500]  eta: 0:39:13  loss: 26.1614 (26.1969)  lr: 0.0000 (0.0000)  time: 0.207559  data: 0.000475  max mem: 3586
I20250120 12:01:08 3545703 dinov2 helpers.py:102] Training  [ 2170/12500]  eta: 0:39:10  loss: 26.1614 (26.2021)  lr: 0.0000 (0.0000)  time: 0.207630  data: 0.000447  max mem: 3586
I20250120 12:01:10 3545703 dinov2 helpers.py:102] Training  [ 2180/12500]  eta: 0:39:07  loss: 25.7189 (26.1717)  lr: 0.0000 (0.0000)  time: 0.207940  data: 0.000447  max mem: 3586
I20250120 12:01:12 3545703 dinov2 helpers.py:102] Training  [ 2190/12500]  eta: 0:39:04  loss: 26.1614 (26.1747)  lr: 0.0000 (0.0000)  time: 0.207912  data: 0.000475  max mem: 3586
I20250120 12:01:14 3545703 dinov2 helpers.py:102] Training  [ 2200/12500]  eta: 0:39:00  loss: 25.7189 (26.1639)  lr: 0.0000 (0.0000)  time: 0.207742  data: 0.000481  max mem: 3586
I20250120 12:01:16 3545703 dinov2 helpers.py:102] Training  [ 2210/12500]  eta: 0:38:57  loss: 25.7189 (26.1638)  lr: 0.0000 (0.0000)  time: 0.207842  data: 0.000481  max mem: 3586
I20250120 12:01:18 3545703 dinov2 helpers.py:102] Training  [ 2220/12500]  eta: 0:38:54  loss: 24.6549 (26.1373)  lr: 0.0000 (0.0000)  time: 0.207772  data: 0.000433  max mem: 3586
I20250120 12:01:21 3545703 dinov2 helpers.py:102] Training  [ 2230/12500]  eta: 0:38:51  loss: 25.7189 (26.1444)  lr: 0.0000 (0.0000)  time: 0.207497  data: 0.000397  max mem: 3586
I20250120 12:01:23 3545703 dinov2 helpers.py:102] Training  [ 2240/12500]  eta: 0:38:48  loss: 26.1278 (26.1504)  lr: 0.0000 (0.0000)  time: 0.207637  data: 0.000446  max mem: 3586
I20250120 12:01:25 3545703 dinov2 helpers.py:102] Training  [ 2250/12500]  eta: 0:38:45  loss: 26.8360 (26.1756)  lr: 0.0000 (0.0000)  time: 0.208061  data: 0.000481  max mem: 3586
I20250120 12:01:27 3545703 dinov2 helpers.py:102] Training  [ 2260/12500]  eta: 0:38:42  loss: 26.9032 (26.1788)  lr: 0.0000 (0.0000)  time: 0.208125  data: 0.000460  max mem: 3586
I20250120 12:01:29 3545703 dinov2 helpers.py:102] Training  [ 2270/12500]  eta: 0:38:38  loss: 26.8360 (26.1803)  lr: 0.0000 (0.0000)  time: 0.207746  data: 0.000423  max mem: 3586
I20250120 12:01:31 3545703 dinov2 helpers.py:102] Training  [ 2280/12500]  eta: 0:38:35  loss: 26.5162 (26.1801)  lr: 0.0000 (0.0000)  time: 0.207534  data: 0.000449  max mem: 3586
I20250120 12:01:33 3545703 dinov2 helpers.py:102] Training  [ 2290/12500]  eta: 0:38:32  loss: 26.5162 (26.1665)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000477  max mem: 3586
I20250120 12:01:35 3545703 dinov2 helpers.py:102] Training  [ 2300/12500]  eta: 0:38:29  loss: 26.5162 (26.1623)  lr: 0.0000 (0.0000)  time: 0.207652  data: 0.000452  max mem: 3586
I20250120 12:01:37 3545703 dinov2 helpers.py:102] Training  [ 2310/12500]  eta: 0:38:26  loss: 26.5162 (26.1555)  lr: 0.0000 (0.0000)  time: 0.207861  data: 0.000420  max mem: 3586
I20250120 12:01:39 3545703 dinov2 helpers.py:102] Training  [ 2320/12500]  eta: 0:38:23  loss: 26.5162 (26.1642)  lr: 0.0000 (0.0000)  time: 0.207814  data: 0.000452  max mem: 3586
I20250120 12:01:41 3545703 dinov2 helpers.py:102] Training  [ 2330/12500]  eta: 0:38:20  loss: 26.1508 (26.1328)  lr: 0.0000 (0.0000)  time: 0.207882  data: 0.000473  max mem: 3586
I20250120 12:01:43 3545703 dinov2 helpers.py:102] Training  [ 2340/12500]  eta: 0:38:17  loss: 26.1278 (26.1103)  lr: 0.0000 (0.0000)  time: 0.207992  data: 0.000456  max mem: 3586
I20250120 12:01:45 3545703 dinov2 helpers.py:102] Training  [ 2350/12500]  eta: 0:38:14  loss: 26.1278 (26.1075)  lr: 0.0000 (0.0000)  time: 0.207829  data: 0.000473  max mem: 3586
I20250120 12:01:48 3545703 dinov2 helpers.py:102] Training  [ 2360/12500]  eta: 0:38:11  loss: 25.4549 (26.0959)  lr: 0.0000 (0.0000)  time: 0.207740  data: 0.000477  max mem: 3586
I20250120 12:01:50 3545703 dinov2 helpers.py:102] Training  [ 2370/12500]  eta: 0:38:08  loss: 25.4549 (26.1200)  lr: 0.0000 (0.0000)  time: 0.207688  data: 0.000502  max mem: 3586
I20250120 12:01:52 3545703 dinov2 helpers.py:102] Training  [ 2380/12500]  eta: 0:38:05  loss: 25.4549 (26.1167)  lr: 0.0000 (0.0000)  time: 0.207830  data: 0.000500  max mem: 3586
I20250120 12:01:54 3545703 dinov2 helpers.py:102] Training  [ 2390/12500]  eta: 0:38:02  loss: 25.4549 (26.1421)  lr: 0.0000 (0.0000)  time: 0.208161  data: 0.000460  max mem: 3586
I20250120 12:01:56 3545703 dinov2 helpers.py:102] Training  [ 2400/12500]  eta: 0:37:59  loss: 26.1278 (26.1448)  lr: 0.0000 (0.0000)  time: 0.207994  data: 0.000430  max mem: 3586
I20250120 12:01:58 3545703 dinov2 helpers.py:102] Training  [ 2410/12500]  eta: 0:37:56  loss: 25.4549 (26.1115)  lr: 0.0000 (0.0000)  time: 0.207879  data: 0.000446  max mem: 3586
I20250120 12:02:00 3545703 dinov2 helpers.py:102] Training  [ 2420/12500]  eta: 0:37:53  loss: 26.1508 (26.1245)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000485  max mem: 3586
I20250120 12:02:02 3545703 dinov2 helpers.py:102] Training  [ 2430/12500]  eta: 0:37:50  loss: 26.1508 (26.1521)  lr: 0.0000 (0.0000)  time: 0.208245  data: 0.000462  max mem: 3586
I20250120 12:02:04 3545703 dinov2 helpers.py:102] Training  [ 2440/12500]  eta: 0:37:47  loss: 25.4549 (26.1381)  lr: 0.0000 (0.0000)  time: 0.208108  data: 0.000447  max mem: 3586
I20250120 12:02:06 3545703 dinov2 helpers.py:102] Training  [ 2450/12500]  eta: 0:37:44  loss: 25.3184 (26.1218)  lr: 0.0000 (0.0000)  time: 0.207934  data: 0.000460  max mem: 3586
I20250120 12:02:08 3545703 dinov2 helpers.py:102] Training  [ 2460/12500]  eta: 0:37:41  loss: 25.2136 (26.1038)  lr: 0.0000 (0.0000)  time: 0.207988  data: 0.000475  max mem: 3586
I20250120 12:02:10 3545703 dinov2 helpers.py:102] Training  [ 2470/12500]  eta: 0:37:38  loss: 25.2136 (26.1179)  lr: 0.0000 (0.0000)  time: 0.207842  data: 0.000480  max mem: 3586
I20250120 12:02:13 3545703 dinov2 helpers.py:102] Training  [ 2480/12500]  eta: 0:37:35  loss: 24.5653 (26.1101)  lr: 0.0000 (0.0000)  time: 0.207599  data: 0.000466  max mem: 3586
I20250120 12:02:15 3545703 dinov2 helpers.py:102] Training  [ 2490/12500]  eta: 0:37:32  loss: 24.5653 (26.0995)  lr: 0.0000 (0.0000)  time: 0.207593  data: 0.000454  max mem: 3586
I20250120 12:02:16 3545703 dinov2 linear.py:272] running validation !
I20250120 12:02:18 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:18    time: 1.667830  data: 1.458379  max mem: 3586
I20250120 12:02:20 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:50    time: 0.347148  data: 0.133350  max mem: 3586
I20250120 12:02:22 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:38    time: 0.213408  data: 0.000736  max mem: 3586
I20250120 12:02:25 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.210948  data: 0.000418  max mem: 3586
I20250120 12:02:27 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210055  data: 0.000249  max mem: 3586
I20250120 12:02:29 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.210386  data: 0.000266  max mem: 3586
I20250120 12:02:31 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210697  data: 0.000251  max mem: 3586
I20250120 12:02:33 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210572  data: 0.000253  max mem: 3586
I20250120 12:02:35 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210696  data: 0.000228  max mem: 3586
I20250120 12:02:37 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210709  data: 0.000259  max mem: 3586
I20250120 12:02:39 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210893  data: 0.000271  max mem: 3586
I20250120 12:02:41 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210719  data: 0.000239  max mem: 3586
I20250120 12:02:43 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210193  data: 0.000266  max mem: 3586
I20250120 12:02:46 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210528  data: 0.000263  max mem: 3586
I20250120 12:02:48 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210787  data: 0.000235  max mem: 3586
I20250120 12:02:50 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210312  data: 0.000177  max mem: 3586
I20250120 12:02:51 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205985  data: 0.000157  max mem: 3586
I20250120 12:02:51 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.220761 s / it)
I20250120 12:02:51 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:02:51 3545703 dinov2 linear.py:287] 
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8436, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8558, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8599, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8676, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8718, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8737, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8743, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8721, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8682, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8516, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8460, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8465, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8539, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8641, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8699, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8767, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8789, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8794, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8761, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8713, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8674, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8520, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8530, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8655, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8710, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8744, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8778, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8785, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8714, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8678, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8355, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8056, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8096, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8598, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8716, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8752, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8786, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8727, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8408, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8417, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8319, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8809114694595337}
I20250120 12:02:51 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:02:51 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:02:51 3545703 dinov2 helpers.py:102] Training  [ 2500/12500]  eta: 0:39:46  loss: 24.5653 (26.1095)  lr: 0.0000 (0.0000)  time: 1.923254  data: 0.000431  max mem: 3586
I20250120 12:02:53 3545703 dinov2 helpers.py:102] Training  [ 2510/12500]  eta: 0:39:43  loss: 24.1744 (26.0879)  lr: 0.0000 (0.0000)  time: 1.922509  data: 0.000415  max mem: 3586
I20250120 12:02:56 3545703 dinov2 helpers.py:102] Training  [ 2520/12500]  eta: 0:39:41  loss: 24.1744 (26.1004)  lr: 0.0000 (0.0000)  time: 0.229879  data: 0.027453  max mem: 3586
I20250120 12:02:58 3545703 dinov2 helpers.py:102] Training  [ 2530/12500]  eta: 0:39:37  loss: 24.1744 (26.0800)  lr: 0.0000 (0.0000)  time: 0.230369  data: 0.027452  max mem: 3586
I20250120 12:03:00 3545703 dinov2 helpers.py:102] Training  [ 2540/12500]  eta: 0:39:33  loss: 24.1744 (26.0498)  lr: 0.0000 (0.0000)  time: 0.207000  data: 0.000430  max mem: 3586
I20250120 12:03:02 3545703 dinov2 helpers.py:102] Training  [ 2550/12500]  eta: 0:39:30  loss: 24.1744 (26.0475)  lr: 0.0000 (0.0000)  time: 0.206666  data: 0.000448  max mem: 3586
I20250120 12:03:04 3545703 dinov2 helpers.py:102] Training  [ 2560/12500]  eta: 0:39:26  loss: 24.1744 (26.0233)  lr: 0.0000 (0.0000)  time: 0.206616  data: 0.000452  max mem: 3586
I20250120 12:03:06 3545703 dinov2 helpers.py:102] Training  [ 2570/12500]  eta: 0:39:23  loss: 23.4485 (26.0068)  lr: 0.0000 (0.0000)  time: 0.206808  data: 0.000443  max mem: 3586
I20250120 12:03:08 3545703 dinov2 helpers.py:102] Training  [ 2580/12500]  eta: 0:39:19  loss: 23.4485 (26.0067)  lr: 0.0000 (0.0000)  time: 0.206736  data: 0.000427  max mem: 3586
I20250120 12:03:10 3545703 dinov2 helpers.py:102] Training  [ 2590/12500]  eta: 0:39:15  loss: 22.7216 (25.9684)  lr: 0.0000 (0.0000)  time: 0.206737  data: 0.000443  max mem: 3586
I20250120 12:03:12 3545703 dinov2 helpers.py:102] Training  [ 2600/12500]  eta: 0:39:12  loss: 22.7216 (25.9626)  lr: 0.0000 (0.0000)  time: 0.206863  data: 0.000432  max mem: 3586
I20250120 12:03:14 3545703 dinov2 helpers.py:102] Training  [ 2610/12500]  eta: 0:39:08  loss: 23.4485 (25.9598)  lr: 0.0000 (0.0000)  time: 0.206914  data: 0.000429  max mem: 3586
I20250120 12:03:16 3545703 dinov2 helpers.py:102] Training  [ 2620/12500]  eta: 0:39:05  loss: 23.4485 (25.9529)  lr: 0.0000 (0.0000)  time: 0.206852  data: 0.000417  max mem: 3586
I20250120 12:03:18 3545703 dinov2 helpers.py:102] Training  [ 2630/12500]  eta: 0:39:01  loss: 22.7216 (25.9295)  lr: 0.0000 (0.0000)  time: 0.206997  data: 0.000370  max mem: 3586
I20250120 12:03:20 3545703 dinov2 helpers.py:102] Training  [ 2640/12500]  eta: 0:38:58  loss: 23.4485 (25.9225)  lr: 0.0000 (0.0000)  time: 0.207072  data: 0.000426  max mem: 3586
I20250120 12:03:23 3545703 dinov2 helpers.py:102] Training  [ 2650/12500]  eta: 0:38:54  loss: 23.4485 (25.8954)  lr: 0.0000 (0.0000)  time: 0.207184  data: 0.000455  max mem: 3586
I20250120 12:03:25 3545703 dinov2 helpers.py:102] Training  [ 2660/12500]  eta: 0:38:51  loss: 23.4485 (25.8820)  lr: 0.0000 (0.0000)  time: 0.207423  data: 0.000438  max mem: 3586
I20250120 12:03:27 3545703 dinov2 helpers.py:102] Training  [ 2670/12500]  eta: 0:38:47  loss: 23.4454 (25.8729)  lr: 0.0000 (0.0000)  time: 0.207443  data: 0.000453  max mem: 3586
I20250120 12:03:29 3545703 dinov2 helpers.py:102] Training  [ 2680/12500]  eta: 0:38:44  loss: 22.9060 (25.8619)  lr: 0.0000 (0.0000)  time: 0.207392  data: 0.000422  max mem: 3586
I20250120 12:03:31 3545703 dinov2 helpers.py:102] Training  [ 2690/12500]  eta: 0:38:41  loss: 22.9060 (25.8548)  lr: 0.0000 (0.0000)  time: 0.207356  data: 0.000392  max mem: 3586
I20250120 12:03:33 3545703 dinov2 helpers.py:102] Training  [ 2700/12500]  eta: 0:38:37  loss: 22.9060 (25.8475)  lr: 0.0000 (0.0000)  time: 0.207258  data: 0.000431  max mem: 3586
I20250120 12:03:35 3545703 dinov2 helpers.py:102] Training  [ 2710/12500]  eta: 0:38:34  loss: 23.4454 (25.8445)  lr: 0.0000 (0.0000)  time: 0.207199  data: 0.000494  max mem: 3586
I20250120 12:03:37 3545703 dinov2 helpers.py:102] Training  [ 2720/12500]  eta: 0:38:30  loss: 22.9060 (25.8240)  lr: 0.0000 (0.0000)  time: 0.207359  data: 0.000461  max mem: 3586
I20250120 12:03:39 3545703 dinov2 helpers.py:102] Training  [ 2730/12500]  eta: 0:38:27  loss: 23.2998 (25.8148)  lr: 0.0000 (0.0000)  time: 0.207567  data: 0.000450  max mem: 3586
I20250120 12:03:41 3545703 dinov2 helpers.py:102] Training  [ 2740/12500]  eta: 0:38:24  loss: 23.4454 (25.8258)  lr: 0.0000 (0.0000)  time: 0.207606  data: 0.000492  max mem: 3586
I20250120 12:03:43 3545703 dinov2 helpers.py:102] Training  [ 2750/12500]  eta: 0:38:20  loss: 23.4454 (25.8195)  lr: 0.0000 (0.0000)  time: 0.207527  data: 0.000490  max mem: 3586
I20250120 12:03:45 3545703 dinov2 helpers.py:102] Training  [ 2760/12500]  eta: 0:38:17  loss: 23.4454 (25.8063)  lr: 0.0000 (0.0000)  time: 0.207493  data: 0.000474  max mem: 3586
I20250120 12:03:47 3545703 dinov2 helpers.py:102] Training  [ 2770/12500]  eta: 0:38:13  loss: 23.8869 (25.8034)  lr: 0.0000 (0.0000)  time: 0.207557  data: 0.000476  max mem: 3586
I20250120 12:03:49 3545703 dinov2 helpers.py:102] Training  [ 2780/12500]  eta: 0:38:10  loss: 23.8869 (25.8001)  lr: 0.0000 (0.0000)  time: 0.207728  data: 0.000508  max mem: 3586
I20250120 12:03:52 3545703 dinov2 helpers.py:102] Training  [ 2790/12500]  eta: 0:38:07  loss: 23.9545 (25.8102)  lr: 0.0000 (0.0000)  time: 0.207845  data: 0.000512  max mem: 3586
I20250120 12:03:54 3545703 dinov2 helpers.py:102] Training  [ 2800/12500]  eta: 0:38:04  loss: 23.8869 (25.7938)  lr: 0.0000 (0.0000)  time: 0.208009  data: 0.000502  max mem: 3586
I20250120 12:03:56 3545703 dinov2 helpers.py:102] Training  [ 2810/12500]  eta: 0:38:00  loss: 23.4454 (25.7745)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000457  max mem: 3586
I20250120 12:03:58 3545703 dinov2 helpers.py:102] Training  [ 2820/12500]  eta: 0:37:57  loss: 23.4454 (25.8149)  lr: 0.0000 (0.0000)  time: 0.208234  data: 0.000368  max mem: 3586
I20250120 12:04:00 3545703 dinov2 helpers.py:102] Training  [ 2830/12500]  eta: 0:37:54  loss: 23.4454 (25.7879)  lr: 0.0000 (0.0000)  time: 0.208068  data: 0.000395  max mem: 3586
I20250120 12:04:02 3545703 dinov2 helpers.py:102] Training  [ 2840/12500]  eta: 0:37:50  loss: 23.4454 (25.7810)  lr: 0.0000 (0.0000)  time: 0.207802  data: 0.000429  max mem: 3586
I20250120 12:04:04 3545703 dinov2 helpers.py:102] Training  [ 2850/12500]  eta: 0:37:47  loss: 23.8316 (25.7854)  lr: 0.0000 (0.0000)  time: 0.207636  data: 0.000432  max mem: 3586
I20250120 12:04:09 3545703 dinov2 helpers.py:102] Training  [ 2860/12500]  eta: 0:37:53  loss: 23.8869 (25.7947)  lr: 0.0000 (0.0000)  time: 0.349924  data: 0.146957  max mem: 3586
I20250120 12:04:13 3545703 dinov2 helpers.py:102] Training  [ 2870/12500]  eta: 0:37:55  loss: 23.8869 (25.7871)  lr: 0.0000 (0.0000)  time: 0.430342  data: 0.232351  max mem: 3586
I20250120 12:04:15 3545703 dinov2 helpers.py:102] Training  [ 2880/12500]  eta: 0:37:52  loss: 23.9545 (25.7871)  lr: 0.0000 (0.0000)  time: 0.287214  data: 0.086120  max mem: 3586
I20250120 12:04:17 3545703 dinov2 helpers.py:102] Training  [ 2890/12500]  eta: 0:37:49  loss: 23.8869 (25.7801)  lr: 0.0000 (0.0000)  time: 0.206120  data: 0.000738  max mem: 3586
I20250120 12:04:19 3545703 dinov2 helpers.py:102] Training  [ 2900/12500]  eta: 0:37:45  loss: 23.8316 (25.7715)  lr: 0.0000 (0.0000)  time: 0.206457  data: 0.000461  max mem: 3586
I20250120 12:04:21 3545703 dinov2 helpers.py:102] Training  [ 2910/12500]  eta: 0:37:42  loss: 23.8316 (25.7872)  lr: 0.0000 (0.0000)  time: 0.206769  data: 0.000457  max mem: 3586
I20250120 12:04:23 3545703 dinov2 helpers.py:102] Training  [ 2920/12500]  eta: 0:37:39  loss: 23.8316 (25.7758)  lr: 0.0000 (0.0000)  time: 0.206936  data: 0.000517  max mem: 3586
I20250120 12:04:25 3545703 dinov2 helpers.py:102] Training  [ 2930/12500]  eta: 0:37:35  loss: 24.0736 (25.7895)  lr: 0.0000 (0.0000)  time: 0.207176  data: 0.000485  max mem: 3586
I20250120 12:04:27 3545703 dinov2 helpers.py:102] Training  [ 2940/12500]  eta: 0:37:32  loss: 24.0736 (25.7849)  lr: 0.0000 (0.0000)  time: 0.207682  data: 0.000413  max mem: 3586
I20250120 12:04:29 3545703 dinov2 helpers.py:102] Training  [ 2950/12500]  eta: 0:37:29  loss: 24.4238 (25.7823)  lr: 0.0000 (0.0000)  time: 0.207807  data: 0.000413  max mem: 3586
I20250120 12:04:31 3545703 dinov2 helpers.py:102] Training  [ 2960/12500]  eta: 0:37:26  loss: 24.4238 (25.7575)  lr: 0.0000 (0.0000)  time: 0.207766  data: 0.000418  max mem: 3586
I20250120 12:04:33 3545703 dinov2 helpers.py:102] Training  [ 2970/12500]  eta: 0:37:22  loss: 23.8316 (25.7426)  lr: 0.0000 (0.0000)  time: 0.207788  data: 0.000438  max mem: 3586
I20250120 12:04:35 3545703 dinov2 helpers.py:102] Training  [ 2980/12500]  eta: 0:37:19  loss: 23.8316 (25.7633)  lr: 0.0000 (0.0000)  time: 0.207971  data: 0.000455  max mem: 3586
I20250120 12:04:38 3545703 dinov2 helpers.py:102] Training  [ 2990/12500]  eta: 0:37:16  loss: 23.8316 (25.7683)  lr: 0.0000 (0.0000)  time: 0.208356  data: 0.000475  max mem: 3586
I20250120 12:04:40 3545703 dinov2 helpers.py:102] Training  [ 3000/12500]  eta: 0:37:13  loss: 24.3605 (25.7636)  lr: 0.0000 (0.0000)  time: 0.208474  data: 0.000483  max mem: 3586
I20250120 12:04:42 3545703 dinov2 helpers.py:102] Training  [ 3010/12500]  eta: 0:37:10  loss: 24.3605 (25.7543)  lr: 0.0000 (0.0000)  time: 0.208570  data: 0.000464  max mem: 3586
I20250120 12:04:44 3545703 dinov2 helpers.py:102] Training  [ 3020/12500]  eta: 0:37:07  loss: 24.3605 (25.7541)  lr: 0.0000 (0.0000)  time: 0.208822  data: 0.000486  max mem: 3586
I20250120 12:04:46 3545703 dinov2 helpers.py:102] Training  [ 3030/12500]  eta: 0:37:03  loss: 24.3605 (25.7449)  lr: 0.0000 (0.0000)  time: 0.209026  data: 0.000463  max mem: 3586
I20250120 12:04:48 3545703 dinov2 helpers.py:102] Training  [ 3040/12500]  eta: 0:37:00  loss: 24.3605 (25.7308)  lr: 0.0000 (0.0000)  time: 0.209131  data: 0.000431  max mem: 3586
I20250120 12:04:50 3545703 dinov2 helpers.py:102] Training  [ 3050/12500]  eta: 0:36:57  loss: 24.3605 (25.7467)  lr: 0.0000 (0.0000)  time: 0.209106  data: 0.000446  max mem: 3586
I20250120 12:04:52 3545703 dinov2 helpers.py:102] Training  [ 3060/12500]  eta: 0:36:54  loss: 24.3605 (25.7571)  lr: 0.0000 (0.0000)  time: 0.209114  data: 0.000466  max mem: 3586
I20250120 12:04:54 3545703 dinov2 helpers.py:102] Training  [ 3070/12500]  eta: 0:36:51  loss: 24.4238 (25.7597)  lr: 0.0000 (0.0000)  time: 0.209224  data: 0.000472  max mem: 3586
I20250120 12:04:56 3545703 dinov2 helpers.py:102] Training  [ 3080/12500]  eta: 0:36:48  loss: 24.4238 (25.7622)  lr: 0.0000 (0.0000)  time: 0.209267  data: 0.000410  max mem: 3586
I20250120 12:04:58 3545703 dinov2 helpers.py:102] Training  [ 3090/12500]  eta: 0:36:45  loss: 24.4238 (25.7391)  lr: 0.0000 (0.0000)  time: 0.209229  data: 0.000400  max mem: 3586
I20250120 12:05:01 3545703 dinov2 helpers.py:102] Training  [ 3100/12500]  eta: 0:36:41  loss: 24.4238 (25.7321)  lr: 0.0000 (0.0000)  time: 0.209364  data: 0.000416  max mem: 3586
I20250120 12:05:03 3545703 dinov2 helpers.py:102] Training  [ 3110/12500]  eta: 0:36:38  loss: 24.3605 (25.7194)  lr: 0.0000 (0.0000)  time: 0.209396  data: 0.000420  max mem: 3586
I20250120 12:05:05 3545703 dinov2 helpers.py:102] Training  [ 3120/12500]  eta: 0:36:35  loss: 24.3605 (25.7087)  lr: 0.0000 (0.0000)  time: 0.209153  data: 0.000459  max mem: 3586
I20250120 12:05:07 3545703 dinov2 helpers.py:102] Training  [ 3130/12500]  eta: 0:36:32  loss: 23.5872 (25.6956)  lr: 0.0000 (0.0000)  time: 0.209105  data: 0.000467  max mem: 3586
I20250120 12:05:09 3545703 dinov2 helpers.py:102] Training  [ 3140/12500]  eta: 0:36:29  loss: 23.5872 (25.7177)  lr: 0.0000 (0.0000)  time: 0.209219  data: 0.000441  max mem: 3586
I20250120 12:05:11 3545703 dinov2 helpers.py:102] Training  [ 3150/12500]  eta: 0:36:26  loss: 22.9678 (25.6929)  lr: 0.0000 (0.0000)  time: 0.209224  data: 0.000427  max mem: 3586
I20250120 12:05:13 3545703 dinov2 helpers.py:102] Training  [ 3160/12500]  eta: 0:36:23  loss: 23.5872 (25.6880)  lr: 0.0000 (0.0000)  time: 0.209189  data: 0.000412  max mem: 3586
I20250120 12:05:15 3545703 dinov2 helpers.py:102] Training  [ 3170/12500]  eta: 0:36:20  loss: 23.5872 (25.6738)  lr: 0.0000 (0.0000)  time: 0.209312  data: 0.000417  max mem: 3586
I20250120 12:05:17 3545703 dinov2 helpers.py:102] Training  [ 3180/12500]  eta: 0:36:17  loss: 22.9678 (25.6578)  lr: 0.0000 (0.0000)  time: 0.209426  data: 0.000453  max mem: 3586
I20250120 12:05:19 3545703 dinov2 helpers.py:102] Training  [ 3190/12500]  eta: 0:36:14  loss: 22.9678 (25.6541)  lr: 0.0000 (0.0000)  time: 0.209416  data: 0.000464  max mem: 3586
I20250120 12:05:21 3545703 dinov2 helpers.py:102] Training  [ 3200/12500]  eta: 0:36:11  loss: 22.9678 (25.6481)  lr: 0.0000 (0.0000)  time: 0.209556  data: 0.000444  max mem: 3586
I20250120 12:05:24 3545703 dinov2 helpers.py:102] Training  [ 3210/12500]  eta: 0:36:08  loss: 22.9678 (25.6377)  lr: 0.0000 (0.0000)  time: 0.209623  data: 0.000440  max mem: 3586
I20250120 12:05:26 3545703 dinov2 helpers.py:102] Training  [ 3220/12500]  eta: 0:36:05  loss: 22.3455 (25.6229)  lr: 0.0000 (0.0000)  time: 0.209558  data: 0.000452  max mem: 3586
I20250120 12:05:28 3545703 dinov2 helpers.py:102] Training  [ 3230/12500]  eta: 0:36:02  loss: 22.3455 (25.6316)  lr: 0.0000 (0.0000)  time: 0.209556  data: 0.000470  max mem: 3586
I20250120 12:05:30 3545703 dinov2 helpers.py:102] Training  [ 3240/12500]  eta: 0:35:59  loss: 23.5010 (25.6250)  lr: 0.0000 (0.0000)  time: 0.209512  data: 0.000494  max mem: 3586
I20250120 12:05:32 3545703 dinov2 helpers.py:102] Training  [ 3250/12500]  eta: 0:35:56  loss: 22.3455 (25.6141)  lr: 0.0000 (0.0000)  time: 0.209524  data: 0.000496  max mem: 3586
I20250120 12:05:34 3545703 dinov2 helpers.py:102] Training  [ 3260/12500]  eta: 0:35:53  loss: 22.3455 (25.6095)  lr: 0.0000 (0.0000)  time: 0.209604  data: 0.000478  max mem: 3586
I20250120 12:05:36 3545703 dinov2 helpers.py:102] Training  [ 3270/12500]  eta: 0:35:50  loss: 22.3064 (25.5977)  lr: 0.0000 (0.0000)  time: 0.209753  data: 0.000527  max mem: 3586
I20250120 12:05:38 3545703 dinov2 helpers.py:102] Training  [ 3280/12500]  eta: 0:35:47  loss: 22.3064 (25.5889)  lr: 0.0000 (0.0000)  time: 0.209871  data: 0.000566  max mem: 3586
I20250120 12:05:40 3545703 dinov2 helpers.py:102] Training  [ 3290/12500]  eta: 0:35:44  loss: 22.3455 (25.5895)  lr: 0.0000 (0.0000)  time: 0.209869  data: 0.000449  max mem: 3586
I20250120 12:05:42 3545703 dinov2 helpers.py:102] Training  [ 3300/12500]  eta: 0:35:41  loss: 22.3064 (25.5670)  lr: 0.0000 (0.0000)  time: 0.209875  data: 0.000347  max mem: 3586
I20250120 12:05:45 3545703 dinov2 helpers.py:102] Training  [ 3310/12500]  eta: 0:35:38  loss: 22.3064 (25.5409)  lr: 0.0000 (0.0000)  time: 0.209905  data: 0.000393  max mem: 3586
I20250120 12:05:47 3545703 dinov2 helpers.py:102] Training  [ 3320/12500]  eta: 0:35:35  loss: 22.0670 (25.5285)  lr: 0.0000 (0.0000)  time: 0.209944  data: 0.000419  max mem: 3586
I20250120 12:05:49 3545703 dinov2 helpers.py:102] Training  [ 3330/12500]  eta: 0:35:32  loss: 22.0670 (25.5142)  lr: 0.0000 (0.0000)  time: 0.209833  data: 0.000407  max mem: 3586
I20250120 12:05:51 3545703 dinov2 helpers.py:102] Training  [ 3340/12500]  eta: 0:35:29  loss: 22.0670 (25.5187)  lr: 0.0000 (0.0000)  time: 0.209744  data: 0.000456  max mem: 3586
I20250120 12:05:53 3545703 dinov2 helpers.py:102] Training  [ 3350/12500]  eta: 0:35:26  loss: 22.3064 (25.5145)  lr: 0.0000 (0.0000)  time: 0.209734  data: 0.000477  max mem: 3586
I20250120 12:05:55 3545703 dinov2 helpers.py:102] Training  [ 3360/12500]  eta: 0:35:23  loss: 22.3064 (25.5082)  lr: 0.0000 (0.0000)  time: 0.209650  data: 0.000448  max mem: 3586
I20250120 12:05:57 3545703 dinov2 helpers.py:102] Training  [ 3370/12500]  eta: 0:35:20  loss: 22.6894 (25.5100)  lr: 0.0000 (0.0000)  time: 0.209723  data: 0.000437  max mem: 3586
I20250120 12:05:59 3545703 dinov2 helpers.py:102] Training  [ 3380/12500]  eta: 0:35:17  loss: 23.3816 (25.5063)  lr: 0.0000 (0.0000)  time: 0.209649  data: 0.000476  max mem: 3586
I20250120 12:06:01 3545703 dinov2 helpers.py:102] Training  [ 3390/12500]  eta: 0:35:14  loss: 22.6894 (25.4841)  lr: 0.0000 (0.0000)  time: 0.209633  data: 0.000500  max mem: 3586
I20250120 12:06:03 3545703 dinov2 helpers.py:102] Training  [ 3400/12500]  eta: 0:35:11  loss: 22.3064 (25.4604)  lr: 0.0000 (0.0000)  time: 0.209688  data: 0.000458  max mem: 3586
I20250120 12:06:06 3545703 dinov2 helpers.py:102] Training  [ 3410/12500]  eta: 0:35:08  loss: 22.0670 (25.4493)  lr: 0.0000 (0.0000)  time: 0.209680  data: 0.000419  max mem: 3586
I20250120 12:06:08 3545703 dinov2 helpers.py:102] Training  [ 3420/12500]  eta: 0:35:06  loss: 22.1515 (25.4396)  lr: 0.0000 (0.0000)  time: 0.209691  data: 0.000432  max mem: 3586
I20250120 12:06:10 3545703 dinov2 helpers.py:102] Training  [ 3430/12500]  eta: 0:35:03  loss: 22.0670 (25.4199)  lr: 0.0000 (0.0000)  time: 0.209760  data: 0.000447  max mem: 3586
I20250120 12:06:12 3545703 dinov2 helpers.py:102] Training  [ 3440/12500]  eta: 0:35:00  loss: 22.0670 (25.4269)  lr: 0.0000 (0.0000)  time: 0.209930  data: 0.000423  max mem: 3586
I20250120 12:06:14 3545703 dinov2 helpers.py:102] Training  [ 3450/12500]  eta: 0:34:57  loss: 22.1515 (25.4307)  lr: 0.0000 (0.0000)  time: 0.209948  data: 0.000439  max mem: 3586
I20250120 12:06:16 3545703 dinov2 helpers.py:102] Training  [ 3460/12500]  eta: 0:34:54  loss: 22.1515 (25.4226)  lr: 0.0000 (0.0000)  time: 0.209968  data: 0.000472  max mem: 3586
I20250120 12:06:18 3545703 dinov2 helpers.py:102] Training  [ 3470/12500]  eta: 0:34:51  loss: 22.1515 (25.4130)  lr: 0.0000 (0.0000)  time: 0.209960  data: 0.000441  max mem: 3586
I20250120 12:06:20 3545703 dinov2 helpers.py:102] Training  [ 3480/12500]  eta: 0:34:48  loss: 22.0608 (25.4010)  lr: 0.0000 (0.0000)  time: 0.209762  data: 0.000407  max mem: 3586
I20250120 12:06:22 3545703 dinov2 helpers.py:102] Training  [ 3490/12500]  eta: 0:34:45  loss: 22.0608 (25.3972)  lr: 0.0000 (0.0000)  time: 0.209737  data: 0.000430  max mem: 3586
I20250120 12:06:24 3545703 dinov2 helpers.py:102] Training  [ 3500/12500]  eta: 0:34:42  loss: 22.0608 (25.3862)  lr: 0.0000 (0.0000)  time: 0.209684  data: 0.000472  max mem: 3586
I20250120 12:06:27 3545703 dinov2 helpers.py:102] Training  [ 3510/12500]  eta: 0:34:40  loss: 22.1515 (25.3809)  lr: 0.0000 (0.0000)  time: 0.209616  data: 0.000427  max mem: 3586
I20250120 12:06:29 3545703 dinov2 helpers.py:102] Training  [ 3520/12500]  eta: 0:34:37  loss: 22.6471 (25.3736)  lr: 0.0000 (0.0000)  time: 0.209677  data: 0.000434  max mem: 3586
I20250120 12:06:31 3545703 dinov2 helpers.py:102] Training  [ 3530/12500]  eta: 0:34:34  loss: 22.7934 (25.3860)  lr: 0.0000 (0.0000)  time: 0.209729  data: 0.000468  max mem: 3586
I20250120 12:06:33 3545703 dinov2 helpers.py:102] Training  [ 3540/12500]  eta: 0:34:31  loss: 22.6471 (25.3780)  lr: 0.0000 (0.0000)  time: 0.209801  data: 0.000448  max mem: 3586
I20250120 12:06:35 3545703 dinov2 helpers.py:102] Training  [ 3550/12500]  eta: 0:34:28  loss: 22.5368 (25.3648)  lr: 0.0000 (0.0000)  time: 0.209734  data: 0.000459  max mem: 3586
I20250120 12:06:37 3545703 dinov2 helpers.py:102] Training  [ 3560/12500]  eta: 0:34:25  loss: 22.5368 (25.3652)  lr: 0.0000 (0.0000)  time: 0.209681  data: 0.000474  max mem: 3586
I20250120 12:06:39 3545703 dinov2 helpers.py:102] Training  [ 3570/12500]  eta: 0:34:22  loss: 22.5368 (25.3591)  lr: 0.0000 (0.0000)  time: 0.209789  data: 0.000452  max mem: 3586
I20250120 12:06:41 3545703 dinov2 helpers.py:102] Training  [ 3580/12500]  eta: 0:34:20  loss: 22.1515 (25.3371)  lr: 0.0000 (0.0000)  time: 0.209820  data: 0.000433  max mem: 3586
I20250120 12:06:43 3545703 dinov2 helpers.py:102] Training  [ 3590/12500]  eta: 0:34:17  loss: 22.2882 (25.3286)  lr: 0.0000 (0.0000)  time: 0.209771  data: 0.000420  max mem: 3586
I20250120 12:06:45 3545703 dinov2 helpers.py:102] Training  [ 3600/12500]  eta: 0:34:14  loss: 22.5368 (25.3274)  lr: 0.0000 (0.0000)  time: 0.209769  data: 0.000429  max mem: 3586
I20250120 12:06:48 3545703 dinov2 helpers.py:102] Training  [ 3610/12500]  eta: 0:34:11  loss: 22.6471 (25.3250)  lr: 0.0000 (0.0000)  time: 0.209879  data: 0.000422  max mem: 3586
I20250120 12:06:50 3545703 dinov2 helpers.py:102] Training  [ 3620/12500]  eta: 0:34:08  loss: 22.7934 (25.3198)  lr: 0.0000 (0.0000)  time: 0.209976  data: 0.000428  max mem: 3586
I20250120 12:06:52 3545703 dinov2 helpers.py:102] Training  [ 3630/12500]  eta: 0:34:05  loss: 23.1905 (25.3184)  lr: 0.0000 (0.0000)  time: 0.209894  data: 0.000465  max mem: 3586
I20250120 12:06:54 3545703 dinov2 helpers.py:102] Training  [ 3640/12500]  eta: 0:34:03  loss: 23.1905 (25.3239)  lr: 0.0000 (0.0000)  time: 0.209873  data: 0.000483  max mem: 3586
I20250120 12:06:56 3545703 dinov2 helpers.py:102] Training  [ 3650/12500]  eta: 0:34:00  loss: 23.1056 (25.3178)  lr: 0.0000 (0.0000)  time: 0.209985  data: 0.000499  max mem: 3586
I20250120 12:06:58 3545703 dinov2 helpers.py:102] Training  [ 3660/12500]  eta: 0:33:57  loss: 23.1905 (25.3125)  lr: 0.0000 (0.0000)  time: 0.210098  data: 0.000463  max mem: 3586
I20250120 12:07:00 3545703 dinov2 helpers.py:102] Training  [ 3670/12500]  eta: 0:33:54  loss: 23.3936 (25.3204)  lr: 0.0000 (0.0000)  time: 0.210093  data: 0.000425  max mem: 3586
I20250120 12:07:02 3545703 dinov2 helpers.py:102] Training  [ 3680/12500]  eta: 0:33:52  loss: 23.3936 (25.3111)  lr: 0.0000 (0.0000)  time: 0.210244  data: 0.000432  max mem: 3586
I20250120 12:07:04 3545703 dinov2 helpers.py:102] Training  [ 3690/12500]  eta: 0:33:49  loss: 23.3936 (25.3242)  lr: 0.0000 (0.0000)  time: 0.210182  data: 0.000442  max mem: 3586
I20250120 12:07:06 3545703 dinov2 helpers.py:102] Training  [ 3700/12500]  eta: 0:33:46  loss: 23.3936 (25.3148)  lr: 0.0000 (0.0000)  time: 0.210023  data: 0.000429  max mem: 3586
I20250120 12:07:09 3545703 dinov2 helpers.py:102] Training  [ 3710/12500]  eta: 0:33:43  loss: 23.3936 (25.3144)  lr: 0.0000 (0.0000)  time: 0.210116  data: 0.000411  max mem: 3586
I20250120 12:07:11 3545703 dinov2 helpers.py:102] Training  [ 3720/12500]  eta: 0:33:40  loss: 23.3936 (25.2979)  lr: 0.0000 (0.0000)  time: 0.210140  data: 0.000450  max mem: 3586
I20250120 12:07:13 3545703 dinov2 helpers.py:102] Training  [ 3730/12500]  eta: 0:33:38  loss: 23.3936 (25.2988)  lr: 0.0000 (0.0000)  time: 0.210150  data: 0.000442  max mem: 3586
I20250120 12:07:15 3545703 dinov2 helpers.py:102] Training  [ 3740/12500]  eta: 0:33:35  loss: 23.3936 (25.2836)  lr: 0.0000 (0.0000)  time: 0.210310  data: 0.000436  max mem: 3586
I20250120 12:07:17 3545703 dinov2 linear.py:272] running validation !
I20250120 12:07:18 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:58    time: 1.538982  data: 1.331011  max mem: 3586
I20250120 12:07:20 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.332477  data: 0.121799  max mem: 3586
I20250120 12:07:23 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.211674  data: 0.000632  max mem: 3586
I20250120 12:07:25 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.211008  data: 0.000337  max mem: 3586
I20250120 12:07:27 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210657  data: 0.000255  max mem: 3586
I20250120 12:07:29 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.210686  data: 0.000259  max mem: 3586
I20250120 12:07:31 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210474  data: 0.000285  max mem: 3586
I20250120 12:07:33 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210944  data: 0.000246  max mem: 3586
I20250120 12:07:35 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.211515  data: 0.000227  max mem: 3586
I20250120 12:07:37 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.211087  data: 0.000233  max mem: 3586
I20250120 12:07:39 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210911  data: 0.000254  max mem: 3586
I20250120 12:07:41 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210843  data: 0.000270  max mem: 3586
I20250120 12:07:44 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210587  data: 0.000278  max mem: 3586
I20250120 12:07:46 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210716  data: 0.000285  max mem: 3586
I20250120 12:07:48 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210795  data: 0.000240  max mem: 3586
I20250120 12:07:50 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210363  data: 0.000165  max mem: 3586
I20250120 12:07:51 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205996  data: 0.000150  max mem: 3586
I20250120 12:07:51 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.219838 s / it)
I20250120 12:07:51 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:07:51 3545703 dinov2 linear.py:287] 
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8499, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8595, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8633, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8698, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8744, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8746, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8705, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8623, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8494, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8433, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8517, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8582, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8720, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8757, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8786, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8797, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8748, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8572, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8728, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8388, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8583, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8685, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8777, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8773, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8739, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8607, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8619, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8585, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8574, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8625, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8694, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8737, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8796, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8782, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8657, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8781, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8664, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8560, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8577, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8797494173049927}
I20250120 12:07:51 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:07:51 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:07:51 3545703 dinov2 helpers.py:102] Training  [ 3750/12500]  eta: 0:34:52  loss: 23.3936 (25.2505)  lr: 0.0000 (0.0000)  time: 1.918873  data: 0.000478  max mem: 3586
I20250120 12:07:53 3545703 dinov2 helpers.py:102] Training  [ 3760/12500]  eta: 0:34:49  loss: 23.3936 (25.2769)  lr: 0.0000 (0.0000)  time: 1.916689  data: 0.000459  max mem: 3586
I20250120 12:07:55 3545703 dinov2 helpers.py:102] Training  [ 3770/12500]  eta: 0:34:46  loss: 23.3936 (25.2585)  lr: 0.0000 (0.0000)  time: 0.206942  data: 0.000417  max mem: 3586
I20250120 12:07:57 3545703 dinov2 helpers.py:102] Training  [ 3780/12500]  eta: 0:34:42  loss: 23.3936 (25.2469)  lr: 0.0000 (0.0000)  time: 0.207781  data: 0.000455  max mem: 3586
I20250120 12:08:00 3545703 dinov2 helpers.py:102] Training  [ 3790/12500]  eta: 0:34:40  loss: 23.4509 (25.2493)  lr: 0.0000 (0.0000)  time: 0.231506  data: 0.027667  max mem: 3586
I20250120 12:08:02 3545703 dinov2 helpers.py:102] Training  [ 3800/12500]  eta: 0:34:37  loss: 23.3936 (25.2406)  lr: 0.0000 (0.0000)  time: 0.231338  data: 0.027632  max mem: 3586
I20250120 12:08:04 3545703 dinov2 helpers.py:102] Training  [ 3810/12500]  eta: 0:34:34  loss: 23.1056 (25.2265)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000454  max mem: 3586
I20250120 12:08:06 3545703 dinov2 helpers.py:102] Training  [ 3820/12500]  eta: 0:34:31  loss: 21.9118 (25.2129)  lr: 0.0000 (0.0000)  time: 0.207323  data: 0.000453  max mem: 3586
I20250120 12:08:08 3545703 dinov2 helpers.py:102] Training  [ 3830/12500]  eta: 0:34:28  loss: 21.8780 (25.1982)  lr: 0.0000 (0.0000)  time: 0.207428  data: 0.000451  max mem: 3586
I20250120 12:08:10 3545703 dinov2 helpers.py:102] Training  [ 3840/12500]  eta: 0:34:25  loss: 21.8780 (25.1909)  lr: 0.0000 (0.0000)  time: 0.207617  data: 0.000428  max mem: 3586
I20250120 12:08:12 3545703 dinov2 helpers.py:102] Training  [ 3850/12500]  eta: 0:34:22  loss: 21.8780 (25.1999)  lr: 0.0000 (0.0000)  time: 0.207700  data: 0.000414  max mem: 3586
I20250120 12:08:14 3545703 dinov2 helpers.py:102] Training  [ 3860/12500]  eta: 0:34:19  loss: 21.8780 (25.1956)  lr: 0.0000 (0.0000)  time: 0.207697  data: 0.000400  max mem: 3586
I20250120 12:08:16 3545703 dinov2 helpers.py:102] Training  [ 3870/12500]  eta: 0:34:16  loss: 21.8780 (25.1914)  lr: 0.0000 (0.0000)  time: 0.207535  data: 0.000410  max mem: 3586
I20250120 12:08:19 3545703 dinov2 helpers.py:102] Training  [ 3880/12500]  eta: 0:34:13  loss: 21.8237 (25.1736)  lr: 0.0000 (0.0000)  time: 0.207611  data: 0.000445  max mem: 3586
I20250120 12:08:21 3545703 dinov2 helpers.py:102] Training  [ 3890/12500]  eta: 0:34:10  loss: 21.8237 (25.1666)  lr: 0.0000 (0.0000)  time: 0.207779  data: 0.000479  max mem: 3586
I20250120 12:08:23 3545703 dinov2 helpers.py:102] Training  [ 3900/12500]  eta: 0:34:07  loss: 21.9118 (25.1636)  lr: 0.0000 (0.0000)  time: 0.207729  data: 0.000450  max mem: 3586
I20250120 12:08:25 3545703 dinov2 helpers.py:102] Training  [ 3910/12500]  eta: 0:34:03  loss: 20.8665 (25.1525)  lr: 0.0000 (0.0000)  time: 0.207683  data: 0.000405  max mem: 3586
I20250120 12:08:27 3545703 dinov2 helpers.py:102] Training  [ 3920/12500]  eta: 0:34:00  loss: 21.9118 (25.1566)  lr: 0.0000 (0.0000)  time: 0.207749  data: 0.000358  max mem: 3586
I20250120 12:08:29 3545703 dinov2 helpers.py:102] Training  [ 3930/12500]  eta: 0:33:57  loss: 21.9118 (25.1593)  lr: 0.0000 (0.0000)  time: 0.207666  data: 0.000355  max mem: 3586
I20250120 12:08:31 3545703 dinov2 helpers.py:102] Training  [ 3940/12500]  eta: 0:33:54  loss: 22.1294 (25.1517)  lr: 0.0000 (0.0000)  time: 0.207783  data: 0.000466  max mem: 3586
I20250120 12:08:33 3545703 dinov2 helpers.py:102] Training  [ 3950/12500]  eta: 0:33:51  loss: 22.4063 (25.1561)  lr: 0.0000 (0.0000)  time: 0.207971  data: 0.000447  max mem: 3586
I20250120 12:08:35 3545703 dinov2 helpers.py:102] Training  [ 3960/12500]  eta: 0:33:48  loss: 22.1294 (25.1407)  lr: 0.0000 (0.0000)  time: 0.207905  data: 0.000425  max mem: 3586
I20250120 12:08:37 3545703 dinov2 helpers.py:102] Training  [ 3970/12500]  eta: 0:33:45  loss: 22.4063 (25.1480)  lr: 0.0000 (0.0000)  time: 0.207999  data: 0.000463  max mem: 3586
I20250120 12:08:39 3545703 dinov2 helpers.py:102] Training  [ 3980/12500]  eta: 0:33:42  loss: 22.4384 (25.1594)  lr: 0.0000 (0.0000)  time: 0.207834  data: 0.000452  max mem: 3586
I20250120 12:08:41 3545703 dinov2 helpers.py:102] Training  [ 3990/12500]  eta: 0:33:39  loss: 22.4063 (25.1488)  lr: 0.0000 (0.0000)  time: 0.207704  data: 0.000470  max mem: 3586
I20250120 12:08:44 3545703 dinov2 helpers.py:102] Training  [ 4000/12500]  eta: 0:33:36  loss: 22.4384 (25.1433)  lr: 0.0000 (0.0000)  time: 0.207712  data: 0.000439  max mem: 3586
I20250120 12:08:46 3545703 dinov2 helpers.py:102] Training  [ 4010/12500]  eta: 0:33:33  loss: 22.9567 (25.1457)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000399  max mem: 3586
I20250120 12:08:48 3545703 dinov2 helpers.py:102] Training  [ 4020/12500]  eta: 0:33:30  loss: 22.9567 (25.1389)  lr: 0.0000 (0.0000)  time: 0.207776  data: 0.000416  max mem: 3586
I20250120 12:08:50 3545703 dinov2 helpers.py:102] Training  [ 4030/12500]  eta: 0:33:27  loss: 22.9567 (25.1325)  lr: 0.0000 (0.0000)  time: 0.207980  data: 0.000420  max mem: 3586
I20250120 12:08:52 3545703 dinov2 helpers.py:102] Training  [ 4040/12500]  eta: 0:33:24  loss: 22.9567 (25.1257)  lr: 0.0000 (0.0000)  time: 0.208059  data: 0.000428  max mem: 3586
I20250120 12:08:54 3545703 dinov2 helpers.py:102] Training  [ 4050/12500]  eta: 0:33:21  loss: 22.7262 (25.1198)  lr: 0.0000 (0.0000)  time: 0.207795  data: 0.000439  max mem: 3586
I20250120 12:08:56 3545703 dinov2 helpers.py:102] Training  [ 4060/12500]  eta: 0:33:18  loss: 22.7262 (25.1183)  lr: 0.0000 (0.0000)  time: 0.207516  data: 0.000399  max mem: 3586
I20250120 12:08:58 3545703 dinov2 helpers.py:102] Training  [ 4070/12500]  eta: 0:33:15  loss: 22.7262 (25.1245)  lr: 0.0000 (0.0000)  time: 0.207829  data: 0.000394  max mem: 3586
I20250120 12:09:00 3545703 dinov2 helpers.py:102] Training  [ 4080/12500]  eta: 0:33:12  loss: 22.7262 (25.1132)  lr: 0.0000 (0.0000)  time: 0.207960  data: 0.000423  max mem: 3586
I20250120 12:09:02 3545703 dinov2 helpers.py:102] Training  [ 4090/12500]  eta: 0:33:09  loss: 22.9567 (25.1208)  lr: 0.0000 (0.0000)  time: 0.207910  data: 0.000412  max mem: 3586
I20250120 12:09:04 3545703 dinov2 helpers.py:102] Training  [ 4100/12500]  eta: 0:33:07  loss: 22.9567 (25.1178)  lr: 0.0000 (0.0000)  time: 0.208024  data: 0.000412  max mem: 3586
I20250120 12:09:06 3545703 dinov2 helpers.py:102] Training  [ 4110/12500]  eta: 0:33:04  loss: 23.9036 (25.1189)  lr: 0.0000 (0.0000)  time: 0.207917  data: 0.000407  max mem: 3586
I20250120 12:09:08 3545703 dinov2 helpers.py:102] Training  [ 4120/12500]  eta: 0:33:01  loss: 23.9036 (25.1313)  lr: 0.0000 (0.0000)  time: 0.208045  data: 0.000414  max mem: 3586
I20250120 12:09:11 3545703 dinov2 helpers.py:102] Training  [ 4130/12500]  eta: 0:32:58  loss: 23.9036 (25.1294)  lr: 0.0000 (0.0000)  time: 0.208223  data: 0.000402  max mem: 3586
I20250120 12:09:13 3545703 dinov2 helpers.py:102] Training  [ 4140/12500]  eta: 0:32:55  loss: 24.3452 (25.1288)  lr: 0.0000 (0.0000)  time: 0.207989  data: 0.000384  max mem: 3586
I20250120 12:09:15 3545703 dinov2 helpers.py:102] Training  [ 4150/12500]  eta: 0:32:52  loss: 23.9036 (25.1235)  lr: 0.0000 (0.0000)  time: 0.207963  data: 0.000408  max mem: 3586
I20250120 12:09:17 3545703 dinov2 helpers.py:102] Training  [ 4160/12500]  eta: 0:32:49  loss: 24.3452 (25.1376)  lr: 0.0000 (0.0000)  time: 0.207927  data: 0.000404  max mem: 3586
I20250120 12:09:19 3545703 dinov2 helpers.py:102] Training  [ 4170/12500]  eta: 0:32:46  loss: 24.3452 (25.1389)  lr: 0.0000 (0.0000)  time: 0.208023  data: 0.000450  max mem: 3586
I20250120 12:09:21 3545703 dinov2 helpers.py:102] Training  [ 4180/12500]  eta: 0:32:43  loss: 23.9036 (25.1265)  lr: 0.0000 (0.0000)  time: 0.208032  data: 0.000425  max mem: 3586
I20250120 12:09:23 3545703 dinov2 helpers.py:102] Training  [ 4190/12500]  eta: 0:32:40  loss: 23.9036 (25.1114)  lr: 0.0000 (0.0000)  time: 0.208030  data: 0.000416  max mem: 3586
I20250120 12:09:25 3545703 dinov2 helpers.py:102] Training  [ 4200/12500]  eta: 0:32:37  loss: 23.9036 (25.1025)  lr: 0.0000 (0.0000)  time: 0.208014  data: 0.000482  max mem: 3586
I20250120 12:09:27 3545703 dinov2 helpers.py:102] Training  [ 4210/12500]  eta: 0:32:34  loss: 22.9997 (25.0975)  lr: 0.0000 (0.0000)  time: 0.207953  data: 0.000473  max mem: 3586
I20250120 12:09:29 3545703 dinov2 helpers.py:102] Training  [ 4220/12500]  eta: 0:32:31  loss: 22.9997 (25.0904)  lr: 0.0000 (0.0000)  time: 0.208070  data: 0.000469  max mem: 3586
I20250120 12:09:31 3545703 dinov2 helpers.py:102] Training  [ 4230/12500]  eta: 0:32:29  loss: 23.9036 (25.0884)  lr: 0.0000 (0.0000)  time: 0.208076  data: 0.000406  max mem: 3586
I20250120 12:09:33 3545703 dinov2 helpers.py:102] Training  [ 4240/12500]  eta: 0:32:26  loss: 23.9036 (25.0822)  lr: 0.0000 (0.0000)  time: 0.208106  data: 0.000366  max mem: 3586
I20250120 12:09:36 3545703 dinov2 helpers.py:102] Training  [ 4250/12500]  eta: 0:32:23  loss: 23.9036 (25.0763)  lr: 0.0000 (0.0000)  time: 0.207997  data: 0.000396  max mem: 3586
I20250120 12:09:38 3545703 dinov2 helpers.py:102] Training  [ 4260/12500]  eta: 0:32:20  loss: 23.9036 (25.0751)  lr: 0.0000 (0.0000)  time: 0.207779  data: 0.000464  max mem: 3586
I20250120 12:09:40 3545703 dinov2 helpers.py:102] Training  [ 4270/12500]  eta: 0:32:17  loss: 23.9036 (25.0766)  lr: 0.0000 (0.0000)  time: 0.207678  data: 0.000455  max mem: 3586
I20250120 12:09:42 3545703 dinov2 helpers.py:102] Training  [ 4280/12500]  eta: 0:32:14  loss: 23.9036 (25.0736)  lr: 0.0000 (0.0000)  time: 0.207942  data: 0.000370  max mem: 3586
I20250120 12:09:44 3545703 dinov2 helpers.py:102] Training  [ 4290/12500]  eta: 0:32:11  loss: 23.8045 (25.0523)  lr: 0.0000 (0.0000)  time: 0.208026  data: 0.000407  max mem: 3586
I20250120 12:09:46 3545703 dinov2 helpers.py:102] Training  [ 4300/12500]  eta: 0:32:08  loss: 23.8045 (25.0567)  lr: 0.0000 (0.0000)  time: 0.208026  data: 0.000413  max mem: 3586
I20250120 12:09:48 3545703 dinov2 helpers.py:102] Training  [ 4310/12500]  eta: 0:32:05  loss: 23.8045 (25.0618)  lr: 0.0000 (0.0000)  time: 0.208051  data: 0.000376  max mem: 3586
I20250120 12:09:50 3545703 dinov2 helpers.py:102] Training  [ 4320/12500]  eta: 0:32:03  loss: 23.8045 (25.0659)  lr: 0.0000 (0.0000)  time: 0.207844  data: 0.000413  max mem: 3586
I20250120 12:09:52 3545703 dinov2 helpers.py:102] Training  [ 4330/12500]  eta: 0:32:00  loss: 22.9997 (25.0593)  lr: 0.0000 (0.0000)  time: 0.207849  data: 0.000421  max mem: 3586
I20250120 12:09:54 3545703 dinov2 helpers.py:102] Training  [ 4340/12500]  eta: 0:31:57  loss: 22.9997 (25.0551)  lr: 0.0000 (0.0000)  time: 0.208134  data: 0.000445  max mem: 3586
I20250120 12:09:56 3545703 dinov2 helpers.py:102] Training  [ 4350/12500]  eta: 0:31:54  loss: 22.9997 (25.0310)  lr: 0.0000 (0.0000)  time: 0.208196  data: 0.000434  max mem: 3586
I20250120 12:09:58 3545703 dinov2 helpers.py:102] Training  [ 4360/12500]  eta: 0:31:51  loss: 22.9997 (25.0380)  lr: 0.0000 (0.0000)  time: 0.208299  data: 0.000405  max mem: 3586
I20250120 12:10:00 3545703 dinov2 helpers.py:102] Training  [ 4370/12500]  eta: 0:31:48  loss: 22.9997 (25.0345)  lr: 0.0000 (0.0000)  time: 0.208297  data: 0.000390  max mem: 3586
I20250120 12:10:03 3545703 dinov2 helpers.py:102] Training  [ 4380/12500]  eta: 0:31:45  loss: 22.9997 (25.0250)  lr: 0.0000 (0.0000)  time: 0.207939  data: 0.000393  max mem: 3586
I20250120 12:10:05 3545703 dinov2 helpers.py:102] Training  [ 4390/12500]  eta: 0:31:43  loss: 22.9997 (25.0112)  lr: 0.0000 (0.0000)  time: 0.208115  data: 0.000438  max mem: 3586
I20250120 12:10:07 3545703 dinov2 helpers.py:102] Training  [ 4400/12500]  eta: 0:31:40  loss: 22.9997 (24.9950)  lr: 0.0000 (0.0000)  time: 0.208158  data: 0.000451  max mem: 3586
I20250120 12:10:09 3545703 dinov2 helpers.py:102] Training  [ 4410/12500]  eta: 0:31:37  loss: 22.6006 (24.9878)  lr: 0.0000 (0.0000)  time: 0.208356  data: 0.000430  max mem: 3586
I20250120 12:10:11 3545703 dinov2 helpers.py:102] Training  [ 4420/12500]  eta: 0:31:34  loss: 23.2447 (24.9847)  lr: 0.0000 (0.0000)  time: 0.208275  data: 0.000372  max mem: 3586
I20250120 12:10:13 3545703 dinov2 helpers.py:102] Training  [ 4430/12500]  eta: 0:31:31  loss: 23.2447 (24.9940)  lr: 0.0000 (0.0000)  time: 0.207979  data: 0.000378  max mem: 3586
I20250120 12:10:15 3545703 dinov2 helpers.py:102] Training  [ 4440/12500]  eta: 0:31:29  loss: 23.2447 (24.9889)  lr: 0.0000 (0.0000)  time: 0.208089  data: 0.000424  max mem: 3586
I20250120 12:10:17 3545703 dinov2 helpers.py:102] Training  [ 4450/12500]  eta: 0:31:26  loss: 23.2447 (24.9816)  lr: 0.0000 (0.0000)  time: 0.207807  data: 0.000402  max mem: 3586
I20250120 12:10:19 3545703 dinov2 helpers.py:102] Training  [ 4460/12500]  eta: 0:31:23  loss: 23.2447 (24.9824)  lr: 0.0000 (0.0000)  time: 0.207894  data: 0.000392  max mem: 3586
I20250120 12:10:21 3545703 dinov2 helpers.py:102] Training  [ 4470/12500]  eta: 0:31:20  loss: 22.6962 (24.9753)  lr: 0.0000 (0.0000)  time: 0.208130  data: 0.000407  max mem: 3586
I20250120 12:10:23 3545703 dinov2 helpers.py:102] Training  [ 4480/12500]  eta: 0:31:17  loss: 22.2235 (24.9679)  lr: 0.0000 (0.0000)  time: 0.207854  data: 0.000385  max mem: 3586
I20250120 12:10:25 3545703 dinov2 helpers.py:102] Training  [ 4490/12500]  eta: 0:31:14  loss: 22.6962 (24.9674)  lr: 0.0000 (0.0000)  time: 0.207754  data: 0.000418  max mem: 3586
I20250120 12:10:28 3545703 dinov2 helpers.py:102] Training  [ 4500/12500]  eta: 0:31:12  loss: 22.6962 (24.9670)  lr: 0.0000 (0.0000)  time: 0.207810  data: 0.000489  max mem: 3586
I20250120 12:10:30 3545703 dinov2 helpers.py:102] Training  [ 4510/12500]  eta: 0:31:09  loss: 22.6962 (24.9701)  lr: 0.0000 (0.0000)  time: 0.207984  data: 0.000470  max mem: 3586
I20250120 12:10:32 3545703 dinov2 helpers.py:102] Training  [ 4520/12500]  eta: 0:31:06  loss: 22.6962 (24.9734)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000447  max mem: 3586
I20250120 12:10:34 3545703 dinov2 helpers.py:102] Training  [ 4530/12500]  eta: 0:31:03  loss: 23.0330 (24.9691)  lr: 0.0000 (0.0000)  time: 0.208098  data: 0.000425  max mem: 3586
I20250120 12:10:36 3545703 dinov2 helpers.py:102] Training  [ 4540/12500]  eta: 0:31:00  loss: 23.0330 (24.9784)  lr: 0.0000 (0.0000)  time: 0.208139  data: 0.000420  max mem: 3586
I20250120 12:10:38 3545703 dinov2 helpers.py:102] Training  [ 4550/12500]  eta: 0:30:58  loss: 23.0330 (24.9711)  lr: 0.0000 (0.0000)  time: 0.207985  data: 0.000417  max mem: 3586
I20250120 12:10:40 3545703 dinov2 helpers.py:102] Training  [ 4560/12500]  eta: 0:30:55  loss: 22.6962 (24.9657)  lr: 0.0000 (0.0000)  time: 0.208196  data: 0.000404  max mem: 3586
I20250120 12:10:42 3545703 dinov2 helpers.py:102] Training  [ 4570/12500]  eta: 0:30:52  loss: 22.5182 (24.9556)  lr: 0.0000 (0.0000)  time: 0.208362  data: 0.000410  max mem: 3586
I20250120 12:10:44 3545703 dinov2 helpers.py:102] Training  [ 4580/12500]  eta: 0:30:49  loss: 22.5182 (24.9474)  lr: 0.0000 (0.0000)  time: 0.208145  data: 0.000403  max mem: 3586
I20250120 12:10:46 3545703 dinov2 helpers.py:102] Training  [ 4590/12500]  eta: 0:30:47  loss: 22.6962 (24.9445)  lr: 0.0000 (0.0000)  time: 0.208334  data: 0.000395  max mem: 3586
I20250120 12:10:48 3545703 dinov2 helpers.py:102] Training  [ 4600/12500]  eta: 0:30:44  loss: 23.0330 (24.9435)  lr: 0.0000 (0.0000)  time: 0.208235  data: 0.000404  max mem: 3586
I20250120 12:10:50 3545703 dinov2 helpers.py:102] Training  [ 4610/12500]  eta: 0:30:41  loss: 23.0330 (24.9362)  lr: 0.0000 (0.0000)  time: 0.208082  data: 0.000437  max mem: 3586
I20250120 12:10:53 3545703 dinov2 helpers.py:102] Training  [ 4620/12500]  eta: 0:30:38  loss: 22.6962 (24.9254)  lr: 0.0000 (0.0000)  time: 0.208360  data: 0.000481  max mem: 3586
I20250120 12:10:55 3545703 dinov2 helpers.py:102] Training  [ 4630/12500]  eta: 0:30:36  loss: 22.6962 (24.9265)  lr: 0.0000 (0.0000)  time: 0.208255  data: 0.000494  max mem: 3586
I20250120 12:10:57 3545703 dinov2 helpers.py:102] Training  [ 4640/12500]  eta: 0:30:33  loss: 23.0330 (24.9267)  lr: 0.0000 (0.0000)  time: 0.207962  data: 0.000430  max mem: 3586
I20250120 12:10:59 3545703 dinov2 helpers.py:102] Training  [ 4650/12500]  eta: 0:30:30  loss: 23.0330 (24.9078)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000391  max mem: 3586
I20250120 12:11:01 3545703 dinov2 helpers.py:102] Training  [ 4660/12500]  eta: 0:30:27  loss: 22.5182 (24.9006)  lr: 0.0000 (0.0000)  time: 0.208342  data: 0.000394  max mem: 3586
I20250120 12:11:03 3545703 dinov2 helpers.py:102] Training  [ 4670/12500]  eta: 0:30:24  loss: 22.5182 (24.8880)  lr: 0.0000 (0.0000)  time: 0.208064  data: 0.000401  max mem: 3586
I20250120 12:11:05 3545703 dinov2 helpers.py:102] Training  [ 4680/12500]  eta: 0:30:22  loss: 22.5182 (24.8784)  lr: 0.0000 (0.0000)  time: 0.208104  data: 0.000369  max mem: 3586
I20250120 12:11:07 3545703 dinov2 helpers.py:102] Training  [ 4690/12500]  eta: 0:30:19  loss: 22.5182 (24.8861)  lr: 0.0000 (0.0000)  time: 0.208426  data: 0.000361  max mem: 3586
I20250120 12:11:09 3545703 dinov2 helpers.py:102] Training  [ 4700/12500]  eta: 0:30:16  loss: 21.6436 (24.8665)  lr: 0.0000 (0.0000)  time: 0.208609  data: 0.000431  max mem: 3586
I20250120 12:11:11 3545703 dinov2 helpers.py:102] Training  [ 4710/12500]  eta: 0:30:14  loss: 21.6436 (24.8603)  lr: 0.0000 (0.0000)  time: 0.208569  data: 0.000441  max mem: 3586
I20250120 12:11:13 3545703 dinov2 helpers.py:102] Training  [ 4720/12500]  eta: 0:30:11  loss: 21.6436 (24.8618)  lr: 0.0000 (0.0000)  time: 0.208620  data: 0.000439  max mem: 3586
I20250120 12:11:15 3545703 dinov2 helpers.py:102] Training  [ 4730/12500]  eta: 0:30:08  loss: 21.5724 (24.8471)  lr: 0.0000 (0.0000)  time: 0.208517  data: 0.000477  max mem: 3586
I20250120 12:11:18 3545703 dinov2 helpers.py:102] Training  [ 4740/12500]  eta: 0:30:05  loss: 21.5724 (24.8486)  lr: 0.0000 (0.0000)  time: 0.208182  data: 0.000477  max mem: 3586
I20250120 12:11:20 3545703 dinov2 helpers.py:102] Training  [ 4750/12500]  eta: 0:30:03  loss: 21.5392 (24.8374)  lr: 0.0000 (0.0000)  time: 0.208270  data: 0.000453  max mem: 3586
I20250120 12:11:22 3545703 dinov2 helpers.py:102] Training  [ 4760/12500]  eta: 0:30:00  loss: 21.5392 (24.8335)  lr: 0.0000 (0.0000)  time: 0.208247  data: 0.000445  max mem: 3586
I20250120 12:11:24 3545703 dinov2 helpers.py:102] Training  [ 4770/12500]  eta: 0:29:57  loss: 21.5724 (24.8318)  lr: 0.0000 (0.0000)  time: 0.208107  data: 0.000416  max mem: 3586
I20250120 12:11:26 3545703 dinov2 helpers.py:102] Training  [ 4780/12500]  eta: 0:29:54  loss: 21.5724 (24.8231)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000440  max mem: 3586
I20250120 12:11:28 3545703 dinov2 helpers.py:102] Training  [ 4790/12500]  eta: 0:29:52  loss: 21.5724 (24.8215)  lr: 0.0000 (0.0000)  time: 0.208247  data: 0.000493  max mem: 3586
I20250120 12:11:30 3545703 dinov2 helpers.py:102] Training  [ 4800/12500]  eta: 0:29:49  loss: 21.5724 (24.8234)  lr: 0.0000 (0.0000)  time: 0.208421  data: 0.000492  max mem: 3586
I20250120 12:11:32 3545703 dinov2 helpers.py:102] Training  [ 4810/12500]  eta: 0:29:46  loss: 21.5392 (24.8052)  lr: 0.0000 (0.0000)  time: 0.208644  data: 0.000451  max mem: 3586
I20250120 12:11:34 3545703 dinov2 helpers.py:102] Training  [ 4820/12500]  eta: 0:29:44  loss: 21.5461 (24.7985)  lr: 0.0000 (0.0000)  time: 0.208657  data: 0.000446  max mem: 3586
I20250120 12:11:36 3545703 dinov2 helpers.py:102] Training  [ 4830/12500]  eta: 0:29:41  loss: 21.5461 (24.8011)  lr: 0.0000 (0.0000)  time: 0.208539  data: 0.000453  max mem: 3586
I20250120 12:11:38 3545703 dinov2 helpers.py:102] Training  [ 4840/12500]  eta: 0:29:38  loss: 21.5461 (24.7978)  lr: 0.0000 (0.0000)  time: 0.208507  data: 0.000445  max mem: 3586
I20250120 12:11:40 3545703 dinov2 helpers.py:102] Training  [ 4850/12500]  eta: 0:29:36  loss: 21.5461 (24.7848)  lr: 0.0000 (0.0000)  time: 0.208273  data: 0.000446  max mem: 3586
I20250120 12:11:43 3545703 dinov2 helpers.py:102] Training  [ 4860/12500]  eta: 0:29:33  loss: 21.9677 (24.7858)  lr: 0.0000 (0.0000)  time: 0.208048  data: 0.000367  max mem: 3586
I20250120 12:11:45 3545703 dinov2 helpers.py:102] Training  [ 4870/12500]  eta: 0:29:30  loss: 21.9677 (24.7781)  lr: 0.0000 (0.0000)  time: 0.208149  data: 0.000349  max mem: 3586
I20250120 12:11:47 3545703 dinov2 helpers.py:102] Training  [ 4880/12500]  eta: 0:29:27  loss: 21.9677 (24.7698)  lr: 0.0000 (0.0000)  time: 0.208166  data: 0.000387  max mem: 3586
I20250120 12:11:49 3545703 dinov2 helpers.py:102] Training  [ 4890/12500]  eta: 0:29:25  loss: 21.5461 (24.7627)  lr: 0.0000 (0.0000)  time: 0.208552  data: 0.000485  max mem: 3586
I20250120 12:11:51 3545703 dinov2 helpers.py:102] Training  [ 4900/12500]  eta: 0:29:22  loss: 21.5461 (24.7506)  lr: 0.0000 (0.0000)  time: 0.208771  data: 0.000491  max mem: 3586
I20250120 12:11:53 3545703 dinov2 helpers.py:102] Training  [ 4910/12500]  eta: 0:29:19  loss: 21.2837 (24.7423)  lr: 0.0000 (0.0000)  time: 0.208693  data: 0.000452  max mem: 3586
I20250120 12:11:55 3545703 dinov2 helpers.py:102] Training  [ 4920/12500]  eta: 0:29:17  loss: 21.2837 (24.7372)  lr: 0.0000 (0.0000)  time: 0.208875  data: 0.000462  max mem: 3586
I20250120 12:11:57 3545703 dinov2 helpers.py:102] Training  [ 4930/12500]  eta: 0:29:14  loss: 21.2837 (24.7238)  lr: 0.0000 (0.0000)  time: 0.208942  data: 0.000417  max mem: 3586
I20250120 12:11:59 3545703 dinov2 helpers.py:102] Training  [ 4940/12500]  eta: 0:29:11  loss: 21.2837 (24.7179)  lr: 0.0000 (0.0000)  time: 0.208629  data: 0.000420  max mem: 3586
I20250120 12:12:01 3545703 dinov2 helpers.py:102] Training  [ 4950/12500]  eta: 0:29:09  loss: 21.5461 (24.7173)  lr: 0.0000 (0.0000)  time: 0.208175  data: 0.000433  max mem: 3586
I20250120 12:12:03 3545703 dinov2 helpers.py:102] Training  [ 4960/12500]  eta: 0:29:06  loss: 21.5461 (24.7218)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000479  max mem: 3586
I20250120 12:12:05 3545703 dinov2 helpers.py:102] Training  [ 4970/12500]  eta: 0:29:03  loss: 21.5461 (24.7334)  lr: 0.0000 (0.0000)  time: 0.208446  data: 0.000471  max mem: 3586
I20250120 12:12:08 3545703 dinov2 helpers.py:102] Training  [ 4980/12500]  eta: 0:29:01  loss: 21.8012 (24.7321)  lr: 0.0000 (0.0000)  time: 0.208381  data: 0.000428  max mem: 3586
I20250120 12:12:10 3545703 dinov2 helpers.py:102] Training  [ 4990/12500]  eta: 0:28:58  loss: 21.8012 (24.7335)  lr: 0.0000 (0.0000)  time: 0.208371  data: 0.000425  max mem: 3586
I20250120 12:12:11 3545703 dinov2 linear.py:272] running validation !
I20250120 12:12:13 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:55    time: 1.516602  data: 1.299086  max mem: 3586
I20250120 12:12:15 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.329671  data: 0.119069  max mem: 3586
I20250120 12:12:17 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.212684  data: 0.001717  max mem: 3586
I20250120 12:12:19 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212543  data: 0.001358  max mem: 3586
I20250120 12:12:22 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.210303  data: 0.000297  max mem: 3586
I20250120 12:12:24 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.222771  data: 0.000260  max mem: 3586
I20250120 12:12:26 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.223231  data: 0.000258  max mem: 3586
I20250120 12:12:28 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210682  data: 0.000275  max mem: 3586
I20250120 12:12:30 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210704  data: 0.000290  max mem: 3586
I20250120 12:12:32 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210442  data: 0.000273  max mem: 3586
I20250120 12:12:34 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210267  data: 0.000275  max mem: 3586
I20250120 12:12:37 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210673  data: 0.000260  max mem: 3586
I20250120 12:12:39 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210317  data: 0.000260  max mem: 3586
I20250120 12:12:41 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209839  data: 0.000258  max mem: 3586
I20250120 12:12:43 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210098  data: 0.000246  max mem: 3586
I20250120 12:12:45 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209652  data: 0.000188  max mem: 3586
I20250120 12:12:46 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205515  data: 0.000159  max mem: 3586
I20250120 12:12:46 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.221079 s / it)
I20250120 12:12:46 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:12:46 3545703 dinov2 linear.py:287] 
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8531, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8612, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8659, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8702, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8753, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8755, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8746, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8747, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8596, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8499, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8542, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8611, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8691, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8732, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8764, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8766, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8789, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8812, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8834, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8788, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8588, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8611, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8689, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8745, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8769, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8781, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8667, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8637, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8435, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8147, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8713, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8747, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8765, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8792, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8815, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8812, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8826, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8725, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8325, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8355, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8833872079849243}
I20250120 12:12:46 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:12:46 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:12:46 3545703 dinov2 helpers.py:102] Training  [ 5000/12500]  eta: 0:29:47  loss: 21.5461 (24.7197)  lr: 0.0000 (0.0000)  time: 1.926001  data: 0.000404  max mem: 3586
I20250120 12:12:48 3545703 dinov2 helpers.py:102] Training  [ 5010/12500]  eta: 0:29:44  loss: 21.8012 (24.7230)  lr: 0.0000 (0.0000)  time: 1.924966  data: 0.000439  max mem: 3586
I20250120 12:12:50 3545703 dinov2 helpers.py:102] Training  [ 5020/12500]  eta: 0:29:41  loss: 22.1895 (24.7185)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000494  max mem: 3586
I20250120 12:12:52 3545703 dinov2 helpers.py:102] Training  [ 5030/12500]  eta: 0:29:38  loss: 21.8012 (24.7103)  lr: 0.0000 (0.0000)  time: 0.206764  data: 0.000495  max mem: 3586
I20250120 12:12:54 3545703 dinov2 helpers.py:102] Training  [ 5040/12500]  eta: 0:29:35  loss: 21.8012 (24.7085)  lr: 0.0000 (0.0000)  time: 0.207115  data: 0.000467  max mem: 3586
I20250120 12:12:57 3545703 dinov2 helpers.py:102] Training  [ 5050/12500]  eta: 0:29:33  loss: 22.1895 (24.7109)  lr: 0.0000 (0.0000)  time: 0.230712  data: 0.027425  max mem: 3586
I20250120 12:12:59 3545703 dinov2 helpers.py:102] Training  [ 5060/12500]  eta: 0:29:31  loss: 21.8012 (24.7002)  lr: 0.0000 (0.0000)  time: 0.230593  data: 0.027413  max mem: 3586
I20250120 12:13:01 3545703 dinov2 helpers.py:102] Training  [ 5070/12500]  eta: 0:29:28  loss: 22.1895 (24.7029)  lr: 0.0000 (0.0000)  time: 0.207014  data: 0.000416  max mem: 3586
I20250120 12:13:03 3545703 dinov2 helpers.py:102] Training  [ 5080/12500]  eta: 0:29:25  loss: 22.1895 (24.6924)  lr: 0.0000 (0.0000)  time: 0.206765  data: 0.000428  max mem: 3586
I20250120 12:13:05 3545703 dinov2 helpers.py:102] Training  [ 5090/12500]  eta: 0:29:22  loss: 22.1895 (24.6857)  lr: 0.0000 (0.0000)  time: 0.206984  data: 0.000480  max mem: 3586
I20250120 12:13:07 3545703 dinov2 helpers.py:102] Training  [ 5100/12500]  eta: 0:29:19  loss: 22.1895 (24.6729)  lr: 0.0000 (0.0000)  time: 0.207255  data: 0.000503  max mem: 3586
I20250120 12:13:09 3545703 dinov2 helpers.py:102] Training  [ 5110/12500]  eta: 0:29:16  loss: 22.1895 (24.6632)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000478  max mem: 3586
I20250120 12:13:11 3545703 dinov2 helpers.py:102] Training  [ 5120/12500]  eta: 0:29:14  loss: 21.8012 (24.6570)  lr: 0.0000 (0.0000)  time: 0.207326  data: 0.000485  max mem: 3586
I20250120 12:13:13 3545703 dinov2 helpers.py:102] Training  [ 5130/12500]  eta: 0:29:11  loss: 21.8012 (24.6483)  lr: 0.0000 (0.0000)  time: 0.207365  data: 0.000495  max mem: 3586
I20250120 12:13:16 3545703 dinov2 helpers.py:102] Training  [ 5140/12500]  eta: 0:29:08  loss: 21.4604 (24.6377)  lr: 0.0000 (0.0000)  time: 0.207409  data: 0.000502  max mem: 3586
I20250120 12:13:18 3545703 dinov2 helpers.py:102] Training  [ 5150/12500]  eta: 0:29:05  loss: 21.4604 (24.6333)  lr: 0.0000 (0.0000)  time: 0.207502  data: 0.000480  max mem: 3586
I20250120 12:13:20 3545703 dinov2 helpers.py:102] Training  [ 5160/12500]  eta: 0:29:02  loss: 21.2927 (24.6231)  lr: 0.0000 (0.0000)  time: 0.207478  data: 0.000456  max mem: 3586
I20250120 12:13:22 3545703 dinov2 helpers.py:102] Training  [ 5170/12500]  eta: 0:29:00  loss: 20.5850 (24.6153)  lr: 0.0000 (0.0000)  time: 0.207475  data: 0.000449  max mem: 3586
I20250120 12:13:24 3545703 dinov2 helpers.py:102] Training  [ 5180/12500]  eta: 0:28:57  loss: 20.5850 (24.6108)  lr: 0.0000 (0.0000)  time: 0.207635  data: 0.000448  max mem: 3586
I20250120 12:13:26 3545703 dinov2 helpers.py:102] Training  [ 5190/12500]  eta: 0:28:54  loss: 20.5645 (24.6020)  lr: 0.0000 (0.0000)  time: 0.207777  data: 0.000475  max mem: 3586
I20250120 12:13:28 3545703 dinov2 helpers.py:102] Training  [ 5200/12500]  eta: 0:28:51  loss: 20.5850 (24.6023)  lr: 0.0000 (0.0000)  time: 0.207796  data: 0.000492  max mem: 3586
I20250120 12:13:30 3545703 dinov2 helpers.py:102] Training  [ 5210/12500]  eta: 0:28:48  loss: 20.5850 (24.5970)  lr: 0.0000 (0.0000)  time: 0.207635  data: 0.000453  max mem: 3586
I20250120 12:13:32 3545703 dinov2 helpers.py:102] Training  [ 5220/12500]  eta: 0:28:46  loss: 20.5850 (24.5963)  lr: 0.0000 (0.0000)  time: 0.207650  data: 0.000425  max mem: 3586
I20250120 12:13:34 3545703 dinov2 helpers.py:102] Training  [ 5230/12500]  eta: 0:28:43  loss: 20.5850 (24.5882)  lr: 0.0000 (0.0000)  time: 0.207891  data: 0.000460  max mem: 3586
I20250120 12:13:36 3545703 dinov2 helpers.py:102] Training  [ 5240/12500]  eta: 0:28:40  loss: 20.3424 (24.5798)  lr: 0.0000 (0.0000)  time: 0.208258  data: 0.000446  max mem: 3586
I20250120 12:13:38 3545703 dinov2 helpers.py:102] Training  [ 5250/12500]  eta: 0:28:37  loss: 20.1796 (24.5699)  lr: 0.0000 (0.0000)  time: 0.208203  data: 0.000442  max mem: 3586
I20250120 12:13:41 3545703 dinov2 helpers.py:102] Training  [ 5260/12500]  eta: 0:28:35  loss: 20.1796 (24.5583)  lr: 0.0000 (0.0000)  time: 0.207952  data: 0.000427  max mem: 3586
I20250120 12:13:43 3545703 dinov2 helpers.py:102] Training  [ 5270/12500]  eta: 0:28:32  loss: 20.1796 (24.5534)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000453  max mem: 3586
I20250120 12:13:45 3545703 dinov2 helpers.py:102] Training  [ 5280/12500]  eta: 0:28:29  loss: 20.3424 (24.5485)  lr: 0.0000 (0.0000)  time: 0.208069  data: 0.000497  max mem: 3586
I20250120 12:13:50 3545703 dinov2 helpers.py:102] Training  [ 5290/12500]  eta: 0:28:31  loss: 20.3424 (24.5448)  lr: 0.0000 (0.0000)  time: 0.381737  data: 0.186701  max mem: 3586
I20250120 12:13:53 3545703 dinov2 helpers.py:102] Training  [ 5300/12500]  eta: 0:28:29  loss: 20.5850 (24.5452)  lr: 0.0000 (0.0000)  time: 0.421633  data: 0.234661  max mem: 3586
I20250120 12:13:55 3545703 dinov2 helpers.py:102] Training  [ 5310/12500]  eta: 0:28:26  loss: 20.5850 (24.5362)  lr: 0.0000 (0.0000)  time: 0.246244  data: 0.048571  max mem: 3586
I20250120 12:13:57 3545703 dinov2 helpers.py:102] Training  [ 5320/12500]  eta: 0:28:24  loss: 20.5850 (24.5327)  lr: 0.0000 (0.0000)  time: 0.205349  data: 0.000620  max mem: 3586
I20250120 12:13:59 3545703 dinov2 helpers.py:102] Training  [ 5330/12500]  eta: 0:28:21  loss: 21.8154 (24.5292)  lr: 0.0000 (0.0000)  time: 0.205955  data: 0.000438  max mem: 3586
I20250120 12:14:01 3545703 dinov2 helpers.py:102] Training  [ 5340/12500]  eta: 0:28:18  loss: 21.8154 (24.5162)  lr: 0.0000 (0.0000)  time: 0.206384  data: 0.000441  max mem: 3586
I20250120 12:14:03 3545703 dinov2 helpers.py:102] Training  [ 5350/12500]  eta: 0:28:15  loss: 21.8154 (24.5140)  lr: 0.0000 (0.0000)  time: 0.206809  data: 0.000509  max mem: 3586
I20250120 12:14:05 3545703 dinov2 helpers.py:102] Training  [ 5360/12500]  eta: 0:28:13  loss: 21.9651 (24.5151)  lr: 0.0000 (0.0000)  time: 0.206897  data: 0.000450  max mem: 3586
I20250120 12:14:08 3545703 dinov2 helpers.py:102] Training  [ 5370/12500]  eta: 0:28:10  loss: 21.9860 (24.5208)  lr: 0.0000 (0.0000)  time: 0.207188  data: 0.000414  max mem: 3586
I20250120 12:14:10 3545703 dinov2 helpers.py:102] Training  [ 5380/12500]  eta: 0:28:07  loss: 21.9860 (24.5256)  lr: 0.0000 (0.0000)  time: 0.207323  data: 0.000474  max mem: 3586
I20250120 12:14:12 3545703 dinov2 helpers.py:102] Training  [ 5390/12500]  eta: 0:28:04  loss: 22.5699 (24.5241)  lr: 0.0000 (0.0000)  time: 0.207419  data: 0.000484  max mem: 3586
I20250120 12:14:14 3545703 dinov2 helpers.py:102] Training  [ 5400/12500]  eta: 0:28:01  loss: 21.9860 (24.5163)  lr: 0.0000 (0.0000)  time: 0.207464  data: 0.000447  max mem: 3586
I20250120 12:14:16 3545703 dinov2 helpers.py:102] Training  [ 5410/12500]  eta: 0:27:59  loss: 21.9860 (24.5066)  lr: 0.0000 (0.0000)  time: 0.207545  data: 0.000478  max mem: 3586
I20250120 12:14:18 3545703 dinov2 helpers.py:102] Training  [ 5420/12500]  eta: 0:27:56  loss: 21.9651 (24.5001)  lr: 0.0000 (0.0000)  time: 0.207793  data: 0.000485  max mem: 3586
I20250120 12:14:20 3545703 dinov2 helpers.py:102] Training  [ 5430/12500]  eta: 0:27:53  loss: 21.9651 (24.4924)  lr: 0.0000 (0.0000)  time: 0.207703  data: 0.000448  max mem: 3586
I20250120 12:14:22 3545703 dinov2 helpers.py:102] Training  [ 5440/12500]  eta: 0:27:50  loss: 21.9651 (24.4856)  lr: 0.0000 (0.0000)  time: 0.207604  data: 0.000429  max mem: 3586
I20250120 12:14:24 3545703 dinov2 helpers.py:102] Training  [ 5450/12500]  eta: 0:27:48  loss: 21.9651 (24.4774)  lr: 0.0000 (0.0000)  time: 0.207699  data: 0.000412  max mem: 3586
I20250120 12:14:26 3545703 dinov2 helpers.py:102] Training  [ 5460/12500]  eta: 0:27:45  loss: 21.9651 (24.4701)  lr: 0.0000 (0.0000)  time: 0.207883  data: 0.000425  max mem: 3586
I20250120 12:14:28 3545703 dinov2 helpers.py:102] Training  [ 5470/12500]  eta: 0:27:42  loss: 21.9651 (24.4753)  lr: 0.0000 (0.0000)  time: 0.208156  data: 0.000440  max mem: 3586
I20250120 12:14:30 3545703 dinov2 helpers.py:102] Training  [ 5480/12500]  eta: 0:27:40  loss: 22.5119 (24.4717)  lr: 0.0000 (0.0000)  time: 0.208171  data: 0.000442  max mem: 3586
I20250120 12:14:33 3545703 dinov2 helpers.py:102] Training  [ 5490/12500]  eta: 0:27:37  loss: 20.9881 (24.4654)  lr: 0.0000 (0.0000)  time: 0.208271  data: 0.000435  max mem: 3586
I20250120 12:14:35 3545703 dinov2 helpers.py:102] Training  [ 5500/12500]  eta: 0:27:34  loss: 20.9881 (24.4639)  lr: 0.0000 (0.0000)  time: 0.208369  data: 0.000426  max mem: 3586
I20250120 12:14:37 3545703 dinov2 helpers.py:102] Training  [ 5510/12500]  eta: 0:27:31  loss: 20.9881 (24.4421)  lr: 0.0000 (0.0000)  time: 0.208328  data: 0.000409  max mem: 3586
I20250120 12:14:39 3545703 dinov2 helpers.py:102] Training  [ 5520/12500]  eta: 0:27:29  loss: 20.9881 (24.4370)  lr: 0.0000 (0.0000)  time: 0.208404  data: 0.000447  max mem: 3586
I20250120 12:14:41 3545703 dinov2 helpers.py:102] Training  [ 5530/12500]  eta: 0:27:26  loss: 20.9881 (24.4336)  lr: 0.0000 (0.0000)  time: 0.208337  data: 0.000467  max mem: 3586
I20250120 12:14:43 3545703 dinov2 helpers.py:102] Training  [ 5540/12500]  eta: 0:27:23  loss: 21.5377 (24.4284)  lr: 0.0000 (0.0000)  time: 0.208419  data: 0.000483  max mem: 3586
I20250120 12:14:45 3545703 dinov2 helpers.py:102] Training  [ 5550/12500]  eta: 0:27:21  loss: 21.5377 (24.4369)  lr: 0.0000 (0.0000)  time: 0.208441  data: 0.000483  max mem: 3586
I20250120 12:14:47 3545703 dinov2 helpers.py:102] Training  [ 5560/12500]  eta: 0:27:18  loss: 21.5377 (24.4350)  lr: 0.0000 (0.0000)  time: 0.208358  data: 0.000468  max mem: 3586
I20250120 12:14:49 3545703 dinov2 helpers.py:102] Training  [ 5570/12500]  eta: 0:27:15  loss: 21.5377 (24.4392)  lr: 0.0000 (0.0000)  time: 0.208514  data: 0.000462  max mem: 3586
I20250120 12:14:51 3545703 dinov2 helpers.py:102] Training  [ 5580/12500]  eta: 0:27:12  loss: 21.5377 (24.4393)  lr: 0.0000 (0.0000)  time: 0.208653  data: 0.000479  max mem: 3586
I20250120 12:14:53 3545703 dinov2 helpers.py:102] Training  [ 5590/12500]  eta: 0:27:10  loss: 20.9881 (24.4299)  lr: 0.0000 (0.0000)  time: 0.208795  data: 0.000509  max mem: 3586
I20250120 12:14:55 3545703 dinov2 helpers.py:102] Training  [ 5600/12500]  eta: 0:27:07  loss: 21.5377 (24.4275)  lr: 0.0000 (0.0000)  time: 0.208752  data: 0.000486  max mem: 3586
I20250120 12:14:58 3545703 dinov2 helpers.py:102] Training  [ 5610/12500]  eta: 0:27:04  loss: 21.6147 (24.4259)  lr: 0.0000 (0.0000)  time: 0.208814  data: 0.000475  max mem: 3586
I20250120 12:15:00 3545703 dinov2 helpers.py:102] Training  [ 5620/12500]  eta: 0:27:02  loss: 22.5119 (24.4236)  lr: 0.0000 (0.0000)  time: 0.208843  data: 0.000492  max mem: 3586
I20250120 12:15:02 3545703 dinov2 helpers.py:102] Training  [ 5630/12500]  eta: 0:26:59  loss: 22.5119 (24.4150)  lr: 0.0000 (0.0000)  time: 0.208763  data: 0.000522  max mem: 3586
I20250120 12:15:04 3545703 dinov2 helpers.py:102] Training  [ 5640/12500]  eta: 0:26:56  loss: 22.5119 (24.4032)  lr: 0.0000 (0.0000)  time: 0.208994  data: 0.000515  max mem: 3586
I20250120 12:15:06 3545703 dinov2 helpers.py:102] Training  [ 5650/12500]  eta: 0:26:54  loss: 22.5119 (24.3937)  lr: 0.0000 (0.0000)  time: 0.209141  data: 0.000461  max mem: 3586
I20250120 12:15:08 3545703 dinov2 helpers.py:102] Training  [ 5660/12500]  eta: 0:26:51  loss: 22.5119 (24.3856)  lr: 0.0000 (0.0000)  time: 0.209082  data: 0.000441  max mem: 3586
I20250120 12:15:10 3545703 dinov2 helpers.py:102] Training  [ 5670/12500]  eta: 0:26:48  loss: 21.6147 (24.3689)  lr: 0.0000 (0.0000)  time: 0.209290  data: 0.000464  max mem: 3586
I20250120 12:15:12 3545703 dinov2 helpers.py:102] Training  [ 5680/12500]  eta: 0:26:46  loss: 21.5377 (24.3639)  lr: 0.0000 (0.0000)  time: 0.209753  data: 0.000440  max mem: 3586
I20250120 12:15:14 3545703 dinov2 helpers.py:102] Training  [ 5690/12500]  eta: 0:26:43  loss: 21.5377 (24.3557)  lr: 0.0000 (0.0000)  time: 0.209650  data: 0.000439  max mem: 3586
I20250120 12:15:16 3545703 dinov2 helpers.py:102] Training  [ 5700/12500]  eta: 0:26:40  loss: 21.5377 (24.3532)  lr: 0.0000 (0.0000)  time: 0.209267  data: 0.000484  max mem: 3586
I20250120 12:15:18 3545703 dinov2 helpers.py:102] Training  [ 5710/12500]  eta: 0:26:38  loss: 21.5377 (24.3459)  lr: 0.0000 (0.0000)  time: 0.208961  data: 0.000507  max mem: 3586
I20250120 12:15:21 3545703 dinov2 helpers.py:102] Training  [ 5720/12500]  eta: 0:26:35  loss: 21.5377 (24.3412)  lr: 0.0000 (0.0000)  time: 0.209158  data: 0.000521  max mem: 3586
I20250120 12:15:23 3545703 dinov2 helpers.py:102] Training  [ 5730/12500]  eta: 0:26:32  loss: 21.5255 (24.3336)  lr: 0.0000 (0.0000)  time: 0.209018  data: 0.000527  max mem: 3586
I20250120 12:15:25 3545703 dinov2 helpers.py:102] Training  [ 5740/12500]  eta: 0:26:30  loss: 21.5255 (24.3371)  lr: 0.0000 (0.0000)  time: 0.208774  data: 0.000498  max mem: 3586
I20250120 12:15:27 3545703 dinov2 helpers.py:102] Training  [ 5750/12500]  eta: 0:26:27  loss: 21.5255 (24.3370)  lr: 0.0000 (0.0000)  time: 0.208859  data: 0.000486  max mem: 3586
I20250120 12:15:29 3545703 dinov2 helpers.py:102] Training  [ 5760/12500]  eta: 0:26:24  loss: 21.5255 (24.3339)  lr: 0.0000 (0.0000)  time: 0.208942  data: 0.000501  max mem: 3586
I20250120 12:15:31 3545703 dinov2 helpers.py:102] Training  [ 5770/12500]  eta: 0:26:22  loss: 20.1638 (24.3247)  lr: 0.0000 (0.0000)  time: 0.209019  data: 0.000496  max mem: 3586
I20250120 12:15:33 3545703 dinov2 helpers.py:102] Training  [ 5780/12500]  eta: 0:26:19  loss: 20.1638 (24.3189)  lr: 0.0000 (0.0000)  time: 0.209063  data: 0.000460  max mem: 3586
I20250120 12:15:35 3545703 dinov2 helpers.py:102] Training  [ 5790/12500]  eta: 0:26:16  loss: 20.1638 (24.3068)  lr: 0.0000 (0.0000)  time: 0.209272  data: 0.000478  max mem: 3586
I20250120 12:15:37 3545703 dinov2 helpers.py:102] Training  [ 5800/12500]  eta: 0:26:14  loss: 20.0517 (24.2995)  lr: 0.0000 (0.0000)  time: 0.209342  data: 0.000512  max mem: 3586
I20250120 12:15:39 3545703 dinov2 helpers.py:102] Training  [ 5810/12500]  eta: 0:26:11  loss: 20.0517 (24.2976)  lr: 0.0000 (0.0000)  time: 0.209409  data: 0.000508  max mem: 3586
I20250120 12:15:41 3545703 dinov2 helpers.py:102] Training  [ 5820/12500]  eta: 0:26:08  loss: 19.9851 (24.2879)  lr: 0.0000 (0.0000)  time: 0.209424  data: 0.000466  max mem: 3586
I20250120 12:15:44 3545703 dinov2 helpers.py:102] Training  [ 5830/12500]  eta: 0:26:06  loss: 19.9851 (24.2784)  lr: 0.0000 (0.0000)  time: 0.209253  data: 0.000476  max mem: 3586
I20250120 12:15:46 3545703 dinov2 helpers.py:102] Training  [ 5840/12500]  eta: 0:26:03  loss: 19.9851 (24.2652)  lr: 0.0000 (0.0000)  time: 0.208824  data: 0.000542  max mem: 3586
I20250120 12:15:48 3545703 dinov2 helpers.py:102] Training  [ 5850/12500]  eta: 0:26:00  loss: 20.0517 (24.2656)  lr: 0.0000 (0.0000)  time: 0.208856  data: 0.000616  max mem: 3586
I20250120 12:15:50 3545703 dinov2 helpers.py:102] Training  [ 5860/12500]  eta: 0:25:58  loss: 20.0517 (24.2578)  lr: 0.0000 (0.0000)  time: 0.208987  data: 0.000671  max mem: 3586
I20250120 12:15:52 3545703 dinov2 helpers.py:102] Training  [ 5870/12500]  eta: 0:25:55  loss: 20.1638 (24.2548)  lr: 0.0000 (0.0000)  time: 0.208833  data: 0.000619  max mem: 3586
I20250120 12:15:54 3545703 dinov2 helpers.py:102] Training  [ 5880/12500]  eta: 0:25:53  loss: 20.1638 (24.2595)  lr: 0.0000 (0.0000)  time: 0.208654  data: 0.000582  max mem: 3586
I20250120 12:15:56 3545703 dinov2 helpers.py:102] Training  [ 5890/12500]  eta: 0:25:50  loss: 20.4828 (24.2531)  lr: 0.0000 (0.0000)  time: 0.208524  data: 0.000642  max mem: 3586
I20250120 12:15:58 3545703 dinov2 helpers.py:102] Training  [ 5900/12500]  eta: 0:25:47  loss: 20.4828 (24.2499)  lr: 0.0000 (0.0000)  time: 0.208719  data: 0.000655  max mem: 3586
I20250120 12:16:00 3545703 dinov2 helpers.py:102] Training  [ 5910/12500]  eta: 0:25:45  loss: 20.4828 (24.2359)  lr: 0.0000 (0.0000)  time: 0.208657  data: 0.000568  max mem: 3586
I20250120 12:16:02 3545703 dinov2 helpers.py:102] Training  [ 5920/12500]  eta: 0:25:42  loss: 20.0517 (24.2237)  lr: 0.0000 (0.0000)  time: 0.208638  data: 0.000493  max mem: 3586
I20250120 12:16:04 3545703 dinov2 helpers.py:102] Training  [ 5930/12500]  eta: 0:25:39  loss: 20.0517 (24.2164)  lr: 0.0000 (0.0000)  time: 0.208685  data: 0.000460  max mem: 3586
I20250120 12:16:07 3545703 dinov2 helpers.py:102] Training  [ 5940/12500]  eta: 0:25:37  loss: 20.0517 (24.2124)  lr: 0.0000 (0.0000)  time: 0.208844  data: 0.000479  max mem: 3586
I20250120 12:16:09 3545703 dinov2 helpers.py:102] Training  [ 5950/12500]  eta: 0:25:34  loss: 19.8652 (24.2005)  lr: 0.0000 (0.0000)  time: 0.209105  data: 0.000453  max mem: 3586
I20250120 12:16:11 3545703 dinov2 helpers.py:102] Training  [ 5960/12500]  eta: 0:25:32  loss: 19.8652 (24.1987)  lr: 0.0000 (0.0000)  time: 0.208901  data: 0.000455  max mem: 3586
I20250120 12:16:13 3545703 dinov2 helpers.py:102] Training  [ 5970/12500]  eta: 0:25:29  loss: 19.8652 (24.1855)  lr: 0.0000 (0.0000)  time: 0.208809  data: 0.000445  max mem: 3586
I20250120 12:16:15 3545703 dinov2 helpers.py:102] Training  [ 5980/12500]  eta: 0:25:26  loss: 19.8652 (24.1893)  lr: 0.0000 (0.0000)  time: 0.208904  data: 0.000435  max mem: 3586
I20250120 12:16:17 3545703 dinov2 helpers.py:102] Training  [ 5990/12500]  eta: 0:25:24  loss: 20.0517 (24.1888)  lr: 0.0000 (0.0000)  time: 0.208903  data: 0.000458  max mem: 3586
I20250120 12:16:19 3545703 dinov2 helpers.py:102] Training  [ 6000/12500]  eta: 0:25:21  loss: 19.8652 (24.1755)  lr: 0.0000 (0.0000)  time: 0.208785  data: 0.000440  max mem: 3586
I20250120 12:16:21 3545703 dinov2 helpers.py:102] Training  [ 6010/12500]  eta: 0:25:18  loss: 19.8652 (24.1698)  lr: 0.0000 (0.0000)  time: 0.208698  data: 0.000477  max mem: 3586
I20250120 12:16:23 3545703 dinov2 helpers.py:102] Training  [ 6020/12500]  eta: 0:25:16  loss: 20.4828 (24.1682)  lr: 0.0000 (0.0000)  time: 0.208470  data: 0.000506  max mem: 3586
I20250120 12:16:25 3545703 dinov2 helpers.py:102] Training  [ 6030/12500]  eta: 0:25:13  loss: 20.7905 (24.1627)  lr: 0.0000 (0.0000)  time: 0.208409  data: 0.000477  max mem: 3586
I20250120 12:16:27 3545703 dinov2 helpers.py:102] Training  [ 6040/12500]  eta: 0:25:11  loss: 20.7905 (24.1499)  lr: 0.0000 (0.0000)  time: 0.208436  data: 0.000461  max mem: 3586
I20250120 12:16:30 3545703 dinov2 helpers.py:102] Training  [ 6050/12500]  eta: 0:25:08  loss: 20.7905 (24.1471)  lr: 0.0000 (0.0000)  time: 0.208390  data: 0.000487  max mem: 3586
I20250120 12:16:32 3545703 dinov2 helpers.py:102] Training  [ 6060/12500]  eta: 0:25:05  loss: 20.7905 (24.1387)  lr: 0.0000 (0.0000)  time: 0.208357  data: 0.000472  max mem: 3586
I20250120 12:16:34 3545703 dinov2 helpers.py:102] Training  [ 6070/12500]  eta: 0:25:03  loss: 20.7905 (24.1348)  lr: 0.0000 (0.0000)  time: 0.208505  data: 0.000459  max mem: 3586
I20250120 12:16:36 3545703 dinov2 helpers.py:102] Training  [ 6080/12500]  eta: 0:25:00  loss: 20.4828 (24.1246)  lr: 0.0000 (0.0000)  time: 0.208636  data: 0.000434  max mem: 3586
I20250120 12:16:38 3545703 dinov2 helpers.py:102] Training  [ 6090/12500]  eta: 0:24:58  loss: 20.7905 (24.1220)  lr: 0.0000 (0.0000)  time: 0.208383  data: 0.000411  max mem: 3586
I20250120 12:16:40 3545703 dinov2 helpers.py:102] Training  [ 6100/12500]  eta: 0:24:55  loss: 20.7905 (24.1233)  lr: 0.0000 (0.0000)  time: 0.208602  data: 0.000416  max mem: 3586
I20250120 12:16:42 3545703 dinov2 helpers.py:102] Training  [ 6110/12500]  eta: 0:24:52  loss: 20.7905 (24.1145)  lr: 0.0000 (0.0000)  time: 0.208681  data: 0.000435  max mem: 3586
I20250120 12:16:44 3545703 dinov2 helpers.py:102] Training  [ 6120/12500]  eta: 0:24:50  loss: 20.8540 (24.1130)  lr: 0.0000 (0.0000)  time: 0.208567  data: 0.000392  max mem: 3586
I20250120 12:16:46 3545703 dinov2 helpers.py:102] Training  [ 6130/12500]  eta: 0:24:47  loss: 21.7710 (24.1100)  lr: 0.0000 (0.0000)  time: 0.208414  data: 0.000382  max mem: 3586
I20250120 12:16:48 3545703 dinov2 helpers.py:102] Training  [ 6140/12500]  eta: 0:24:45  loss: 21.7710 (24.1091)  lr: 0.0000 (0.0000)  time: 0.208222  data: 0.000491  max mem: 3586
I20250120 12:16:50 3545703 dinov2 helpers.py:102] Training  [ 6150/12500]  eta: 0:24:42  loss: 22.2508 (24.1067)  lr: 0.0000 (0.0000)  time: 0.208275  data: 0.000532  max mem: 3586
I20250120 12:16:52 3545703 dinov2 helpers.py:102] Training  [ 6160/12500]  eta: 0:24:39  loss: 22.2508 (24.1069)  lr: 0.0000 (0.0000)  time: 0.208187  data: 0.000509  max mem: 3586
I20250120 12:16:55 3545703 dinov2 helpers.py:102] Training  [ 6170/12500]  eta: 0:24:37  loss: 22.2508 (24.0983)  lr: 0.0000 (0.0000)  time: 0.208394  data: 0.000466  max mem: 3586
I20250120 12:16:57 3545703 dinov2 helpers.py:102] Training  [ 6180/12500]  eta: 0:24:34  loss: 22.2508 (24.0994)  lr: 0.0000 (0.0000)  time: 0.208344  data: 0.000479  max mem: 3586
I20250120 12:16:59 3545703 dinov2 helpers.py:102] Training  [ 6190/12500]  eta: 0:24:32  loss: 21.7710 (24.0894)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000484  max mem: 3586
I20250120 12:17:01 3545703 dinov2 helpers.py:102] Training  [ 6200/12500]  eta: 0:24:29  loss: 21.7710 (24.0835)  lr: 0.0000 (0.0000)  time: 0.208283  data: 0.000468  max mem: 3586
I20250120 12:17:03 3545703 dinov2 helpers.py:102] Training  [ 6210/12500]  eta: 0:24:26  loss: 21.7710 (24.0759)  lr: 0.0000 (0.0000)  time: 0.208154  data: 0.000481  max mem: 3586
I20250120 12:17:05 3545703 dinov2 helpers.py:102] Training  [ 6220/12500]  eta: 0:24:24  loss: 21.7710 (24.0776)  lr: 0.0000 (0.0000)  time: 0.207935  data: 0.000460  max mem: 3586
I20250120 12:17:07 3545703 dinov2 helpers.py:102] Training  [ 6230/12500]  eta: 0:24:21  loss: 22.2508 (24.0781)  lr: 0.0000 (0.0000)  time: 0.207822  data: 0.000423  max mem: 3586
I20250120 12:17:09 3545703 dinov2 helpers.py:102] Training  [ 6240/12500]  eta: 0:24:19  loss: 22.2508 (24.0699)  lr: 0.0000 (0.0000)  time: 0.207910  data: 0.000449  max mem: 3586
I20250120 12:17:11 3545703 dinov2 linear.py:272] running validation !
I20250120 12:17:13 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:58    time: 1.541541  data: 1.334565  max mem: 3586
I20250120 12:17:15 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.331553  data: 0.122873  max mem: 3586
I20250120 12:17:17 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.212224  data: 0.001037  max mem: 3586
I20250120 12:17:19 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212054  data: 0.000330  max mem: 3586
I20250120 12:17:21 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210384  data: 0.000277  max mem: 3586
I20250120 12:17:23 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.210292  data: 0.000253  max mem: 3586
I20250120 12:17:25 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209592  data: 0.000252  max mem: 3586
I20250120 12:17:27 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209763  data: 0.000256  max mem: 3586
I20250120 12:17:29 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210168  data: 0.000269  max mem: 3586
I20250120 12:17:31 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210115  data: 0.000260  max mem: 3586
I20250120 12:17:34 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210260  data: 0.000256  max mem: 3586
I20250120 12:17:36 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210214  data: 0.000265  max mem: 3586
I20250120 12:17:38 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209904  data: 0.000237  max mem: 3586
I20250120 12:17:40 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210093  data: 0.000223  max mem: 3586
I20250120 12:17:42 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210403  data: 0.000236  max mem: 3586
I20250120 12:17:44 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209815  data: 0.000186  max mem: 3586
I20250120 12:17:45 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205635  data: 0.000164  max mem: 3586
I20250120 12:17:45 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.219435 s / it)
I20250120 12:17:45 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:17:45 3545703 dinov2 linear.py:287] 
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8547, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8634, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8717, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8763, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8771, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8777, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8752, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8700, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8573, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8555, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8628, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8699, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8769, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8791, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8804, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8833, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8831, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8821, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8794, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8608, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8631, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8703, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8758, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8784, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8756, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8630, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8168, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8293, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8660, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8757, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8785, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8840, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8837, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8837, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8802, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8732, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8410, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8384, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00050', 'accuracy': 0.8839935064315796}
I20250120 12:17:45 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:17:45 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:17:45 3545703 dinov2 helpers.py:102] Training  [ 6250/12500]  eta: 0:24:50  loss: 21.7710 (24.0580)  lr: 0.0000 (0.0000)  time: 1.913076  data: 0.000481  max mem: 3586
I20250120 12:17:47 3545703 dinov2 helpers.py:102] Training  [ 6260/12500]  eta: 0:24:47  loss: 21.7710 (24.0473)  lr: 0.0000 (0.0000)  time: 1.912079  data: 0.000425  max mem: 3586
I20250120 12:17:49 3545703 dinov2 helpers.py:102] Training  [ 6270/12500]  eta: 0:24:45  loss: 20.3998 (24.0414)  lr: 0.0000 (0.0000)  time: 0.206515  data: 0.000419  max mem: 3586
I20250120 12:17:51 3545703 dinov2 helpers.py:102] Training  [ 6280/12500]  eta: 0:24:42  loss: 22.2508 (24.0432)  lr: 0.0000 (0.0000)  time: 0.207166  data: 0.000435  max mem: 3586
I20250120 12:17:54 3545703 dinov2 helpers.py:102] Training  [ 6290/12500]  eta: 0:24:39  loss: 20.3998 (24.0365)  lr: 0.0000 (0.0000)  time: 0.207255  data: 0.000419  max mem: 3586
I20250120 12:17:56 3545703 dinov2 helpers.py:102] Training  [ 6300/12500]  eta: 0:24:37  loss: 20.3835 (24.0258)  lr: 0.0000 (0.0000)  time: 0.207295  data: 0.000437  max mem: 3586
I20250120 12:17:58 3545703 dinov2 helpers.py:102] Training  [ 6310/12500]  eta: 0:24:34  loss: 20.3835 (24.0169)  lr: 0.0000 (0.0000)  time: 0.207205  data: 0.000403  max mem: 3586
I20250120 12:18:00 3545703 dinov2 helpers.py:102] Training  [ 6320/12500]  eta: 0:24:32  loss: 20.3835 (24.0188)  lr: 0.0000 (0.0000)  time: 0.231194  data: 0.028205  max mem: 3586
I20250120 12:18:02 3545703 dinov2 helpers.py:102] Training  [ 6330/12500]  eta: 0:24:29  loss: 20.3835 (24.0150)  lr: 0.0000 (0.0000)  time: 0.231036  data: 0.028267  max mem: 3586
I20250120 12:18:04 3545703 dinov2 helpers.py:102] Training  [ 6340/12500]  eta: 0:24:26  loss: 20.3835 (24.0109)  lr: 0.0000 (0.0000)  time: 0.206725  data: 0.000513  max mem: 3586
I20250120 12:18:06 3545703 dinov2 helpers.py:102] Training  [ 6350/12500]  eta: 0:24:24  loss: 19.8138 (24.0025)  lr: 0.0000 (0.0000)  time: 0.206565  data: 0.000500  max mem: 3586
I20250120 12:18:09 3545703 dinov2 helpers.py:102] Training  [ 6360/12500]  eta: 0:24:21  loss: 19.3342 (23.9939)  lr: 0.0000 (0.0000)  time: 0.206553  data: 0.000469  max mem: 3586
I20250120 12:18:11 3545703 dinov2 helpers.py:102] Training  [ 6370/12500]  eta: 0:24:18  loss: 19.8138 (23.9906)  lr: 0.0000 (0.0000)  time: 0.206486  data: 0.000454  max mem: 3586
I20250120 12:18:13 3545703 dinov2 helpers.py:102] Training  [ 6380/12500]  eta: 0:24:16  loss: 19.3431 (23.9833)  lr: 0.0000 (0.0000)  time: 0.206579  data: 0.000443  max mem: 3586
I20250120 12:18:15 3545703 dinov2 helpers.py:102] Training  [ 6390/12500]  eta: 0:24:13  loss: 19.8138 (23.9841)  lr: 0.0000 (0.0000)  time: 0.206875  data: 0.000451  max mem: 3586
I20250120 12:18:17 3545703 dinov2 helpers.py:102] Training  [ 6400/12500]  eta: 0:24:10  loss: 19.8138 (23.9839)  lr: 0.0000 (0.0000)  time: 0.207055  data: 0.000478  max mem: 3586
I20250120 12:18:19 3545703 dinov2 helpers.py:102] Training  [ 6410/12500]  eta: 0:24:08  loss: 20.3835 (23.9891)  lr: 0.0000 (0.0000)  time: 0.206986  data: 0.000507  max mem: 3586
I20250120 12:18:21 3545703 dinov2 helpers.py:102] Training  [ 6420/12500]  eta: 0:24:05  loss: 20.3835 (23.9869)  lr: 0.0000 (0.0000)  time: 0.207045  data: 0.000447  max mem: 3586
I20250120 12:18:23 3545703 dinov2 helpers.py:102] Training  [ 6430/12500]  eta: 0:24:02  loss: 20.3835 (23.9816)  lr: 0.0000 (0.0000)  time: 0.207224  data: 0.000471  max mem: 3586
I20250120 12:18:25 3545703 dinov2 helpers.py:102] Training  [ 6440/12500]  eta: 0:24:00  loss: 20.5521 (23.9793)  lr: 0.0000 (0.0000)  time: 0.207235  data: 0.000511  max mem: 3586
I20250120 12:18:27 3545703 dinov2 helpers.py:102] Training  [ 6450/12500]  eta: 0:23:57  loss: 21.2409 (23.9751)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000447  max mem: 3586
I20250120 12:18:29 3545703 dinov2 helpers.py:102] Training  [ 6460/12500]  eta: 0:23:54  loss: 21.2409 (23.9670)  lr: 0.0000 (0.0000)  time: 0.207045  data: 0.000444  max mem: 3586
I20250120 12:18:31 3545703 dinov2 helpers.py:102] Training  [ 6470/12500]  eta: 0:23:52  loss: 21.2409 (23.9575)  lr: 0.0000 (0.0000)  time: 0.207205  data: 0.000488  max mem: 3586
I20250120 12:18:33 3545703 dinov2 helpers.py:102] Training  [ 6480/12500]  eta: 0:23:49  loss: 20.5521 (23.9461)  lr: 0.0000 (0.0000)  time: 0.207312  data: 0.000500  max mem: 3586
I20250120 12:18:35 3545703 dinov2 helpers.py:102] Training  [ 6490/12500]  eta: 0:23:46  loss: 20.5521 (23.9387)  lr: 0.0000 (0.0000)  time: 0.207175  data: 0.000508  max mem: 3586
I20250120 12:18:38 3545703 dinov2 helpers.py:102] Training  [ 6500/12500]  eta: 0:23:44  loss: 21.2409 (23.9377)  lr: 0.0000 (0.0000)  time: 0.207285  data: 0.000515  max mem: 3586
I20250120 12:18:40 3545703 dinov2 helpers.py:102] Training  [ 6510/12500]  eta: 0:23:41  loss: 21.4084 (23.9363)  lr: 0.0000 (0.0000)  time: 0.207367  data: 0.000467  max mem: 3586
I20250120 12:18:42 3545703 dinov2 helpers.py:102] Training  [ 6520/12500]  eta: 0:23:38  loss: 21.2409 (23.9313)  lr: 0.0000 (0.0000)  time: 0.207312  data: 0.000403  max mem: 3586
I20250120 12:18:44 3545703 dinov2 helpers.py:102] Training  [ 6530/12500]  eta: 0:23:36  loss: 21.2409 (23.9304)  lr: 0.0000 (0.0000)  time: 0.207239  data: 0.000435  max mem: 3586
I20250120 12:18:46 3545703 dinov2 helpers.py:102] Training  [ 6540/12500]  eta: 0:23:33  loss: 20.6223 (23.9244)  lr: 0.0000 (0.0000)  time: 0.207254  data: 0.000507  max mem: 3586
I20250120 12:18:48 3545703 dinov2 helpers.py:102] Training  [ 6550/12500]  eta: 0:23:30  loss: 21.2409 (23.9251)  lr: 0.0000 (0.0000)  time: 0.207329  data: 0.000515  max mem: 3586
I20250120 12:18:50 3545703 dinov2 helpers.py:102] Training  [ 6560/12500]  eta: 0:23:28  loss: 21.2409 (23.9161)  lr: 0.0000 (0.0000)  time: 0.207261  data: 0.000514  max mem: 3586
I20250120 12:18:52 3545703 dinov2 helpers.py:102] Training  [ 6570/12500]  eta: 0:23:25  loss: 20.6223 (23.9089)  lr: 0.0000 (0.0000)  time: 0.207279  data: 0.000467  max mem: 3586
I20250120 12:18:54 3545703 dinov2 helpers.py:102] Training  [ 6580/12500]  eta: 0:23:23  loss: 21.2409 (23.9060)  lr: 0.0000 (0.0000)  time: 0.207184  data: 0.000421  max mem: 3586
I20250120 12:18:56 3545703 dinov2 helpers.py:102] Training  [ 6590/12500]  eta: 0:23:20  loss: 20.6223 (23.8953)  lr: 0.0000 (0.0000)  time: 0.207138  data: 0.000473  max mem: 3586
I20250120 12:18:58 3545703 dinov2 helpers.py:102] Training  [ 6600/12500]  eta: 0:23:17  loss: 20.6223 (23.8918)  lr: 0.0000 (0.0000)  time: 0.207340  data: 0.000488  max mem: 3586
I20250120 12:19:00 3545703 dinov2 helpers.py:102] Training  [ 6610/12500]  eta: 0:23:15  loss: 20.5521 (23.8850)  lr: 0.0000 (0.0000)  time: 0.207471  data: 0.000465  max mem: 3586
I20250120 12:19:02 3545703 dinov2 helpers.py:102] Training  [ 6620/12500]  eta: 0:23:12  loss: 20.5521 (23.8845)  lr: 0.0000 (0.0000)  time: 0.207359  data: 0.000458  max mem: 3586
I20250120 12:19:04 3545703 dinov2 helpers.py:102] Training  [ 6630/12500]  eta: 0:23:09  loss: 20.0045 (23.8780)  lr: 0.0000 (0.0000)  time: 0.207213  data: 0.000493  max mem: 3586
I20250120 12:19:07 3545703 dinov2 helpers.py:102] Training  [ 6640/12500]  eta: 0:23:07  loss: 19.5732 (23.8708)  lr: 0.0000 (0.0000)  time: 0.207174  data: 0.000518  max mem: 3586
I20250120 12:19:09 3545703 dinov2 helpers.py:102] Training  [ 6650/12500]  eta: 0:23:04  loss: 19.3634 (23.8624)  lr: 0.0000 (0.0000)  time: 0.207229  data: 0.000476  max mem: 3586
I20250120 12:19:11 3545703 dinov2 helpers.py:102] Training  [ 6660/12500]  eta: 0:23:02  loss: 19.5732 (23.8592)  lr: 0.0000 (0.0000)  time: 0.207137  data: 0.000478  max mem: 3586
I20250120 12:19:13 3545703 dinov2 helpers.py:102] Training  [ 6670/12500]  eta: 0:22:59  loss: 19.5732 (23.8491)  lr: 0.0000 (0.0000)  time: 0.207176  data: 0.000443  max mem: 3586
I20250120 12:19:15 3545703 dinov2 helpers.py:102] Training  [ 6680/12500]  eta: 0:22:56  loss: 19.5732 (23.8389)  lr: 0.0000 (0.0000)  time: 0.207419  data: 0.000432  max mem: 3586
I20250120 12:19:17 3545703 dinov2 helpers.py:102] Training  [ 6690/12500]  eta: 0:22:54  loss: 20.0045 (23.8373)  lr: 0.0000 (0.0000)  time: 0.207483  data: 0.000488  max mem: 3586
I20250120 12:19:19 3545703 dinov2 helpers.py:102] Training  [ 6700/12500]  eta: 0:22:51  loss: 20.0045 (23.8318)  lr: 0.0000 (0.0000)  time: 0.207376  data: 0.000443  max mem: 3586
I20250120 12:19:21 3545703 dinov2 helpers.py:102] Training  [ 6710/12500]  eta: 0:22:48  loss: 19.5732 (23.8191)  lr: 0.0000 (0.0000)  time: 0.207410  data: 0.000415  max mem: 3586
I20250120 12:19:23 3545703 dinov2 helpers.py:102] Training  [ 6720/12500]  eta: 0:22:46  loss: 19.5732 (23.8182)  lr: 0.0000 (0.0000)  time: 0.207339  data: 0.000469  max mem: 3586
I20250120 12:19:25 3545703 dinov2 helpers.py:102] Training  [ 6730/12500]  eta: 0:22:43  loss: 19.5732 (23.8140)  lr: 0.0000 (0.0000)  time: 0.207410  data: 0.000516  max mem: 3586
I20250120 12:19:27 3545703 dinov2 helpers.py:102] Training  [ 6740/12500]  eta: 0:22:41  loss: 19.3634 (23.8051)  lr: 0.0000 (0.0000)  time: 0.207405  data: 0.000535  max mem: 3586
I20250120 12:19:29 3545703 dinov2 helpers.py:102] Training  [ 6750/12500]  eta: 0:22:38  loss: 19.3634 (23.8032)  lr: 0.0000 (0.0000)  time: 0.207087  data: 0.000513  max mem: 3586
I20250120 12:19:31 3545703 dinov2 helpers.py:102] Training  [ 6760/12500]  eta: 0:22:35  loss: 19.3634 (23.7952)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000477  max mem: 3586
I20250120 12:19:34 3545703 dinov2 helpers.py:102] Training  [ 6770/12500]  eta: 0:22:33  loss: 19.3634 (23.7832)  lr: 0.0000 (0.0000)  time: 0.207729  data: 0.000418  max mem: 3586
I20250120 12:19:36 3545703 dinov2 helpers.py:102] Training  [ 6780/12500]  eta: 0:22:30  loss: 19.0463 (23.7701)  lr: 0.0000 (0.0000)  time: 0.207598  data: 0.000435  max mem: 3586
I20250120 12:19:38 3545703 dinov2 helpers.py:102] Training  [ 6790/12500]  eta: 0:22:28  loss: 19.0463 (23.7587)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000500  max mem: 3586
I20250120 12:19:40 3545703 dinov2 helpers.py:102] Training  [ 6800/12500]  eta: 0:22:25  loss: 19.0463 (23.7534)  lr: 0.0000 (0.0000)  time: 0.207609  data: 0.000510  max mem: 3586
I20250120 12:19:42 3545703 dinov2 helpers.py:102] Training  [ 6810/12500]  eta: 0:22:22  loss: 19.0463 (23.7492)  lr: 0.0000 (0.0000)  time: 0.207562  data: 0.000536  max mem: 3586
I20250120 12:19:44 3545703 dinov2 helpers.py:102] Training  [ 6820/12500]  eta: 0:22:20  loss: 19.0463 (23.7438)  lr: 0.0000 (0.0000)  time: 0.207531  data: 0.000504  max mem: 3586
I20250120 12:19:46 3545703 dinov2 helpers.py:102] Training  [ 6830/12500]  eta: 0:22:17  loss: 18.4053 (23.7355)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000485  max mem: 3586

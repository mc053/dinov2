I20250120 11:52:32 3545703 dinov2 config.py:59] git:
  sha: 3ded4e34eb54a7264c5d718f22ec7b24d73ba04c, status: has uncommitted changes, branch: main

I20250120 11:52:32 3545703 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: CelebA_pixelated_A/config.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
pretrained_weights: CelebA_pixelated_A/eval/training_124999/teacher_checkpoint.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: CelebAPixelatedTrain
val_class_mapping_fpath: None
val_dataset_str: CelebAPixelatedVal
val_metric_type: mean_accuracy
I20250120 11:52:32 3545703 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250120 11:52:32 3545703 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAPixelatedABTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
  a_b_training: A
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250120 11:52:32 3545703 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250120 11:52:50 3545703 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250120 11:52:50 3545703 dinov2 utils.py:33] Pretrained weights found at CelebA_pixelated_A/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250120 11:52:50 3545703 dinov2 loaders.py:116] using dataset: "CelebAPixelatedTrain"
I20250120 11:52:52 3545703 dinov2 loaders.py:121] # of dataset samples: 162,127
I20250120 11:52:53 3545703 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:52:53 3545703 dinov2 loaders.py:154] sampler: sharded infinite
I20250120 11:52:53 3545703 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:52:53 3545703 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:52:53 3545703 dinov2 loaders.py:253] infinite data loader
I20250120 11:52:53 3545703 dinov2 loaders.py:116] using dataset: "CelebAPixelatedVal"
I20250120 11:52:54 3545703 dinov2 loaders.py:121] # of dataset samples: 19,792
I20250120 11:52:54 3545703 dinov2 loaders.py:179] sampler: distributed
I20250120 11:52:54 3545703 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:52:54 3545703 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:52:54 3545703 dinov2 loaders.py:251] # of batches: 155
I20250120 11:52:54 3545703 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:52:54 3545703 dinov2 linear.py:338] Starting training from iteration 0
I20250120 11:52:59 3545703 dinov2 helpers.py:102] Training  [    0/12500]  eta: 16:12:47  loss: 35.3044 (35.3044)  lr: 0.0000 (0.0000)  time: 4.669375  data: 4.368509  max mem: 2706
I20250120 11:52:59 3545703 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20250120 11:53:01 3545703 dinov2 helpers.py:102] Training  [   10/12500]  eta: 2:06:29  loss: 31.9666 (33.6355)  lr: 0.0000 (0.0000)  time: 0.607647  data: 0.397993  max mem: 3115
I20250120 11:53:03 3545703 dinov2 helpers.py:102] Training  [   20/12500]  eta: 1:25:29  loss: 31.9666 (31.1541)  lr: 0.0000 (0.0000)  time: 0.198127  data: 0.000783  max mem: 3115
I20250120 11:53:04 3545703 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:10:54  loss: 26.1911 (29.5527)  lr: 0.0000 (0.0000)  time: 0.194680  data: 0.000581  max mem: 3115
I20250120 11:53:06 3545703 dinov2 helpers.py:102] Training  [   40/12500]  eta: 1:03:27  loss: 29.7441 (29.5910)  lr: 0.0000 (0.0000)  time: 0.194815  data: 0.000591  max mem: 3115
I20250120 11:53:08 3545703 dinov2 helpers.py:102] Training  [   50/12500]  eta: 0:58:56  loss: 26.1911 (28.8561)  lr: 0.0000 (0.0000)  time: 0.195401  data: 0.000607  max mem: 3115
I20250120 11:53:10 3545703 dinov2 helpers.py:102] Training  [   60/12500]  eta: 0:55:56  loss: 29.7441 (29.2944)  lr: 0.0000 (0.0000)  time: 0.196468  data: 0.000580  max mem: 3115
I20250120 11:53:12 3545703 dinov2 helpers.py:102] Training  [   70/12500]  eta: 0:53:45  loss: 27.8419 (29.1129)  lr: 0.0000 (0.0000)  time: 0.196861  data: 0.000604  max mem: 3115
I20250120 11:53:14 3545703 dinov2 helpers.py:102] Training  [   80/12500]  eta: 0:52:08  loss: 29.7441 (29.4461)  lr: 0.0000 (0.0000)  time: 0.197214  data: 0.000690  max mem: 3115
I20250120 11:53:16 3545703 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:50:52  loss: 29.7441 (29.6813)  lr: 0.0000 (0.0000)  time: 0.198021  data: 0.000646  max mem: 3115
I20250120 11:53:18 3545703 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:49:51  loss: 29.7441 (29.1589)  lr: 0.0000 (0.0000)  time: 0.198091  data: 0.000495  max mem: 3115
I20250120 11:53:20 3545703 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:49:01  loss: 29.7441 (29.2145)  lr: 0.0000 (0.0000)  time: 0.198432  data: 0.000419  max mem: 3115
I20250120 11:53:28 3545703 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:57:59  loss: 29.7441 (29.0134)  lr: 0.0000 (0.0000)  time: 0.482075  data: 0.288888  max mem: 3115
I20250120 11:53:30 3545703 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:56:37  loss: 27.8419 (28.7581)  lr: 0.0000 (0.0000)  time: 0.481405  data: 0.289849  max mem: 3115
I20250120 11:53:32 3545703 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:55:27  loss: 29.7441 (29.2045)  lr: 0.0000 (0.0000)  time: 0.197885  data: 0.001428  max mem: 3115
I20250120 11:53:34 3545703 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:54:27  loss: 27.8419 (29.0313)  lr: 0.0000 (0.0000)  time: 0.198572  data: 0.000538  max mem: 3115
I20250120 11:53:36 3545703 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:53:35  loss: 27.9921 (28.9702)  lr: 0.0000 (0.0000)  time: 0.199347  data: 0.000509  max mem: 3115
I20250120 11:53:38 3545703 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:52:49  loss: 27.8419 (28.8476)  lr: 0.0000 (0.0000)  time: 0.199986  data: 0.000527  max mem: 3115
I20250120 11:53:40 3545703 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:52:07  loss: 27.9921 (28.9040)  lr: 0.0000 (0.0000)  time: 0.200194  data: 0.000568  max mem: 3115
I20250120 11:53:42 3545703 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:51:30  loss: 27.9921 (28.9156)  lr: 0.0000 (0.0000)  time: 0.200373  data: 0.000532  max mem: 3115
I20250120 11:53:44 3545703 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:50:57  loss: 27.9921 (28.9324)  lr: 0.0000 (0.0000)  time: 0.200800  data: 0.000494  max mem: 3115
I20250120 11:53:46 3545703 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:50:27  loss: 27.8419 (28.5573)  lr: 0.0000 (0.0000)  time: 0.201181  data: 0.000491  max mem: 3115
I20250120 11:53:48 3545703 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:50:00  loss: 27.8419 (28.4572)  lr: 0.0000 (0.0000)  time: 0.201443  data: 0.000495  max mem: 3115
I20250120 11:53:50 3545703 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:49:35  loss: 27.8419 (28.3022)  lr: 0.0000 (0.0000)  time: 0.201733  data: 0.000494  max mem: 3115
I20250120 11:53:52 3545703 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:49:12  loss: 27.8419 (28.3375)  lr: 0.0000 (0.0000)  time: 0.202017  data: 0.000561  max mem: 3115
I20250120 11:53:54 3545703 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:48:51  loss: 27.9921 (28.3409)  lr: 0.0000 (0.0000)  time: 0.202424  data: 0.000581  max mem: 3115
I20250120 11:53:56 3545703 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:48:32  loss: 27.8419 (28.2371)  lr: 0.0000 (0.0000)  time: 0.202942  data: 0.000514  max mem: 3115
I20250120 11:53:58 3545703 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:48:14  loss: 26.7641 (28.1816)  lr: 0.0000 (0.0000)  time: 0.203104  data: 0.000500  max mem: 3115
I20250120 11:54:00 3545703 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:47:57  loss: 26.7641 (28.1798)  lr: 0.0000 (0.0000)  time: 0.203330  data: 0.000488  max mem: 3115
I20250120 11:54:02 3545703 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:47:41  loss: 26.6842 (28.1228)  lr: 0.0000 (0.0000)  time: 0.203660  data: 0.000478  max mem: 3115
I20250120 11:54:04 3545703 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:47:26  loss: 26.6842 (27.9342)  lr: 0.0000 (0.0000)  time: 0.203758  data: 0.000506  max mem: 3115
I20250120 11:54:06 3545703 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:47:13  loss: 26.6842 (27.9989)  lr: 0.0000 (0.0000)  time: 0.203949  data: 0.000883  max mem: 3115
I20250120 11:54:08 3545703 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:46:59  loss: 26.6842 (27.8141)  lr: 0.0000 (0.0000)  time: 0.203985  data: 0.000872  max mem: 3115
I20250120 11:54:10 3545703 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:46:47  loss: 26.6842 (27.7168)  lr: 0.0000 (0.0000)  time: 0.204595  data: 0.000513  max mem: 3115
I20250120 11:54:12 3545703 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:46:36  loss: 26.6842 (27.7652)  lr: 0.0000 (0.0000)  time: 0.205062  data: 0.000541  max mem: 3115
I20250120 11:54:14 3545703 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:46:25  loss: 26.6842 (27.6573)  lr: 0.0000 (0.0000)  time: 0.205030  data: 0.000569  max mem: 3115
I20250120 11:54:16 3545703 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:46:15  loss: 26.4708 (27.5688)  lr: 0.0000 (0.0000)  time: 0.205269  data: 0.000555  max mem: 3115
I20250120 11:54:19 3545703 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:46:05  loss: 26.4708 (27.5582)  lr: 0.0000 (0.0000)  time: 0.205362  data: 0.000542  max mem: 3115
I20250120 11:54:21 3545703 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:45:55  loss: 26.2538 (27.4845)  lr: 0.0000 (0.0000)  time: 0.205348  data: 0.000485  max mem: 3115
I20250120 11:54:23 3545703 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:45:46  loss: 26.2538 (27.6075)  lr: 0.0000 (0.0000)  time: 0.205537  data: 0.000461  max mem: 3115
I20250120 11:54:25 3545703 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:45:38  loss: 26.2538 (27.6076)  lr: 0.0000 (0.0000)  time: 0.206077  data: 0.000505  max mem: 3115
I20250120 11:54:27 3545703 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:45:30  loss: 26.2538 (27.5191)  lr: 0.0000 (0.0000)  time: 0.206229  data: 0.000475  max mem: 3115
I20250120 11:54:29 3545703 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:45:22  loss: 25.5375 (27.4395)  lr: 0.0000 (0.0000)  time: 0.206154  data: 0.000473  max mem: 3115
I20250120 11:54:31 3545703 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:45:14  loss: 26.4708 (27.4249)  lr: 0.0000 (0.0000)  time: 0.206157  data: 0.000489  max mem: 3115
I20250120 11:54:33 3545703 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:45:07  loss: 26.4708 (27.4842)  lr: 0.0000 (0.0000)  time: 0.206264  data: 0.000476  max mem: 3115
I20250120 11:54:35 3545703 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:45:00  loss: 25.6180 (27.4436)  lr: 0.0000 (0.0000)  time: 0.206391  data: 0.000517  max mem: 3115
I20250120 11:54:37 3545703 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:44:53  loss: 26.4708 (27.4445)  lr: 0.0000 (0.0000)  time: 0.206316  data: 0.000500  max mem: 3115
I20250120 11:54:39 3545703 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:44:46  loss: 25.6180 (27.3501)  lr: 0.0000 (0.0000)  time: 0.206343  data: 0.000486  max mem: 3115
I20250120 11:54:41 3545703 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:44:40  loss: 24.6866 (27.2825)  lr: 0.0000 (0.0000)  time: 0.206327  data: 0.000513  max mem: 3115
I20250120 11:54:43 3545703 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:44:34  loss: 24.5083 (27.1742)  lr: 0.0000 (0.0000)  time: 0.206466  data: 0.000479  max mem: 3115
I20250120 11:54:45 3545703 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:44:28  loss: 24.5083 (27.1083)  lr: 0.0000 (0.0000)  time: 0.206751  data: 0.000457  max mem: 3115
I20250120 11:54:47 3545703 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:44:22  loss: 24.5083 (27.0958)  lr: 0.0000 (0.0000)  time: 0.207063  data: 0.000492  max mem: 3115
I20250120 11:54:49 3545703 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:44:16  loss: 24.6866 (27.0980)  lr: 0.0000 (0.0000)  time: 0.207107  data: 0.000486  max mem: 3115
I20250120 11:54:52 3545703 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:44:11  loss: 25.6180 (27.0891)  lr: 0.0000 (0.0000)  time: 0.207056  data: 0.000489  max mem: 3115
I20250120 11:54:54 3545703 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:44:05  loss: 25.6180 (27.2202)  lr: 0.0000 (0.0000)  time: 0.207056  data: 0.000537  max mem: 3115
I20250120 11:54:56 3545703 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:44:00  loss: 25.6180 (27.1903)  lr: 0.0000 (0.0000)  time: 0.207133  data: 0.000495  max mem: 3115
I20250120 11:54:58 3545703 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:43:55  loss: 26.4574 (27.2172)  lr: 0.0000 (0.0000)  time: 0.207336  data: 0.000498  max mem: 3115
I20250120 11:55:00 3545703 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:43:50  loss: 26.4574 (27.4079)  lr: 0.0000 (0.0000)  time: 0.207014  data: 0.000495  max mem: 3115
I20250120 11:55:02 3545703 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:43:45  loss: 26.6203 (27.4734)  lr: 0.0000 (0.0000)  time: 0.207083  data: 0.000449  max mem: 3115
I20250120 11:55:04 3545703 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:43:40  loss: 26.4574 (27.3861)  lr: 0.0000 (0.0000)  time: 0.207207  data: 0.000477  max mem: 3115
I20250120 11:55:06 3545703 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:43:35  loss: 26.4574 (27.4713)  lr: 0.0000 (0.0000)  time: 0.207016  data: 0.000515  max mem: 3115
I20250120 11:55:08 3545703 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:43:31  loss: 26.4574 (27.3952)  lr: 0.0000 (0.0000)  time: 0.207317  data: 0.000560  max mem: 3115
I20250120 11:55:10 3545703 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:43:26  loss: 26.4574 (27.3641)  lr: 0.0000 (0.0000)  time: 0.207461  data: 0.000548  max mem: 3115
I20250120 11:55:12 3545703 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:43:22  loss: 26.2687 (27.3470)  lr: 0.0000 (0.0000)  time: 0.207574  data: 0.000480  max mem: 3115
I20250120 11:55:14 3545703 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:43:17  loss: 26.2687 (27.3363)  lr: 0.0000 (0.0000)  time: 0.207498  data: 0.000489  max mem: 3115
I20250120 11:55:16 3545703 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:43:13  loss: 26.4574 (27.3677)  lr: 0.0000 (0.0000)  time: 0.207268  data: 0.000514  max mem: 3115
I20250120 11:55:19 3545703 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:43:09  loss: 26.2687 (27.3086)  lr: 0.0000 (0.0000)  time: 0.207572  data: 0.000515  max mem: 3115
I20250120 11:55:21 3545703 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:43:05  loss: 26.4574 (27.3176)  lr: 0.0000 (0.0000)  time: 0.207809  data: 0.000490  max mem: 3115
I20250120 11:55:23 3545703 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:43:01  loss: 26.4574 (27.1729)  lr: 0.0000 (0.0000)  time: 0.207745  data: 0.000478  max mem: 3115
I20250120 11:55:25 3545703 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:42:57  loss: 26.4574 (27.1395)  lr: 0.0000 (0.0000)  time: 0.207661  data: 0.000498  max mem: 3115
I20250120 11:55:27 3545703 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:42:53  loss: 26.4574 (27.0814)  lr: 0.0000 (0.0000)  time: 0.207633  data: 0.000477  max mem: 3115
I20250120 11:55:29 3545703 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:42:49  loss: 26.2687 (27.0337)  lr: 0.0000 (0.0000)  time: 0.207795  data: 0.000510  max mem: 3115
I20250120 11:55:31 3545703 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:42:45  loss: 26.2668 (27.0232)  lr: 0.0000 (0.0000)  time: 0.207953  data: 0.000494  max mem: 3115
I20250120 11:55:33 3545703 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:42:41  loss: 26.2668 (27.0250)  lr: 0.0000 (0.0000)  time: 0.207853  data: 0.000465  max mem: 3115
I20250120 11:55:35 3545703 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:42:37  loss: 25.5441 (26.9650)  lr: 0.0000 (0.0000)  time: 0.207806  data: 0.000464  max mem: 3115
I20250120 11:55:37 3545703 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:42:34  loss: 25.4345 (26.9395)  lr: 0.0000 (0.0000)  time: 0.207837  data: 0.000473  max mem: 3115
I20250120 11:55:39 3545703 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:42:30  loss: 25.0309 (26.9073)  lr: 0.0000 (0.0000)  time: 0.207802  data: 0.000453  max mem: 3115
I20250120 11:55:41 3545703 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:42:26  loss: 25.0309 (26.8987)  lr: 0.0000 (0.0000)  time: 0.207846  data: 0.000431  max mem: 3115
I20250120 11:55:43 3545703 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:42:23  loss: 25.0309 (26.9452)  lr: 0.0000 (0.0000)  time: 0.207921  data: 0.000478  max mem: 3115
I20250120 11:55:46 3545703 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:42:19  loss: 25.4345 (27.0991)  lr: 0.0000 (0.0000)  time: 0.207840  data: 0.000468  max mem: 3115
I20250120 11:55:48 3545703 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:42:16  loss: 25.4345 (27.1204)  lr: 0.0000 (0.0000)  time: 0.207804  data: 0.000477  max mem: 3115
I20250120 11:55:50 3545703 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:42:12  loss: 26.2371 (27.1506)  lr: 0.0000 (0.0000)  time: 0.207923  data: 0.000500  max mem: 3115
I20250120 11:55:52 3545703 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:42:09  loss: 26.2668 (27.1495)  lr: 0.0000 (0.0000)  time: 0.207844  data: 0.000511  max mem: 3115
I20250120 11:55:54 3545703 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:42:06  loss: 26.2668 (27.1474)  lr: 0.0000 (0.0000)  time: 0.207735  data: 0.000527  max mem: 3115
I20250120 11:55:56 3545703 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:42:02  loss: 26.2668 (27.1396)  lr: 0.0000 (0.0000)  time: 0.207686  data: 0.000505  max mem: 3115
I20250120 11:55:58 3545703 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:41:59  loss: 26.2668 (27.1401)  lr: 0.0000 (0.0000)  time: 0.207654  data: 0.000470  max mem: 3115
I20250120 11:56:00 3545703 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:41:56  loss: 26.4816 (27.1849)  lr: 0.0000 (0.0000)  time: 0.207676  data: 0.000473  max mem: 3115
I20250120 11:56:02 3545703 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:41:52  loss: 26.2668 (27.1339)  lr: 0.0000 (0.0000)  time: 0.207717  data: 0.000452  max mem: 3115
I20250120 11:56:04 3545703 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:41:49  loss: 26.2668 (27.0955)  lr: 0.0000 (0.0000)  time: 0.207850  data: 0.000419  max mem: 3115
I20250120 11:56:06 3545703 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:41:46  loss: 26.2668 (27.0495)  lr: 0.0000 (0.0000)  time: 0.207923  data: 0.000420  max mem: 3115
I20250120 11:56:08 3545703 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:41:43  loss: 26.2668 (27.0264)  lr: 0.0000 (0.0000)  time: 0.207932  data: 0.000442  max mem: 3115
I20250120 11:56:10 3545703 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:41:39  loss: 26.4816 (27.0932)  lr: 0.0000 (0.0000)  time: 0.207934  data: 0.000489  max mem: 3115
I20250120 11:56:13 3545703 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:41:36  loss: 26.4816 (27.0085)  lr: 0.0000 (0.0000)  time: 0.207785  data: 0.000476  max mem: 3115
I20250120 11:56:15 3545703 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:41:33  loss: 26.2371 (26.9896)  lr: 0.0000 (0.0000)  time: 0.207956  data: 0.000467  max mem: 3115
I20250120 11:56:17 3545703 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:41:30  loss: 26.4816 (26.9977)  lr: 0.0000 (0.0000)  time: 0.208053  data: 0.000493  max mem: 3115
I20250120 11:56:19 3545703 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:41:27  loss: 26.4816 (26.9803)  lr: 0.0000 (0.0000)  time: 0.208121  data: 0.000492  max mem: 3115
I20250120 11:56:21 3545703 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:41:24  loss: 26.9756 (26.9947)  lr: 0.0000 (0.0000)  time: 0.208495  data: 0.000474  max mem: 3115
I20250120 11:56:23 3545703 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:41:21  loss: 27.0614 (27.0624)  lr: 0.0000 (0.0000)  time: 0.208323  data: 0.000515  max mem: 3115
I20250120 11:56:25 3545703 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:41:18  loss: 26.9756 (27.0201)  lr: 0.0000 (0.0000)  time: 0.208248  data: 0.000510  max mem: 3115
I20250120 11:56:27 3545703 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:41:15  loss: 26.4816 (26.9734)  lr: 0.0000 (0.0000)  time: 0.208288  data: 0.000475  max mem: 3115
I20250120 11:56:29 3545703 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:41:12  loss: 26.4816 (26.9846)  lr: 0.0000 (0.0000)  time: 0.208205  data: 0.000487  max mem: 3115
I20250120 11:56:31 3545703 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:41:09  loss: 26.4816 (27.0089)  lr: 0.0000 (0.0000)  time: 0.208343  data: 0.000512  max mem: 3115
I20250120 11:56:33 3545703 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:41:07  loss: 26.4816 (27.0157)  lr: 0.0000 (0.0000)  time: 0.208405  data: 0.000544  max mem: 3115
I20250120 11:56:35 3545703 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:41:04  loss: 25.3313 (26.9445)  lr: 0.0000 (0.0000)  time: 0.208605  data: 0.000491  max mem: 3115
I20250120 11:56:38 3545703 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:41:01  loss: 25.2391 (26.8657)  lr: 0.0000 (0.0000)  time: 0.208520  data: 0.000516  max mem: 3115
I20250120 11:56:40 3545703 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:40:58  loss: 25.2391 (26.8506)  lr: 0.0000 (0.0000)  time: 0.208287  data: 0.000481  max mem: 3115
I20250120 11:56:42 3545703 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:40:55  loss: 24.9452 (26.8102)  lr: 0.0000 (0.0000)  time: 0.208412  data: 0.000434  max mem: 3115
I20250120 11:56:44 3545703 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:40:52  loss: 24.9452 (26.7568)  lr: 0.0000 (0.0000)  time: 0.208425  data: 0.000483  max mem: 3115
I20250120 11:56:46 3545703 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:40:50  loss: 24.9452 (26.6932)  lr: 0.0000 (0.0000)  time: 0.208474  data: 0.000523  max mem: 3115
I20250120 11:56:48 3545703 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:40:47  loss: 25.2391 (26.6871)  lr: 0.0000 (0.0000)  time: 0.208728  data: 0.000548  max mem: 3115
I20250120 11:56:50 3545703 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:40:44  loss: 25.2391 (26.6526)  lr: 0.0000 (0.0000)  time: 0.208811  data: 0.000532  max mem: 3115
I20250120 11:56:52 3545703 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:40:41  loss: 25.2391 (26.6832)  lr: 0.0000 (0.0000)  time: 0.208714  data: 0.000533  max mem: 3115
I20250120 11:56:54 3545703 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:40:39  loss: 25.2391 (26.6486)  lr: 0.0000 (0.0000)  time: 0.208599  data: 0.000508  max mem: 3115
I20250120 11:56:56 3545703 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:40:36  loss: 25.2697 (26.6404)  lr: 0.0000 (0.0000)  time: 0.208524  data: 0.000535  max mem: 3115
I20250120 11:56:58 3545703 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:40:33  loss: 25.2697 (26.6368)  lr: 0.0000 (0.0000)  time: 0.208807  data: 0.000523  max mem: 3115
I20250120 11:57:01 3545703 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:40:31  loss: 25.2697 (26.6280)  lr: 0.0000 (0.0000)  time: 0.208882  data: 0.000452  max mem: 3115
I20250120 11:57:03 3545703 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:40:28  loss: 25.2697 (26.6561)  lr: 0.0000 (0.0000)  time: 0.208476  data: 0.000450  max mem: 3115
I20250120 11:57:05 3545703 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:40:25  loss: 25.2697 (26.6667)  lr: 0.0000 (0.0000)  time: 0.208902  data: 0.000497  max mem: 3115
I20250120 11:57:07 3545703 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:40:23  loss: 25.2697 (26.6219)  lr: 0.0000 (0.0000)  time: 0.209119  data: 0.000482  max mem: 3115
I20250120 11:57:09 3545703 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:40:20  loss: 25.6123 (26.6602)  lr: 0.0000 (0.0000)  time: 0.208719  data: 0.000514  max mem: 3115
I20250120 11:57:11 3545703 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:40:17  loss: 25.6123 (26.6706)  lr: 0.0000 (0.0000)  time: 0.208580  data: 0.000501  max mem: 3115
I20250120 11:57:13 3545703 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:40:15  loss: 25.6123 (26.7147)  lr: 0.0000 (0.0000)  time: 0.208473  data: 0.000472  max mem: 3115
I20250120 11:57:15 3545703 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:40:12  loss: 25.2697 (26.6978)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000548  max mem: 3115
I20250120 11:57:17 3545703 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:40:09  loss: 25.6123 (26.6995)  lr: 0.0000 (0.0000)  time: 0.208183  data: 0.000545  max mem: 3115
I20250120 11:57:19 3545703 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:40:07  loss: 25.7109 (26.7103)  lr: 0.0000 (0.0000)  time: 0.208308  data: 0.000533  max mem: 3115
I20250120 11:57:21 3545703 dinov2 linear.py:272] running validation !
I20250120 11:57:23 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:05:46    time: 2.234083  data: 1.963048  max mem: 3190
I20250120 11:57:26 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:59    time: 0.410785  data: 0.178701  max mem: 3586
I20250120 11:57:28 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:43    time: 0.224336  data: 0.000262  max mem: 3586
I20250120 11:57:30 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:35    time: 0.215030  data: 0.000277  max mem: 3586
I20250120 11:57:32 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:30    time: 0.212841  data: 0.000255  max mem: 3586
I20250120 11:57:34 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:26    time: 0.213075  data: 0.000228  max mem: 3586
I20250120 11:57:36 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:23    time: 0.210609  data: 0.000237  max mem: 3586
I20250120 11:57:38 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:20    time: 0.210597  data: 0.000268  max mem: 3586
I20250120 11:57:41 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210250  data: 0.000281  max mem: 3586
I20250120 11:57:43 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:15    time: 0.210481  data: 0.000231  max mem: 3586
I20250120 11:57:45 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210453  data: 0.000255  max mem: 3586
I20250120 11:57:47 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.209406  data: 0.000283  max mem: 3586
I20250120 11:57:49 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:08    time: 0.209720  data: 0.000232  max mem: 3586
I20250120 11:57:51 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210502  data: 0.000207  max mem: 3586
I20250120 11:57:53 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210531  data: 0.000268  max mem: 3586
I20250120 11:57:55 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210305  data: 0.000224  max mem: 3586
I20250120 11:57:56 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.210501  data: 0.000179  max mem: 3586
I20250120 11:57:56 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:35 (0.226440 s / it)
I20250120 11:57:56 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 11:57:56 3545703 dinov2 linear.py:287] 
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8204, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8450, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8515, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8626, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8675, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8712, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8729, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8725, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8683, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8618, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8551, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8472, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8337, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8445, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8567, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8734, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8771, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8626, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8559, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8447, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8580, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8657, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8753, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8751, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8695, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8608, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8511, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8469, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8526, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8544, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8612, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8690, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8708, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8756, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8759, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8731, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8712, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8632, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8566, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8509, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8414, device='cuda:0')}
I20250120 11:57:56 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8770715594291687}
I20250120 11:57:57 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:57:57 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:57:57 3545703 dinov2 helpers.py:102] Training  [ 1250/12500]  eta: 0:45:25  loss: 26.0156 (26.7164)  lr: 0.0000 (0.0000)  time: 1.994699  data: 0.027359  max mem: 3586
I20250120 11:57:59 3545703 dinov2 helpers.py:102] Training  [ 1260/12500]  eta: 0:45:20  loss: 26.2280 (26.7362)  lr: 0.0000 (0.0000)  time: 1.993421  data: 0.027303  max mem: 3586
I20250120 11:58:01 3545703 dinov2 helpers.py:102] Training  [ 1270/12500]  eta: 0:45:14  loss: 26.2280 (26.7146)  lr: 0.0000 (0.0000)  time: 0.206270  data: 0.000400  max mem: 3586
I20250120 11:58:03 3545703 dinov2 helpers.py:102] Training  [ 1280/12500]  eta: 0:45:09  loss: 26.9061 (26.7241)  lr: 0.0000 (0.0000)  time: 0.206721  data: 0.000396  max mem: 3586
I20250120 11:58:05 3545703 dinov2 helpers.py:102] Training  [ 1290/12500]  eta: 0:45:03  loss: 26.9061 (26.6695)  lr: 0.0000 (0.0000)  time: 0.206695  data: 0.000372  max mem: 3586
I20250120 11:58:07 3545703 dinov2 helpers.py:102] Training  [ 1300/12500]  eta: 0:44:58  loss: 27.1965 (26.6735)  lr: 0.0000 (0.0000)  time: 0.206744  data: 0.000390  max mem: 3586
I20250120 11:58:10 3545703 dinov2 helpers.py:102] Training  [ 1310/12500]  eta: 0:44:52  loss: 26.9061 (26.6060)  lr: 0.0000 (0.0000)  time: 0.206887  data: 0.000468  max mem: 3586
I20250120 11:58:12 3545703 dinov2 helpers.py:102] Training  [ 1320/12500]  eta: 0:44:47  loss: 27.1965 (26.6160)  lr: 0.0000 (0.0000)  time: 0.206988  data: 0.000470  max mem: 3586
I20250120 11:58:14 3545703 dinov2 helpers.py:102] Training  [ 1330/12500]  eta: 0:44:42  loss: 27.1965 (26.5663)  lr: 0.0000 (0.0000)  time: 0.207374  data: 0.000447  max mem: 3586
I20250120 11:58:16 3545703 dinov2 helpers.py:102] Training  [ 1340/12500]  eta: 0:44:37  loss: 27.1965 (26.5426)  lr: 0.0000 (0.0000)  time: 0.207568  data: 0.000461  max mem: 3586
I20250120 11:58:18 3545703 dinov2 helpers.py:102] Training  [ 1350/12500]  eta: 0:44:32  loss: 27.4726 (26.5795)  lr: 0.0000 (0.0000)  time: 0.207327  data: 0.000494  max mem: 3586
I20250120 11:58:20 3545703 dinov2 helpers.py:102] Training  [ 1360/12500]  eta: 0:44:27  loss: 27.1965 (26.5531)  lr: 0.0000 (0.0000)  time: 0.207248  data: 0.000457  max mem: 3586
I20250120 11:58:22 3545703 dinov2 helpers.py:102] Training  [ 1370/12500]  eta: 0:44:22  loss: 26.9061 (26.5472)  lr: 0.0000 (0.0000)  time: 0.207416  data: 0.000443  max mem: 3586
I20250120 11:58:24 3545703 dinov2 helpers.py:102] Training  [ 1380/12500]  eta: 0:44:17  loss: 26.9061 (26.5215)  lr: 0.0000 (0.0000)  time: 0.207522  data: 0.000467  max mem: 3586
I20250120 11:58:26 3545703 dinov2 helpers.py:102] Training  [ 1390/12500]  eta: 0:44:12  loss: 25.9925 (26.5177)  lr: 0.0000 (0.0000)  time: 0.207454  data: 0.000464  max mem: 3586
I20250120 11:58:28 3545703 dinov2 helpers.py:102] Training  [ 1400/12500]  eta: 0:44:07  loss: 25.7274 (26.5118)  lr: 0.0000 (0.0000)  time: 0.207289  data: 0.000471  max mem: 3586
I20250120 11:58:30 3545703 dinov2 helpers.py:102] Training  [ 1410/12500]  eta: 0:44:02  loss: 25.6863 (26.4853)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000477  max mem: 3586
I20250120 11:58:32 3545703 dinov2 helpers.py:102] Training  [ 1420/12500]  eta: 0:43:57  loss: 25.7274 (26.5006)  lr: 0.0000 (0.0000)  time: 0.207687  data: 0.000465  max mem: 3586
I20250120 11:58:34 3545703 dinov2 helpers.py:102] Training  [ 1430/12500]  eta: 0:43:53  loss: 25.7274 (26.5127)  lr: 0.0000 (0.0000)  time: 0.207568  data: 0.000447  max mem: 3586
I20250120 11:58:36 3545703 dinov2 helpers.py:102] Training  [ 1440/12500]  eta: 0:43:48  loss: 25.7274 (26.5101)  lr: 0.0000 (0.0000)  time: 0.207563  data: 0.000450  max mem: 3586
I20250120 11:58:39 3545703 dinov2 helpers.py:102] Training  [ 1450/12500]  eta: 0:43:43  loss: 25.6863 (26.4630)  lr: 0.0000 (0.0000)  time: 0.207596  data: 0.000454  max mem: 3586
I20250120 11:58:41 3545703 dinov2 helpers.py:102] Training  [ 1460/12500]  eta: 0:43:39  loss: 25.6863 (26.4761)  lr: 0.0000 (0.0000)  time: 0.207340  data: 0.000457  max mem: 3586
I20250120 11:58:43 3545703 dinov2 helpers.py:102] Training  [ 1470/12500]  eta: 0:43:34  loss: 25.6863 (26.4314)  lr: 0.0000 (0.0000)  time: 0.206982  data: 0.000478  max mem: 3586
I20250120 11:58:45 3545703 dinov2 helpers.py:102] Training  [ 1480/12500]  eta: 0:43:29  loss: 23.3628 (26.4081)  lr: 0.0000 (0.0000)  time: 0.207010  data: 0.000464  max mem: 3586
I20250120 11:58:47 3545703 dinov2 helpers.py:102] Training  [ 1490/12500]  eta: 0:43:25  loss: 23.3628 (26.3731)  lr: 0.0000 (0.0000)  time: 0.207343  data: 0.000455  max mem: 3586
I20250120 11:58:49 3545703 dinov2 helpers.py:102] Training  [ 1500/12500]  eta: 0:43:20  loss: 23.3628 (26.3618)  lr: 0.0000 (0.0000)  time: 0.207290  data: 0.000466  max mem: 3586
I20250120 11:58:51 3545703 dinov2 helpers.py:102] Training  [ 1510/12500]  eta: 0:43:16  loss: 23.3628 (26.3210)  lr: 0.0000 (0.0000)  time: 0.207311  data: 0.000473  max mem: 3586
I20250120 11:58:53 3545703 dinov2 helpers.py:102] Training  [ 1520/12500]  eta: 0:43:11  loss: 23.3628 (26.3104)  lr: 0.0000 (0.0000)  time: 0.207488  data: 0.000492  max mem: 3586
I20250120 11:58:55 3545703 dinov2 helpers.py:102] Training  [ 1530/12500]  eta: 0:43:07  loss: 23.3628 (26.2893)  lr: 0.0000 (0.0000)  time: 0.207264  data: 0.000485  max mem: 3586
I20250120 11:58:57 3545703 dinov2 helpers.py:102] Training  [ 1540/12500]  eta: 0:43:03  loss: 24.6630 (26.2877)  lr: 0.0000 (0.0000)  time: 0.207288  data: 0.000436  max mem: 3586
I20250120 11:58:59 3545703 dinov2 helpers.py:102] Training  [ 1550/12500]  eta: 0:42:58  loss: 24.6630 (26.2982)  lr: 0.0000 (0.0000)  time: 0.207284  data: 0.000419  max mem: 3586
I20250120 11:59:01 3545703 dinov2 helpers.py:102] Training  [ 1560/12500]  eta: 0:42:54  loss: 24.6630 (26.2464)  lr: 0.0000 (0.0000)  time: 0.207298  data: 0.000433  max mem: 3586
I20250120 11:59:03 3545703 dinov2 helpers.py:102] Training  [ 1570/12500]  eta: 0:42:50  loss: 24.6630 (26.3141)  lr: 0.0000 (0.0000)  time: 0.207612  data: 0.000440  max mem: 3586
I20250120 11:59:06 3545703 dinov2 helpers.py:102] Training  [ 1580/12500]  eta: 0:42:45  loss: 24.6969 (26.3433)  lr: 0.0000 (0.0000)  time: 0.207581  data: 0.000423  max mem: 3586
I20250120 11:59:08 3545703 dinov2 helpers.py:102] Training  [ 1590/12500]  eta: 0:42:41  loss: 24.6630 (26.3301)  lr: 0.0000 (0.0000)  time: 0.207704  data: 0.000426  max mem: 3586
I20250120 11:59:10 3545703 dinov2 helpers.py:102] Training  [ 1600/12500]  eta: 0:42:37  loss: 24.2223 (26.2773)  lr: 0.0000 (0.0000)  time: 0.207805  data: 0.000479  max mem: 3586
I20250120 11:59:12 3545703 dinov2 helpers.py:102] Training  [ 1610/12500]  eta: 0:42:33  loss: 24.2223 (26.2433)  lr: 0.0000 (0.0000)  time: 0.207450  data: 0.000476  max mem: 3586
I20250120 11:59:14 3545703 dinov2 helpers.py:102] Training  [ 1620/12500]  eta: 0:42:29  loss: 24.2223 (26.2407)  lr: 0.0000 (0.0000)  time: 0.207426  data: 0.000446  max mem: 3586
I20250120 11:59:16 3545703 dinov2 helpers.py:102] Training  [ 1630/12500]  eta: 0:42:25  loss: 23.0537 (26.1959)  lr: 0.0000 (0.0000)  time: 0.207596  data: 0.000449  max mem: 3586
I20250120 11:59:18 3545703 dinov2 helpers.py:102] Training  [ 1640/12500]  eta: 0:42:20  loss: 23.0537 (26.2035)  lr: 0.0000 (0.0000)  time: 0.207720  data: 0.000451  max mem: 3586
I20250120 11:59:20 3545703 dinov2 helpers.py:102] Training  [ 1650/12500]  eta: 0:42:16  loss: 24.2223 (26.2386)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000399  max mem: 3586
I20250120 11:59:22 3545703 dinov2 helpers.py:102] Training  [ 1660/12500]  eta: 0:42:12  loss: 24.2223 (26.2971)  lr: 0.0000 (0.0000)  time: 0.207474  data: 0.000409  max mem: 3586
I20250120 11:59:24 3545703 dinov2 helpers.py:102] Training  [ 1670/12500]  eta: 0:42:08  loss: 24.2223 (26.2817)  lr: 0.0000 (0.0000)  time: 0.207510  data: 0.000452  max mem: 3586
I20250120 11:59:26 3545703 dinov2 helpers.py:102] Training  [ 1680/12500]  eta: 0:42:04  loss: 24.6630 (26.2761)  lr: 0.0000 (0.0000)  time: 0.207455  data: 0.000435  max mem: 3586
I20250120 11:59:28 3545703 dinov2 helpers.py:102] Training  [ 1690/12500]  eta: 0:42:00  loss: 24.6969 (26.2801)  lr: 0.0000 (0.0000)  time: 0.207484  data: 0.000442  max mem: 3586
I20250120 11:59:30 3545703 dinov2 helpers.py:102] Training  [ 1700/12500]  eta: 0:41:56  loss: 24.6969 (26.2637)  lr: 0.0000 (0.0000)  time: 0.207869  data: 0.000469  max mem: 3586
I20250120 11:59:33 3545703 dinov2 helpers.py:102] Training  [ 1710/12500]  eta: 0:41:53  loss: 24.6969 (26.2141)  lr: 0.0000 (0.0000)  time: 0.208157  data: 0.000504  max mem: 3586
I20250120 11:59:35 3545703 dinov2 helpers.py:102] Training  [ 1720/12500]  eta: 0:41:49  loss: 25.3392 (26.2189)  lr: 0.0000 (0.0000)  time: 0.207993  data: 0.000479  max mem: 3586
I20250120 11:59:37 3545703 dinov2 helpers.py:102] Training  [ 1730/12500]  eta: 0:41:45  loss: 25.3392 (26.1949)  lr: 0.0000 (0.0000)  time: 0.207564  data: 0.000450  max mem: 3586
I20250120 11:59:39 3545703 dinov2 helpers.py:102] Training  [ 1740/12500]  eta: 0:41:41  loss: 24.2223 (26.1384)  lr: 0.0000 (0.0000)  time: 0.207403  data: 0.000435  max mem: 3586
I20250120 11:59:41 3545703 dinov2 helpers.py:102] Training  [ 1750/12500]  eta: 0:41:37  loss: 24.2223 (26.1332)  lr: 0.0000 (0.0000)  time: 0.207763  data: 0.000441  max mem: 3586
I20250120 11:59:43 3545703 dinov2 helpers.py:102] Training  [ 1760/12500]  eta: 0:41:33  loss: 25.2109 (26.1587)  lr: 0.0000 (0.0000)  time: 0.207827  data: 0.000453  max mem: 3586
I20250120 11:59:45 3545703 dinov2 helpers.py:102] Training  [ 1770/12500]  eta: 0:41:29  loss: 25.2109 (26.1647)  lr: 0.0000 (0.0000)  time: 0.207812  data: 0.000475  max mem: 3586
I20250120 11:59:47 3545703 dinov2 helpers.py:102] Training  [ 1780/12500]  eta: 0:41:26  loss: 24.2223 (26.1377)  lr: 0.0000 (0.0000)  time: 0.207847  data: 0.000484  max mem: 3586
I20250120 11:59:49 3545703 dinov2 helpers.py:102] Training  [ 1790/12500]  eta: 0:41:22  loss: 25.2109 (26.1451)  lr: 0.0000 (0.0000)  time: 0.207603  data: 0.000436  max mem: 3586
I20250120 11:59:51 3545703 dinov2 helpers.py:102] Training  [ 1800/12500]  eta: 0:41:18  loss: 25.2109 (26.1385)  lr: 0.0000 (0.0000)  time: 0.207816  data: 0.000452  max mem: 3586
I20250120 11:59:53 3545703 dinov2 helpers.py:102] Training  [ 1810/12500]  eta: 0:41:14  loss: 25.3392 (26.1352)  lr: 0.0000 (0.0000)  time: 0.208003  data: 0.000468  max mem: 3586
I20250120 11:59:55 3545703 dinov2 helpers.py:102] Training  [ 1820/12500]  eta: 0:41:11  loss: 25.2109 (26.1042)  lr: 0.0000 (0.0000)  time: 0.207743  data: 0.000469  max mem: 3586
I20250120 11:59:57 3545703 dinov2 helpers.py:102] Training  [ 1830/12500]  eta: 0:41:07  loss: 25.2109 (26.0963)  lr: 0.0000 (0.0000)  time: 0.207609  data: 0.000468  max mem: 3586
I20250120 12:00:00 3545703 dinov2 helpers.py:102] Training  [ 1840/12500]  eta: 0:41:03  loss: 25.2109 (26.1300)  lr: 0.0000 (0.0000)  time: 0.207566  data: 0.000459  max mem: 3586
I20250120 12:00:02 3545703 dinov2 helpers.py:102] Training  [ 1850/12500]  eta: 0:41:00  loss: 25.2109 (26.1418)  lr: 0.0000 (0.0000)  time: 0.207695  data: 0.000451  max mem: 3586
I20250120 12:00:04 3545703 dinov2 helpers.py:102] Training  [ 1860/12500]  eta: 0:40:56  loss: 24.9663 (26.1332)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000398  max mem: 3586
I20250120 12:00:06 3545703 dinov2 helpers.py:102] Training  [ 1870/12500]  eta: 0:40:52  loss: 24.9663 (26.1101)  lr: 0.0000 (0.0000)  time: 0.207626  data: 0.000413  max mem: 3586
I20250120 12:00:08 3545703 dinov2 helpers.py:102] Training  [ 1880/12500]  eta: 0:40:49  loss: 24.9663 (26.1104)  lr: 0.0000 (0.0000)  time: 0.207815  data: 0.000443  max mem: 3586
I20250120 12:00:10 3545703 dinov2 helpers.py:102] Training  [ 1890/12500]  eta: 0:40:45  loss: 24.6491 (26.0991)  lr: 0.0000 (0.0000)  time: 0.207678  data: 0.000435  max mem: 3586
I20250120 12:00:12 3545703 dinov2 helpers.py:102] Training  [ 1900/12500]  eta: 0:40:42  loss: 24.6491 (26.0714)  lr: 0.0000 (0.0000)  time: 0.207641  data: 0.000448  max mem: 3586
I20250120 12:00:14 3545703 dinov2 helpers.py:102] Training  [ 1910/12500]  eta: 0:40:38  loss: 24.9663 (26.1033)  lr: 0.0000 (0.0000)  time: 0.207631  data: 0.000448  max mem: 3586
I20250120 12:00:16 3545703 dinov2 helpers.py:102] Training  [ 1920/12500]  eta: 0:40:34  loss: 24.9663 (26.1238)  lr: 0.0000 (0.0000)  time: 0.207677  data: 0.000460  max mem: 3586
I20250120 12:00:18 3545703 dinov2 helpers.py:102] Training  [ 1930/12500]  eta: 0:40:31  loss: 24.9663 (26.0957)  lr: 0.0000 (0.0000)  time: 0.207808  data: 0.000467  max mem: 3586
I20250120 12:00:20 3545703 dinov2 helpers.py:102] Training  [ 1940/12500]  eta: 0:40:27  loss: 25.2109 (26.1105)  lr: 0.0000 (0.0000)  time: 0.207531  data: 0.000488  max mem: 3586
I20250120 12:00:22 3545703 dinov2 helpers.py:102] Training  [ 1950/12500]  eta: 0:40:24  loss: 25.5376 (26.1496)  lr: 0.0000 (0.0000)  time: 0.207246  data: 0.000499  max mem: 3586
I20250120 12:00:24 3545703 dinov2 helpers.py:102] Training  [ 1960/12500]  eta: 0:40:20  loss: 25.0007 (26.1437)  lr: 0.0000 (0.0000)  time: 0.207471  data: 0.000489  max mem: 3586
I20250120 12:00:27 3545703 dinov2 helpers.py:102] Training  [ 1970/12500]  eta: 0:40:17  loss: 25.0007 (26.1722)  lr: 0.0000 (0.0000)  time: 0.207541  data: 0.000439  max mem: 3586
I20250120 12:00:29 3545703 dinov2 helpers.py:102] Training  [ 1980/12500]  eta: 0:40:13  loss: 25.5376 (26.1799)  lr: 0.0000 (0.0000)  time: 0.207627  data: 0.000432  max mem: 3586
I20250120 12:00:31 3545703 dinov2 helpers.py:102] Training  [ 1990/12500]  eta: 0:40:10  loss: 25.0007 (26.1386)  lr: 0.0000 (0.0000)  time: 0.207665  data: 0.000484  max mem: 3586
I20250120 12:00:33 3545703 dinov2 helpers.py:102] Training  [ 2000/12500]  eta: 0:40:07  loss: 25.5376 (26.1387)  lr: 0.0000 (0.0000)  time: 0.207474  data: 0.000495  max mem: 3586
I20250120 12:00:35 3545703 dinov2 helpers.py:102] Training  [ 2010/12500]  eta: 0:40:03  loss: 26.1614 (26.1792)  lr: 0.0000 (0.0000)  time: 0.207563  data: 0.000502  max mem: 3586
I20250120 12:00:37 3545703 dinov2 helpers.py:102] Training  [ 2020/12500]  eta: 0:40:00  loss: 26.1663 (26.2056)  lr: 0.0000 (0.0000)  time: 0.207636  data: 0.000507  max mem: 3586
I20250120 12:00:39 3545703 dinov2 helpers.py:102] Training  [ 2030/12500]  eta: 0:39:56  loss: 26.1663 (26.1980)  lr: 0.0000 (0.0000)  time: 0.207631  data: 0.000492  max mem: 3586
I20250120 12:00:41 3545703 dinov2 helpers.py:102] Training  [ 2040/12500]  eta: 0:39:53  loss: 26.1614 (26.1807)  lr: 0.0000 (0.0000)  time: 0.207690  data: 0.000441  max mem: 3586
I20250120 12:00:43 3545703 dinov2 helpers.py:102] Training  [ 2050/12500]  eta: 0:39:50  loss: 25.0007 (26.1633)  lr: 0.0000 (0.0000)  time: 0.207573  data: 0.000411  max mem: 3586
I20250120 12:00:45 3545703 dinov2 helpers.py:102] Training  [ 2060/12500]  eta: 0:39:46  loss: 25.0007 (26.1248)  lr: 0.0000 (0.0000)  time: 0.207512  data: 0.000443  max mem: 3586
I20250120 12:00:47 3545703 dinov2 helpers.py:102] Training  [ 2070/12500]  eta: 0:39:43  loss: 26.1614 (26.1310)  lr: 0.0000 (0.0000)  time: 0.207687  data: 0.000466  max mem: 3586
I20250120 12:00:49 3545703 dinov2 helpers.py:102] Training  [ 2080/12500]  eta: 0:39:40  loss: 26.1614 (26.1484)  lr: 0.0000 (0.0000)  time: 0.207908  data: 0.000458  max mem: 3586
I20250120 12:00:51 3545703 dinov2 helpers.py:102] Training  [ 2090/12500]  eta: 0:39:36  loss: 26.1614 (26.1362)  lr: 0.0000 (0.0000)  time: 0.207767  data: 0.000450  max mem: 3586
I20250120 12:00:54 3545703 dinov2 helpers.py:102] Training  [ 2100/12500]  eta: 0:39:33  loss: 26.1614 (26.1169)  lr: 0.0000 (0.0000)  time: 0.207302  data: 0.000421  max mem: 3586
I20250120 12:00:56 3545703 dinov2 helpers.py:102] Training  [ 2110/12500]  eta: 0:39:30  loss: 25.7189 (26.1150)  lr: 0.0000 (0.0000)  time: 0.207452  data: 0.000401  max mem: 3586
I20250120 12:00:58 3545703 dinov2 helpers.py:102] Training  [ 2120/12500]  eta: 0:39:26  loss: 25.7189 (26.1234)  lr: 0.0000 (0.0000)  time: 0.207610  data: 0.000430  max mem: 3586
I20250120 12:01:00 3545703 dinov2 helpers.py:102] Training  [ 2130/12500]  eta: 0:39:23  loss: 26.1614 (26.1496)  lr: 0.0000 (0.0000)  time: 0.207619  data: 0.000466  max mem: 3586
I20250120 12:01:02 3545703 dinov2 helpers.py:102] Training  [ 2140/12500]  eta: 0:39:20  loss: 26.1614 (26.1749)  lr: 0.0000 (0.0000)  time: 0.207692  data: 0.000466  max mem: 3586
I20250120 12:01:04 3545703 dinov2 helpers.py:102] Training  [ 2150/12500]  eta: 0:39:17  loss: 25.7189 (26.1654)  lr: 0.0000 (0.0000)  time: 0.207601  data: 0.000471  max mem: 3586
I20250120 12:01:06 3545703 dinov2 helpers.py:102] Training  [ 2160/12500]  eta: 0:39:13  loss: 26.1614 (26.1969)  lr: 0.0000 (0.0000)  time: 0.207559  data: 0.000475  max mem: 3586
I20250120 12:01:08 3545703 dinov2 helpers.py:102] Training  [ 2170/12500]  eta: 0:39:10  loss: 26.1614 (26.2021)  lr: 0.0000 (0.0000)  time: 0.207630  data: 0.000447  max mem: 3586
I20250120 12:01:10 3545703 dinov2 helpers.py:102] Training  [ 2180/12500]  eta: 0:39:07  loss: 25.7189 (26.1717)  lr: 0.0000 (0.0000)  time: 0.207940  data: 0.000447  max mem: 3586
I20250120 12:01:12 3545703 dinov2 helpers.py:102] Training  [ 2190/12500]  eta: 0:39:04  loss: 26.1614 (26.1747)  lr: 0.0000 (0.0000)  time: 0.207912  data: 0.000475  max mem: 3586
I20250120 12:01:14 3545703 dinov2 helpers.py:102] Training  [ 2200/12500]  eta: 0:39:00  loss: 25.7189 (26.1639)  lr: 0.0000 (0.0000)  time: 0.207742  data: 0.000481  max mem: 3586
I20250120 12:01:16 3545703 dinov2 helpers.py:102] Training  [ 2210/12500]  eta: 0:38:57  loss: 25.7189 (26.1638)  lr: 0.0000 (0.0000)  time: 0.207842  data: 0.000481  max mem: 3586
I20250120 12:01:18 3545703 dinov2 helpers.py:102] Training  [ 2220/12500]  eta: 0:38:54  loss: 24.6549 (26.1373)  lr: 0.0000 (0.0000)  time: 0.207772  data: 0.000433  max mem: 3586
I20250120 12:01:21 3545703 dinov2 helpers.py:102] Training  [ 2230/12500]  eta: 0:38:51  loss: 25.7189 (26.1444)  lr: 0.0000 (0.0000)  time: 0.207497  data: 0.000397  max mem: 3586
I20250120 12:01:23 3545703 dinov2 helpers.py:102] Training  [ 2240/12500]  eta: 0:38:48  loss: 26.1278 (26.1504)  lr: 0.0000 (0.0000)  time: 0.207637  data: 0.000446  max mem: 3586
I20250120 12:01:25 3545703 dinov2 helpers.py:102] Training  [ 2250/12500]  eta: 0:38:45  loss: 26.8360 (26.1756)  lr: 0.0000 (0.0000)  time: 0.208061  data: 0.000481  max mem: 3586
I20250120 12:01:27 3545703 dinov2 helpers.py:102] Training  [ 2260/12500]  eta: 0:38:42  loss: 26.9032 (26.1788)  lr: 0.0000 (0.0000)  time: 0.208125  data: 0.000460  max mem: 3586
I20250120 12:01:29 3545703 dinov2 helpers.py:102] Training  [ 2270/12500]  eta: 0:38:38  loss: 26.8360 (26.1803)  lr: 0.0000 (0.0000)  time: 0.207746  data: 0.000423  max mem: 3586
I20250120 12:01:31 3545703 dinov2 helpers.py:102] Training  [ 2280/12500]  eta: 0:38:35  loss: 26.5162 (26.1801)  lr: 0.0000 (0.0000)  time: 0.207534  data: 0.000449  max mem: 3586
I20250120 12:01:33 3545703 dinov2 helpers.py:102] Training  [ 2290/12500]  eta: 0:38:32  loss: 26.5162 (26.1665)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000477  max mem: 3586
I20250120 12:01:35 3545703 dinov2 helpers.py:102] Training  [ 2300/12500]  eta: 0:38:29  loss: 26.5162 (26.1623)  lr: 0.0000 (0.0000)  time: 0.207652  data: 0.000452  max mem: 3586
I20250120 12:01:37 3545703 dinov2 helpers.py:102] Training  [ 2310/12500]  eta: 0:38:26  loss: 26.5162 (26.1555)  lr: 0.0000 (0.0000)  time: 0.207861  data: 0.000420  max mem: 3586
I20250120 12:01:39 3545703 dinov2 helpers.py:102] Training  [ 2320/12500]  eta: 0:38:23  loss: 26.5162 (26.1642)  lr: 0.0000 (0.0000)  time: 0.207814  data: 0.000452  max mem: 3586
I20250120 12:01:41 3545703 dinov2 helpers.py:102] Training  [ 2330/12500]  eta: 0:38:20  loss: 26.1508 (26.1328)  lr: 0.0000 (0.0000)  time: 0.207882  data: 0.000473  max mem: 3586
I20250120 12:01:43 3545703 dinov2 helpers.py:102] Training  [ 2340/12500]  eta: 0:38:17  loss: 26.1278 (26.1103)  lr: 0.0000 (0.0000)  time: 0.207992  data: 0.000456  max mem: 3586
I20250120 12:01:45 3545703 dinov2 helpers.py:102] Training  [ 2350/12500]  eta: 0:38:14  loss: 26.1278 (26.1075)  lr: 0.0000 (0.0000)  time: 0.207829  data: 0.000473  max mem: 3586
I20250120 12:01:48 3545703 dinov2 helpers.py:102] Training  [ 2360/12500]  eta: 0:38:11  loss: 25.4549 (26.0959)  lr: 0.0000 (0.0000)  time: 0.207740  data: 0.000477  max mem: 3586
I20250120 12:01:50 3545703 dinov2 helpers.py:102] Training  [ 2370/12500]  eta: 0:38:08  loss: 25.4549 (26.1200)  lr: 0.0000 (0.0000)  time: 0.207688  data: 0.000502  max mem: 3586
I20250120 12:01:52 3545703 dinov2 helpers.py:102] Training  [ 2380/12500]  eta: 0:38:05  loss: 25.4549 (26.1167)  lr: 0.0000 (0.0000)  time: 0.207830  data: 0.000500  max mem: 3586
I20250120 12:01:54 3545703 dinov2 helpers.py:102] Training  [ 2390/12500]  eta: 0:38:02  loss: 25.4549 (26.1421)  lr: 0.0000 (0.0000)  time: 0.208161  data: 0.000460  max mem: 3586
I20250120 12:01:56 3545703 dinov2 helpers.py:102] Training  [ 2400/12500]  eta: 0:37:59  loss: 26.1278 (26.1448)  lr: 0.0000 (0.0000)  time: 0.207994  data: 0.000430  max mem: 3586
I20250120 12:01:58 3545703 dinov2 helpers.py:102] Training  [ 2410/12500]  eta: 0:37:56  loss: 25.4549 (26.1115)  lr: 0.0000 (0.0000)  time: 0.207879  data: 0.000446  max mem: 3586
I20250120 12:02:00 3545703 dinov2 helpers.py:102] Training  [ 2420/12500]  eta: 0:37:53  loss: 26.1508 (26.1245)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000485  max mem: 3586
I20250120 12:02:02 3545703 dinov2 helpers.py:102] Training  [ 2430/12500]  eta: 0:37:50  loss: 26.1508 (26.1521)  lr: 0.0000 (0.0000)  time: 0.208245  data: 0.000462  max mem: 3586
I20250120 12:02:04 3545703 dinov2 helpers.py:102] Training  [ 2440/12500]  eta: 0:37:47  loss: 25.4549 (26.1381)  lr: 0.0000 (0.0000)  time: 0.208108  data: 0.000447  max mem: 3586
I20250120 12:02:06 3545703 dinov2 helpers.py:102] Training  [ 2450/12500]  eta: 0:37:44  loss: 25.3184 (26.1218)  lr: 0.0000 (0.0000)  time: 0.207934  data: 0.000460  max mem: 3586
I20250120 12:02:08 3545703 dinov2 helpers.py:102] Training  [ 2460/12500]  eta: 0:37:41  loss: 25.2136 (26.1038)  lr: 0.0000 (0.0000)  time: 0.207988  data: 0.000475  max mem: 3586
I20250120 12:02:10 3545703 dinov2 helpers.py:102] Training  [ 2470/12500]  eta: 0:37:38  loss: 25.2136 (26.1179)  lr: 0.0000 (0.0000)  time: 0.207842  data: 0.000480  max mem: 3586
I20250120 12:02:13 3545703 dinov2 helpers.py:102] Training  [ 2480/12500]  eta: 0:37:35  loss: 24.5653 (26.1101)  lr: 0.0000 (0.0000)  time: 0.207599  data: 0.000466  max mem: 3586
I20250120 12:02:15 3545703 dinov2 helpers.py:102] Training  [ 2490/12500]  eta: 0:37:32  loss: 24.5653 (26.0995)  lr: 0.0000 (0.0000)  time: 0.207593  data: 0.000454  max mem: 3586
I20250120 12:02:16 3545703 dinov2 linear.py:272] running validation !
I20250120 12:02:18 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:18    time: 1.667830  data: 1.458379  max mem: 3586
I20250120 12:02:20 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:50    time: 0.347148  data: 0.133350  max mem: 3586
I20250120 12:02:22 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:38    time: 0.213408  data: 0.000736  max mem: 3586
I20250120 12:02:25 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.210948  data: 0.000418  max mem: 3586
I20250120 12:02:27 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210055  data: 0.000249  max mem: 3586
I20250120 12:02:29 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.210386  data: 0.000266  max mem: 3586
I20250120 12:02:31 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210697  data: 0.000251  max mem: 3586
I20250120 12:02:33 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210572  data: 0.000253  max mem: 3586
I20250120 12:02:35 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210696  data: 0.000228  max mem: 3586
I20250120 12:02:37 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210709  data: 0.000259  max mem: 3586
I20250120 12:02:39 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210893  data: 0.000271  max mem: 3586
I20250120 12:02:41 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210719  data: 0.000239  max mem: 3586
I20250120 12:02:43 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210193  data: 0.000266  max mem: 3586
I20250120 12:02:46 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210528  data: 0.000263  max mem: 3586
I20250120 12:02:48 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210787  data: 0.000235  max mem: 3586
I20250120 12:02:50 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210312  data: 0.000177  max mem: 3586
I20250120 12:02:51 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205985  data: 0.000157  max mem: 3586
I20250120 12:02:51 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.220761 s / it)
I20250120 12:02:51 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:02:51 3545703 dinov2 linear.py:287] 
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8436, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8558, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8599, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8676, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8718, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8737, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8743, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8721, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8682, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8516, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8460, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8465, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8539, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8641, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8699, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8767, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8789, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8794, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8761, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8713, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8674, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8520, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8530, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8655, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8710, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8744, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8778, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8785, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8714, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8678, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8355, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8056, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8096, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8598, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8716, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8752, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8786, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8727, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8408, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8417, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8319, device='cuda:0')}
I20250120 12:02:51 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8809114694595337}
I20250120 12:02:51 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:02:51 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:02:51 3545703 dinov2 helpers.py:102] Training  [ 2500/12500]  eta: 0:39:46  loss: 24.5653 (26.1095)  lr: 0.0000 (0.0000)  time: 1.923254  data: 0.000431  max mem: 3586
I20250120 12:02:53 3545703 dinov2 helpers.py:102] Training  [ 2510/12500]  eta: 0:39:43  loss: 24.1744 (26.0879)  lr: 0.0000 (0.0000)  time: 1.922509  data: 0.000415  max mem: 3586
I20250120 12:02:56 3545703 dinov2 helpers.py:102] Training  [ 2520/12500]  eta: 0:39:41  loss: 24.1744 (26.1004)  lr: 0.0000 (0.0000)  time: 0.229879  data: 0.027453  max mem: 3586
I20250120 12:02:58 3545703 dinov2 helpers.py:102] Training  [ 2530/12500]  eta: 0:39:37  loss: 24.1744 (26.0800)  lr: 0.0000 (0.0000)  time: 0.230369  data: 0.027452  max mem: 3586
I20250120 12:03:00 3545703 dinov2 helpers.py:102] Training  [ 2540/12500]  eta: 0:39:33  loss: 24.1744 (26.0498)  lr: 0.0000 (0.0000)  time: 0.207000  data: 0.000430  max mem: 3586
I20250120 12:03:02 3545703 dinov2 helpers.py:102] Training  [ 2550/12500]  eta: 0:39:30  loss: 24.1744 (26.0475)  lr: 0.0000 (0.0000)  time: 0.206666  data: 0.000448  max mem: 3586
I20250120 12:03:04 3545703 dinov2 helpers.py:102] Training  [ 2560/12500]  eta: 0:39:26  loss: 24.1744 (26.0233)  lr: 0.0000 (0.0000)  time: 0.206616  data: 0.000452  max mem: 3586
I20250120 12:03:06 3545703 dinov2 helpers.py:102] Training  [ 2570/12500]  eta: 0:39:23  loss: 23.4485 (26.0068)  lr: 0.0000 (0.0000)  time: 0.206808  data: 0.000443  max mem: 3586
I20250120 12:03:08 3545703 dinov2 helpers.py:102] Training  [ 2580/12500]  eta: 0:39:19  loss: 23.4485 (26.0067)  lr: 0.0000 (0.0000)  time: 0.206736  data: 0.000427  max mem: 3586
I20250120 12:03:10 3545703 dinov2 helpers.py:102] Training  [ 2590/12500]  eta: 0:39:15  loss: 22.7216 (25.9684)  lr: 0.0000 (0.0000)  time: 0.206737  data: 0.000443  max mem: 3586
I20250120 12:03:12 3545703 dinov2 helpers.py:102] Training  [ 2600/12500]  eta: 0:39:12  loss: 22.7216 (25.9626)  lr: 0.0000 (0.0000)  time: 0.206863  data: 0.000432  max mem: 3586
I20250120 12:03:14 3545703 dinov2 helpers.py:102] Training  [ 2610/12500]  eta: 0:39:08  loss: 23.4485 (25.9598)  lr: 0.0000 (0.0000)  time: 0.206914  data: 0.000429  max mem: 3586
I20250120 12:03:16 3545703 dinov2 helpers.py:102] Training  [ 2620/12500]  eta: 0:39:05  loss: 23.4485 (25.9529)  lr: 0.0000 (0.0000)  time: 0.206852  data: 0.000417  max mem: 3586
I20250120 12:03:18 3545703 dinov2 helpers.py:102] Training  [ 2630/12500]  eta: 0:39:01  loss: 22.7216 (25.9295)  lr: 0.0000 (0.0000)  time: 0.206997  data: 0.000370  max mem: 3586
I20250120 12:03:20 3545703 dinov2 helpers.py:102] Training  [ 2640/12500]  eta: 0:38:58  loss: 23.4485 (25.9225)  lr: 0.0000 (0.0000)  time: 0.207072  data: 0.000426  max mem: 3586
I20250120 12:03:23 3545703 dinov2 helpers.py:102] Training  [ 2650/12500]  eta: 0:38:54  loss: 23.4485 (25.8954)  lr: 0.0000 (0.0000)  time: 0.207184  data: 0.000455  max mem: 3586
I20250120 12:03:25 3545703 dinov2 helpers.py:102] Training  [ 2660/12500]  eta: 0:38:51  loss: 23.4485 (25.8820)  lr: 0.0000 (0.0000)  time: 0.207423  data: 0.000438  max mem: 3586
I20250120 12:03:27 3545703 dinov2 helpers.py:102] Training  [ 2670/12500]  eta: 0:38:47  loss: 23.4454 (25.8729)  lr: 0.0000 (0.0000)  time: 0.207443  data: 0.000453  max mem: 3586
I20250120 12:03:29 3545703 dinov2 helpers.py:102] Training  [ 2680/12500]  eta: 0:38:44  loss: 22.9060 (25.8619)  lr: 0.0000 (0.0000)  time: 0.207392  data: 0.000422  max mem: 3586
I20250120 12:03:31 3545703 dinov2 helpers.py:102] Training  [ 2690/12500]  eta: 0:38:41  loss: 22.9060 (25.8548)  lr: 0.0000 (0.0000)  time: 0.207356  data: 0.000392  max mem: 3586
I20250120 12:03:33 3545703 dinov2 helpers.py:102] Training  [ 2700/12500]  eta: 0:38:37  loss: 22.9060 (25.8475)  lr: 0.0000 (0.0000)  time: 0.207258  data: 0.000431  max mem: 3586
I20250120 12:03:35 3545703 dinov2 helpers.py:102] Training  [ 2710/12500]  eta: 0:38:34  loss: 23.4454 (25.8445)  lr: 0.0000 (0.0000)  time: 0.207199  data: 0.000494  max mem: 3586
I20250120 12:03:37 3545703 dinov2 helpers.py:102] Training  [ 2720/12500]  eta: 0:38:30  loss: 22.9060 (25.8240)  lr: 0.0000 (0.0000)  time: 0.207359  data: 0.000461  max mem: 3586
I20250120 12:03:39 3545703 dinov2 helpers.py:102] Training  [ 2730/12500]  eta: 0:38:27  loss: 23.2998 (25.8148)  lr: 0.0000 (0.0000)  time: 0.207567  data: 0.000450  max mem: 3586
I20250120 12:03:41 3545703 dinov2 helpers.py:102] Training  [ 2740/12500]  eta: 0:38:24  loss: 23.4454 (25.8258)  lr: 0.0000 (0.0000)  time: 0.207606  data: 0.000492  max mem: 3586
I20250120 12:03:43 3545703 dinov2 helpers.py:102] Training  [ 2750/12500]  eta: 0:38:20  loss: 23.4454 (25.8195)  lr: 0.0000 (0.0000)  time: 0.207527  data: 0.000490  max mem: 3586
I20250120 12:03:45 3545703 dinov2 helpers.py:102] Training  [ 2760/12500]  eta: 0:38:17  loss: 23.4454 (25.8063)  lr: 0.0000 (0.0000)  time: 0.207493  data: 0.000474  max mem: 3586
I20250120 12:03:47 3545703 dinov2 helpers.py:102] Training  [ 2770/12500]  eta: 0:38:13  loss: 23.8869 (25.8034)  lr: 0.0000 (0.0000)  time: 0.207557  data: 0.000476  max mem: 3586
I20250120 12:03:49 3545703 dinov2 helpers.py:102] Training  [ 2780/12500]  eta: 0:38:10  loss: 23.8869 (25.8001)  lr: 0.0000 (0.0000)  time: 0.207728  data: 0.000508  max mem: 3586
I20250120 12:03:52 3545703 dinov2 helpers.py:102] Training  [ 2790/12500]  eta: 0:38:07  loss: 23.9545 (25.8102)  lr: 0.0000 (0.0000)  time: 0.207845  data: 0.000512  max mem: 3586
I20250120 12:03:54 3545703 dinov2 helpers.py:102] Training  [ 2800/12500]  eta: 0:38:04  loss: 23.8869 (25.7938)  lr: 0.0000 (0.0000)  time: 0.208009  data: 0.000502  max mem: 3586
I20250120 12:03:56 3545703 dinov2 helpers.py:102] Training  [ 2810/12500]  eta: 0:38:00  loss: 23.4454 (25.7745)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000457  max mem: 3586
I20250120 12:03:58 3545703 dinov2 helpers.py:102] Training  [ 2820/12500]  eta: 0:37:57  loss: 23.4454 (25.8149)  lr: 0.0000 (0.0000)  time: 0.208234  data: 0.000368  max mem: 3586
I20250120 12:04:00 3545703 dinov2 helpers.py:102] Training  [ 2830/12500]  eta: 0:37:54  loss: 23.4454 (25.7879)  lr: 0.0000 (0.0000)  time: 0.208068  data: 0.000395  max mem: 3586
I20250120 12:04:02 3545703 dinov2 helpers.py:102] Training  [ 2840/12500]  eta: 0:37:50  loss: 23.4454 (25.7810)  lr: 0.0000 (0.0000)  time: 0.207802  data: 0.000429  max mem: 3586
I20250120 12:04:04 3545703 dinov2 helpers.py:102] Training  [ 2850/12500]  eta: 0:37:47  loss: 23.8316 (25.7854)  lr: 0.0000 (0.0000)  time: 0.207636  data: 0.000432  max mem: 3586
I20250120 12:04:09 3545703 dinov2 helpers.py:102] Training  [ 2860/12500]  eta: 0:37:53  loss: 23.8869 (25.7947)  lr: 0.0000 (0.0000)  time: 0.349924  data: 0.146957  max mem: 3586
I20250120 12:04:13 3545703 dinov2 helpers.py:102] Training  [ 2870/12500]  eta: 0:37:55  loss: 23.8869 (25.7871)  lr: 0.0000 (0.0000)  time: 0.430342  data: 0.232351  max mem: 3586
I20250120 12:04:15 3545703 dinov2 helpers.py:102] Training  [ 2880/12500]  eta: 0:37:52  loss: 23.9545 (25.7871)  lr: 0.0000 (0.0000)  time: 0.287214  data: 0.086120  max mem: 3586
I20250120 12:04:17 3545703 dinov2 helpers.py:102] Training  [ 2890/12500]  eta: 0:37:49  loss: 23.8869 (25.7801)  lr: 0.0000 (0.0000)  time: 0.206120  data: 0.000738  max mem: 3586
I20250120 12:04:19 3545703 dinov2 helpers.py:102] Training  [ 2900/12500]  eta: 0:37:45  loss: 23.8316 (25.7715)  lr: 0.0000 (0.0000)  time: 0.206457  data: 0.000461  max mem: 3586
I20250120 12:04:21 3545703 dinov2 helpers.py:102] Training  [ 2910/12500]  eta: 0:37:42  loss: 23.8316 (25.7872)  lr: 0.0000 (0.0000)  time: 0.206769  data: 0.000457  max mem: 3586
I20250120 12:04:23 3545703 dinov2 helpers.py:102] Training  [ 2920/12500]  eta: 0:37:39  loss: 23.8316 (25.7758)  lr: 0.0000 (0.0000)  time: 0.206936  data: 0.000517  max mem: 3586
I20250120 12:04:25 3545703 dinov2 helpers.py:102] Training  [ 2930/12500]  eta: 0:37:35  loss: 24.0736 (25.7895)  lr: 0.0000 (0.0000)  time: 0.207176  data: 0.000485  max mem: 3586
I20250120 12:04:27 3545703 dinov2 helpers.py:102] Training  [ 2940/12500]  eta: 0:37:32  loss: 24.0736 (25.7849)  lr: 0.0000 (0.0000)  time: 0.207682  data: 0.000413  max mem: 3586
I20250120 12:04:29 3545703 dinov2 helpers.py:102] Training  [ 2950/12500]  eta: 0:37:29  loss: 24.4238 (25.7823)  lr: 0.0000 (0.0000)  time: 0.207807  data: 0.000413  max mem: 3586
I20250120 12:04:31 3545703 dinov2 helpers.py:102] Training  [ 2960/12500]  eta: 0:37:26  loss: 24.4238 (25.7575)  lr: 0.0000 (0.0000)  time: 0.207766  data: 0.000418  max mem: 3586
I20250120 12:04:33 3545703 dinov2 helpers.py:102] Training  [ 2970/12500]  eta: 0:37:22  loss: 23.8316 (25.7426)  lr: 0.0000 (0.0000)  time: 0.207788  data: 0.000438  max mem: 3586
I20250120 12:04:35 3545703 dinov2 helpers.py:102] Training  [ 2980/12500]  eta: 0:37:19  loss: 23.8316 (25.7633)  lr: 0.0000 (0.0000)  time: 0.207971  data: 0.000455  max mem: 3586
I20250120 12:04:38 3545703 dinov2 helpers.py:102] Training  [ 2990/12500]  eta: 0:37:16  loss: 23.8316 (25.7683)  lr: 0.0000 (0.0000)  time: 0.208356  data: 0.000475  max mem: 3586
I20250120 12:04:40 3545703 dinov2 helpers.py:102] Training  [ 3000/12500]  eta: 0:37:13  loss: 24.3605 (25.7636)  lr: 0.0000 (0.0000)  time: 0.208474  data: 0.000483  max mem: 3586
I20250120 12:04:42 3545703 dinov2 helpers.py:102] Training  [ 3010/12500]  eta: 0:37:10  loss: 24.3605 (25.7543)  lr: 0.0000 (0.0000)  time: 0.208570  data: 0.000464  max mem: 3586
I20250120 12:04:44 3545703 dinov2 helpers.py:102] Training  [ 3020/12500]  eta: 0:37:07  loss: 24.3605 (25.7541)  lr: 0.0000 (0.0000)  time: 0.208822  data: 0.000486  max mem: 3586
I20250120 12:04:46 3545703 dinov2 helpers.py:102] Training  [ 3030/12500]  eta: 0:37:03  loss: 24.3605 (25.7449)  lr: 0.0000 (0.0000)  time: 0.209026  data: 0.000463  max mem: 3586
I20250120 12:04:48 3545703 dinov2 helpers.py:102] Training  [ 3040/12500]  eta: 0:37:00  loss: 24.3605 (25.7308)  lr: 0.0000 (0.0000)  time: 0.209131  data: 0.000431  max mem: 3586
I20250120 12:04:50 3545703 dinov2 helpers.py:102] Training  [ 3050/12500]  eta: 0:36:57  loss: 24.3605 (25.7467)  lr: 0.0000 (0.0000)  time: 0.209106  data: 0.000446  max mem: 3586
I20250120 12:04:52 3545703 dinov2 helpers.py:102] Training  [ 3060/12500]  eta: 0:36:54  loss: 24.3605 (25.7571)  lr: 0.0000 (0.0000)  time: 0.209114  data: 0.000466  max mem: 3586
I20250120 12:04:54 3545703 dinov2 helpers.py:102] Training  [ 3070/12500]  eta: 0:36:51  loss: 24.4238 (25.7597)  lr: 0.0000 (0.0000)  time: 0.209224  data: 0.000472  max mem: 3586
I20250120 12:04:56 3545703 dinov2 helpers.py:102] Training  [ 3080/12500]  eta: 0:36:48  loss: 24.4238 (25.7622)  lr: 0.0000 (0.0000)  time: 0.209267  data: 0.000410  max mem: 3586
I20250120 12:04:58 3545703 dinov2 helpers.py:102] Training  [ 3090/12500]  eta: 0:36:45  loss: 24.4238 (25.7391)  lr: 0.0000 (0.0000)  time: 0.209229  data: 0.000400  max mem: 3586
I20250120 12:05:01 3545703 dinov2 helpers.py:102] Training  [ 3100/12500]  eta: 0:36:41  loss: 24.4238 (25.7321)  lr: 0.0000 (0.0000)  time: 0.209364  data: 0.000416  max mem: 3586
I20250120 12:05:03 3545703 dinov2 helpers.py:102] Training  [ 3110/12500]  eta: 0:36:38  loss: 24.3605 (25.7194)  lr: 0.0000 (0.0000)  time: 0.209396  data: 0.000420  max mem: 3586
I20250120 12:05:05 3545703 dinov2 helpers.py:102] Training  [ 3120/12500]  eta: 0:36:35  loss: 24.3605 (25.7087)  lr: 0.0000 (0.0000)  time: 0.209153  data: 0.000459  max mem: 3586
I20250120 12:05:07 3545703 dinov2 helpers.py:102] Training  [ 3130/12500]  eta: 0:36:32  loss: 23.5872 (25.6956)  lr: 0.0000 (0.0000)  time: 0.209105  data: 0.000467  max mem: 3586
I20250120 12:05:09 3545703 dinov2 helpers.py:102] Training  [ 3140/12500]  eta: 0:36:29  loss: 23.5872 (25.7177)  lr: 0.0000 (0.0000)  time: 0.209219  data: 0.000441  max mem: 3586
I20250120 12:05:11 3545703 dinov2 helpers.py:102] Training  [ 3150/12500]  eta: 0:36:26  loss: 22.9678 (25.6929)  lr: 0.0000 (0.0000)  time: 0.209224  data: 0.000427  max mem: 3586
I20250120 12:05:13 3545703 dinov2 helpers.py:102] Training  [ 3160/12500]  eta: 0:36:23  loss: 23.5872 (25.6880)  lr: 0.0000 (0.0000)  time: 0.209189  data: 0.000412  max mem: 3586
I20250120 12:05:15 3545703 dinov2 helpers.py:102] Training  [ 3170/12500]  eta: 0:36:20  loss: 23.5872 (25.6738)  lr: 0.0000 (0.0000)  time: 0.209312  data: 0.000417  max mem: 3586
I20250120 12:05:17 3545703 dinov2 helpers.py:102] Training  [ 3180/12500]  eta: 0:36:17  loss: 22.9678 (25.6578)  lr: 0.0000 (0.0000)  time: 0.209426  data: 0.000453  max mem: 3586
I20250120 12:05:19 3545703 dinov2 helpers.py:102] Training  [ 3190/12500]  eta: 0:36:14  loss: 22.9678 (25.6541)  lr: 0.0000 (0.0000)  time: 0.209416  data: 0.000464  max mem: 3586
I20250120 12:05:21 3545703 dinov2 helpers.py:102] Training  [ 3200/12500]  eta: 0:36:11  loss: 22.9678 (25.6481)  lr: 0.0000 (0.0000)  time: 0.209556  data: 0.000444  max mem: 3586
I20250120 12:05:24 3545703 dinov2 helpers.py:102] Training  [ 3210/12500]  eta: 0:36:08  loss: 22.9678 (25.6377)  lr: 0.0000 (0.0000)  time: 0.209623  data: 0.000440  max mem: 3586
I20250120 12:05:26 3545703 dinov2 helpers.py:102] Training  [ 3220/12500]  eta: 0:36:05  loss: 22.3455 (25.6229)  lr: 0.0000 (0.0000)  time: 0.209558  data: 0.000452  max mem: 3586
I20250120 12:05:28 3545703 dinov2 helpers.py:102] Training  [ 3230/12500]  eta: 0:36:02  loss: 22.3455 (25.6316)  lr: 0.0000 (0.0000)  time: 0.209556  data: 0.000470  max mem: 3586
I20250120 12:05:30 3545703 dinov2 helpers.py:102] Training  [ 3240/12500]  eta: 0:35:59  loss: 23.5010 (25.6250)  lr: 0.0000 (0.0000)  time: 0.209512  data: 0.000494  max mem: 3586
I20250120 12:05:32 3545703 dinov2 helpers.py:102] Training  [ 3250/12500]  eta: 0:35:56  loss: 22.3455 (25.6141)  lr: 0.0000 (0.0000)  time: 0.209524  data: 0.000496  max mem: 3586
I20250120 12:05:34 3545703 dinov2 helpers.py:102] Training  [ 3260/12500]  eta: 0:35:53  loss: 22.3455 (25.6095)  lr: 0.0000 (0.0000)  time: 0.209604  data: 0.000478  max mem: 3586
I20250120 12:05:36 3545703 dinov2 helpers.py:102] Training  [ 3270/12500]  eta: 0:35:50  loss: 22.3064 (25.5977)  lr: 0.0000 (0.0000)  time: 0.209753  data: 0.000527  max mem: 3586
I20250120 12:05:38 3545703 dinov2 helpers.py:102] Training  [ 3280/12500]  eta: 0:35:47  loss: 22.3064 (25.5889)  lr: 0.0000 (0.0000)  time: 0.209871  data: 0.000566  max mem: 3586
I20250120 12:05:40 3545703 dinov2 helpers.py:102] Training  [ 3290/12500]  eta: 0:35:44  loss: 22.3455 (25.5895)  lr: 0.0000 (0.0000)  time: 0.209869  data: 0.000449  max mem: 3586
I20250120 12:05:42 3545703 dinov2 helpers.py:102] Training  [ 3300/12500]  eta: 0:35:41  loss: 22.3064 (25.5670)  lr: 0.0000 (0.0000)  time: 0.209875  data: 0.000347  max mem: 3586
I20250120 12:05:45 3545703 dinov2 helpers.py:102] Training  [ 3310/12500]  eta: 0:35:38  loss: 22.3064 (25.5409)  lr: 0.0000 (0.0000)  time: 0.209905  data: 0.000393  max mem: 3586
I20250120 12:05:47 3545703 dinov2 helpers.py:102] Training  [ 3320/12500]  eta: 0:35:35  loss: 22.0670 (25.5285)  lr: 0.0000 (0.0000)  time: 0.209944  data: 0.000419  max mem: 3586
I20250120 12:05:49 3545703 dinov2 helpers.py:102] Training  [ 3330/12500]  eta: 0:35:32  loss: 22.0670 (25.5142)  lr: 0.0000 (0.0000)  time: 0.209833  data: 0.000407  max mem: 3586
I20250120 12:05:51 3545703 dinov2 helpers.py:102] Training  [ 3340/12500]  eta: 0:35:29  loss: 22.0670 (25.5187)  lr: 0.0000 (0.0000)  time: 0.209744  data: 0.000456  max mem: 3586
I20250120 12:05:53 3545703 dinov2 helpers.py:102] Training  [ 3350/12500]  eta: 0:35:26  loss: 22.3064 (25.5145)  lr: 0.0000 (0.0000)  time: 0.209734  data: 0.000477  max mem: 3586
I20250120 12:05:55 3545703 dinov2 helpers.py:102] Training  [ 3360/12500]  eta: 0:35:23  loss: 22.3064 (25.5082)  lr: 0.0000 (0.0000)  time: 0.209650  data: 0.000448  max mem: 3586
I20250120 12:05:57 3545703 dinov2 helpers.py:102] Training  [ 3370/12500]  eta: 0:35:20  loss: 22.6894 (25.5100)  lr: 0.0000 (0.0000)  time: 0.209723  data: 0.000437  max mem: 3586
I20250120 12:05:59 3545703 dinov2 helpers.py:102] Training  [ 3380/12500]  eta: 0:35:17  loss: 23.3816 (25.5063)  lr: 0.0000 (0.0000)  time: 0.209649  data: 0.000476  max mem: 3586
I20250120 12:06:01 3545703 dinov2 helpers.py:102] Training  [ 3390/12500]  eta: 0:35:14  loss: 22.6894 (25.4841)  lr: 0.0000 (0.0000)  time: 0.209633  data: 0.000500  max mem: 3586
I20250120 12:06:03 3545703 dinov2 helpers.py:102] Training  [ 3400/12500]  eta: 0:35:11  loss: 22.3064 (25.4604)  lr: 0.0000 (0.0000)  time: 0.209688  data: 0.000458  max mem: 3586
I20250120 12:06:06 3545703 dinov2 helpers.py:102] Training  [ 3410/12500]  eta: 0:35:08  loss: 22.0670 (25.4493)  lr: 0.0000 (0.0000)  time: 0.209680  data: 0.000419  max mem: 3586
I20250120 12:06:08 3545703 dinov2 helpers.py:102] Training  [ 3420/12500]  eta: 0:35:06  loss: 22.1515 (25.4396)  lr: 0.0000 (0.0000)  time: 0.209691  data: 0.000432  max mem: 3586
I20250120 12:06:10 3545703 dinov2 helpers.py:102] Training  [ 3430/12500]  eta: 0:35:03  loss: 22.0670 (25.4199)  lr: 0.0000 (0.0000)  time: 0.209760  data: 0.000447  max mem: 3586
I20250120 12:06:12 3545703 dinov2 helpers.py:102] Training  [ 3440/12500]  eta: 0:35:00  loss: 22.0670 (25.4269)  lr: 0.0000 (0.0000)  time: 0.209930  data: 0.000423  max mem: 3586
I20250120 12:06:14 3545703 dinov2 helpers.py:102] Training  [ 3450/12500]  eta: 0:34:57  loss: 22.1515 (25.4307)  lr: 0.0000 (0.0000)  time: 0.209948  data: 0.000439  max mem: 3586
I20250120 12:06:16 3545703 dinov2 helpers.py:102] Training  [ 3460/12500]  eta: 0:34:54  loss: 22.1515 (25.4226)  lr: 0.0000 (0.0000)  time: 0.209968  data: 0.000472  max mem: 3586
I20250120 12:06:18 3545703 dinov2 helpers.py:102] Training  [ 3470/12500]  eta: 0:34:51  loss: 22.1515 (25.4130)  lr: 0.0000 (0.0000)  time: 0.209960  data: 0.000441  max mem: 3586
I20250120 12:06:20 3545703 dinov2 helpers.py:102] Training  [ 3480/12500]  eta: 0:34:48  loss: 22.0608 (25.4010)  lr: 0.0000 (0.0000)  time: 0.209762  data: 0.000407  max mem: 3586
I20250120 12:06:22 3545703 dinov2 helpers.py:102] Training  [ 3490/12500]  eta: 0:34:45  loss: 22.0608 (25.3972)  lr: 0.0000 (0.0000)  time: 0.209737  data: 0.000430  max mem: 3586
I20250120 12:06:24 3545703 dinov2 helpers.py:102] Training  [ 3500/12500]  eta: 0:34:42  loss: 22.0608 (25.3862)  lr: 0.0000 (0.0000)  time: 0.209684  data: 0.000472  max mem: 3586
I20250120 12:06:27 3545703 dinov2 helpers.py:102] Training  [ 3510/12500]  eta: 0:34:40  loss: 22.1515 (25.3809)  lr: 0.0000 (0.0000)  time: 0.209616  data: 0.000427  max mem: 3586
I20250120 12:06:29 3545703 dinov2 helpers.py:102] Training  [ 3520/12500]  eta: 0:34:37  loss: 22.6471 (25.3736)  lr: 0.0000 (0.0000)  time: 0.209677  data: 0.000434  max mem: 3586
I20250120 12:06:31 3545703 dinov2 helpers.py:102] Training  [ 3530/12500]  eta: 0:34:34  loss: 22.7934 (25.3860)  lr: 0.0000 (0.0000)  time: 0.209729  data: 0.000468  max mem: 3586
I20250120 12:06:33 3545703 dinov2 helpers.py:102] Training  [ 3540/12500]  eta: 0:34:31  loss: 22.6471 (25.3780)  lr: 0.0000 (0.0000)  time: 0.209801  data: 0.000448  max mem: 3586
I20250120 12:06:35 3545703 dinov2 helpers.py:102] Training  [ 3550/12500]  eta: 0:34:28  loss: 22.5368 (25.3648)  lr: 0.0000 (0.0000)  time: 0.209734  data: 0.000459  max mem: 3586
I20250120 12:06:37 3545703 dinov2 helpers.py:102] Training  [ 3560/12500]  eta: 0:34:25  loss: 22.5368 (25.3652)  lr: 0.0000 (0.0000)  time: 0.209681  data: 0.000474  max mem: 3586
I20250120 12:06:39 3545703 dinov2 helpers.py:102] Training  [ 3570/12500]  eta: 0:34:22  loss: 22.5368 (25.3591)  lr: 0.0000 (0.0000)  time: 0.209789  data: 0.000452  max mem: 3586
I20250120 12:06:41 3545703 dinov2 helpers.py:102] Training  [ 3580/12500]  eta: 0:34:20  loss: 22.1515 (25.3371)  lr: 0.0000 (0.0000)  time: 0.209820  data: 0.000433  max mem: 3586
I20250120 12:06:43 3545703 dinov2 helpers.py:102] Training  [ 3590/12500]  eta: 0:34:17  loss: 22.2882 (25.3286)  lr: 0.0000 (0.0000)  time: 0.209771  data: 0.000420  max mem: 3586
I20250120 12:06:45 3545703 dinov2 helpers.py:102] Training  [ 3600/12500]  eta: 0:34:14  loss: 22.5368 (25.3274)  lr: 0.0000 (0.0000)  time: 0.209769  data: 0.000429  max mem: 3586
I20250120 12:06:48 3545703 dinov2 helpers.py:102] Training  [ 3610/12500]  eta: 0:34:11  loss: 22.6471 (25.3250)  lr: 0.0000 (0.0000)  time: 0.209879  data: 0.000422  max mem: 3586
I20250120 12:06:50 3545703 dinov2 helpers.py:102] Training  [ 3620/12500]  eta: 0:34:08  loss: 22.7934 (25.3198)  lr: 0.0000 (0.0000)  time: 0.209976  data: 0.000428  max mem: 3586
I20250120 12:06:52 3545703 dinov2 helpers.py:102] Training  [ 3630/12500]  eta: 0:34:05  loss: 23.1905 (25.3184)  lr: 0.0000 (0.0000)  time: 0.209894  data: 0.000465  max mem: 3586
I20250120 12:06:54 3545703 dinov2 helpers.py:102] Training  [ 3640/12500]  eta: 0:34:03  loss: 23.1905 (25.3239)  lr: 0.0000 (0.0000)  time: 0.209873  data: 0.000483  max mem: 3586
I20250120 12:06:56 3545703 dinov2 helpers.py:102] Training  [ 3650/12500]  eta: 0:34:00  loss: 23.1056 (25.3178)  lr: 0.0000 (0.0000)  time: 0.209985  data: 0.000499  max mem: 3586
I20250120 12:06:58 3545703 dinov2 helpers.py:102] Training  [ 3660/12500]  eta: 0:33:57  loss: 23.1905 (25.3125)  lr: 0.0000 (0.0000)  time: 0.210098  data: 0.000463  max mem: 3586
I20250120 12:07:00 3545703 dinov2 helpers.py:102] Training  [ 3670/12500]  eta: 0:33:54  loss: 23.3936 (25.3204)  lr: 0.0000 (0.0000)  time: 0.210093  data: 0.000425  max mem: 3586
I20250120 12:07:02 3545703 dinov2 helpers.py:102] Training  [ 3680/12500]  eta: 0:33:52  loss: 23.3936 (25.3111)  lr: 0.0000 (0.0000)  time: 0.210244  data: 0.000432  max mem: 3586
I20250120 12:07:04 3545703 dinov2 helpers.py:102] Training  [ 3690/12500]  eta: 0:33:49  loss: 23.3936 (25.3242)  lr: 0.0000 (0.0000)  time: 0.210182  data: 0.000442  max mem: 3586
I20250120 12:07:06 3545703 dinov2 helpers.py:102] Training  [ 3700/12500]  eta: 0:33:46  loss: 23.3936 (25.3148)  lr: 0.0000 (0.0000)  time: 0.210023  data: 0.000429  max mem: 3586
I20250120 12:07:09 3545703 dinov2 helpers.py:102] Training  [ 3710/12500]  eta: 0:33:43  loss: 23.3936 (25.3144)  lr: 0.0000 (0.0000)  time: 0.210116  data: 0.000411  max mem: 3586
I20250120 12:07:11 3545703 dinov2 helpers.py:102] Training  [ 3720/12500]  eta: 0:33:40  loss: 23.3936 (25.2979)  lr: 0.0000 (0.0000)  time: 0.210140  data: 0.000450  max mem: 3586
I20250120 12:07:13 3545703 dinov2 helpers.py:102] Training  [ 3730/12500]  eta: 0:33:38  loss: 23.3936 (25.2988)  lr: 0.0000 (0.0000)  time: 0.210150  data: 0.000442  max mem: 3586
I20250120 12:07:15 3545703 dinov2 helpers.py:102] Training  [ 3740/12500]  eta: 0:33:35  loss: 23.3936 (25.2836)  lr: 0.0000 (0.0000)  time: 0.210310  data: 0.000436  max mem: 3586
I20250120 12:07:17 3545703 dinov2 linear.py:272] running validation !
I20250120 12:07:18 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:58    time: 1.538982  data: 1.331011  max mem: 3586
I20250120 12:07:20 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.332477  data: 0.121799  max mem: 3586
I20250120 12:07:23 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.211674  data: 0.000632  max mem: 3586
I20250120 12:07:25 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.211008  data: 0.000337  max mem: 3586
I20250120 12:07:27 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210657  data: 0.000255  max mem: 3586
I20250120 12:07:29 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.210686  data: 0.000259  max mem: 3586
I20250120 12:07:31 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210474  data: 0.000285  max mem: 3586
I20250120 12:07:33 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210944  data: 0.000246  max mem: 3586
I20250120 12:07:35 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.211515  data: 0.000227  max mem: 3586
I20250120 12:07:37 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.211087  data: 0.000233  max mem: 3586
I20250120 12:07:39 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210911  data: 0.000254  max mem: 3586
I20250120 12:07:41 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210843  data: 0.000270  max mem: 3586
I20250120 12:07:44 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210587  data: 0.000278  max mem: 3586
I20250120 12:07:46 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210716  data: 0.000285  max mem: 3586
I20250120 12:07:48 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210795  data: 0.000240  max mem: 3586
I20250120 12:07:50 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.210363  data: 0.000165  max mem: 3586
I20250120 12:07:51 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205996  data: 0.000150  max mem: 3586
I20250120 12:07:51 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.219838 s / it)
I20250120 12:07:51 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:07:51 3545703 dinov2 linear.py:287] 
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8499, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8595, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8633, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8698, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8744, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8746, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8705, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8623, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8494, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8433, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8517, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8582, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8720, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8757, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8786, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8797, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8748, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8572, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8728, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8388, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8583, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8685, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8777, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8773, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8739, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8607, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8619, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8585, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8574, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8625, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8694, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8737, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8796, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8782, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8657, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8781, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8664, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8560, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8577, device='cuda:0')}
I20250120 12:07:51 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00100', 'accuracy': 0.8797494173049927}
I20250120 12:07:51 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:07:51 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:07:51 3545703 dinov2 helpers.py:102] Training  [ 3750/12500]  eta: 0:34:52  loss: 23.3936 (25.2505)  lr: 0.0000 (0.0000)  time: 1.918873  data: 0.000478  max mem: 3586
I20250120 12:07:53 3545703 dinov2 helpers.py:102] Training  [ 3760/12500]  eta: 0:34:49  loss: 23.3936 (25.2769)  lr: 0.0000 (0.0000)  time: 1.916689  data: 0.000459  max mem: 3586
I20250120 12:07:55 3545703 dinov2 helpers.py:102] Training  [ 3770/12500]  eta: 0:34:46  loss: 23.3936 (25.2585)  lr: 0.0000 (0.0000)  time: 0.206942  data: 0.000417  max mem: 3586
I20250120 12:07:57 3545703 dinov2 helpers.py:102] Training  [ 3780/12500]  eta: 0:34:42  loss: 23.3936 (25.2469)  lr: 0.0000 (0.0000)  time: 0.207781  data: 0.000455  max mem: 3586
I20250120 12:08:00 3545703 dinov2 helpers.py:102] Training  [ 3790/12500]  eta: 0:34:40  loss: 23.4509 (25.2493)  lr: 0.0000 (0.0000)  time: 0.231506  data: 0.027667  max mem: 3586
I20250120 12:08:02 3545703 dinov2 helpers.py:102] Training  [ 3800/12500]  eta: 0:34:37  loss: 23.3936 (25.2406)  lr: 0.0000 (0.0000)  time: 0.231338  data: 0.027632  max mem: 3586
I20250120 12:08:04 3545703 dinov2 helpers.py:102] Training  [ 3810/12500]  eta: 0:34:34  loss: 23.1056 (25.2265)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000454  max mem: 3586
I20250120 12:08:06 3545703 dinov2 helpers.py:102] Training  [ 3820/12500]  eta: 0:34:31  loss: 21.9118 (25.2129)  lr: 0.0000 (0.0000)  time: 0.207323  data: 0.000453  max mem: 3586
I20250120 12:08:08 3545703 dinov2 helpers.py:102] Training  [ 3830/12500]  eta: 0:34:28  loss: 21.8780 (25.1982)  lr: 0.0000 (0.0000)  time: 0.207428  data: 0.000451  max mem: 3586
I20250120 12:08:10 3545703 dinov2 helpers.py:102] Training  [ 3840/12500]  eta: 0:34:25  loss: 21.8780 (25.1909)  lr: 0.0000 (0.0000)  time: 0.207617  data: 0.000428  max mem: 3586
I20250120 12:08:12 3545703 dinov2 helpers.py:102] Training  [ 3850/12500]  eta: 0:34:22  loss: 21.8780 (25.1999)  lr: 0.0000 (0.0000)  time: 0.207700  data: 0.000414  max mem: 3586
I20250120 12:08:14 3545703 dinov2 helpers.py:102] Training  [ 3860/12500]  eta: 0:34:19  loss: 21.8780 (25.1956)  lr: 0.0000 (0.0000)  time: 0.207697  data: 0.000400  max mem: 3586
I20250120 12:08:16 3545703 dinov2 helpers.py:102] Training  [ 3870/12500]  eta: 0:34:16  loss: 21.8780 (25.1914)  lr: 0.0000 (0.0000)  time: 0.207535  data: 0.000410  max mem: 3586
I20250120 12:08:19 3545703 dinov2 helpers.py:102] Training  [ 3880/12500]  eta: 0:34:13  loss: 21.8237 (25.1736)  lr: 0.0000 (0.0000)  time: 0.207611  data: 0.000445  max mem: 3586
I20250120 12:08:21 3545703 dinov2 helpers.py:102] Training  [ 3890/12500]  eta: 0:34:10  loss: 21.8237 (25.1666)  lr: 0.0000 (0.0000)  time: 0.207779  data: 0.000479  max mem: 3586
I20250120 12:08:23 3545703 dinov2 helpers.py:102] Training  [ 3900/12500]  eta: 0:34:07  loss: 21.9118 (25.1636)  lr: 0.0000 (0.0000)  time: 0.207729  data: 0.000450  max mem: 3586
I20250120 12:08:25 3545703 dinov2 helpers.py:102] Training  [ 3910/12500]  eta: 0:34:03  loss: 20.8665 (25.1525)  lr: 0.0000 (0.0000)  time: 0.207683  data: 0.000405  max mem: 3586
I20250120 12:08:27 3545703 dinov2 helpers.py:102] Training  [ 3920/12500]  eta: 0:34:00  loss: 21.9118 (25.1566)  lr: 0.0000 (0.0000)  time: 0.207749  data: 0.000358  max mem: 3586
I20250120 12:08:29 3545703 dinov2 helpers.py:102] Training  [ 3930/12500]  eta: 0:33:57  loss: 21.9118 (25.1593)  lr: 0.0000 (0.0000)  time: 0.207666  data: 0.000355  max mem: 3586
I20250120 12:08:31 3545703 dinov2 helpers.py:102] Training  [ 3940/12500]  eta: 0:33:54  loss: 22.1294 (25.1517)  lr: 0.0000 (0.0000)  time: 0.207783  data: 0.000466  max mem: 3586
I20250120 12:08:33 3545703 dinov2 helpers.py:102] Training  [ 3950/12500]  eta: 0:33:51  loss: 22.4063 (25.1561)  lr: 0.0000 (0.0000)  time: 0.207971  data: 0.000447  max mem: 3586
I20250120 12:08:35 3545703 dinov2 helpers.py:102] Training  [ 3960/12500]  eta: 0:33:48  loss: 22.1294 (25.1407)  lr: 0.0000 (0.0000)  time: 0.207905  data: 0.000425  max mem: 3586
I20250120 12:08:37 3545703 dinov2 helpers.py:102] Training  [ 3970/12500]  eta: 0:33:45  loss: 22.4063 (25.1480)  lr: 0.0000 (0.0000)  time: 0.207999  data: 0.000463  max mem: 3586
I20250120 12:08:39 3545703 dinov2 helpers.py:102] Training  [ 3980/12500]  eta: 0:33:42  loss: 22.4384 (25.1594)  lr: 0.0000 (0.0000)  time: 0.207834  data: 0.000452  max mem: 3586
I20250120 12:08:41 3545703 dinov2 helpers.py:102] Training  [ 3990/12500]  eta: 0:33:39  loss: 22.4063 (25.1488)  lr: 0.0000 (0.0000)  time: 0.207704  data: 0.000470  max mem: 3586
I20250120 12:08:44 3545703 dinov2 helpers.py:102] Training  [ 4000/12500]  eta: 0:33:36  loss: 22.4384 (25.1433)  lr: 0.0000 (0.0000)  time: 0.207712  data: 0.000439  max mem: 3586
I20250120 12:08:46 3545703 dinov2 helpers.py:102] Training  [ 4010/12500]  eta: 0:33:33  loss: 22.9567 (25.1457)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000399  max mem: 3586
I20250120 12:08:48 3545703 dinov2 helpers.py:102] Training  [ 4020/12500]  eta: 0:33:30  loss: 22.9567 (25.1389)  lr: 0.0000 (0.0000)  time: 0.207776  data: 0.000416  max mem: 3586
I20250120 12:08:50 3545703 dinov2 helpers.py:102] Training  [ 4030/12500]  eta: 0:33:27  loss: 22.9567 (25.1325)  lr: 0.0000 (0.0000)  time: 0.207980  data: 0.000420  max mem: 3586
I20250120 12:08:52 3545703 dinov2 helpers.py:102] Training  [ 4040/12500]  eta: 0:33:24  loss: 22.9567 (25.1257)  lr: 0.0000 (0.0000)  time: 0.208059  data: 0.000428  max mem: 3586
I20250120 12:08:54 3545703 dinov2 helpers.py:102] Training  [ 4050/12500]  eta: 0:33:21  loss: 22.7262 (25.1198)  lr: 0.0000 (0.0000)  time: 0.207795  data: 0.000439  max mem: 3586
I20250120 12:08:56 3545703 dinov2 helpers.py:102] Training  [ 4060/12500]  eta: 0:33:18  loss: 22.7262 (25.1183)  lr: 0.0000 (0.0000)  time: 0.207516  data: 0.000399  max mem: 3586
I20250120 12:08:58 3545703 dinov2 helpers.py:102] Training  [ 4070/12500]  eta: 0:33:15  loss: 22.7262 (25.1245)  lr: 0.0000 (0.0000)  time: 0.207829  data: 0.000394  max mem: 3586
I20250120 12:09:00 3545703 dinov2 helpers.py:102] Training  [ 4080/12500]  eta: 0:33:12  loss: 22.7262 (25.1132)  lr: 0.0000 (0.0000)  time: 0.207960  data: 0.000423  max mem: 3586
I20250120 12:09:02 3545703 dinov2 helpers.py:102] Training  [ 4090/12500]  eta: 0:33:09  loss: 22.9567 (25.1208)  lr: 0.0000 (0.0000)  time: 0.207910  data: 0.000412  max mem: 3586
I20250120 12:09:04 3545703 dinov2 helpers.py:102] Training  [ 4100/12500]  eta: 0:33:07  loss: 22.9567 (25.1178)  lr: 0.0000 (0.0000)  time: 0.208024  data: 0.000412  max mem: 3586
I20250120 12:09:06 3545703 dinov2 helpers.py:102] Training  [ 4110/12500]  eta: 0:33:04  loss: 23.9036 (25.1189)  lr: 0.0000 (0.0000)  time: 0.207917  data: 0.000407  max mem: 3586
I20250120 12:09:08 3545703 dinov2 helpers.py:102] Training  [ 4120/12500]  eta: 0:33:01  loss: 23.9036 (25.1313)  lr: 0.0000 (0.0000)  time: 0.208045  data: 0.000414  max mem: 3586
I20250120 12:09:11 3545703 dinov2 helpers.py:102] Training  [ 4130/12500]  eta: 0:32:58  loss: 23.9036 (25.1294)  lr: 0.0000 (0.0000)  time: 0.208223  data: 0.000402  max mem: 3586
I20250120 12:09:13 3545703 dinov2 helpers.py:102] Training  [ 4140/12500]  eta: 0:32:55  loss: 24.3452 (25.1288)  lr: 0.0000 (0.0000)  time: 0.207989  data: 0.000384  max mem: 3586
I20250120 12:09:15 3545703 dinov2 helpers.py:102] Training  [ 4150/12500]  eta: 0:32:52  loss: 23.9036 (25.1235)  lr: 0.0000 (0.0000)  time: 0.207963  data: 0.000408  max mem: 3586
I20250120 12:09:17 3545703 dinov2 helpers.py:102] Training  [ 4160/12500]  eta: 0:32:49  loss: 24.3452 (25.1376)  lr: 0.0000 (0.0000)  time: 0.207927  data: 0.000404  max mem: 3586
I20250120 12:09:19 3545703 dinov2 helpers.py:102] Training  [ 4170/12500]  eta: 0:32:46  loss: 24.3452 (25.1389)  lr: 0.0000 (0.0000)  time: 0.208023  data: 0.000450  max mem: 3586
I20250120 12:09:21 3545703 dinov2 helpers.py:102] Training  [ 4180/12500]  eta: 0:32:43  loss: 23.9036 (25.1265)  lr: 0.0000 (0.0000)  time: 0.208032  data: 0.000425  max mem: 3586
I20250120 12:09:23 3545703 dinov2 helpers.py:102] Training  [ 4190/12500]  eta: 0:32:40  loss: 23.9036 (25.1114)  lr: 0.0000 (0.0000)  time: 0.208030  data: 0.000416  max mem: 3586
I20250120 12:09:25 3545703 dinov2 helpers.py:102] Training  [ 4200/12500]  eta: 0:32:37  loss: 23.9036 (25.1025)  lr: 0.0000 (0.0000)  time: 0.208014  data: 0.000482  max mem: 3586
I20250120 12:09:27 3545703 dinov2 helpers.py:102] Training  [ 4210/12500]  eta: 0:32:34  loss: 22.9997 (25.0975)  lr: 0.0000 (0.0000)  time: 0.207953  data: 0.000473  max mem: 3586
I20250120 12:09:29 3545703 dinov2 helpers.py:102] Training  [ 4220/12500]  eta: 0:32:31  loss: 22.9997 (25.0904)  lr: 0.0000 (0.0000)  time: 0.208070  data: 0.000469  max mem: 3586
I20250120 12:09:31 3545703 dinov2 helpers.py:102] Training  [ 4230/12500]  eta: 0:32:29  loss: 23.9036 (25.0884)  lr: 0.0000 (0.0000)  time: 0.208076  data: 0.000406  max mem: 3586
I20250120 12:09:33 3545703 dinov2 helpers.py:102] Training  [ 4240/12500]  eta: 0:32:26  loss: 23.9036 (25.0822)  lr: 0.0000 (0.0000)  time: 0.208106  data: 0.000366  max mem: 3586
I20250120 12:09:36 3545703 dinov2 helpers.py:102] Training  [ 4250/12500]  eta: 0:32:23  loss: 23.9036 (25.0763)  lr: 0.0000 (0.0000)  time: 0.207997  data: 0.000396  max mem: 3586
I20250120 12:09:38 3545703 dinov2 helpers.py:102] Training  [ 4260/12500]  eta: 0:32:20  loss: 23.9036 (25.0751)  lr: 0.0000 (0.0000)  time: 0.207779  data: 0.000464  max mem: 3586
I20250120 12:09:40 3545703 dinov2 helpers.py:102] Training  [ 4270/12500]  eta: 0:32:17  loss: 23.9036 (25.0766)  lr: 0.0000 (0.0000)  time: 0.207678  data: 0.000455  max mem: 3586
I20250120 12:09:42 3545703 dinov2 helpers.py:102] Training  [ 4280/12500]  eta: 0:32:14  loss: 23.9036 (25.0736)  lr: 0.0000 (0.0000)  time: 0.207942  data: 0.000370  max mem: 3586
I20250120 12:09:44 3545703 dinov2 helpers.py:102] Training  [ 4290/12500]  eta: 0:32:11  loss: 23.8045 (25.0523)  lr: 0.0000 (0.0000)  time: 0.208026  data: 0.000407  max mem: 3586
I20250120 12:09:46 3545703 dinov2 helpers.py:102] Training  [ 4300/12500]  eta: 0:32:08  loss: 23.8045 (25.0567)  lr: 0.0000 (0.0000)  time: 0.208026  data: 0.000413  max mem: 3586
I20250120 12:09:48 3545703 dinov2 helpers.py:102] Training  [ 4310/12500]  eta: 0:32:05  loss: 23.8045 (25.0618)  lr: 0.0000 (0.0000)  time: 0.208051  data: 0.000376  max mem: 3586
I20250120 12:09:50 3545703 dinov2 helpers.py:102] Training  [ 4320/12500]  eta: 0:32:03  loss: 23.8045 (25.0659)  lr: 0.0000 (0.0000)  time: 0.207844  data: 0.000413  max mem: 3586
I20250120 12:09:52 3545703 dinov2 helpers.py:102] Training  [ 4330/12500]  eta: 0:32:00  loss: 22.9997 (25.0593)  lr: 0.0000 (0.0000)  time: 0.207849  data: 0.000421  max mem: 3586
I20250120 12:09:54 3545703 dinov2 helpers.py:102] Training  [ 4340/12500]  eta: 0:31:57  loss: 22.9997 (25.0551)  lr: 0.0000 (0.0000)  time: 0.208134  data: 0.000445  max mem: 3586
I20250120 12:09:56 3545703 dinov2 helpers.py:102] Training  [ 4350/12500]  eta: 0:31:54  loss: 22.9997 (25.0310)  lr: 0.0000 (0.0000)  time: 0.208196  data: 0.000434  max mem: 3586
I20250120 12:09:58 3545703 dinov2 helpers.py:102] Training  [ 4360/12500]  eta: 0:31:51  loss: 22.9997 (25.0380)  lr: 0.0000 (0.0000)  time: 0.208299  data: 0.000405  max mem: 3586
I20250120 12:10:00 3545703 dinov2 helpers.py:102] Training  [ 4370/12500]  eta: 0:31:48  loss: 22.9997 (25.0345)  lr: 0.0000 (0.0000)  time: 0.208297  data: 0.000390  max mem: 3586
I20250120 12:10:03 3545703 dinov2 helpers.py:102] Training  [ 4380/12500]  eta: 0:31:45  loss: 22.9997 (25.0250)  lr: 0.0000 (0.0000)  time: 0.207939  data: 0.000393  max mem: 3586
I20250120 12:10:05 3545703 dinov2 helpers.py:102] Training  [ 4390/12500]  eta: 0:31:43  loss: 22.9997 (25.0112)  lr: 0.0000 (0.0000)  time: 0.208115  data: 0.000438  max mem: 3586
I20250120 12:10:07 3545703 dinov2 helpers.py:102] Training  [ 4400/12500]  eta: 0:31:40  loss: 22.9997 (24.9950)  lr: 0.0000 (0.0000)  time: 0.208158  data: 0.000451  max mem: 3586
I20250120 12:10:09 3545703 dinov2 helpers.py:102] Training  [ 4410/12500]  eta: 0:31:37  loss: 22.6006 (24.9878)  lr: 0.0000 (0.0000)  time: 0.208356  data: 0.000430  max mem: 3586
I20250120 12:10:11 3545703 dinov2 helpers.py:102] Training  [ 4420/12500]  eta: 0:31:34  loss: 23.2447 (24.9847)  lr: 0.0000 (0.0000)  time: 0.208275  data: 0.000372  max mem: 3586
I20250120 12:10:13 3545703 dinov2 helpers.py:102] Training  [ 4430/12500]  eta: 0:31:31  loss: 23.2447 (24.9940)  lr: 0.0000 (0.0000)  time: 0.207979  data: 0.000378  max mem: 3586
I20250120 12:10:15 3545703 dinov2 helpers.py:102] Training  [ 4440/12500]  eta: 0:31:29  loss: 23.2447 (24.9889)  lr: 0.0000 (0.0000)  time: 0.208089  data: 0.000424  max mem: 3586
I20250120 12:10:17 3545703 dinov2 helpers.py:102] Training  [ 4450/12500]  eta: 0:31:26  loss: 23.2447 (24.9816)  lr: 0.0000 (0.0000)  time: 0.207807  data: 0.000402  max mem: 3586
I20250120 12:10:19 3545703 dinov2 helpers.py:102] Training  [ 4460/12500]  eta: 0:31:23  loss: 23.2447 (24.9824)  lr: 0.0000 (0.0000)  time: 0.207894  data: 0.000392  max mem: 3586
I20250120 12:10:21 3545703 dinov2 helpers.py:102] Training  [ 4470/12500]  eta: 0:31:20  loss: 22.6962 (24.9753)  lr: 0.0000 (0.0000)  time: 0.208130  data: 0.000407  max mem: 3586
I20250120 12:10:23 3545703 dinov2 helpers.py:102] Training  [ 4480/12500]  eta: 0:31:17  loss: 22.2235 (24.9679)  lr: 0.0000 (0.0000)  time: 0.207854  data: 0.000385  max mem: 3586
I20250120 12:10:25 3545703 dinov2 helpers.py:102] Training  [ 4490/12500]  eta: 0:31:14  loss: 22.6962 (24.9674)  lr: 0.0000 (0.0000)  time: 0.207754  data: 0.000418  max mem: 3586
I20250120 12:10:28 3545703 dinov2 helpers.py:102] Training  [ 4500/12500]  eta: 0:31:12  loss: 22.6962 (24.9670)  lr: 0.0000 (0.0000)  time: 0.207810  data: 0.000489  max mem: 3586
I20250120 12:10:30 3545703 dinov2 helpers.py:102] Training  [ 4510/12500]  eta: 0:31:09  loss: 22.6962 (24.9701)  lr: 0.0000 (0.0000)  time: 0.207984  data: 0.000470  max mem: 3586
I20250120 12:10:32 3545703 dinov2 helpers.py:102] Training  [ 4520/12500]  eta: 0:31:06  loss: 22.6962 (24.9734)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000447  max mem: 3586
I20250120 12:10:34 3545703 dinov2 helpers.py:102] Training  [ 4530/12500]  eta: 0:31:03  loss: 23.0330 (24.9691)  lr: 0.0000 (0.0000)  time: 0.208098  data: 0.000425  max mem: 3586
I20250120 12:10:36 3545703 dinov2 helpers.py:102] Training  [ 4540/12500]  eta: 0:31:00  loss: 23.0330 (24.9784)  lr: 0.0000 (0.0000)  time: 0.208139  data: 0.000420  max mem: 3586
I20250120 12:10:38 3545703 dinov2 helpers.py:102] Training  [ 4550/12500]  eta: 0:30:58  loss: 23.0330 (24.9711)  lr: 0.0000 (0.0000)  time: 0.207985  data: 0.000417  max mem: 3586
I20250120 12:10:40 3545703 dinov2 helpers.py:102] Training  [ 4560/12500]  eta: 0:30:55  loss: 22.6962 (24.9657)  lr: 0.0000 (0.0000)  time: 0.208196  data: 0.000404  max mem: 3586
I20250120 12:10:42 3545703 dinov2 helpers.py:102] Training  [ 4570/12500]  eta: 0:30:52  loss: 22.5182 (24.9556)  lr: 0.0000 (0.0000)  time: 0.208362  data: 0.000410  max mem: 3586
I20250120 12:10:44 3545703 dinov2 helpers.py:102] Training  [ 4580/12500]  eta: 0:30:49  loss: 22.5182 (24.9474)  lr: 0.0000 (0.0000)  time: 0.208145  data: 0.000403  max mem: 3586
I20250120 12:10:46 3545703 dinov2 helpers.py:102] Training  [ 4590/12500]  eta: 0:30:47  loss: 22.6962 (24.9445)  lr: 0.0000 (0.0000)  time: 0.208334  data: 0.000395  max mem: 3586
I20250120 12:10:48 3545703 dinov2 helpers.py:102] Training  [ 4600/12500]  eta: 0:30:44  loss: 23.0330 (24.9435)  lr: 0.0000 (0.0000)  time: 0.208235  data: 0.000404  max mem: 3586
I20250120 12:10:50 3545703 dinov2 helpers.py:102] Training  [ 4610/12500]  eta: 0:30:41  loss: 23.0330 (24.9362)  lr: 0.0000 (0.0000)  time: 0.208082  data: 0.000437  max mem: 3586
I20250120 12:10:53 3545703 dinov2 helpers.py:102] Training  [ 4620/12500]  eta: 0:30:38  loss: 22.6962 (24.9254)  lr: 0.0000 (0.0000)  time: 0.208360  data: 0.000481  max mem: 3586
I20250120 12:10:55 3545703 dinov2 helpers.py:102] Training  [ 4630/12500]  eta: 0:30:36  loss: 22.6962 (24.9265)  lr: 0.0000 (0.0000)  time: 0.208255  data: 0.000494  max mem: 3586
I20250120 12:10:57 3545703 dinov2 helpers.py:102] Training  [ 4640/12500]  eta: 0:30:33  loss: 23.0330 (24.9267)  lr: 0.0000 (0.0000)  time: 0.207962  data: 0.000430  max mem: 3586
I20250120 12:10:59 3545703 dinov2 helpers.py:102] Training  [ 4650/12500]  eta: 0:30:30  loss: 23.0330 (24.9078)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000391  max mem: 3586
I20250120 12:11:01 3545703 dinov2 helpers.py:102] Training  [ 4660/12500]  eta: 0:30:27  loss: 22.5182 (24.9006)  lr: 0.0000 (0.0000)  time: 0.208342  data: 0.000394  max mem: 3586
I20250120 12:11:03 3545703 dinov2 helpers.py:102] Training  [ 4670/12500]  eta: 0:30:24  loss: 22.5182 (24.8880)  lr: 0.0000 (0.0000)  time: 0.208064  data: 0.000401  max mem: 3586
I20250120 12:11:05 3545703 dinov2 helpers.py:102] Training  [ 4680/12500]  eta: 0:30:22  loss: 22.5182 (24.8784)  lr: 0.0000 (0.0000)  time: 0.208104  data: 0.000369  max mem: 3586
I20250120 12:11:07 3545703 dinov2 helpers.py:102] Training  [ 4690/12500]  eta: 0:30:19  loss: 22.5182 (24.8861)  lr: 0.0000 (0.0000)  time: 0.208426  data: 0.000361  max mem: 3586
I20250120 12:11:09 3545703 dinov2 helpers.py:102] Training  [ 4700/12500]  eta: 0:30:16  loss: 21.6436 (24.8665)  lr: 0.0000 (0.0000)  time: 0.208609  data: 0.000431  max mem: 3586
I20250120 12:11:11 3545703 dinov2 helpers.py:102] Training  [ 4710/12500]  eta: 0:30:14  loss: 21.6436 (24.8603)  lr: 0.0000 (0.0000)  time: 0.208569  data: 0.000441  max mem: 3586
I20250120 12:11:13 3545703 dinov2 helpers.py:102] Training  [ 4720/12500]  eta: 0:30:11  loss: 21.6436 (24.8618)  lr: 0.0000 (0.0000)  time: 0.208620  data: 0.000439  max mem: 3586
I20250120 12:11:15 3545703 dinov2 helpers.py:102] Training  [ 4730/12500]  eta: 0:30:08  loss: 21.5724 (24.8471)  lr: 0.0000 (0.0000)  time: 0.208517  data: 0.000477  max mem: 3586
I20250120 12:11:18 3545703 dinov2 helpers.py:102] Training  [ 4740/12500]  eta: 0:30:05  loss: 21.5724 (24.8486)  lr: 0.0000 (0.0000)  time: 0.208182  data: 0.000477  max mem: 3586
I20250120 12:11:20 3545703 dinov2 helpers.py:102] Training  [ 4750/12500]  eta: 0:30:03  loss: 21.5392 (24.8374)  lr: 0.0000 (0.0000)  time: 0.208270  data: 0.000453  max mem: 3586
I20250120 12:11:22 3545703 dinov2 helpers.py:102] Training  [ 4760/12500]  eta: 0:30:00  loss: 21.5392 (24.8335)  lr: 0.0000 (0.0000)  time: 0.208247  data: 0.000445  max mem: 3586
I20250120 12:11:24 3545703 dinov2 helpers.py:102] Training  [ 4770/12500]  eta: 0:29:57  loss: 21.5724 (24.8318)  lr: 0.0000 (0.0000)  time: 0.208107  data: 0.000416  max mem: 3586
I20250120 12:11:26 3545703 dinov2 helpers.py:102] Training  [ 4780/12500]  eta: 0:29:54  loss: 21.5724 (24.8231)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000440  max mem: 3586
I20250120 12:11:28 3545703 dinov2 helpers.py:102] Training  [ 4790/12500]  eta: 0:29:52  loss: 21.5724 (24.8215)  lr: 0.0000 (0.0000)  time: 0.208247  data: 0.000493  max mem: 3586
I20250120 12:11:30 3545703 dinov2 helpers.py:102] Training  [ 4800/12500]  eta: 0:29:49  loss: 21.5724 (24.8234)  lr: 0.0000 (0.0000)  time: 0.208421  data: 0.000492  max mem: 3586
I20250120 12:11:32 3545703 dinov2 helpers.py:102] Training  [ 4810/12500]  eta: 0:29:46  loss: 21.5392 (24.8052)  lr: 0.0000 (0.0000)  time: 0.208644  data: 0.000451  max mem: 3586
I20250120 12:11:34 3545703 dinov2 helpers.py:102] Training  [ 4820/12500]  eta: 0:29:44  loss: 21.5461 (24.7985)  lr: 0.0000 (0.0000)  time: 0.208657  data: 0.000446  max mem: 3586
I20250120 12:11:36 3545703 dinov2 helpers.py:102] Training  [ 4830/12500]  eta: 0:29:41  loss: 21.5461 (24.8011)  lr: 0.0000 (0.0000)  time: 0.208539  data: 0.000453  max mem: 3586
I20250120 12:11:38 3545703 dinov2 helpers.py:102] Training  [ 4840/12500]  eta: 0:29:38  loss: 21.5461 (24.7978)  lr: 0.0000 (0.0000)  time: 0.208507  data: 0.000445  max mem: 3586
I20250120 12:11:40 3545703 dinov2 helpers.py:102] Training  [ 4850/12500]  eta: 0:29:36  loss: 21.5461 (24.7848)  lr: 0.0000 (0.0000)  time: 0.208273  data: 0.000446  max mem: 3586
I20250120 12:11:43 3545703 dinov2 helpers.py:102] Training  [ 4860/12500]  eta: 0:29:33  loss: 21.9677 (24.7858)  lr: 0.0000 (0.0000)  time: 0.208048  data: 0.000367  max mem: 3586
I20250120 12:11:45 3545703 dinov2 helpers.py:102] Training  [ 4870/12500]  eta: 0:29:30  loss: 21.9677 (24.7781)  lr: 0.0000 (0.0000)  time: 0.208149  data: 0.000349  max mem: 3586
I20250120 12:11:47 3545703 dinov2 helpers.py:102] Training  [ 4880/12500]  eta: 0:29:27  loss: 21.9677 (24.7698)  lr: 0.0000 (0.0000)  time: 0.208166  data: 0.000387  max mem: 3586
I20250120 12:11:49 3545703 dinov2 helpers.py:102] Training  [ 4890/12500]  eta: 0:29:25  loss: 21.5461 (24.7627)  lr: 0.0000 (0.0000)  time: 0.208552  data: 0.000485  max mem: 3586
I20250120 12:11:51 3545703 dinov2 helpers.py:102] Training  [ 4900/12500]  eta: 0:29:22  loss: 21.5461 (24.7506)  lr: 0.0000 (0.0000)  time: 0.208771  data: 0.000491  max mem: 3586
I20250120 12:11:53 3545703 dinov2 helpers.py:102] Training  [ 4910/12500]  eta: 0:29:19  loss: 21.2837 (24.7423)  lr: 0.0000 (0.0000)  time: 0.208693  data: 0.000452  max mem: 3586
I20250120 12:11:55 3545703 dinov2 helpers.py:102] Training  [ 4920/12500]  eta: 0:29:17  loss: 21.2837 (24.7372)  lr: 0.0000 (0.0000)  time: 0.208875  data: 0.000462  max mem: 3586
I20250120 12:11:57 3545703 dinov2 helpers.py:102] Training  [ 4930/12500]  eta: 0:29:14  loss: 21.2837 (24.7238)  lr: 0.0000 (0.0000)  time: 0.208942  data: 0.000417  max mem: 3586
I20250120 12:11:59 3545703 dinov2 helpers.py:102] Training  [ 4940/12500]  eta: 0:29:11  loss: 21.2837 (24.7179)  lr: 0.0000 (0.0000)  time: 0.208629  data: 0.000420  max mem: 3586
I20250120 12:12:01 3545703 dinov2 helpers.py:102] Training  [ 4950/12500]  eta: 0:29:09  loss: 21.5461 (24.7173)  lr: 0.0000 (0.0000)  time: 0.208175  data: 0.000433  max mem: 3586
I20250120 12:12:03 3545703 dinov2 helpers.py:102] Training  [ 4960/12500]  eta: 0:29:06  loss: 21.5461 (24.7218)  lr: 0.0000 (0.0000)  time: 0.208265  data: 0.000479  max mem: 3586
I20250120 12:12:05 3545703 dinov2 helpers.py:102] Training  [ 4970/12500]  eta: 0:29:03  loss: 21.5461 (24.7334)  lr: 0.0000 (0.0000)  time: 0.208446  data: 0.000471  max mem: 3586
I20250120 12:12:08 3545703 dinov2 helpers.py:102] Training  [ 4980/12500]  eta: 0:29:01  loss: 21.8012 (24.7321)  lr: 0.0000 (0.0000)  time: 0.208381  data: 0.000428  max mem: 3586
I20250120 12:12:10 3545703 dinov2 helpers.py:102] Training  [ 4990/12500]  eta: 0:28:58  loss: 21.8012 (24.7335)  lr: 0.0000 (0.0000)  time: 0.208371  data: 0.000425  max mem: 3586
I20250120 12:12:11 3545703 dinov2 linear.py:272] running validation !
I20250120 12:12:13 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:55    time: 1.516602  data: 1.299086  max mem: 3586
I20250120 12:12:15 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.329671  data: 0.119069  max mem: 3586
I20250120 12:12:17 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.212684  data: 0.001717  max mem: 3586
I20250120 12:12:19 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212543  data: 0.001358  max mem: 3586
I20250120 12:12:22 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.210303  data: 0.000297  max mem: 3586
I20250120 12:12:24 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.222771  data: 0.000260  max mem: 3586
I20250120 12:12:26 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.223231  data: 0.000258  max mem: 3586
I20250120 12:12:28 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210682  data: 0.000275  max mem: 3586
I20250120 12:12:30 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210704  data: 0.000290  max mem: 3586
I20250120 12:12:32 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210442  data: 0.000273  max mem: 3586
I20250120 12:12:34 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210267  data: 0.000275  max mem: 3586
I20250120 12:12:37 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210673  data: 0.000260  max mem: 3586
I20250120 12:12:39 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210317  data: 0.000260  max mem: 3586
I20250120 12:12:41 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209839  data: 0.000258  max mem: 3586
I20250120 12:12:43 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210098  data: 0.000246  max mem: 3586
I20250120 12:12:45 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209652  data: 0.000188  max mem: 3586
I20250120 12:12:46 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205515  data: 0.000159  max mem: 3586
I20250120 12:12:46 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.221079 s / it)
I20250120 12:12:46 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:12:46 3545703 dinov2 linear.py:287] 
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8531, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8612, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8659, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8702, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8753, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8755, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8746, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8747, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8596, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8499, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8542, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8611, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8691, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8732, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8764, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8766, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8789, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8812, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8834, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8788, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8588, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8611, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8689, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8745, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8769, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8781, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8667, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8637, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8435, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8147, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8713, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8747, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8765, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8792, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8815, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8812, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8826, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8725, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8325, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8355, device='cuda:0')}
I20250120 12:12:46 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8833872079849243}
I20250120 12:12:46 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:12:46 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:12:46 3545703 dinov2 helpers.py:102] Training  [ 5000/12500]  eta: 0:29:47  loss: 21.5461 (24.7197)  lr: 0.0000 (0.0000)  time: 1.926001  data: 0.000404  max mem: 3586
I20250120 12:12:48 3545703 dinov2 helpers.py:102] Training  [ 5010/12500]  eta: 0:29:44  loss: 21.8012 (24.7230)  lr: 0.0000 (0.0000)  time: 1.924966  data: 0.000439  max mem: 3586
I20250120 12:12:50 3545703 dinov2 helpers.py:102] Training  [ 5020/12500]  eta: 0:29:41  loss: 22.1895 (24.7185)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000494  max mem: 3586
I20250120 12:12:52 3545703 dinov2 helpers.py:102] Training  [ 5030/12500]  eta: 0:29:38  loss: 21.8012 (24.7103)  lr: 0.0000 (0.0000)  time: 0.206764  data: 0.000495  max mem: 3586
I20250120 12:12:54 3545703 dinov2 helpers.py:102] Training  [ 5040/12500]  eta: 0:29:35  loss: 21.8012 (24.7085)  lr: 0.0000 (0.0000)  time: 0.207115  data: 0.000467  max mem: 3586
I20250120 12:12:57 3545703 dinov2 helpers.py:102] Training  [ 5050/12500]  eta: 0:29:33  loss: 22.1895 (24.7109)  lr: 0.0000 (0.0000)  time: 0.230712  data: 0.027425  max mem: 3586
I20250120 12:12:59 3545703 dinov2 helpers.py:102] Training  [ 5060/12500]  eta: 0:29:31  loss: 21.8012 (24.7002)  lr: 0.0000 (0.0000)  time: 0.230593  data: 0.027413  max mem: 3586
I20250120 12:13:01 3545703 dinov2 helpers.py:102] Training  [ 5070/12500]  eta: 0:29:28  loss: 22.1895 (24.7029)  lr: 0.0000 (0.0000)  time: 0.207014  data: 0.000416  max mem: 3586
I20250120 12:13:03 3545703 dinov2 helpers.py:102] Training  [ 5080/12500]  eta: 0:29:25  loss: 22.1895 (24.6924)  lr: 0.0000 (0.0000)  time: 0.206765  data: 0.000428  max mem: 3586
I20250120 12:13:05 3545703 dinov2 helpers.py:102] Training  [ 5090/12500]  eta: 0:29:22  loss: 22.1895 (24.6857)  lr: 0.0000 (0.0000)  time: 0.206984  data: 0.000480  max mem: 3586
I20250120 12:13:07 3545703 dinov2 helpers.py:102] Training  [ 5100/12500]  eta: 0:29:19  loss: 22.1895 (24.6729)  lr: 0.0000 (0.0000)  time: 0.207255  data: 0.000503  max mem: 3586
I20250120 12:13:09 3545703 dinov2 helpers.py:102] Training  [ 5110/12500]  eta: 0:29:16  loss: 22.1895 (24.6632)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000478  max mem: 3586
I20250120 12:13:11 3545703 dinov2 helpers.py:102] Training  [ 5120/12500]  eta: 0:29:14  loss: 21.8012 (24.6570)  lr: 0.0000 (0.0000)  time: 0.207326  data: 0.000485  max mem: 3586
I20250120 12:13:13 3545703 dinov2 helpers.py:102] Training  [ 5130/12500]  eta: 0:29:11  loss: 21.8012 (24.6483)  lr: 0.0000 (0.0000)  time: 0.207365  data: 0.000495  max mem: 3586
I20250120 12:13:16 3545703 dinov2 helpers.py:102] Training  [ 5140/12500]  eta: 0:29:08  loss: 21.4604 (24.6377)  lr: 0.0000 (0.0000)  time: 0.207409  data: 0.000502  max mem: 3586
I20250120 12:13:18 3545703 dinov2 helpers.py:102] Training  [ 5150/12500]  eta: 0:29:05  loss: 21.4604 (24.6333)  lr: 0.0000 (0.0000)  time: 0.207502  data: 0.000480  max mem: 3586
I20250120 12:13:20 3545703 dinov2 helpers.py:102] Training  [ 5160/12500]  eta: 0:29:02  loss: 21.2927 (24.6231)  lr: 0.0000 (0.0000)  time: 0.207478  data: 0.000456  max mem: 3586
I20250120 12:13:22 3545703 dinov2 helpers.py:102] Training  [ 5170/12500]  eta: 0:29:00  loss: 20.5850 (24.6153)  lr: 0.0000 (0.0000)  time: 0.207475  data: 0.000449  max mem: 3586
I20250120 12:13:24 3545703 dinov2 helpers.py:102] Training  [ 5180/12500]  eta: 0:28:57  loss: 20.5850 (24.6108)  lr: 0.0000 (0.0000)  time: 0.207635  data: 0.000448  max mem: 3586
I20250120 12:13:26 3545703 dinov2 helpers.py:102] Training  [ 5190/12500]  eta: 0:28:54  loss: 20.5645 (24.6020)  lr: 0.0000 (0.0000)  time: 0.207777  data: 0.000475  max mem: 3586
I20250120 12:13:28 3545703 dinov2 helpers.py:102] Training  [ 5200/12500]  eta: 0:28:51  loss: 20.5850 (24.6023)  lr: 0.0000 (0.0000)  time: 0.207796  data: 0.000492  max mem: 3586
I20250120 12:13:30 3545703 dinov2 helpers.py:102] Training  [ 5210/12500]  eta: 0:28:48  loss: 20.5850 (24.5970)  lr: 0.0000 (0.0000)  time: 0.207635  data: 0.000453  max mem: 3586
I20250120 12:13:32 3545703 dinov2 helpers.py:102] Training  [ 5220/12500]  eta: 0:28:46  loss: 20.5850 (24.5963)  lr: 0.0000 (0.0000)  time: 0.207650  data: 0.000425  max mem: 3586
I20250120 12:13:34 3545703 dinov2 helpers.py:102] Training  [ 5230/12500]  eta: 0:28:43  loss: 20.5850 (24.5882)  lr: 0.0000 (0.0000)  time: 0.207891  data: 0.000460  max mem: 3586
I20250120 12:13:36 3545703 dinov2 helpers.py:102] Training  [ 5240/12500]  eta: 0:28:40  loss: 20.3424 (24.5798)  lr: 0.0000 (0.0000)  time: 0.208258  data: 0.000446  max mem: 3586
I20250120 12:13:38 3545703 dinov2 helpers.py:102] Training  [ 5250/12500]  eta: 0:28:37  loss: 20.1796 (24.5699)  lr: 0.0000 (0.0000)  time: 0.208203  data: 0.000442  max mem: 3586
I20250120 12:13:41 3545703 dinov2 helpers.py:102] Training  [ 5260/12500]  eta: 0:28:35  loss: 20.1796 (24.5583)  lr: 0.0000 (0.0000)  time: 0.207952  data: 0.000427  max mem: 3586
I20250120 12:13:43 3545703 dinov2 helpers.py:102] Training  [ 5270/12500]  eta: 0:28:32  loss: 20.1796 (24.5534)  lr: 0.0000 (0.0000)  time: 0.208148  data: 0.000453  max mem: 3586
I20250120 12:13:45 3545703 dinov2 helpers.py:102] Training  [ 5280/12500]  eta: 0:28:29  loss: 20.3424 (24.5485)  lr: 0.0000 (0.0000)  time: 0.208069  data: 0.000497  max mem: 3586
I20250120 12:13:50 3545703 dinov2 helpers.py:102] Training  [ 5290/12500]  eta: 0:28:31  loss: 20.3424 (24.5448)  lr: 0.0000 (0.0000)  time: 0.381737  data: 0.186701  max mem: 3586
I20250120 12:13:53 3545703 dinov2 helpers.py:102] Training  [ 5300/12500]  eta: 0:28:29  loss: 20.5850 (24.5452)  lr: 0.0000 (0.0000)  time: 0.421633  data: 0.234661  max mem: 3586
I20250120 12:13:55 3545703 dinov2 helpers.py:102] Training  [ 5310/12500]  eta: 0:28:26  loss: 20.5850 (24.5362)  lr: 0.0000 (0.0000)  time: 0.246244  data: 0.048571  max mem: 3586
I20250120 12:13:57 3545703 dinov2 helpers.py:102] Training  [ 5320/12500]  eta: 0:28:24  loss: 20.5850 (24.5327)  lr: 0.0000 (0.0000)  time: 0.205349  data: 0.000620  max mem: 3586
I20250120 12:13:59 3545703 dinov2 helpers.py:102] Training  [ 5330/12500]  eta: 0:28:21  loss: 21.8154 (24.5292)  lr: 0.0000 (0.0000)  time: 0.205955  data: 0.000438  max mem: 3586
I20250120 12:14:01 3545703 dinov2 helpers.py:102] Training  [ 5340/12500]  eta: 0:28:18  loss: 21.8154 (24.5162)  lr: 0.0000 (0.0000)  time: 0.206384  data: 0.000441  max mem: 3586
I20250120 12:14:03 3545703 dinov2 helpers.py:102] Training  [ 5350/12500]  eta: 0:28:15  loss: 21.8154 (24.5140)  lr: 0.0000 (0.0000)  time: 0.206809  data: 0.000509  max mem: 3586
I20250120 12:14:05 3545703 dinov2 helpers.py:102] Training  [ 5360/12500]  eta: 0:28:13  loss: 21.9651 (24.5151)  lr: 0.0000 (0.0000)  time: 0.206897  data: 0.000450  max mem: 3586
I20250120 12:14:08 3545703 dinov2 helpers.py:102] Training  [ 5370/12500]  eta: 0:28:10  loss: 21.9860 (24.5208)  lr: 0.0000 (0.0000)  time: 0.207188  data: 0.000414  max mem: 3586
I20250120 12:14:10 3545703 dinov2 helpers.py:102] Training  [ 5380/12500]  eta: 0:28:07  loss: 21.9860 (24.5256)  lr: 0.0000 (0.0000)  time: 0.207323  data: 0.000474  max mem: 3586
I20250120 12:14:12 3545703 dinov2 helpers.py:102] Training  [ 5390/12500]  eta: 0:28:04  loss: 22.5699 (24.5241)  lr: 0.0000 (0.0000)  time: 0.207419  data: 0.000484  max mem: 3586
I20250120 12:14:14 3545703 dinov2 helpers.py:102] Training  [ 5400/12500]  eta: 0:28:01  loss: 21.9860 (24.5163)  lr: 0.0000 (0.0000)  time: 0.207464  data: 0.000447  max mem: 3586
I20250120 12:14:16 3545703 dinov2 helpers.py:102] Training  [ 5410/12500]  eta: 0:27:59  loss: 21.9860 (24.5066)  lr: 0.0000 (0.0000)  time: 0.207545  data: 0.000478  max mem: 3586
I20250120 12:14:18 3545703 dinov2 helpers.py:102] Training  [ 5420/12500]  eta: 0:27:56  loss: 21.9651 (24.5001)  lr: 0.0000 (0.0000)  time: 0.207793  data: 0.000485  max mem: 3586
I20250120 12:14:20 3545703 dinov2 helpers.py:102] Training  [ 5430/12500]  eta: 0:27:53  loss: 21.9651 (24.4924)  lr: 0.0000 (0.0000)  time: 0.207703  data: 0.000448  max mem: 3586
I20250120 12:14:22 3545703 dinov2 helpers.py:102] Training  [ 5440/12500]  eta: 0:27:50  loss: 21.9651 (24.4856)  lr: 0.0000 (0.0000)  time: 0.207604  data: 0.000429  max mem: 3586
I20250120 12:14:24 3545703 dinov2 helpers.py:102] Training  [ 5450/12500]  eta: 0:27:48  loss: 21.9651 (24.4774)  lr: 0.0000 (0.0000)  time: 0.207699  data: 0.000412  max mem: 3586
I20250120 12:14:26 3545703 dinov2 helpers.py:102] Training  [ 5460/12500]  eta: 0:27:45  loss: 21.9651 (24.4701)  lr: 0.0000 (0.0000)  time: 0.207883  data: 0.000425  max mem: 3586
I20250120 12:14:28 3545703 dinov2 helpers.py:102] Training  [ 5470/12500]  eta: 0:27:42  loss: 21.9651 (24.4753)  lr: 0.0000 (0.0000)  time: 0.208156  data: 0.000440  max mem: 3586
I20250120 12:14:30 3545703 dinov2 helpers.py:102] Training  [ 5480/12500]  eta: 0:27:40  loss: 22.5119 (24.4717)  lr: 0.0000 (0.0000)  time: 0.208171  data: 0.000442  max mem: 3586
I20250120 12:14:33 3545703 dinov2 helpers.py:102] Training  [ 5490/12500]  eta: 0:27:37  loss: 20.9881 (24.4654)  lr: 0.0000 (0.0000)  time: 0.208271  data: 0.000435  max mem: 3586
I20250120 12:14:35 3545703 dinov2 helpers.py:102] Training  [ 5500/12500]  eta: 0:27:34  loss: 20.9881 (24.4639)  lr: 0.0000 (0.0000)  time: 0.208369  data: 0.000426  max mem: 3586
I20250120 12:14:37 3545703 dinov2 helpers.py:102] Training  [ 5510/12500]  eta: 0:27:31  loss: 20.9881 (24.4421)  lr: 0.0000 (0.0000)  time: 0.208328  data: 0.000409  max mem: 3586
I20250120 12:14:39 3545703 dinov2 helpers.py:102] Training  [ 5520/12500]  eta: 0:27:29  loss: 20.9881 (24.4370)  lr: 0.0000 (0.0000)  time: 0.208404  data: 0.000447  max mem: 3586
I20250120 12:14:41 3545703 dinov2 helpers.py:102] Training  [ 5530/12500]  eta: 0:27:26  loss: 20.9881 (24.4336)  lr: 0.0000 (0.0000)  time: 0.208337  data: 0.000467  max mem: 3586
I20250120 12:14:43 3545703 dinov2 helpers.py:102] Training  [ 5540/12500]  eta: 0:27:23  loss: 21.5377 (24.4284)  lr: 0.0000 (0.0000)  time: 0.208419  data: 0.000483  max mem: 3586
I20250120 12:14:45 3545703 dinov2 helpers.py:102] Training  [ 5550/12500]  eta: 0:27:21  loss: 21.5377 (24.4369)  lr: 0.0000 (0.0000)  time: 0.208441  data: 0.000483  max mem: 3586
I20250120 12:14:47 3545703 dinov2 helpers.py:102] Training  [ 5560/12500]  eta: 0:27:18  loss: 21.5377 (24.4350)  lr: 0.0000 (0.0000)  time: 0.208358  data: 0.000468  max mem: 3586
I20250120 12:14:49 3545703 dinov2 helpers.py:102] Training  [ 5570/12500]  eta: 0:27:15  loss: 21.5377 (24.4392)  lr: 0.0000 (0.0000)  time: 0.208514  data: 0.000462  max mem: 3586
I20250120 12:14:51 3545703 dinov2 helpers.py:102] Training  [ 5580/12500]  eta: 0:27:12  loss: 21.5377 (24.4393)  lr: 0.0000 (0.0000)  time: 0.208653  data: 0.000479  max mem: 3586
I20250120 12:14:53 3545703 dinov2 helpers.py:102] Training  [ 5590/12500]  eta: 0:27:10  loss: 20.9881 (24.4299)  lr: 0.0000 (0.0000)  time: 0.208795  data: 0.000509  max mem: 3586
I20250120 12:14:55 3545703 dinov2 helpers.py:102] Training  [ 5600/12500]  eta: 0:27:07  loss: 21.5377 (24.4275)  lr: 0.0000 (0.0000)  time: 0.208752  data: 0.000486  max mem: 3586
I20250120 12:14:58 3545703 dinov2 helpers.py:102] Training  [ 5610/12500]  eta: 0:27:04  loss: 21.6147 (24.4259)  lr: 0.0000 (0.0000)  time: 0.208814  data: 0.000475  max mem: 3586
I20250120 12:15:00 3545703 dinov2 helpers.py:102] Training  [ 5620/12500]  eta: 0:27:02  loss: 22.5119 (24.4236)  lr: 0.0000 (0.0000)  time: 0.208843  data: 0.000492  max mem: 3586
I20250120 12:15:02 3545703 dinov2 helpers.py:102] Training  [ 5630/12500]  eta: 0:26:59  loss: 22.5119 (24.4150)  lr: 0.0000 (0.0000)  time: 0.208763  data: 0.000522  max mem: 3586
I20250120 12:15:04 3545703 dinov2 helpers.py:102] Training  [ 5640/12500]  eta: 0:26:56  loss: 22.5119 (24.4032)  lr: 0.0000 (0.0000)  time: 0.208994  data: 0.000515  max mem: 3586
I20250120 12:15:06 3545703 dinov2 helpers.py:102] Training  [ 5650/12500]  eta: 0:26:54  loss: 22.5119 (24.3937)  lr: 0.0000 (0.0000)  time: 0.209141  data: 0.000461  max mem: 3586
I20250120 12:15:08 3545703 dinov2 helpers.py:102] Training  [ 5660/12500]  eta: 0:26:51  loss: 22.5119 (24.3856)  lr: 0.0000 (0.0000)  time: 0.209082  data: 0.000441  max mem: 3586
I20250120 12:15:10 3545703 dinov2 helpers.py:102] Training  [ 5670/12500]  eta: 0:26:48  loss: 21.6147 (24.3689)  lr: 0.0000 (0.0000)  time: 0.209290  data: 0.000464  max mem: 3586
I20250120 12:15:12 3545703 dinov2 helpers.py:102] Training  [ 5680/12500]  eta: 0:26:46  loss: 21.5377 (24.3639)  lr: 0.0000 (0.0000)  time: 0.209753  data: 0.000440  max mem: 3586
I20250120 12:15:14 3545703 dinov2 helpers.py:102] Training  [ 5690/12500]  eta: 0:26:43  loss: 21.5377 (24.3557)  lr: 0.0000 (0.0000)  time: 0.209650  data: 0.000439  max mem: 3586
I20250120 12:15:16 3545703 dinov2 helpers.py:102] Training  [ 5700/12500]  eta: 0:26:40  loss: 21.5377 (24.3532)  lr: 0.0000 (0.0000)  time: 0.209267  data: 0.000484  max mem: 3586
I20250120 12:15:18 3545703 dinov2 helpers.py:102] Training  [ 5710/12500]  eta: 0:26:38  loss: 21.5377 (24.3459)  lr: 0.0000 (0.0000)  time: 0.208961  data: 0.000507  max mem: 3586
I20250120 12:15:21 3545703 dinov2 helpers.py:102] Training  [ 5720/12500]  eta: 0:26:35  loss: 21.5377 (24.3412)  lr: 0.0000 (0.0000)  time: 0.209158  data: 0.000521  max mem: 3586
I20250120 12:15:23 3545703 dinov2 helpers.py:102] Training  [ 5730/12500]  eta: 0:26:32  loss: 21.5255 (24.3336)  lr: 0.0000 (0.0000)  time: 0.209018  data: 0.000527  max mem: 3586
I20250120 12:15:25 3545703 dinov2 helpers.py:102] Training  [ 5740/12500]  eta: 0:26:30  loss: 21.5255 (24.3371)  lr: 0.0000 (0.0000)  time: 0.208774  data: 0.000498  max mem: 3586
I20250120 12:15:27 3545703 dinov2 helpers.py:102] Training  [ 5750/12500]  eta: 0:26:27  loss: 21.5255 (24.3370)  lr: 0.0000 (0.0000)  time: 0.208859  data: 0.000486  max mem: 3586
I20250120 12:15:29 3545703 dinov2 helpers.py:102] Training  [ 5760/12500]  eta: 0:26:24  loss: 21.5255 (24.3339)  lr: 0.0000 (0.0000)  time: 0.208942  data: 0.000501  max mem: 3586
I20250120 12:15:31 3545703 dinov2 helpers.py:102] Training  [ 5770/12500]  eta: 0:26:22  loss: 20.1638 (24.3247)  lr: 0.0000 (0.0000)  time: 0.209019  data: 0.000496  max mem: 3586
I20250120 12:15:33 3545703 dinov2 helpers.py:102] Training  [ 5780/12500]  eta: 0:26:19  loss: 20.1638 (24.3189)  lr: 0.0000 (0.0000)  time: 0.209063  data: 0.000460  max mem: 3586
I20250120 12:15:35 3545703 dinov2 helpers.py:102] Training  [ 5790/12500]  eta: 0:26:16  loss: 20.1638 (24.3068)  lr: 0.0000 (0.0000)  time: 0.209272  data: 0.000478  max mem: 3586
I20250120 12:15:37 3545703 dinov2 helpers.py:102] Training  [ 5800/12500]  eta: 0:26:14  loss: 20.0517 (24.2995)  lr: 0.0000 (0.0000)  time: 0.209342  data: 0.000512  max mem: 3586
I20250120 12:15:39 3545703 dinov2 helpers.py:102] Training  [ 5810/12500]  eta: 0:26:11  loss: 20.0517 (24.2976)  lr: 0.0000 (0.0000)  time: 0.209409  data: 0.000508  max mem: 3586
I20250120 12:15:41 3545703 dinov2 helpers.py:102] Training  [ 5820/12500]  eta: 0:26:08  loss: 19.9851 (24.2879)  lr: 0.0000 (0.0000)  time: 0.209424  data: 0.000466  max mem: 3586
I20250120 12:15:44 3545703 dinov2 helpers.py:102] Training  [ 5830/12500]  eta: 0:26:06  loss: 19.9851 (24.2784)  lr: 0.0000 (0.0000)  time: 0.209253  data: 0.000476  max mem: 3586
I20250120 12:15:46 3545703 dinov2 helpers.py:102] Training  [ 5840/12500]  eta: 0:26:03  loss: 19.9851 (24.2652)  lr: 0.0000 (0.0000)  time: 0.208824  data: 0.000542  max mem: 3586
I20250120 12:15:48 3545703 dinov2 helpers.py:102] Training  [ 5850/12500]  eta: 0:26:00  loss: 20.0517 (24.2656)  lr: 0.0000 (0.0000)  time: 0.208856  data: 0.000616  max mem: 3586
I20250120 12:15:50 3545703 dinov2 helpers.py:102] Training  [ 5860/12500]  eta: 0:25:58  loss: 20.0517 (24.2578)  lr: 0.0000 (0.0000)  time: 0.208987  data: 0.000671  max mem: 3586
I20250120 12:15:52 3545703 dinov2 helpers.py:102] Training  [ 5870/12500]  eta: 0:25:55  loss: 20.1638 (24.2548)  lr: 0.0000 (0.0000)  time: 0.208833  data: 0.000619  max mem: 3586
I20250120 12:15:54 3545703 dinov2 helpers.py:102] Training  [ 5880/12500]  eta: 0:25:53  loss: 20.1638 (24.2595)  lr: 0.0000 (0.0000)  time: 0.208654  data: 0.000582  max mem: 3586
I20250120 12:15:56 3545703 dinov2 helpers.py:102] Training  [ 5890/12500]  eta: 0:25:50  loss: 20.4828 (24.2531)  lr: 0.0000 (0.0000)  time: 0.208524  data: 0.000642  max mem: 3586
I20250120 12:15:58 3545703 dinov2 helpers.py:102] Training  [ 5900/12500]  eta: 0:25:47  loss: 20.4828 (24.2499)  lr: 0.0000 (0.0000)  time: 0.208719  data: 0.000655  max mem: 3586
I20250120 12:16:00 3545703 dinov2 helpers.py:102] Training  [ 5910/12500]  eta: 0:25:45  loss: 20.4828 (24.2359)  lr: 0.0000 (0.0000)  time: 0.208657  data: 0.000568  max mem: 3586
I20250120 12:16:02 3545703 dinov2 helpers.py:102] Training  [ 5920/12500]  eta: 0:25:42  loss: 20.0517 (24.2237)  lr: 0.0000 (0.0000)  time: 0.208638  data: 0.000493  max mem: 3586
I20250120 12:16:04 3545703 dinov2 helpers.py:102] Training  [ 5930/12500]  eta: 0:25:39  loss: 20.0517 (24.2164)  lr: 0.0000 (0.0000)  time: 0.208685  data: 0.000460  max mem: 3586
I20250120 12:16:07 3545703 dinov2 helpers.py:102] Training  [ 5940/12500]  eta: 0:25:37  loss: 20.0517 (24.2124)  lr: 0.0000 (0.0000)  time: 0.208844  data: 0.000479  max mem: 3586
I20250120 12:16:09 3545703 dinov2 helpers.py:102] Training  [ 5950/12500]  eta: 0:25:34  loss: 19.8652 (24.2005)  lr: 0.0000 (0.0000)  time: 0.209105  data: 0.000453  max mem: 3586
I20250120 12:16:11 3545703 dinov2 helpers.py:102] Training  [ 5960/12500]  eta: 0:25:32  loss: 19.8652 (24.1987)  lr: 0.0000 (0.0000)  time: 0.208901  data: 0.000455  max mem: 3586
I20250120 12:16:13 3545703 dinov2 helpers.py:102] Training  [ 5970/12500]  eta: 0:25:29  loss: 19.8652 (24.1855)  lr: 0.0000 (0.0000)  time: 0.208809  data: 0.000445  max mem: 3586
I20250120 12:16:15 3545703 dinov2 helpers.py:102] Training  [ 5980/12500]  eta: 0:25:26  loss: 19.8652 (24.1893)  lr: 0.0000 (0.0000)  time: 0.208904  data: 0.000435  max mem: 3586
I20250120 12:16:17 3545703 dinov2 helpers.py:102] Training  [ 5990/12500]  eta: 0:25:24  loss: 20.0517 (24.1888)  lr: 0.0000 (0.0000)  time: 0.208903  data: 0.000458  max mem: 3586
I20250120 12:16:19 3545703 dinov2 helpers.py:102] Training  [ 6000/12500]  eta: 0:25:21  loss: 19.8652 (24.1755)  lr: 0.0000 (0.0000)  time: 0.208785  data: 0.000440  max mem: 3586
I20250120 12:16:21 3545703 dinov2 helpers.py:102] Training  [ 6010/12500]  eta: 0:25:18  loss: 19.8652 (24.1698)  lr: 0.0000 (0.0000)  time: 0.208698  data: 0.000477  max mem: 3586
I20250120 12:16:23 3545703 dinov2 helpers.py:102] Training  [ 6020/12500]  eta: 0:25:16  loss: 20.4828 (24.1682)  lr: 0.0000 (0.0000)  time: 0.208470  data: 0.000506  max mem: 3586
I20250120 12:16:25 3545703 dinov2 helpers.py:102] Training  [ 6030/12500]  eta: 0:25:13  loss: 20.7905 (24.1627)  lr: 0.0000 (0.0000)  time: 0.208409  data: 0.000477  max mem: 3586
I20250120 12:16:27 3545703 dinov2 helpers.py:102] Training  [ 6040/12500]  eta: 0:25:11  loss: 20.7905 (24.1499)  lr: 0.0000 (0.0000)  time: 0.208436  data: 0.000461  max mem: 3586
I20250120 12:16:30 3545703 dinov2 helpers.py:102] Training  [ 6050/12500]  eta: 0:25:08  loss: 20.7905 (24.1471)  lr: 0.0000 (0.0000)  time: 0.208390  data: 0.000487  max mem: 3586
I20250120 12:16:32 3545703 dinov2 helpers.py:102] Training  [ 6060/12500]  eta: 0:25:05  loss: 20.7905 (24.1387)  lr: 0.0000 (0.0000)  time: 0.208357  data: 0.000472  max mem: 3586
I20250120 12:16:34 3545703 dinov2 helpers.py:102] Training  [ 6070/12500]  eta: 0:25:03  loss: 20.7905 (24.1348)  lr: 0.0000 (0.0000)  time: 0.208505  data: 0.000459  max mem: 3586
I20250120 12:16:36 3545703 dinov2 helpers.py:102] Training  [ 6080/12500]  eta: 0:25:00  loss: 20.4828 (24.1246)  lr: 0.0000 (0.0000)  time: 0.208636  data: 0.000434  max mem: 3586
I20250120 12:16:38 3545703 dinov2 helpers.py:102] Training  [ 6090/12500]  eta: 0:24:58  loss: 20.7905 (24.1220)  lr: 0.0000 (0.0000)  time: 0.208383  data: 0.000411  max mem: 3586
I20250120 12:16:40 3545703 dinov2 helpers.py:102] Training  [ 6100/12500]  eta: 0:24:55  loss: 20.7905 (24.1233)  lr: 0.0000 (0.0000)  time: 0.208602  data: 0.000416  max mem: 3586
I20250120 12:16:42 3545703 dinov2 helpers.py:102] Training  [ 6110/12500]  eta: 0:24:52  loss: 20.7905 (24.1145)  lr: 0.0000 (0.0000)  time: 0.208681  data: 0.000435  max mem: 3586
I20250120 12:16:44 3545703 dinov2 helpers.py:102] Training  [ 6120/12500]  eta: 0:24:50  loss: 20.8540 (24.1130)  lr: 0.0000 (0.0000)  time: 0.208567  data: 0.000392  max mem: 3586
I20250120 12:16:46 3545703 dinov2 helpers.py:102] Training  [ 6130/12500]  eta: 0:24:47  loss: 21.7710 (24.1100)  lr: 0.0000 (0.0000)  time: 0.208414  data: 0.000382  max mem: 3586
I20250120 12:16:48 3545703 dinov2 helpers.py:102] Training  [ 6140/12500]  eta: 0:24:45  loss: 21.7710 (24.1091)  lr: 0.0000 (0.0000)  time: 0.208222  data: 0.000491  max mem: 3586
I20250120 12:16:50 3545703 dinov2 helpers.py:102] Training  [ 6150/12500]  eta: 0:24:42  loss: 22.2508 (24.1067)  lr: 0.0000 (0.0000)  time: 0.208275  data: 0.000532  max mem: 3586
I20250120 12:16:52 3545703 dinov2 helpers.py:102] Training  [ 6160/12500]  eta: 0:24:39  loss: 22.2508 (24.1069)  lr: 0.0000 (0.0000)  time: 0.208187  data: 0.000509  max mem: 3586
I20250120 12:16:55 3545703 dinov2 helpers.py:102] Training  [ 6170/12500]  eta: 0:24:37  loss: 22.2508 (24.0983)  lr: 0.0000 (0.0000)  time: 0.208394  data: 0.000466  max mem: 3586
I20250120 12:16:57 3545703 dinov2 helpers.py:102] Training  [ 6180/12500]  eta: 0:24:34  loss: 22.2508 (24.0994)  lr: 0.0000 (0.0000)  time: 0.208344  data: 0.000479  max mem: 3586
I20250120 12:16:59 3545703 dinov2 helpers.py:102] Training  [ 6190/12500]  eta: 0:24:32  loss: 21.7710 (24.0894)  lr: 0.0000 (0.0000)  time: 0.208216  data: 0.000484  max mem: 3586
I20250120 12:17:01 3545703 dinov2 helpers.py:102] Training  [ 6200/12500]  eta: 0:24:29  loss: 21.7710 (24.0835)  lr: 0.0000 (0.0000)  time: 0.208283  data: 0.000468  max mem: 3586
I20250120 12:17:03 3545703 dinov2 helpers.py:102] Training  [ 6210/12500]  eta: 0:24:26  loss: 21.7710 (24.0759)  lr: 0.0000 (0.0000)  time: 0.208154  data: 0.000481  max mem: 3586
I20250120 12:17:05 3545703 dinov2 helpers.py:102] Training  [ 6220/12500]  eta: 0:24:24  loss: 21.7710 (24.0776)  lr: 0.0000 (0.0000)  time: 0.207935  data: 0.000460  max mem: 3586
I20250120 12:17:07 3545703 dinov2 helpers.py:102] Training  [ 6230/12500]  eta: 0:24:21  loss: 22.2508 (24.0781)  lr: 0.0000 (0.0000)  time: 0.207822  data: 0.000423  max mem: 3586
I20250120 12:17:09 3545703 dinov2 helpers.py:102] Training  [ 6240/12500]  eta: 0:24:19  loss: 22.2508 (24.0699)  lr: 0.0000 (0.0000)  time: 0.207910  data: 0.000449  max mem: 3586
I20250120 12:17:11 3545703 dinov2 linear.py:272] running validation !
I20250120 12:17:13 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:58    time: 1.541541  data: 1.334565  max mem: 3586
I20250120 12:17:15 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.331553  data: 0.122873  max mem: 3586
I20250120 12:17:17 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.212224  data: 0.001037  max mem: 3586
I20250120 12:17:19 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212054  data: 0.000330  max mem: 3586
I20250120 12:17:21 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.210384  data: 0.000277  max mem: 3586
I20250120 12:17:23 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.210292  data: 0.000253  max mem: 3586
I20250120 12:17:25 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209592  data: 0.000252  max mem: 3586
I20250120 12:17:27 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209763  data: 0.000256  max mem: 3586
I20250120 12:17:29 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.210168  data: 0.000269  max mem: 3586
I20250120 12:17:31 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210115  data: 0.000260  max mem: 3586
I20250120 12:17:34 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210260  data: 0.000256  max mem: 3586
I20250120 12:17:36 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210214  data: 0.000265  max mem: 3586
I20250120 12:17:38 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209904  data: 0.000237  max mem: 3586
I20250120 12:17:40 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210093  data: 0.000223  max mem: 3586
I20250120 12:17:42 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210403  data: 0.000236  max mem: 3586
I20250120 12:17:44 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209815  data: 0.000186  max mem: 3586
I20250120 12:17:45 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205635  data: 0.000164  max mem: 3586
I20250120 12:17:45 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.219435 s / it)
I20250120 12:17:45 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:17:45 3545703 dinov2 linear.py:287] 
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8547, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8634, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8717, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8763, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8771, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8777, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8752, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8700, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8573, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8555, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8628, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8699, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8736, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8769, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8791, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8804, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8833, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8831, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8821, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8794, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8608, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8631, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8703, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8758, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8800, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8784, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8756, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8630, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8168, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8293, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8660, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8726, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8757, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8785, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8840, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8837, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8837, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8802, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8732, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8410, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8384, device='cuda:0')}
I20250120 12:17:45 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00050', 'accuracy': 0.8839935064315796}
I20250120 12:17:45 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:17:45 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:17:45 3545703 dinov2 helpers.py:102] Training  [ 6250/12500]  eta: 0:24:50  loss: 21.7710 (24.0580)  lr: 0.0000 (0.0000)  time: 1.913076  data: 0.000481  max mem: 3586
I20250120 12:17:47 3545703 dinov2 helpers.py:102] Training  [ 6260/12500]  eta: 0:24:47  loss: 21.7710 (24.0473)  lr: 0.0000 (0.0000)  time: 1.912079  data: 0.000425  max mem: 3586
I20250120 12:17:49 3545703 dinov2 helpers.py:102] Training  [ 6270/12500]  eta: 0:24:45  loss: 20.3998 (24.0414)  lr: 0.0000 (0.0000)  time: 0.206515  data: 0.000419  max mem: 3586
I20250120 12:17:51 3545703 dinov2 helpers.py:102] Training  [ 6280/12500]  eta: 0:24:42  loss: 22.2508 (24.0432)  lr: 0.0000 (0.0000)  time: 0.207166  data: 0.000435  max mem: 3586
I20250120 12:17:54 3545703 dinov2 helpers.py:102] Training  [ 6290/12500]  eta: 0:24:39  loss: 20.3998 (24.0365)  lr: 0.0000 (0.0000)  time: 0.207255  data: 0.000419  max mem: 3586
I20250120 12:17:56 3545703 dinov2 helpers.py:102] Training  [ 6300/12500]  eta: 0:24:37  loss: 20.3835 (24.0258)  lr: 0.0000 (0.0000)  time: 0.207295  data: 0.000437  max mem: 3586
I20250120 12:17:58 3545703 dinov2 helpers.py:102] Training  [ 6310/12500]  eta: 0:24:34  loss: 20.3835 (24.0169)  lr: 0.0000 (0.0000)  time: 0.207205  data: 0.000403  max mem: 3586
I20250120 12:18:00 3545703 dinov2 helpers.py:102] Training  [ 6320/12500]  eta: 0:24:32  loss: 20.3835 (24.0188)  lr: 0.0000 (0.0000)  time: 0.231194  data: 0.028205  max mem: 3586
I20250120 12:18:02 3545703 dinov2 helpers.py:102] Training  [ 6330/12500]  eta: 0:24:29  loss: 20.3835 (24.0150)  lr: 0.0000 (0.0000)  time: 0.231036  data: 0.028267  max mem: 3586
I20250120 12:18:04 3545703 dinov2 helpers.py:102] Training  [ 6340/12500]  eta: 0:24:26  loss: 20.3835 (24.0109)  lr: 0.0000 (0.0000)  time: 0.206725  data: 0.000513  max mem: 3586
I20250120 12:18:06 3545703 dinov2 helpers.py:102] Training  [ 6350/12500]  eta: 0:24:24  loss: 19.8138 (24.0025)  lr: 0.0000 (0.0000)  time: 0.206565  data: 0.000500  max mem: 3586
I20250120 12:18:09 3545703 dinov2 helpers.py:102] Training  [ 6360/12500]  eta: 0:24:21  loss: 19.3342 (23.9939)  lr: 0.0000 (0.0000)  time: 0.206553  data: 0.000469  max mem: 3586
I20250120 12:18:11 3545703 dinov2 helpers.py:102] Training  [ 6370/12500]  eta: 0:24:18  loss: 19.8138 (23.9906)  lr: 0.0000 (0.0000)  time: 0.206486  data: 0.000454  max mem: 3586
I20250120 12:18:13 3545703 dinov2 helpers.py:102] Training  [ 6380/12500]  eta: 0:24:16  loss: 19.3431 (23.9833)  lr: 0.0000 (0.0000)  time: 0.206579  data: 0.000443  max mem: 3586
I20250120 12:18:15 3545703 dinov2 helpers.py:102] Training  [ 6390/12500]  eta: 0:24:13  loss: 19.8138 (23.9841)  lr: 0.0000 (0.0000)  time: 0.206875  data: 0.000451  max mem: 3586
I20250120 12:18:17 3545703 dinov2 helpers.py:102] Training  [ 6400/12500]  eta: 0:24:10  loss: 19.8138 (23.9839)  lr: 0.0000 (0.0000)  time: 0.207055  data: 0.000478  max mem: 3586
I20250120 12:18:19 3545703 dinov2 helpers.py:102] Training  [ 6410/12500]  eta: 0:24:08  loss: 20.3835 (23.9891)  lr: 0.0000 (0.0000)  time: 0.206986  data: 0.000507  max mem: 3586
I20250120 12:18:21 3545703 dinov2 helpers.py:102] Training  [ 6420/12500]  eta: 0:24:05  loss: 20.3835 (23.9869)  lr: 0.0000 (0.0000)  time: 0.207045  data: 0.000447  max mem: 3586
I20250120 12:18:23 3545703 dinov2 helpers.py:102] Training  [ 6430/12500]  eta: 0:24:02  loss: 20.3835 (23.9816)  lr: 0.0000 (0.0000)  time: 0.207224  data: 0.000471  max mem: 3586
I20250120 12:18:25 3545703 dinov2 helpers.py:102] Training  [ 6440/12500]  eta: 0:24:00  loss: 20.5521 (23.9793)  lr: 0.0000 (0.0000)  time: 0.207235  data: 0.000511  max mem: 3586
I20250120 12:18:27 3545703 dinov2 helpers.py:102] Training  [ 6450/12500]  eta: 0:23:57  loss: 21.2409 (23.9751)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000447  max mem: 3586
I20250120 12:18:29 3545703 dinov2 helpers.py:102] Training  [ 6460/12500]  eta: 0:23:54  loss: 21.2409 (23.9670)  lr: 0.0000 (0.0000)  time: 0.207045  data: 0.000444  max mem: 3586
I20250120 12:18:31 3545703 dinov2 helpers.py:102] Training  [ 6470/12500]  eta: 0:23:52  loss: 21.2409 (23.9575)  lr: 0.0000 (0.0000)  time: 0.207205  data: 0.000488  max mem: 3586
I20250120 12:18:33 3545703 dinov2 helpers.py:102] Training  [ 6480/12500]  eta: 0:23:49  loss: 20.5521 (23.9461)  lr: 0.0000 (0.0000)  time: 0.207312  data: 0.000500  max mem: 3586
I20250120 12:18:35 3545703 dinov2 helpers.py:102] Training  [ 6490/12500]  eta: 0:23:46  loss: 20.5521 (23.9387)  lr: 0.0000 (0.0000)  time: 0.207175  data: 0.000508  max mem: 3586
I20250120 12:18:38 3545703 dinov2 helpers.py:102] Training  [ 6500/12500]  eta: 0:23:44  loss: 21.2409 (23.9377)  lr: 0.0000 (0.0000)  time: 0.207285  data: 0.000515  max mem: 3586
I20250120 12:18:40 3545703 dinov2 helpers.py:102] Training  [ 6510/12500]  eta: 0:23:41  loss: 21.4084 (23.9363)  lr: 0.0000 (0.0000)  time: 0.207367  data: 0.000467  max mem: 3586
I20250120 12:18:42 3545703 dinov2 helpers.py:102] Training  [ 6520/12500]  eta: 0:23:38  loss: 21.2409 (23.9313)  lr: 0.0000 (0.0000)  time: 0.207312  data: 0.000403  max mem: 3586
I20250120 12:18:44 3545703 dinov2 helpers.py:102] Training  [ 6530/12500]  eta: 0:23:36  loss: 21.2409 (23.9304)  lr: 0.0000 (0.0000)  time: 0.207239  data: 0.000435  max mem: 3586
I20250120 12:18:46 3545703 dinov2 helpers.py:102] Training  [ 6540/12500]  eta: 0:23:33  loss: 20.6223 (23.9244)  lr: 0.0000 (0.0000)  time: 0.207254  data: 0.000507  max mem: 3586
I20250120 12:18:48 3545703 dinov2 helpers.py:102] Training  [ 6550/12500]  eta: 0:23:30  loss: 21.2409 (23.9251)  lr: 0.0000 (0.0000)  time: 0.207329  data: 0.000515  max mem: 3586
I20250120 12:18:50 3545703 dinov2 helpers.py:102] Training  [ 6560/12500]  eta: 0:23:28  loss: 21.2409 (23.9161)  lr: 0.0000 (0.0000)  time: 0.207261  data: 0.000514  max mem: 3586
I20250120 12:18:52 3545703 dinov2 helpers.py:102] Training  [ 6570/12500]  eta: 0:23:25  loss: 20.6223 (23.9089)  lr: 0.0000 (0.0000)  time: 0.207279  data: 0.000467  max mem: 3586
I20250120 12:18:54 3545703 dinov2 helpers.py:102] Training  [ 6580/12500]  eta: 0:23:23  loss: 21.2409 (23.9060)  lr: 0.0000 (0.0000)  time: 0.207184  data: 0.000421  max mem: 3586
I20250120 12:18:56 3545703 dinov2 helpers.py:102] Training  [ 6590/12500]  eta: 0:23:20  loss: 20.6223 (23.8953)  lr: 0.0000 (0.0000)  time: 0.207138  data: 0.000473  max mem: 3586
I20250120 12:18:58 3545703 dinov2 helpers.py:102] Training  [ 6600/12500]  eta: 0:23:17  loss: 20.6223 (23.8918)  lr: 0.0000 (0.0000)  time: 0.207340  data: 0.000488  max mem: 3586
I20250120 12:19:00 3545703 dinov2 helpers.py:102] Training  [ 6610/12500]  eta: 0:23:15  loss: 20.5521 (23.8850)  lr: 0.0000 (0.0000)  time: 0.207471  data: 0.000465  max mem: 3586
I20250120 12:19:02 3545703 dinov2 helpers.py:102] Training  [ 6620/12500]  eta: 0:23:12  loss: 20.5521 (23.8845)  lr: 0.0000 (0.0000)  time: 0.207359  data: 0.000458  max mem: 3586
I20250120 12:19:04 3545703 dinov2 helpers.py:102] Training  [ 6630/12500]  eta: 0:23:09  loss: 20.0045 (23.8780)  lr: 0.0000 (0.0000)  time: 0.207213  data: 0.000493  max mem: 3586
I20250120 12:19:07 3545703 dinov2 helpers.py:102] Training  [ 6640/12500]  eta: 0:23:07  loss: 19.5732 (23.8708)  lr: 0.0000 (0.0000)  time: 0.207174  data: 0.000518  max mem: 3586
I20250120 12:19:09 3545703 dinov2 helpers.py:102] Training  [ 6650/12500]  eta: 0:23:04  loss: 19.3634 (23.8624)  lr: 0.0000 (0.0000)  time: 0.207229  data: 0.000476  max mem: 3586
I20250120 12:19:11 3545703 dinov2 helpers.py:102] Training  [ 6660/12500]  eta: 0:23:02  loss: 19.5732 (23.8592)  lr: 0.0000 (0.0000)  time: 0.207137  data: 0.000478  max mem: 3586
I20250120 12:19:13 3545703 dinov2 helpers.py:102] Training  [ 6670/12500]  eta: 0:22:59  loss: 19.5732 (23.8491)  lr: 0.0000 (0.0000)  time: 0.207176  data: 0.000443  max mem: 3586
I20250120 12:19:15 3545703 dinov2 helpers.py:102] Training  [ 6680/12500]  eta: 0:22:56  loss: 19.5732 (23.8389)  lr: 0.0000 (0.0000)  time: 0.207419  data: 0.000432  max mem: 3586
I20250120 12:19:17 3545703 dinov2 helpers.py:102] Training  [ 6690/12500]  eta: 0:22:54  loss: 20.0045 (23.8373)  lr: 0.0000 (0.0000)  time: 0.207483  data: 0.000488  max mem: 3586
I20250120 12:19:19 3545703 dinov2 helpers.py:102] Training  [ 6700/12500]  eta: 0:22:51  loss: 20.0045 (23.8318)  lr: 0.0000 (0.0000)  time: 0.207376  data: 0.000443  max mem: 3586
I20250120 12:19:21 3545703 dinov2 helpers.py:102] Training  [ 6710/12500]  eta: 0:22:48  loss: 19.5732 (23.8191)  lr: 0.0000 (0.0000)  time: 0.207410  data: 0.000415  max mem: 3586
I20250120 12:19:23 3545703 dinov2 helpers.py:102] Training  [ 6720/12500]  eta: 0:22:46  loss: 19.5732 (23.8182)  lr: 0.0000 (0.0000)  time: 0.207339  data: 0.000469  max mem: 3586
I20250120 12:19:25 3545703 dinov2 helpers.py:102] Training  [ 6730/12500]  eta: 0:22:43  loss: 19.5732 (23.8140)  lr: 0.0000 (0.0000)  time: 0.207410  data: 0.000516  max mem: 3586
I20250120 12:19:27 3545703 dinov2 helpers.py:102] Training  [ 6740/12500]  eta: 0:22:41  loss: 19.3634 (23.8051)  lr: 0.0000 (0.0000)  time: 0.207405  data: 0.000535  max mem: 3586
I20250120 12:19:29 3545703 dinov2 helpers.py:102] Training  [ 6750/12500]  eta: 0:22:38  loss: 19.3634 (23.8032)  lr: 0.0000 (0.0000)  time: 0.207087  data: 0.000513  max mem: 3586
I20250120 12:19:31 3545703 dinov2 helpers.py:102] Training  [ 6760/12500]  eta: 0:22:35  loss: 19.3634 (23.7952)  lr: 0.0000 (0.0000)  time: 0.207404  data: 0.000477  max mem: 3586
I20250120 12:19:34 3545703 dinov2 helpers.py:102] Training  [ 6770/12500]  eta: 0:22:33  loss: 19.3634 (23.7832)  lr: 0.0000 (0.0000)  time: 0.207729  data: 0.000418  max mem: 3586
I20250120 12:19:36 3545703 dinov2 helpers.py:102] Training  [ 6780/12500]  eta: 0:22:30  loss: 19.0463 (23.7701)  lr: 0.0000 (0.0000)  time: 0.207598  data: 0.000435  max mem: 3586
I20250120 12:19:38 3545703 dinov2 helpers.py:102] Training  [ 6790/12500]  eta: 0:22:28  loss: 19.0463 (23.7587)  lr: 0.0000 (0.0000)  time: 0.207586  data: 0.000500  max mem: 3586
I20250120 12:19:40 3545703 dinov2 helpers.py:102] Training  [ 6800/12500]  eta: 0:22:25  loss: 19.0463 (23.7534)  lr: 0.0000 (0.0000)  time: 0.207609  data: 0.000510  max mem: 3586
I20250120 12:19:42 3545703 dinov2 helpers.py:102] Training  [ 6810/12500]  eta: 0:22:22  loss: 19.0463 (23.7492)  lr: 0.0000 (0.0000)  time: 0.207562  data: 0.000536  max mem: 3586
I20250120 12:19:44 3545703 dinov2 helpers.py:102] Training  [ 6820/12500]  eta: 0:22:20  loss: 19.0463 (23.7438)  lr: 0.0000 (0.0000)  time: 0.207531  data: 0.000504  max mem: 3586
I20250120 12:19:46 3545703 dinov2 helpers.py:102] Training  [ 6830/12500]  eta: 0:22:17  loss: 18.4053 (23.7355)  lr: 0.0000 (0.0000)  time: 0.207577  data: 0.000485  max mem: 3586
I20250120 12:19:48 3545703 dinov2 helpers.py:102] Training  [ 6840/12500]  eta: 0:22:15  loss: 18.4053 (23.7363)  lr: 0.0000 (0.0000)  time: 0.207596  data: 0.000451  max mem: 3586
I20250120 12:19:50 3545703 dinov2 helpers.py:102] Training  [ 6850/12500]  eta: 0:22:12  loss: 18.4053 (23.7251)  lr: 0.0000 (0.0000)  time: 0.207677  data: 0.000427  max mem: 3586
I20250120 12:19:52 3545703 dinov2 helpers.py:102] Training  [ 6860/12500]  eta: 0:22:09  loss: 18.4053 (23.7218)  lr: 0.0000 (0.0000)  time: 0.207660  data: 0.000463  max mem: 3586
I20250120 12:19:54 3545703 dinov2 helpers.py:102] Training  [ 6870/12500]  eta: 0:22:07  loss: 18.4053 (23.7129)  lr: 0.0000 (0.0000)  time: 0.207407  data: 0.000465  max mem: 3586
I20250120 12:19:56 3545703 dinov2 helpers.py:102] Training  [ 6880/12500]  eta: 0:22:04  loss: 19.8454 (23.7073)  lr: 0.0000 (0.0000)  time: 0.207602  data: 0.000484  max mem: 3586
I20250120 12:19:58 3545703 dinov2 helpers.py:102] Training  [ 6890/12500]  eta: 0:22:02  loss: 19.8454 (23.7030)  lr: 0.0000 (0.0000)  time: 0.207638  data: 0.000496  max mem: 3586
I20250120 12:20:01 3545703 dinov2 helpers.py:102] Training  [ 6900/12500]  eta: 0:21:59  loss: 18.4053 (23.6917)  lr: 0.0000 (0.0000)  time: 0.207441  data: 0.000495  max mem: 3586
I20250120 12:20:03 3545703 dinov2 helpers.py:102] Training  [ 6910/12500]  eta: 0:21:56  loss: 18.4915 (23.6842)  lr: 0.0000 (0.0000)  time: 0.207513  data: 0.000456  max mem: 3586
I20250120 12:20:05 3545703 dinov2 helpers.py:102] Training  [ 6920/12500]  eta: 0:21:54  loss: 18.4915 (23.6843)  lr: 0.0000 (0.0000)  time: 0.207858  data: 0.000469  max mem: 3586
I20250120 12:20:07 3545703 dinov2 helpers.py:102] Training  [ 6930/12500]  eta: 0:21:51  loss: 18.4915 (23.6840)  lr: 0.0000 (0.0000)  time: 0.208096  data: 0.000504  max mem: 3586
I20250120 12:20:09 3545703 dinov2 helpers.py:102] Training  [ 6940/12500]  eta: 0:21:49  loss: 19.8454 (23.6793)  lr: 0.0000 (0.0000)  time: 0.207927  data: 0.000491  max mem: 3586
I20250120 12:20:11 3545703 dinov2 helpers.py:102] Training  [ 6950/12500]  eta: 0:21:46  loss: 18.8289 (23.6723)  lr: 0.0000 (0.0000)  time: 0.207852  data: 0.000513  max mem: 3586
I20250120 12:20:13 3545703 dinov2 helpers.py:102] Training  [ 6960/12500]  eta: 0:21:44  loss: 18.8289 (23.6642)  lr: 0.0000 (0.0000)  time: 0.207753  data: 0.000504  max mem: 3586
I20250120 12:20:15 3545703 dinov2 helpers.py:102] Training  [ 6970/12500]  eta: 0:21:41  loss: 18.8289 (23.6565)  lr: 0.0000 (0.0000)  time: 0.207847  data: 0.000447  max mem: 3586
I20250120 12:20:17 3545703 dinov2 helpers.py:102] Training  [ 6980/12500]  eta: 0:21:38  loss: 19.6009 (23.6507)  lr: 0.0000 (0.0000)  time: 0.207900  data: 0.000467  max mem: 3586
I20250120 12:20:19 3545703 dinov2 helpers.py:102] Training  [ 6990/12500]  eta: 0:21:36  loss: 19.8454 (23.6469)  lr: 0.0000 (0.0000)  time: 0.207637  data: 0.000472  max mem: 3586
I20250120 12:20:21 3545703 dinov2 helpers.py:102] Training  [ 7000/12500]  eta: 0:21:33  loss: 19.6278 (23.6412)  lr: 0.0000 (0.0000)  time: 0.207752  data: 0.000432  max mem: 3586
I20250120 12:20:23 3545703 dinov2 helpers.py:102] Training  [ 7010/12500]  eta: 0:21:31  loss: 19.6009 (23.6330)  lr: 0.0000 (0.0000)  time: 0.207650  data: 0.000458  max mem: 3586
I20250120 12:20:25 3545703 dinov2 helpers.py:102] Training  [ 7020/12500]  eta: 0:21:28  loss: 19.6009 (23.6273)  lr: 0.0000 (0.0000)  time: 0.207760  data: 0.000504  max mem: 3586
I20250120 12:20:28 3545703 dinov2 helpers.py:102] Training  [ 7030/12500]  eta: 0:21:26  loss: 19.6009 (23.6172)  lr: 0.0000 (0.0000)  time: 0.208020  data: 0.000492  max mem: 3586
I20250120 12:20:30 3545703 dinov2 helpers.py:102] Training  [ 7040/12500]  eta: 0:21:23  loss: 18.8289 (23.6059)  lr: 0.0000 (0.0000)  time: 0.207926  data: 0.000426  max mem: 3586
I20250120 12:20:32 3545703 dinov2 helpers.py:102] Training  [ 7050/12500]  eta: 0:21:20  loss: 18.8289 (23.5972)  lr: 0.0000 (0.0000)  time: 0.207975  data: 0.000433  max mem: 3586
I20250120 12:20:34 3545703 dinov2 helpers.py:102] Training  [ 7060/12500]  eta: 0:21:18  loss: 18.8289 (23.5973)  lr: 0.0000 (0.0000)  time: 0.207703  data: 0.000466  max mem: 3586
I20250120 12:20:36 3545703 dinov2 helpers.py:102] Training  [ 7070/12500]  eta: 0:21:15  loss: 19.6009 (23.5947)  lr: 0.0000 (0.0000)  time: 0.207800  data: 0.000480  max mem: 3586
I20250120 12:20:38 3545703 dinov2 helpers.py:102] Training  [ 7080/12500]  eta: 0:21:13  loss: 19.6009 (23.5903)  lr: 0.0000 (0.0000)  time: 0.207860  data: 0.000484  max mem: 3586
I20250120 12:20:40 3545703 dinov2 helpers.py:102] Training  [ 7090/12500]  eta: 0:21:10  loss: 18.8289 (23.5821)  lr: 0.0000 (0.0000)  time: 0.207563  data: 0.000510  max mem: 3586
I20250120 12:20:42 3545703 dinov2 helpers.py:102] Training  [ 7100/12500]  eta: 0:21:08  loss: 18.8289 (23.5733)  lr: 0.0000 (0.0000)  time: 0.207585  data: 0.000528  max mem: 3586
I20250120 12:20:44 3545703 dinov2 helpers.py:102] Training  [ 7110/12500]  eta: 0:21:05  loss: 19.1425 (23.5671)  lr: 0.0000 (0.0000)  time: 0.207716  data: 0.000503  max mem: 3586
I20250120 12:20:46 3545703 dinov2 helpers.py:102] Training  [ 7120/12500]  eta: 0:21:03  loss: 19.1425 (23.5617)  lr: 0.0000 (0.0000)  time: 0.207912  data: 0.000485  max mem: 3586
I20250120 12:20:48 3545703 dinov2 helpers.py:102] Training  [ 7130/12500]  eta: 0:21:00  loss: 19.1196 (23.5555)  lr: 0.0000 (0.0000)  time: 0.207967  data: 0.000475  max mem: 3586
I20250120 12:20:50 3545703 dinov2 helpers.py:102] Training  [ 7140/12500]  eta: 0:20:57  loss: 18.8289 (23.5428)  lr: 0.0000 (0.0000)  time: 0.207887  data: 0.000457  max mem: 3586
I20250120 12:20:52 3545703 dinov2 helpers.py:102] Training  [ 7150/12500]  eta: 0:20:55  loss: 18.3210 (23.5329)  lr: 0.0000 (0.0000)  time: 0.207838  data: 0.000466  max mem: 3586
I20250120 12:20:55 3545703 dinov2 helpers.py:102] Training  [ 7160/12500]  eta: 0:20:52  loss: 18.3210 (23.5252)  lr: 0.0000 (0.0000)  time: 0.207859  data: 0.000501  max mem: 3586
I20250120 12:20:57 3545703 dinov2 helpers.py:102] Training  [ 7170/12500]  eta: 0:20:50  loss: 19.1196 (23.5262)  lr: 0.0000 (0.0000)  time: 0.207969  data: 0.000475  max mem: 3586
I20250120 12:20:59 3545703 dinov2 helpers.py:102] Training  [ 7180/12500]  eta: 0:20:47  loss: 17.9543 (23.5176)  lr: 0.0000 (0.0000)  time: 0.208049  data: 0.000493  max mem: 3586
I20250120 12:21:01 3545703 dinov2 helpers.py:102] Training  [ 7190/12500]  eta: 0:20:45  loss: 17.9543 (23.5107)  lr: 0.0000 (0.0000)  time: 0.208039  data: 0.000525  max mem: 3586
I20250120 12:21:03 3545703 dinov2 helpers.py:102] Training  [ 7200/12500]  eta: 0:20:42  loss: 17.9543 (23.5124)  lr: 0.0000 (0.0000)  time: 0.208123  data: 0.000483  max mem: 3586
I20250120 12:21:05 3545703 dinov2 helpers.py:102] Training  [ 7210/12500]  eta: 0:20:40  loss: 18.0352 (23.5048)  lr: 0.0000 (0.0000)  time: 0.208084  data: 0.000448  max mem: 3586
I20250120 12:21:07 3545703 dinov2 helpers.py:102] Training  [ 7220/12500]  eta: 0:20:37  loss: 18.0352 (23.5030)  lr: 0.0000 (0.0000)  time: 0.208019  data: 0.000442  max mem: 3586
I20250120 12:21:09 3545703 dinov2 helpers.py:102] Training  [ 7230/12500]  eta: 0:20:35  loss: 18.0352 (23.4905)  lr: 0.0000 (0.0000)  time: 0.207984  data: 0.000438  max mem: 3586
I20250120 12:21:11 3545703 dinov2 helpers.py:102] Training  [ 7240/12500]  eta: 0:20:32  loss: 18.5498 (23.4879)  lr: 0.0000 (0.0000)  time: 0.207984  data: 0.000448  max mem: 3586
I20250120 12:21:13 3545703 dinov2 helpers.py:102] Training  [ 7250/12500]  eta: 0:20:30  loss: 18.5498 (23.4810)  lr: 0.0000 (0.0000)  time: 0.208008  data: 0.000446  max mem: 3586
I20250120 12:21:15 3545703 dinov2 helpers.py:102] Training  [ 7260/12500]  eta: 0:20:27  loss: 18.5498 (23.4812)  lr: 0.0000 (0.0000)  time: 0.208174  data: 0.000418  max mem: 3586
I20250120 12:21:17 3545703 dinov2 helpers.py:102] Training  [ 7270/12500]  eta: 0:20:24  loss: 18.4561 (23.4743)  lr: 0.0000 (0.0000)  time: 0.208532  data: 0.000431  max mem: 3586
I20250120 12:21:20 3545703 dinov2 helpers.py:102] Training  [ 7280/12500]  eta: 0:20:22  loss: 18.4352 (23.4616)  lr: 0.0000 (0.0000)  time: 0.208332  data: 0.000453  max mem: 3586
I20250120 12:21:22 3545703 dinov2 helpers.py:102] Training  [ 7290/12500]  eta: 0:20:19  loss: 18.4352 (23.4545)  lr: 0.0000 (0.0000)  time: 0.208086  data: 0.000499  max mem: 3586
I20250120 12:21:24 3545703 dinov2 helpers.py:102] Training  [ 7300/12500]  eta: 0:20:17  loss: 18.4561 (23.4495)  lr: 0.0000 (0.0000)  time: 0.207997  data: 0.000548  max mem: 3586
I20250120 12:21:26 3545703 dinov2 helpers.py:102] Training  [ 7310/12500]  eta: 0:20:14  loss: 18.4561 (23.4506)  lr: 0.0000 (0.0000)  time: 0.208034  data: 0.000440  max mem: 3586
I20250120 12:21:28 3545703 dinov2 helpers.py:102] Training  [ 7320/12500]  eta: 0:20:12  loss: 18.4561 (23.4496)  lr: 0.0000 (0.0000)  time: 0.208193  data: 0.000407  max mem: 3586
I20250120 12:21:30 3545703 dinov2 helpers.py:102] Training  [ 7330/12500]  eta: 0:20:09  loss: 18.4561 (23.4457)  lr: 0.0000 (0.0000)  time: 0.207981  data: 0.000489  max mem: 3586
I20250120 12:21:32 3545703 dinov2 helpers.py:102] Training  [ 7340/12500]  eta: 0:20:07  loss: 18.4561 (23.4374)  lr: 0.0000 (0.0000)  time: 0.208036  data: 0.000500  max mem: 3586
I20250120 12:21:34 3545703 dinov2 helpers.py:102] Training  [ 7350/12500]  eta: 0:20:04  loss: 18.4561 (23.4281)  lr: 0.0000 (0.0000)  time: 0.208395  data: 0.000508  max mem: 3586
I20250120 12:21:36 3545703 dinov2 helpers.py:102] Training  [ 7360/12500]  eta: 0:20:02  loss: 18.4561 (23.4208)  lr: 0.0000 (0.0000)  time: 0.208366  data: 0.000493  max mem: 3586
I20250120 12:21:38 3545703 dinov2 helpers.py:102] Training  [ 7370/12500]  eta: 0:19:59  loss: 18.4561 (23.4218)  lr: 0.0000 (0.0000)  time: 0.208008  data: 0.000443  max mem: 3586
I20250120 12:21:40 3545703 dinov2 helpers.py:102] Training  [ 7380/12500]  eta: 0:19:57  loss: 18.5498 (23.4214)  lr: 0.0000 (0.0000)  time: 0.207784  data: 0.000450  max mem: 3586
I20250120 12:21:42 3545703 dinov2 helpers.py:102] Training  [ 7390/12500]  eta: 0:19:54  loss: 18.4561 (23.4140)  lr: 0.0000 (0.0000)  time: 0.207812  data: 0.000481  max mem: 3586
I20250120 12:21:45 3545703 dinov2 helpers.py:102] Training  [ 7400/12500]  eta: 0:19:52  loss: 18.4561 (23.4076)  lr: 0.0000 (0.0000)  time: 0.207744  data: 0.000455  max mem: 3586
I20250120 12:21:47 3545703 dinov2 helpers.py:102] Training  [ 7410/12500]  eta: 0:19:49  loss: 18.6422 (23.4047)  lr: 0.0000 (0.0000)  time: 0.207689  data: 0.000447  max mem: 3586
I20250120 12:21:49 3545703 dinov2 helpers.py:102] Training  [ 7420/12500]  eta: 0:19:47  loss: 18.4561 (23.3956)  lr: 0.0000 (0.0000)  time: 0.207906  data: 0.000436  max mem: 3586
I20250120 12:21:51 3545703 dinov2 helpers.py:102] Training  [ 7430/12500]  eta: 0:19:44  loss: 18.6422 (23.3920)  lr: 0.0000 (0.0000)  time: 0.208067  data: 0.000429  max mem: 3586
I20250120 12:21:53 3545703 dinov2 helpers.py:102] Training  [ 7440/12500]  eta: 0:19:42  loss: 18.6422 (23.3893)  lr: 0.0000 (0.0000)  time: 0.208101  data: 0.000489  max mem: 3586
I20250120 12:21:55 3545703 dinov2 helpers.py:102] Training  [ 7450/12500]  eta: 0:19:39  loss: 18.6422 (23.3806)  lr: 0.0000 (0.0000)  time: 0.208186  data: 0.000476  max mem: 3586
I20250120 12:21:57 3545703 dinov2 helpers.py:102] Training  [ 7460/12500]  eta: 0:19:37  loss: 18.6012 (23.3742)  lr: 0.0000 (0.0000)  time: 0.208292  data: 0.000364  max mem: 3586
I20250120 12:21:59 3545703 dinov2 helpers.py:102] Training  [ 7470/12500]  eta: 0:19:34  loss: 18.6012 (23.3670)  lr: 0.0000 (0.0000)  time: 0.208501  data: 0.000390  max mem: 3586
I20250120 12:22:01 3545703 dinov2 helpers.py:102] Training  [ 7480/12500]  eta: 0:19:32  loss: 18.6422 (23.3645)  lr: 0.0000 (0.0000)  time: 0.208318  data: 0.000392  max mem: 3586
I20250120 12:22:03 3545703 dinov2 helpers.py:102] Training  [ 7490/12500]  eta: 0:19:29  loss: 19.7797 (23.3656)  lr: 0.0000 (0.0000)  time: 0.208080  data: 0.000414  max mem: 3586
I20250120 12:22:05 3545703 dinov2 linear.py:272] running validation !
I20250120 12:22:07 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:50    time: 1.486060  data: 1.268768  max mem: 3586
I20250120 12:22:09 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.328341  data: 0.116581  max mem: 3586
I20250120 12:22:11 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.213674  data: 0.001116  max mem: 3586
I20250120 12:22:13 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212785  data: 0.000578  max mem: 3586
I20250120 12:22:15 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.210505  data: 0.000312  max mem: 3586
I20250120 12:22:17 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.210243  data: 0.000307  max mem: 3586
I20250120 12:22:19 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210485  data: 0.000263  max mem: 3586
I20250120 12:22:21 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210231  data: 0.000251  max mem: 3586
I20250120 12:22:24 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.209980  data: 0.000258  max mem: 3586
I20250120 12:22:26 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210147  data: 0.000260  max mem: 3586
I20250120 12:22:28 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210064  data: 0.000260  max mem: 3586
I20250120 12:22:30 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210087  data: 0.000248  max mem: 3586
I20250120 12:22:32 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210368  data: 0.000232  max mem: 3586
I20250120 12:22:34 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210683  data: 0.000255  max mem: 3586
I20250120 12:22:36 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210299  data: 0.000256  max mem: 3586
I20250120 12:22:38 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209740  data: 0.000176  max mem: 3586
I20250120 12:22:39 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205778  data: 0.000161  max mem: 3586
I20250120 12:22:39 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.219329 s / it)
I20250120 12:22:39 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:22:39 3545703 dinov2 linear.py:287] 
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8551, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8644, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8675, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8727, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8738, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8757, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8773, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8775, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8760, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8658, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8576, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8565, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8640, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8707, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8744, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8772, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8799, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8831, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8840, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8819, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8780, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8663, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8638, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8710, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8764, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8773, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8791, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8745, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8675, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8729, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8418, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8292, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8665, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8735, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8770, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8779, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8808, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8830, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8833, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8803, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8778, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8770, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8455, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8276, device='cuda:0')}
I20250120 12:22:39 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8839935064315796}
I20250120 12:22:39 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:22:39 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:22:39 3545703 dinov2 helpers.py:102] Training  [ 7500/12500]  eta: 0:19:49  loss: 18.6422 (23.3577)  lr: 0.0000 (0.0000)  time: 1.912345  data: 0.000461  max mem: 3586
I20250120 12:22:41 3545703 dinov2 helpers.py:102] Training  [ 7510/12500]  eta: 0:19:47  loss: 18.6012 (23.3461)  lr: 0.0000 (0.0000)  time: 1.911012  data: 0.000454  max mem: 3586
I20250120 12:22:44 3545703 dinov2 helpers.py:102] Training  [ 7520/12500]  eta: 0:19:44  loss: 18.6012 (23.3432)  lr: 0.0000 (0.0000)  time: 0.206148  data: 0.000455  max mem: 3586
I20250120 12:22:46 3545703 dinov2 helpers.py:102] Training  [ 7530/12500]  eta: 0:19:42  loss: 18.6012 (23.3428)  lr: 0.0000 (0.0000)  time: 0.206898  data: 0.000455  max mem: 3586
I20250120 12:22:48 3545703 dinov2 helpers.py:102] Training  [ 7540/12500]  eta: 0:19:39  loss: 18.6012 (23.3341)  lr: 0.0000 (0.0000)  time: 0.206972  data: 0.000489  max mem: 3586
I20250120 12:22:50 3545703 dinov2 helpers.py:102] Training  [ 7550/12500]  eta: 0:19:36  loss: 18.6422 (23.3282)  lr: 0.0000 (0.0000)  time: 0.207187  data: 0.000465  max mem: 3586
I20250120 12:22:52 3545703 dinov2 helpers.py:102] Training  [ 7560/12500]  eta: 0:19:34  loss: 18.8500 (23.3256)  lr: 0.0000 (0.0000)  time: 0.207329  data: 0.000453  max mem: 3586
I20250120 12:22:54 3545703 dinov2 helpers.py:102] Training  [ 7570/12500]  eta: 0:19:31  loss: 18.6422 (23.3184)  lr: 0.0000 (0.0000)  time: 0.207123  data: 0.000436  max mem: 3586
I20250120 12:22:56 3545703 dinov2 helpers.py:102] Training  [ 7580/12500]  eta: 0:19:29  loss: 18.6422 (23.3145)  lr: 0.0000 (0.0000)  time: 0.207303  data: 0.000423  max mem: 3586
I20250120 12:22:59 3545703 dinov2 helpers.py:102] Training  [ 7590/12500]  eta: 0:19:26  loss: 18.6422 (23.3007)  lr: 0.0000 (0.0000)  time: 0.231815  data: 0.028342  max mem: 3586
I20250120 12:23:01 3545703 dinov2 helpers.py:102] Training  [ 7600/12500]  eta: 0:19:24  loss: 18.6012 (23.2938)  lr: 0.0000 (0.0000)  time: 0.231420  data: 0.028326  max mem: 3586
I20250120 12:23:03 3545703 dinov2 helpers.py:102] Training  [ 7610/12500]  eta: 0:19:21  loss: 18.6012 (23.2900)  lr: 0.0000 (0.0000)  time: 0.206834  data: 0.000419  max mem: 3586
I20250120 12:23:05 3545703 dinov2 helpers.py:102] Training  [ 7620/12500]  eta: 0:19:19  loss: 18.8500 (23.2861)  lr: 0.0000 (0.0000)  time: 0.207049  data: 0.000463  max mem: 3586
I20250120 12:23:07 3545703 dinov2 helpers.py:102] Training  [ 7630/12500]  eta: 0:19:16  loss: 18.8500 (23.2826)  lr: 0.0000 (0.0000)  time: 0.207220  data: 0.000469  max mem: 3586
I20250120 12:23:09 3545703 dinov2 helpers.py:102] Training  [ 7640/12500]  eta: 0:19:14  loss: 18.6012 (23.2749)  lr: 0.0000 (0.0000)  time: 0.207083  data: 0.000467  max mem: 3586
I20250120 12:23:11 3545703 dinov2 helpers.py:102] Training  [ 7650/12500]  eta: 0:19:11  loss: 18.6012 (23.2608)  lr: 0.0000 (0.0000)  time: 0.207202  data: 0.000483  max mem: 3586
I20250120 12:23:13 3545703 dinov2 helpers.py:102] Training  [ 7660/12500]  eta: 0:19:08  loss: 18.8500 (23.2610)  lr: 0.0000 (0.0000)  time: 0.207347  data: 0.000492  max mem: 3586
I20250120 12:23:15 3545703 dinov2 helpers.py:102] Training  [ 7670/12500]  eta: 0:19:06  loss: 20.2511 (23.2645)  lr: 0.0000 (0.0000)  time: 0.207079  data: 0.000472  max mem: 3586
I20250120 12:23:17 3545703 dinov2 helpers.py:102] Training  [ 7680/12500]  eta: 0:19:03  loss: 19.2112 (23.2593)  lr: 0.0000 (0.0000)  time: 0.207313  data: 0.000490  max mem: 3586
I20250120 12:23:19 3545703 dinov2 helpers.py:102] Training  [ 7690/12500]  eta: 0:19:01  loss: 18.8500 (23.2456)  lr: 0.0000 (0.0000)  time: 0.207684  data: 0.000490  max mem: 3586
I20250120 12:23:21 3545703 dinov2 helpers.py:102] Training  [ 7700/12500]  eta: 0:18:58  loss: 18.8500 (23.2374)  lr: 0.0000 (0.0000)  time: 0.207713  data: 0.000472  max mem: 3586
I20250120 12:23:23 3545703 dinov2 helpers.py:102] Training  [ 7710/12500]  eta: 0:18:56  loss: 18.8500 (23.2313)  lr: 0.0000 (0.0000)  time: 0.207574  data: 0.000482  max mem: 3586
I20250120 12:23:25 3545703 dinov2 helpers.py:102] Training  [ 7720/12500]  eta: 0:18:53  loss: 18.8500 (23.2264)  lr: 0.0000 (0.0000)  time: 0.207416  data: 0.000485  max mem: 3586
I20250120 12:23:28 3545703 dinov2 helpers.py:102] Training  [ 7730/12500]  eta: 0:18:51  loss: 18.8500 (23.2209)  lr: 0.0000 (0.0000)  time: 0.207414  data: 0.000447  max mem: 3586
I20250120 12:23:30 3545703 dinov2 helpers.py:102] Training  [ 7740/12500]  eta: 0:18:48  loss: 18.8500 (23.2104)  lr: 0.0000 (0.0000)  time: 0.207408  data: 0.000372  max mem: 3586
I20250120 12:23:32 3545703 dinov2 helpers.py:102] Training  [ 7750/12500]  eta: 0:18:45  loss: 18.5528 (23.1995)  lr: 0.0000 (0.0000)  time: 0.207509  data: 0.000404  max mem: 3586
I20250120 12:23:34 3545703 dinov2 helpers.py:102] Training  [ 7760/12500]  eta: 0:18:43  loss: 18.5528 (23.1936)  lr: 0.0000 (0.0000)  time: 0.207648  data: 0.000469  max mem: 3586
I20250120 12:23:36 3545703 dinov2 helpers.py:102] Training  [ 7770/12500]  eta: 0:18:40  loss: 18.6482 (23.1903)  lr: 0.0000 (0.0000)  time: 0.207781  data: 0.000495  max mem: 3586
I20250120 12:23:38 3545703 dinov2 helpers.py:102] Training  [ 7780/12500]  eta: 0:18:38  loss: 18.5528 (23.1838)  lr: 0.0000 (0.0000)  time: 0.207841  data: 0.000489  max mem: 3586
I20250120 12:23:40 3545703 dinov2 helpers.py:102] Training  [ 7790/12500]  eta: 0:18:35  loss: 18.5528 (23.1744)  lr: 0.0000 (0.0000)  time: 0.207799  data: 0.000468  max mem: 3586
I20250120 12:23:42 3545703 dinov2 helpers.py:102] Training  [ 7800/12500]  eta: 0:18:33  loss: 18.6482 (23.1706)  lr: 0.0000 (0.0000)  time: 0.207614  data: 0.000467  max mem: 3586
I20250120 12:23:44 3545703 dinov2 helpers.py:102] Training  [ 7810/12500]  eta: 0:18:30  loss: 18.5528 (23.1624)  lr: 0.0000 (0.0000)  time: 0.207642  data: 0.000432  max mem: 3586
I20250120 12:23:46 3545703 dinov2 helpers.py:102] Training  [ 7820/12500]  eta: 0:18:28  loss: 18.5528 (23.1623)  lr: 0.0000 (0.0000)  time: 0.207578  data: 0.000406  max mem: 3586
I20250120 12:23:48 3545703 dinov2 helpers.py:102] Training  [ 7830/12500]  eta: 0:18:25  loss: 18.1057 (23.1526)  lr: 0.0000 (0.0000)  time: 0.207443  data: 0.000452  max mem: 3586
I20250120 12:23:50 3545703 dinov2 helpers.py:102] Training  [ 7840/12500]  eta: 0:18:23  loss: 18.1057 (23.1433)  lr: 0.0000 (0.0000)  time: 0.207525  data: 0.000479  max mem: 3586
I20250120 12:23:52 3545703 dinov2 helpers.py:102] Training  [ 7850/12500]  eta: 0:18:20  loss: 18.1057 (23.1354)  lr: 0.0000 (0.0000)  time: 0.207535  data: 0.000471  max mem: 3586
I20250120 12:23:55 3545703 dinov2 helpers.py:102] Training  [ 7860/12500]  eta: 0:18:17  loss: 18.1057 (23.1336)  lr: 0.0000 (0.0000)  time: 0.207566  data: 0.000464  max mem: 3586
I20250120 12:23:57 3545703 dinov2 helpers.py:102] Training  [ 7870/12500]  eta: 0:18:15  loss: 18.1057 (23.1284)  lr: 0.0000 (0.0000)  time: 0.207453  data: 0.000436  max mem: 3586
I20250120 12:23:59 3545703 dinov2 helpers.py:102] Training  [ 7880/12500]  eta: 0:18:12  loss: 18.1057 (23.1224)  lr: 0.0000 (0.0000)  time: 0.207643  data: 0.000384  max mem: 3586
I20250120 12:24:01 3545703 dinov2 helpers.py:102] Training  [ 7890/12500]  eta: 0:18:10  loss: 18.1057 (23.1114)  lr: 0.0000 (0.0000)  time: 0.207767  data: 0.000416  max mem: 3586
I20250120 12:24:06 3545703 dinov2 helpers.py:102] Training  [ 7900/12500]  eta: 0:18:09  loss: 18.1057 (23.1045)  lr: 0.0000 (0.0000)  time: 0.372782  data: 0.172994  max mem: 3586
I20250120 12:24:09 3545703 dinov2 helpers.py:102] Training  [ 7910/12500]  eta: 0:18:07  loss: 18.1057 (23.0989)  lr: 0.0000 (0.0000)  time: 0.415837  data: 0.237551  max mem: 3586
I20250120 12:24:11 3545703 dinov2 helpers.py:102] Training  [ 7920/12500]  eta: 0:18:05  loss: 18.1057 (23.0983)  lr: 0.0000 (0.0000)  time: 0.250301  data: 0.065692  max mem: 3586
I20250120 12:24:13 3545703 dinov2 helpers.py:102] Training  [ 7930/12500]  eta: 0:18:02  loss: 18.1057 (23.0947)  lr: 0.0000 (0.0000)  time: 0.206777  data: 0.001121  max mem: 3586
I20250120 12:24:15 3545703 dinov2 helpers.py:102] Training  [ 7940/12500]  eta: 0:18:00  loss: 18.4049 (23.0891)  lr: 0.0000 (0.0000)  time: 0.206682  data: 0.000464  max mem: 3586
I20250120 12:24:17 3545703 dinov2 helpers.py:102] Training  [ 7950/12500]  eta: 0:17:57  loss: 18.6482 (23.0846)  lr: 0.0000 (0.0000)  time: 0.206950  data: 0.000488  max mem: 3586
I20250120 12:24:19 3545703 dinov2 helpers.py:102] Training  [ 7960/12500]  eta: 0:17:54  loss: 18.4049 (23.0748)  lr: 0.0000 (0.0000)  time: 0.207191  data: 0.000418  max mem: 3586
I20250120 12:24:22 3545703 dinov2 helpers.py:102] Training  [ 7970/12500]  eta: 0:17:52  loss: 18.4049 (23.0724)  lr: 0.0000 (0.0000)  time: 0.207221  data: 0.000360  max mem: 3586
I20250120 12:24:24 3545703 dinov2 helpers.py:102] Training  [ 7980/12500]  eta: 0:17:49  loss: 18.6789 (23.0687)  lr: 0.0000 (0.0000)  time: 0.207462  data: 0.000444  max mem: 3586
I20250120 12:24:26 3545703 dinov2 helpers.py:102] Training  [ 7990/12500]  eta: 0:17:47  loss: 18.6789 (23.0618)  lr: 0.0000 (0.0000)  time: 0.207788  data: 0.000466  max mem: 3586
I20250120 12:24:28 3545703 dinov2 helpers.py:102] Training  [ 8000/12500]  eta: 0:17:44  loss: 18.4280 (23.0560)  lr: 0.0000 (0.0000)  time: 0.207969  data: 0.000436  max mem: 3586
I20250120 12:24:30 3545703 dinov2 helpers.py:102] Training  [ 8010/12500]  eta: 0:17:42  loss: 18.6789 (23.0509)  lr: 0.0000 (0.0000)  time: 0.208160  data: 0.000467  max mem: 3586
I20250120 12:24:32 3545703 dinov2 helpers.py:102] Training  [ 8020/12500]  eta: 0:17:39  loss: 18.6789 (23.0501)  lr: 0.0000 (0.0000)  time: 0.208267  data: 0.000500  max mem: 3586
I20250120 12:24:34 3545703 dinov2 helpers.py:102] Training  [ 8030/12500]  eta: 0:17:37  loss: 18.7006 (23.0476)  lr: 0.0000 (0.0000)  time: 0.208324  data: 0.000468  max mem: 3586
I20250120 12:24:36 3545703 dinov2 helpers.py:102] Training  [ 8040/12500]  eta: 0:17:34  loss: 18.7006 (23.0408)  lr: 0.0000 (0.0000)  time: 0.208670  data: 0.000445  max mem: 3586
I20250120 12:24:38 3545703 dinov2 helpers.py:102] Training  [ 8050/12500]  eta: 0:17:32  loss: 18.9787 (23.0372)  lr: 0.0000 (0.0000)  time: 0.208870  data: 0.000527  max mem: 3586
I20250120 12:24:40 3545703 dinov2 helpers.py:102] Training  [ 8060/12500]  eta: 0:17:29  loss: 18.9787 (23.0323)  lr: 0.0000 (0.0000)  time: 0.208919  data: 0.000552  max mem: 3586
I20250120 12:24:42 3545703 dinov2 helpers.py:102] Training  [ 8070/12500]  eta: 0:17:27  loss: 18.7006 (23.0260)  lr: 0.0000 (0.0000)  time: 0.208852  data: 0.000481  max mem: 3586
I20250120 12:24:44 3545703 dinov2 helpers.py:102] Training  [ 8080/12500]  eta: 0:17:24  loss: 18.7006 (23.0190)  lr: 0.0000 (0.0000)  time: 0.208750  data: 0.000440  max mem: 3586
I20250120 12:24:47 3545703 dinov2 helpers.py:102] Training  [ 8090/12500]  eta: 0:17:22  loss: 18.7006 (23.0131)  lr: 0.0000 (0.0000)  time: 0.208966  data: 0.000442  max mem: 3586
I20250120 12:24:49 3545703 dinov2 helpers.py:102] Training  [ 8100/12500]  eta: 0:17:19  loss: 18.9787 (23.0158)  lr: 0.0000 (0.0000)  time: 0.209083  data: 0.000445  max mem: 3586
I20250120 12:24:51 3545703 dinov2 helpers.py:102] Training  [ 8110/12500]  eta: 0:17:17  loss: 18.9787 (23.0092)  lr: 0.0000 (0.0000)  time: 0.209098  data: 0.000469  max mem: 3586
I20250120 12:24:53 3545703 dinov2 helpers.py:102] Training  [ 8120/12500]  eta: 0:17:14  loss: 18.6789 (23.0001)  lr: 0.0000 (0.0000)  time: 0.208975  data: 0.000480  max mem: 3586
I20250120 12:24:55 3545703 dinov2 helpers.py:102] Training  [ 8130/12500]  eta: 0:17:12  loss: 18.6789 (22.9988)  lr: 0.0000 (0.0000)  time: 0.208988  data: 0.000499  max mem: 3586
I20250120 12:24:57 3545703 dinov2 helpers.py:102] Training  [ 8140/12500]  eta: 0:17:09  loss: 18.9787 (22.9951)  lr: 0.0000 (0.0000)  time: 0.209140  data: 0.000525  max mem: 3586
I20250120 12:24:59 3545703 dinov2 helpers.py:102] Training  [ 8150/12500]  eta: 0:17:07  loss: 18.4280 (22.9880)  lr: 0.0000 (0.0000)  time: 0.208997  data: 0.000476  max mem: 3586
I20250120 12:25:01 3545703 dinov2 helpers.py:102] Training  [ 8160/12500]  eta: 0:17:04  loss: 18.9787 (22.9874)  lr: 0.0000 (0.0000)  time: 0.208872  data: 0.000432  max mem: 3586
I20250120 12:25:03 3545703 dinov2 helpers.py:102] Training  [ 8170/12500]  eta: 0:17:02  loss: 18.4280 (22.9784)  lr: 0.0000 (0.0000)  time: 0.209027  data: 0.000430  max mem: 3586
I20250120 12:25:05 3545703 dinov2 helpers.py:102] Training  [ 8180/12500]  eta: 0:16:59  loss: 18.4280 (22.9732)  lr: 0.0000 (0.0000)  time: 0.209186  data: 0.000470  max mem: 3586
I20250120 12:25:07 3545703 dinov2 helpers.py:102] Training  [ 8190/12500]  eta: 0:16:57  loss: 18.6918 (22.9720)  lr: 0.0000 (0.0000)  time: 0.209257  data: 0.000495  max mem: 3586
I20250120 12:25:10 3545703 dinov2 helpers.py:102] Training  [ 8200/12500]  eta: 0:16:54  loss: 18.9787 (22.9720)  lr: 0.0000 (0.0000)  time: 0.209212  data: 0.000433  max mem: 3586
I20250120 12:25:12 3545703 dinov2 helpers.py:102] Training  [ 8210/12500]  eta: 0:16:52  loss: 18.6918 (22.9638)  lr: 0.0000 (0.0000)  time: 0.209110  data: 0.000368  max mem: 3586
I20250120 12:25:14 3545703 dinov2 helpers.py:102] Training  [ 8220/12500]  eta: 0:16:49  loss: 18.6918 (22.9610)  lr: 0.0000 (0.0000)  time: 0.209362  data: 0.000433  max mem: 3586
I20250120 12:25:16 3545703 dinov2 helpers.py:102] Training  [ 8230/12500]  eta: 0:16:47  loss: 18.2725 (22.9529)  lr: 0.0000 (0.0000)  time: 0.209290  data: 0.000508  max mem: 3586
I20250120 12:25:18 3545703 dinov2 helpers.py:102] Training  [ 8240/12500]  eta: 0:16:44  loss: 18.6918 (22.9511)  lr: 0.0000 (0.0000)  time: 0.209224  data: 0.000495  max mem: 3586
I20250120 12:25:20 3545703 dinov2 helpers.py:102] Training  [ 8250/12500]  eta: 0:16:42  loss: 18.6918 (22.9486)  lr: 0.0000 (0.0000)  time: 0.209541  data: 0.000510  max mem: 3586
I20250120 12:25:22 3545703 dinov2 helpers.py:102] Training  [ 8260/12500]  eta: 0:16:39  loss: 18.6918 (22.9443)  lr: 0.0000 (0.0000)  time: 0.209564  data: 0.000439  max mem: 3586
I20250120 12:25:24 3545703 dinov2 helpers.py:102] Training  [ 8270/12500]  eta: 0:16:37  loss: 18.6918 (22.9346)  lr: 0.0000 (0.0000)  time: 0.209496  data: 0.000405  max mem: 3586
I20250120 12:25:26 3545703 dinov2 helpers.py:102] Training  [ 8280/12500]  eta: 0:16:34  loss: 19.3454 (22.9329)  lr: 0.0000 (0.0000)  time: 0.209586  data: 0.000491  max mem: 3586
I20250120 12:25:28 3545703 dinov2 helpers.py:102] Training  [ 8290/12500]  eta: 0:16:32  loss: 19.9542 (22.9354)  lr: 0.0000 (0.0000)  time: 0.209626  data: 0.000504  max mem: 3586
I20250120 12:25:31 3545703 dinov2 helpers.py:102] Training  [ 8300/12500]  eta: 0:16:29  loss: 19.9542 (22.9344)  lr: 0.0000 (0.0000)  time: 0.209679  data: 0.000480  max mem: 3586
I20250120 12:25:33 3545703 dinov2 helpers.py:102] Training  [ 8310/12500]  eta: 0:16:27  loss: 19.9542 (22.9225)  lr: 0.0000 (0.0000)  time: 0.209752  data: 0.000517  max mem: 3586
I20250120 12:25:35 3545703 dinov2 helpers.py:102] Training  [ 8320/12500]  eta: 0:16:24  loss: 19.9542 (22.9153)  lr: 0.0000 (0.0000)  time: 0.209747  data: 0.000496  max mem: 3586
I20250120 12:25:37 3545703 dinov2 helpers.py:102] Training  [ 8330/12500]  eta: 0:16:22  loss: 19.9542 (22.9151)  lr: 0.0000 (0.0000)  time: 0.209664  data: 0.000448  max mem: 3586
I20250120 12:25:39 3545703 dinov2 helpers.py:102] Training  [ 8340/12500]  eta: 0:16:19  loss: 19.3454 (22.9107)  lr: 0.0000 (0.0000)  time: 0.209641  data: 0.000448  max mem: 3586
I20250120 12:25:41 3545703 dinov2 helpers.py:102] Training  [ 8350/12500]  eta: 0:16:17  loss: 19.3454 (22.9035)  lr: 0.0000 (0.0000)  time: 0.209795  data: 0.000469  max mem: 3586
I20250120 12:25:43 3545703 dinov2 helpers.py:102] Training  [ 8360/12500]  eta: 0:16:14  loss: 19.2114 (22.8938)  lr: 0.0000 (0.0000)  time: 0.209859  data: 0.000490  max mem: 3586
I20250120 12:25:45 3545703 dinov2 helpers.py:102] Training  [ 8370/12500]  eta: 0:16:12  loss: 19.3454 (22.8902)  lr: 0.0000 (0.0000)  time: 0.209996  data: 0.000457  max mem: 3586
I20250120 12:25:47 3545703 dinov2 helpers.py:102] Training  [ 8380/12500]  eta: 0:16:09  loss: 19.8454 (22.8869)  lr: 0.0000 (0.0000)  time: 0.210085  data: 0.000443  max mem: 3586
I20250120 12:25:49 3545703 dinov2 helpers.py:102] Training  [ 8390/12500]  eta: 0:16:07  loss: 19.3454 (22.8818)  lr: 0.0000 (0.0000)  time: 0.209905  data: 0.000463  max mem: 3586
I20250120 12:25:52 3545703 dinov2 helpers.py:102] Training  [ 8400/12500]  eta: 0:16:04  loss: 19.2114 (22.8745)  lr: 0.0000 (0.0000)  time: 0.209859  data: 0.000458  max mem: 3586
I20250120 12:25:54 3545703 dinov2 helpers.py:102] Training  [ 8410/12500]  eta: 0:16:02  loss: 19.2114 (22.8642)  lr: 0.0000 (0.0000)  time: 0.209915  data: 0.000461  max mem: 3586
I20250120 12:25:56 3545703 dinov2 helpers.py:102] Training  [ 8420/12500]  eta: 0:15:59  loss: 19.2114 (22.8605)  lr: 0.0000 (0.0000)  time: 0.209920  data: 0.000458  max mem: 3586
I20250120 12:25:58 3545703 dinov2 helpers.py:102] Training  [ 8430/12500]  eta: 0:15:57  loss: 19.3454 (22.8573)  lr: 0.0000 (0.0000)  time: 0.209830  data: 0.000472  max mem: 3586
I20250120 12:26:00 3545703 dinov2 helpers.py:102] Training  [ 8440/12500]  eta: 0:15:54  loss: 19.2114 (22.8475)  lr: 0.0000 (0.0000)  time: 0.209742  data: 0.000462  max mem: 3586
I20250120 12:26:02 3545703 dinov2 helpers.py:102] Training  [ 8450/12500]  eta: 0:15:52  loss: 18.6388 (22.8384)  lr: 0.0000 (0.0000)  time: 0.209802  data: 0.000412  max mem: 3586
I20250120 12:26:04 3545703 dinov2 helpers.py:102] Training  [ 8460/12500]  eta: 0:15:50  loss: 18.6388 (22.8363)  lr: 0.0000 (0.0000)  time: 0.209891  data: 0.000427  max mem: 3586
I20250120 12:26:06 3545703 dinov2 helpers.py:102] Training  [ 8470/12500]  eta: 0:15:47  loss: 18.6388 (22.8306)  lr: 0.0000 (0.0000)  time: 0.209915  data: 0.000479  max mem: 3586
I20250120 12:26:08 3545703 dinov2 helpers.py:102] Training  [ 8480/12500]  eta: 0:15:45  loss: 18.5492 (22.8256)  lr: 0.0000 (0.0000)  time: 0.209856  data: 0.000449  max mem: 3586
I20250120 12:26:10 3545703 dinov2 helpers.py:102] Training  [ 8490/12500]  eta: 0:15:42  loss: 18.0598 (22.8172)  lr: 0.0000 (0.0000)  time: 0.209837  data: 0.000402  max mem: 3586
I20250120 12:26:13 3545703 dinov2 helpers.py:102] Training  [ 8500/12500]  eta: 0:15:40  loss: 18.0598 (22.8157)  lr: 0.0000 (0.0000)  time: 0.209708  data: 0.000485  max mem: 3586
I20250120 12:26:15 3545703 dinov2 helpers.py:102] Training  [ 8510/12500]  eta: 0:15:37  loss: 18.0598 (22.8090)  lr: 0.0000 (0.0000)  time: 0.209638  data: 0.000472  max mem: 3586
I20250120 12:26:17 3545703 dinov2 helpers.py:102] Training  [ 8520/12500]  eta: 0:15:35  loss: 18.0598 (22.8002)  lr: 0.0000 (0.0000)  time: 0.209675  data: 0.000394  max mem: 3586
I20250120 12:26:19 3545703 dinov2 helpers.py:102] Training  [ 8530/12500]  eta: 0:15:32  loss: 18.0598 (22.7986)  lr: 0.0000 (0.0000)  time: 0.209636  data: 0.000417  max mem: 3586
I20250120 12:26:21 3545703 dinov2 helpers.py:102] Training  [ 8540/12500]  eta: 0:15:30  loss: 18.0598 (22.7932)  lr: 0.0000 (0.0000)  time: 0.209554  data: 0.000423  max mem: 3586
I20250120 12:26:23 3545703 dinov2 helpers.py:102] Training  [ 8550/12500]  eta: 0:15:27  loss: 18.0598 (22.7870)  lr: 0.0000 (0.0000)  time: 0.209460  data: 0.000430  max mem: 3586
I20250120 12:26:25 3545703 dinov2 helpers.py:102] Training  [ 8560/12500]  eta: 0:15:25  loss: 18.1350 (22.7838)  lr: 0.0000 (0.0000)  time: 0.209410  data: 0.000488  max mem: 3586
I20250120 12:26:27 3545703 dinov2 helpers.py:102] Training  [ 8570/12500]  eta: 0:15:22  loss: 18.0598 (22.7760)  lr: 0.0000 (0.0000)  time: 0.209570  data: 0.000490  max mem: 3586
I20250120 12:26:29 3545703 dinov2 helpers.py:102] Training  [ 8580/12500]  eta: 0:15:20  loss: 17.4573 (22.7668)  lr: 0.0000 (0.0000)  time: 0.209682  data: 0.000484  max mem: 3586
I20250120 12:26:31 3545703 dinov2 helpers.py:102] Training  [ 8590/12500]  eta: 0:15:17  loss: 17.1052 (22.7575)  lr: 0.0000 (0.0000)  time: 0.209523  data: 0.000494  max mem: 3586
I20250120 12:26:33 3545703 dinov2 helpers.py:102] Training  [ 8600/12500]  eta: 0:15:15  loss: 17.4573 (22.7555)  lr: 0.0000 (0.0000)  time: 0.209694  data: 0.000425  max mem: 3586
I20250120 12:26:36 3545703 dinov2 helpers.py:102] Training  [ 8610/12500]  eta: 0:15:13  loss: 17.4573 (22.7458)  lr: 0.0000 (0.0000)  time: 0.209665  data: 0.000391  max mem: 3586
I20250120 12:26:38 3545703 dinov2 helpers.py:102] Training  [ 8620/12500]  eta: 0:15:10  loss: 17.4573 (22.7408)  lr: 0.0000 (0.0000)  time: 0.209436  data: 0.000432  max mem: 3586
I20250120 12:26:40 3545703 dinov2 helpers.py:102] Training  [ 8630/12500]  eta: 0:15:08  loss: 17.4573 (22.7366)  lr: 0.0000 (0.0000)  time: 0.209478  data: 0.000435  max mem: 3586
I20250120 12:26:42 3545703 dinov2 helpers.py:102] Training  [ 8640/12500]  eta: 0:15:05  loss: 18.0598 (22.7419)  lr: 0.0000 (0.0000)  time: 0.209608  data: 0.000447  max mem: 3586
I20250120 12:26:44 3545703 dinov2 helpers.py:102] Training  [ 8650/12500]  eta: 0:15:03  loss: 18.1350 (22.7375)  lr: 0.0000 (0.0000)  time: 0.209525  data: 0.000488  max mem: 3586
I20250120 12:26:46 3545703 dinov2 helpers.py:102] Training  [ 8660/12500]  eta: 0:15:00  loss: 18.1350 (22.7331)  lr: 0.0000 (0.0000)  time: 0.209215  data: 0.000493  max mem: 3586
I20250120 12:26:48 3545703 dinov2 helpers.py:102] Training  [ 8670/12500]  eta: 0:14:58  loss: 18.1350 (22.7248)  lr: 0.0000 (0.0000)  time: 0.209319  data: 0.000467  max mem: 3586
I20250120 12:26:50 3545703 dinov2 helpers.py:102] Training  [ 8680/12500]  eta: 0:14:55  loss: 18.1350 (22.7200)  lr: 0.0000 (0.0000)  time: 0.209462  data: 0.000444  max mem: 3586
I20250120 12:26:52 3545703 dinov2 helpers.py:102] Training  [ 8690/12500]  eta: 0:14:53  loss: 18.1350 (22.7135)  lr: 0.0000 (0.0000)  time: 0.209481  data: 0.000398  max mem: 3586
I20250120 12:26:54 3545703 dinov2 helpers.py:102] Training  [ 8700/12500]  eta: 0:14:50  loss: 17.4573 (22.7029)  lr: 0.0000 (0.0000)  time: 0.209379  data: 0.000435  max mem: 3586
I20250120 12:26:57 3545703 dinov2 helpers.py:102] Training  [ 8710/12500]  eta: 0:14:48  loss: 17.4573 (22.6893)  lr: 0.0000 (0.0000)  time: 0.209367  data: 0.000493  max mem: 3586
I20250120 12:26:59 3545703 dinov2 helpers.py:102] Training  [ 8720/12500]  eta: 0:14:45  loss: 17.6235 (22.6835)  lr: 0.0000 (0.0000)  time: 0.209273  data: 0.000425  max mem: 3586
I20250120 12:27:01 3545703 dinov2 helpers.py:102] Training  [ 8730/12500]  eta: 0:14:43  loss: 17.6235 (22.6816)  lr: 0.0000 (0.0000)  time: 0.209217  data: 0.000440  max mem: 3586
I20250120 12:27:03 3545703 dinov2 helpers.py:102] Training  [ 8740/12500]  eta: 0:14:41  loss: 17.4573 (22.6718)  lr: 0.0000 (0.0000)  time: 0.209270  data: 0.000462  max mem: 3586
I20250120 12:27:05 3545703 dinov2 linear.py:272] running validation !
I20250120 12:27:06 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:47    time: 1.468078  data: 1.247796  max mem: 3586
I20250120 12:27:08 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.326919  data: 0.113857  max mem: 3586
I20250120 12:27:10 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.211747  data: 0.000511  max mem: 3586
I20250120 12:27:12 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.210114  data: 0.000405  max mem: 3586
I20250120 12:27:15 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209627  data: 0.000248  max mem: 3586
I20250120 12:27:17 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209866  data: 0.000231  max mem: 3586
I20250120 12:27:19 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.210037  data: 0.000248  max mem: 3586
I20250120 12:27:21 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209932  data: 0.000245  max mem: 3586
I20250120 12:27:23 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.209774  data: 0.000227  max mem: 3586
I20250120 12:27:25 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209885  data: 0.000242  max mem: 3586
I20250120 12:27:27 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.209767  data: 0.000274  max mem: 3586
I20250120 12:27:29 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.209687  data: 0.000258  max mem: 3586
I20250120 12:27:31 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209819  data: 0.000210  max mem: 3586
I20250120 12:27:33 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209869  data: 0.000228  max mem: 3586
I20250120 12:27:36 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209937  data: 0.000246  max mem: 3586
I20250120 12:27:38 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209396  data: 0.000190  max mem: 3586
I20250120 12:27:38 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205451  data: 0.000159  max mem: 3586
I20250120 12:27:39 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218516 s / it)
I20250120 12:27:39 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:27:39 3545703 dinov2 linear.py:287] 
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8563, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8653, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8682, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8723, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8754, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8763, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8783, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8780, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8763, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8743, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8691, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8571, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8642, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8709, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8770, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8837, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8844, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8852, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8842, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8797, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8643, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8710, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8759, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8775, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8802, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8805, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8801, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8811, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8714, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8577, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8524, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8669, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8762, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8785, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8805, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8817, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8843, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8860, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8874, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8689, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8662, device='cuda:0')}
I20250120 12:27:39 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.8874292373657227}
I20250120 12:27:39 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:27:39 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:27:39 3545703 dinov2 helpers.py:102] Training  [ 8750/12500]  eta: 0:14:53  loss: 17.6235 (22.6689)  lr: 0.0000 (0.0000)  time: 1.907304  data: 0.000413  max mem: 3586
I20250120 12:27:41 3545703 dinov2 helpers.py:102] Training  [ 8760/12500]  eta: 0:14:50  loss: 17.6235 (22.6655)  lr: 0.0000 (0.0000)  time: 1.905401  data: 0.000386  max mem: 3586
I20250120 12:27:43 3545703 dinov2 helpers.py:102] Training  [ 8770/12500]  eta: 0:14:48  loss: 17.6235 (22.6565)  lr: 0.0000 (0.0000)  time: 0.206016  data: 0.000438  max mem: 3586
I20250120 12:27:45 3545703 dinov2 helpers.py:102] Training  [ 8780/12500]  eta: 0:14:45  loss: 18.3574 (22.6516)  lr: 0.0000 (0.0000)  time: 0.206435  data: 0.000457  max mem: 3586
I20250120 12:27:47 3545703 dinov2 helpers.py:102] Training  [ 8790/12500]  eta: 0:14:43  loss: 18.4121 (22.6517)  lr: 0.0000 (0.0000)  time: 0.206299  data: 0.000470  max mem: 3586
I20250120 12:27:49 3545703 dinov2 helpers.py:102] Training  [ 8800/12500]  eta: 0:14:40  loss: 18.3574 (22.6436)  lr: 0.0000 (0.0000)  time: 0.206350  data: 0.000508  max mem: 3586
I20250120 12:27:51 3545703 dinov2 helpers.py:102] Training  [ 8810/12500]  eta: 0:14:38  loss: 18.4121 (22.6401)  lr: 0.0000 (0.0000)  time: 0.206341  data: 0.000479  max mem: 3586
I20250120 12:27:53 3545703 dinov2 helpers.py:102] Training  [ 8820/12500]  eta: 0:14:35  loss: 18.3574 (22.6350)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000435  max mem: 3586
I20250120 12:27:55 3545703 dinov2 helpers.py:102] Training  [ 8830/12500]  eta: 0:14:33  loss: 18.3574 (22.6316)  lr: 0.0000 (0.0000)  time: 0.206367  data: 0.000408  max mem: 3586
I20250120 12:27:57 3545703 dinov2 helpers.py:102] Training  [ 8840/12500]  eta: 0:14:30  loss: 18.1574 (22.6265)  lr: 0.0000 (0.0000)  time: 0.206406  data: 0.000396  max mem: 3586
I20250120 12:28:00 3545703 dinov2 helpers.py:102] Training  [ 8850/12500]  eta: 0:14:28  loss: 18.1574 (22.6227)  lr: 0.0000 (0.0000)  time: 0.230297  data: 0.027624  max mem: 3586
I20250120 12:28:02 3545703 dinov2 helpers.py:102] Training  [ 8860/12500]  eta: 0:14:25  loss: 18.0673 (22.6155)  lr: 0.0000 (0.0000)  time: 0.230090  data: 0.027654  max mem: 3586
I20250120 12:28:04 3545703 dinov2 helpers.py:102] Training  [ 8870/12500]  eta: 0:14:23  loss: 18.1574 (22.6132)  lr: 0.0000 (0.0000)  time: 0.206175  data: 0.000394  max mem: 3586
I20250120 12:28:06 3545703 dinov2 helpers.py:102] Training  [ 8880/12500]  eta: 0:14:20  loss: 18.1574 (22.6099)  lr: 0.0000 (0.0000)  time: 0.206086  data: 0.000399  max mem: 3586
I20250120 12:28:08 3545703 dinov2 helpers.py:102] Training  [ 8890/12500]  eta: 0:14:18  loss: 18.1574 (22.6028)  lr: 0.0000 (0.0000)  time: 0.206018  data: 0.000414  max mem: 3586
I20250120 12:28:10 3545703 dinov2 helpers.py:102] Training  [ 8900/12500]  eta: 0:14:15  loss: 18.1574 (22.5931)  lr: 0.0000 (0.0000)  time: 0.206279  data: 0.000378  max mem: 3586
I20250120 12:28:12 3545703 dinov2 helpers.py:102] Training  [ 8910/12500]  eta: 0:14:13  loss: 18.3574 (22.5892)  lr: 0.0000 (0.0000)  time: 0.206415  data: 0.000420  max mem: 3586
I20250120 12:28:14 3545703 dinov2 helpers.py:102] Training  [ 8920/12500]  eta: 0:14:10  loss: 19.0048 (22.5852)  lr: 0.0000 (0.0000)  time: 0.206155  data: 0.000459  max mem: 3586
I20250120 12:28:16 3545703 dinov2 helpers.py:102] Training  [ 8930/12500]  eta: 0:14:08  loss: 19.0048 (22.5857)  lr: 0.0000 (0.0000)  time: 0.205990  data: 0.000397  max mem: 3586
I20250120 12:28:19 3545703 dinov2 helpers.py:102] Training  [ 8940/12500]  eta: 0:14:05  loss: 19.0048 (22.5781)  lr: 0.0000 (0.0000)  time: 0.206062  data: 0.000392  max mem: 3586
I20250120 12:28:21 3545703 dinov2 helpers.py:102] Training  [ 8950/12500]  eta: 0:14:03  loss: 18.3574 (22.5719)  lr: 0.0000 (0.0000)  time: 0.206031  data: 0.000393  max mem: 3586
I20250120 12:28:23 3545703 dinov2 helpers.py:102] Training  [ 8960/12500]  eta: 0:14:00  loss: 18.3574 (22.5685)  lr: 0.0000 (0.0000)  time: 0.206044  data: 0.000348  max mem: 3586
I20250120 12:28:25 3545703 dinov2 helpers.py:102] Training  [ 8970/12500]  eta: 0:13:58  loss: 18.3574 (22.5627)  lr: 0.0000 (0.0000)  time: 0.206040  data: 0.000360  max mem: 3586
I20250120 12:28:27 3545703 dinov2 helpers.py:102] Training  [ 8980/12500]  eta: 0:13:55  loss: 18.1574 (22.5550)  lr: 0.0000 (0.0000)  time: 0.206072  data: 0.000414  max mem: 3586
I20250120 12:28:29 3545703 dinov2 helpers.py:102] Training  [ 8990/12500]  eta: 0:13:53  loss: 18.1574 (22.5502)  lr: 0.0000 (0.0000)  time: 0.206143  data: 0.000456  max mem: 3586
I20250120 12:28:31 3545703 dinov2 helpers.py:102] Training  [ 9000/12500]  eta: 0:13:50  loss: 18.1574 (22.5418)  lr: 0.0000 (0.0000)  time: 0.206168  data: 0.000429  max mem: 3586
I20250120 12:28:33 3545703 dinov2 helpers.py:102] Training  [ 9010/12500]  eta: 0:13:48  loss: 18.0673 (22.5363)  lr: 0.0000 (0.0000)  time: 0.206260  data: 0.000434  max mem: 3586
I20250120 12:28:35 3545703 dinov2 helpers.py:102] Training  [ 9020/12500]  eta: 0:13:45  loss: 18.0673 (22.5333)  lr: 0.0000 (0.0000)  time: 0.206067  data: 0.000430  max mem: 3586
I20250120 12:28:37 3545703 dinov2 helpers.py:102] Training  [ 9030/12500]  eta: 0:13:43  loss: 17.6004 (22.5253)  lr: 0.0000 (0.0000)  time: 0.206103  data: 0.000412  max mem: 3586
I20250120 12:28:39 3545703 dinov2 helpers.py:102] Training  [ 9040/12500]  eta: 0:13:40  loss: 17.6004 (22.5213)  lr: 0.0000 (0.0000)  time: 0.206227  data: 0.000440  max mem: 3586
I20250120 12:28:41 3545703 dinov2 helpers.py:102] Training  [ 9050/12500]  eta: 0:13:38  loss: 17.6004 (22.5176)  lr: 0.0000 (0.0000)  time: 0.205998  data: 0.000445  max mem: 3586
I20250120 12:28:43 3545703 dinov2 helpers.py:102] Training  [ 9060/12500]  eta: 0:13:35  loss: 17.6004 (22.5081)  lr: 0.0000 (0.0000)  time: 0.206191  data: 0.000410  max mem: 3586
I20250120 12:28:45 3545703 dinov2 helpers.py:102] Training  [ 9070/12500]  eta: 0:13:33  loss: 17.4302 (22.4988)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000371  max mem: 3586
I20250120 12:28:47 3545703 dinov2 helpers.py:102] Training  [ 9080/12500]  eta: 0:13:30  loss: 17.4302 (22.4958)  lr: 0.0000 (0.0000)  time: 0.206159  data: 0.000391  max mem: 3586
I20250120 12:28:49 3545703 dinov2 helpers.py:102] Training  [ 9090/12500]  eta: 0:13:28  loss: 17.4302 (22.4870)  lr: 0.0000 (0.0000)  time: 0.206034  data: 0.000379  max mem: 3586
I20250120 12:28:52 3545703 dinov2 helpers.py:102] Training  [ 9100/12500]  eta: 0:13:25  loss: 17.4302 (22.4789)  lr: 0.0000 (0.0000)  time: 0.206150  data: 0.000335  max mem: 3586
I20250120 12:28:54 3545703 dinov2 helpers.py:102] Training  [ 9110/12500]  eta: 0:13:23  loss: 17.4302 (22.4752)  lr: 0.0000 (0.0000)  time: 0.206044  data: 0.000348  max mem: 3586
I20250120 12:28:56 3545703 dinov2 helpers.py:102] Training  [ 9120/12500]  eta: 0:13:20  loss: 17.4302 (22.4726)  lr: 0.0000 (0.0000)  time: 0.205950  data: 0.000327  max mem: 3586
I20250120 12:28:58 3545703 dinov2 helpers.py:102] Training  [ 9130/12500]  eta: 0:13:18  loss: 17.0514 (22.4651)  lr: 0.0000 (0.0000)  time: 0.206031  data: 0.000382  max mem: 3586
I20250120 12:29:00 3545703 dinov2 helpers.py:102] Training  [ 9140/12500]  eta: 0:13:15  loss: 17.4302 (22.4613)  lr: 0.0000 (0.0000)  time: 0.205985  data: 0.000465  max mem: 3586
I20250120 12:29:02 3545703 dinov2 helpers.py:102] Training  [ 9150/12500]  eta: 0:13:13  loss: 17.4563 (22.4558)  lr: 0.0000 (0.0000)  time: 0.206115  data: 0.000466  max mem: 3586
I20250120 12:29:04 3545703 dinov2 helpers.py:102] Training  [ 9160/12500]  eta: 0:13:10  loss: 17.4563 (22.4506)  lr: 0.0000 (0.0000)  time: 0.205998  data: 0.000461  max mem: 3586
I20250120 12:29:06 3545703 dinov2 helpers.py:102] Training  [ 9170/12500]  eta: 0:13:08  loss: 17.6004 (22.4466)  lr: 0.0000 (0.0000)  time: 0.205903  data: 0.000471  max mem: 3586
I20250120 12:29:08 3545703 dinov2 helpers.py:102] Training  [ 9180/12500]  eta: 0:13:05  loss: 17.6004 (22.4413)  lr: 0.0000 (0.0000)  time: 0.206150  data: 0.000434  max mem: 3586
I20250120 12:29:10 3545703 dinov2 helpers.py:102] Training  [ 9190/12500]  eta: 0:13:03  loss: 17.6004 (22.4383)  lr: 0.0000 (0.0000)  time: 0.206197  data: 0.000385  max mem: 3586
I20250120 12:29:12 3545703 dinov2 helpers.py:102] Training  [ 9200/12500]  eta: 0:13:00  loss: 17.6004 (22.4328)  lr: 0.0000 (0.0000)  time: 0.206131  data: 0.000373  max mem: 3586
I20250120 12:29:14 3545703 dinov2 helpers.py:102] Training  [ 9210/12500]  eta: 0:12:58  loss: 17.5815 (22.4252)  lr: 0.0000 (0.0000)  time: 0.205936  data: 0.000384  max mem: 3586
I20250120 12:29:16 3545703 dinov2 helpers.py:102] Training  [ 9220/12500]  eta: 0:12:56  loss: 17.5815 (22.4209)  lr: 0.0000 (0.0000)  time: 0.205931  data: 0.000433  max mem: 3586
I20250120 12:29:18 3545703 dinov2 helpers.py:102] Training  [ 9230/12500]  eta: 0:12:53  loss: 17.6616 (22.4168)  lr: 0.0000 (0.0000)  time: 0.206136  data: 0.000417  max mem: 3586
I20250120 12:29:23 3545703 dinov2 helpers.py:102] Training  [ 9240/12500]  eta: 0:12:52  loss: 17.5815 (22.4104)  lr: 0.0000 (0.0000)  time: 0.334124  data: 0.132503  max mem: 3586
I20250120 12:29:27 3545703 dinov2 helpers.py:102] Training  [ 9250/12500]  eta: 0:12:50  loss: 17.5815 (22.4052)  lr: 0.0000 (0.0000)  time: 0.428237  data: 0.231809  max mem: 3586
I20250120 12:29:29 3545703 dinov2 helpers.py:102] Training  [ 9260/12500]  eta: 0:12:47  loss: 17.5815 (22.3997)  lr: 0.0000 (0.0000)  time: 0.298942  data: 0.100725  max mem: 3586
I20250120 12:29:31 3545703 dinov2 helpers.py:102] Training  [ 9270/12500]  eta: 0:12:45  loss: 17.5815 (22.3938)  lr: 0.0000 (0.0000)  time: 0.203538  data: 0.001434  max mem: 3586
I20250120 12:29:33 3545703 dinov2 helpers.py:102] Training  [ 9280/12500]  eta: 0:12:42  loss: 17.5815 (22.3890)  lr: 0.0000 (0.0000)  time: 0.203614  data: 0.000406  max mem: 3586
I20250120 12:29:35 3545703 dinov2 helpers.py:102] Training  [ 9290/12500]  eta: 0:12:40  loss: 17.5815 (22.3791)  lr: 0.0000 (0.0000)  time: 0.203920  data: 0.000400  max mem: 3586
I20250120 12:29:37 3545703 dinov2 helpers.py:102] Training  [ 9300/12500]  eta: 0:12:37  loss: 17.5815 (22.3728)  lr: 0.0000 (0.0000)  time: 0.204296  data: 0.000400  max mem: 3586
I20250120 12:29:39 3545703 dinov2 helpers.py:102] Training  [ 9310/12500]  eta: 0:12:35  loss: 17.5815 (22.3707)  lr: 0.0000 (0.0000)  time: 0.204252  data: 0.000376  max mem: 3586
I20250120 12:29:41 3545703 dinov2 helpers.py:102] Training  [ 9320/12500]  eta: 0:12:32  loss: 17.5815 (22.3657)  lr: 0.0000 (0.0000)  time: 0.204518  data: 0.000397  max mem: 3586
I20250120 12:29:43 3545703 dinov2 helpers.py:102] Training  [ 9330/12500]  eta: 0:12:30  loss: 17.5815 (22.3546)  lr: 0.0000 (0.0000)  time: 0.204789  data: 0.000433  max mem: 3586
I20250120 12:29:45 3545703 dinov2 helpers.py:102] Training  [ 9340/12500]  eta: 0:12:27  loss: 17.5815 (22.3503)  lr: 0.0000 (0.0000)  time: 0.205110  data: 0.000426  max mem: 3586
I20250120 12:29:47 3545703 dinov2 helpers.py:102] Training  [ 9350/12500]  eta: 0:12:25  loss: 17.5815 (22.3450)  lr: 0.0000 (0.0000)  time: 0.205494  data: 0.000417  max mem: 3586
I20250120 12:29:49 3545703 dinov2 helpers.py:102] Training  [ 9360/12500]  eta: 0:12:22  loss: 17.5815 (22.3417)  lr: 0.0000 (0.0000)  time: 0.205393  data: 0.000358  max mem: 3586
I20250120 12:29:51 3545703 dinov2 helpers.py:102] Training  [ 9370/12500]  eta: 0:12:20  loss: 17.3939 (22.3323)  lr: 0.0000 (0.0000)  time: 0.205652  data: 0.000378  max mem: 3586
I20250120 12:29:54 3545703 dinov2 helpers.py:102] Training  [ 9380/12500]  eta: 0:12:17  loss: 17.3574 (22.3242)  lr: 0.0000 (0.0000)  time: 0.205809  data: 0.000423  max mem: 3586
I20250120 12:29:56 3545703 dinov2 helpers.py:102] Training  [ 9390/12500]  eta: 0:12:15  loss: 17.3574 (22.3225)  lr: 0.0000 (0.0000)  time: 0.205755  data: 0.000405  max mem: 3586
I20250120 12:29:58 3545703 dinov2 helpers.py:102] Training  [ 9400/12500]  eta: 0:12:13  loss: 17.2964 (22.3133)  lr: 0.0000 (0.0000)  time: 0.205743  data: 0.000463  max mem: 3586
I20250120 12:30:00 3545703 dinov2 helpers.py:102] Training  [ 9410/12500]  eta: 0:12:10  loss: 17.3574 (22.3128)  lr: 0.0000 (0.0000)  time: 0.205586  data: 0.000484  max mem: 3586
I20250120 12:30:02 3545703 dinov2 helpers.py:102] Training  [ 9420/12500]  eta: 0:12:08  loss: 17.3574 (22.3096)  lr: 0.0000 (0.0000)  time: 0.205710  data: 0.000459  max mem: 3586
I20250120 12:30:04 3545703 dinov2 helpers.py:102] Training  [ 9430/12500]  eta: 0:12:05  loss: 17.3574 (22.3072)  lr: 0.0000 (0.0000)  time: 0.205711  data: 0.000423  max mem: 3586
I20250120 12:30:06 3545703 dinov2 helpers.py:102] Training  [ 9440/12500]  eta: 0:12:03  loss: 17.3574 (22.3005)  lr: 0.0000 (0.0000)  time: 0.205969  data: 0.000361  max mem: 3586
I20250120 12:30:08 3545703 dinov2 helpers.py:102] Training  [ 9450/12500]  eta: 0:12:00  loss: 17.3574 (22.2962)  lr: 0.0000 (0.0000)  time: 0.206185  data: 0.000371  max mem: 3586
I20250120 12:30:10 3545703 dinov2 helpers.py:102] Training  [ 9460/12500]  eta: 0:11:58  loss: 17.6525 (22.2929)  lr: 0.0000 (0.0000)  time: 0.205945  data: 0.000397  max mem: 3586
I20250120 12:30:12 3545703 dinov2 helpers.py:102] Training  [ 9470/12500]  eta: 0:11:55  loss: 17.9332 (22.2924)  lr: 0.0000 (0.0000)  time: 0.206053  data: 0.000439  max mem: 3586
I20250120 12:30:14 3545703 dinov2 helpers.py:102] Training  [ 9480/12500]  eta: 0:11:53  loss: 18.2209 (22.2895)  lr: 0.0000 (0.0000)  time: 0.206114  data: 0.000456  max mem: 3586
I20250120 12:30:16 3545703 dinov2 helpers.py:102] Training  [ 9490/12500]  eta: 0:11:50  loss: 18.3572 (22.2862)  lr: 0.0000 (0.0000)  time: 0.206087  data: 0.000423  max mem: 3586
I20250120 12:30:18 3545703 dinov2 helpers.py:102] Training  [ 9500/12500]  eta: 0:11:48  loss: 19.1344 (22.2862)  lr: 0.0000 (0.0000)  time: 0.206181  data: 0.000383  max mem: 3586
I20250120 12:30:20 3545703 dinov2 helpers.py:102] Training  [ 9510/12500]  eta: 0:11:45  loss: 18.3572 (22.2790)  lr: 0.0000 (0.0000)  time: 0.206331  data: 0.000409  max mem: 3586
I20250120 12:30:22 3545703 dinov2 helpers.py:102] Training  [ 9520/12500]  eta: 0:11:43  loss: 18.3572 (22.2742)  lr: 0.0000 (0.0000)  time: 0.206278  data: 0.000450  max mem: 3586
I20250120 12:30:24 3545703 dinov2 helpers.py:102] Training  [ 9530/12500]  eta: 0:11:41  loss: 18.3572 (22.2688)  lr: 0.0000 (0.0000)  time: 0.206028  data: 0.000443  max mem: 3586
I20250120 12:30:26 3545703 dinov2 helpers.py:102] Training  [ 9540/12500]  eta: 0:11:38  loss: 18.2209 (22.2643)  lr: 0.0000 (0.0000)  time: 0.206065  data: 0.000392  max mem: 3586
I20250120 12:30:29 3545703 dinov2 helpers.py:102] Training  [ 9550/12500]  eta: 0:11:36  loss: 19.1344 (22.2618)  lr: 0.0000 (0.0000)  time: 0.206187  data: 0.000359  max mem: 3586
I20250120 12:30:31 3545703 dinov2 helpers.py:102] Training  [ 9560/12500]  eta: 0:11:33  loss: 18.5249 (22.2579)  lr: 0.0000 (0.0000)  time: 0.206253  data: 0.000380  max mem: 3586
I20250120 12:30:33 3545703 dinov2 helpers.py:102] Training  [ 9570/12500]  eta: 0:11:31  loss: 18.5249 (22.2506)  lr: 0.0000 (0.0000)  time: 0.206253  data: 0.000418  max mem: 3586
I20250120 12:30:35 3545703 dinov2 helpers.py:102] Training  [ 9580/12500]  eta: 0:11:28  loss: 18.5249 (22.2456)  lr: 0.0000 (0.0000)  time: 0.206393  data: 0.000444  max mem: 3586
I20250120 12:30:37 3545703 dinov2 helpers.py:102] Training  [ 9590/12500]  eta: 0:11:26  loss: 18.5249 (22.2437)  lr: 0.0000 (0.0000)  time: 0.206471  data: 0.000457  max mem: 3586
I20250120 12:30:39 3545703 dinov2 helpers.py:102] Training  [ 9600/12500]  eta: 0:11:23  loss: 18.5249 (22.2394)  lr: 0.0000 (0.0000)  time: 0.206373  data: 0.000454  max mem: 3586
I20250120 12:30:41 3545703 dinov2 helpers.py:102] Training  [ 9610/12500]  eta: 0:11:21  loss: 18.5249 (22.2360)  lr: 0.0000 (0.0000)  time: 0.206340  data: 0.000441  max mem: 3586
I20250120 12:30:43 3545703 dinov2 helpers.py:102] Training  [ 9620/12500]  eta: 0:11:19  loss: 18.5249 (22.2330)  lr: 0.0000 (0.0000)  time: 0.206233  data: 0.000485  max mem: 3586
I20250120 12:30:45 3545703 dinov2 helpers.py:102] Training  [ 9630/12500]  eta: 0:11:16  loss: 18.2209 (22.2269)  lr: 0.0000 (0.0000)  time: 0.206390  data: 0.000407  max mem: 3586
I20250120 12:30:47 3545703 dinov2 helpers.py:102] Training  [ 9640/12500]  eta: 0:11:14  loss: 18.5249 (22.2242)  lr: 0.0000 (0.0000)  time: 0.206632  data: 0.000368  max mem: 3586
I20250120 12:30:49 3545703 dinov2 helpers.py:102] Training  [ 9650/12500]  eta: 0:11:11  loss: 18.5249 (22.2160)  lr: 0.0000 (0.0000)  time: 0.206538  data: 0.000427  max mem: 3586
I20250120 12:30:51 3545703 dinov2 helpers.py:102] Training  [ 9660/12500]  eta: 0:11:09  loss: 18.5249 (22.2148)  lr: 0.0000 (0.0000)  time: 0.206436  data: 0.000418  max mem: 3586
I20250120 12:30:53 3545703 dinov2 helpers.py:102] Training  [ 9670/12500]  eta: 0:11:06  loss: 18.5249 (22.2141)  lr: 0.0000 (0.0000)  time: 0.206607  data: 0.000389  max mem: 3586
I20250120 12:30:55 3545703 dinov2 helpers.py:102] Training  [ 9680/12500]  eta: 0:11:04  loss: 18.0787 (22.2090)  lr: 0.0000 (0.0000)  time: 0.206540  data: 0.000372  max mem: 3586
I20250120 12:30:57 3545703 dinov2 helpers.py:102] Training  [ 9690/12500]  eta: 0:11:01  loss: 17.9522 (22.2035)  lr: 0.0000 (0.0000)  time: 0.206320  data: 0.000371  max mem: 3586
I20250120 12:31:00 3545703 dinov2 helpers.py:102] Training  [ 9700/12500]  eta: 0:10:59  loss: 17.6163 (22.1986)  lr: 0.0000 (0.0000)  time: 0.206531  data: 0.000441  max mem: 3586
I20250120 12:31:02 3545703 dinov2 helpers.py:102] Training  [ 9710/12500]  eta: 0:10:57  loss: 17.9522 (22.1960)  lr: 0.0000 (0.0000)  time: 0.206731  data: 0.000482  max mem: 3586
I20250120 12:31:04 3545703 dinov2 helpers.py:102] Training  [ 9720/12500]  eta: 0:10:54  loss: 17.9522 (22.1886)  lr: 0.0000 (0.0000)  time: 0.206988  data: 0.000433  max mem: 3586
I20250120 12:31:06 3545703 dinov2 helpers.py:102] Training  [ 9730/12500]  eta: 0:10:52  loss: 17.9522 (22.1833)  lr: 0.0000 (0.0000)  time: 0.206985  data: 0.000425  max mem: 3586
I20250120 12:31:08 3545703 dinov2 helpers.py:102] Training  [ 9740/12500]  eta: 0:10:49  loss: 17.8709 (22.1789)  lr: 0.0000 (0.0000)  time: 0.206797  data: 0.000414  max mem: 3586
I20250120 12:31:10 3545703 dinov2 helpers.py:102] Training  [ 9750/12500]  eta: 0:10:47  loss: 17.4237 (22.1731)  lr: 0.0000 (0.0000)  time: 0.206669  data: 0.000434  max mem: 3586
I20250120 12:31:12 3545703 dinov2 helpers.py:102] Training  [ 9760/12500]  eta: 0:10:44  loss: 17.4042 (22.1662)  lr: 0.0000 (0.0000)  time: 0.206705  data: 0.000461  max mem: 3586
I20250120 12:31:14 3545703 dinov2 helpers.py:102] Training  [ 9770/12500]  eta: 0:10:42  loss: 17.4237 (22.1652)  lr: 0.0000 (0.0000)  time: 0.206860  data: 0.000426  max mem: 3586
I20250120 12:31:16 3545703 dinov2 helpers.py:102] Training  [ 9780/12500]  eta: 0:10:40  loss: 17.4042 (22.1556)  lr: 0.0000 (0.0000)  time: 0.206597  data: 0.000423  max mem: 3586
I20250120 12:31:18 3545703 dinov2 helpers.py:102] Training  [ 9790/12500]  eta: 0:10:37  loss: 17.4042 (22.1530)  lr: 0.0000 (0.0000)  time: 0.206459  data: 0.000464  max mem: 3586
I20250120 12:31:20 3545703 dinov2 helpers.py:102] Training  [ 9800/12500]  eta: 0:10:35  loss: 17.4042 (22.1487)  lr: 0.0000 (0.0000)  time: 0.206526  data: 0.000424  max mem: 3586
I20250120 12:31:22 3545703 dinov2 helpers.py:102] Training  [ 9810/12500]  eta: 0:10:32  loss: 17.4042 (22.1460)  lr: 0.0000 (0.0000)  time: 0.206611  data: 0.000398  max mem: 3586
I20250120 12:31:24 3545703 dinov2 helpers.py:102] Training  [ 9820/12500]  eta: 0:10:30  loss: 17.4042 (22.1452)  lr: 0.0000 (0.0000)  time: 0.206914  data: 0.000413  max mem: 3586
I20250120 12:31:26 3545703 dinov2 helpers.py:102] Training  [ 9830/12500]  eta: 0:10:27  loss: 17.8709 (22.1444)  lr: 0.0000 (0.0000)  time: 0.207008  data: 0.000394  max mem: 3586
I20250120 12:31:28 3545703 dinov2 helpers.py:102] Training  [ 9840/12500]  eta: 0:10:25  loss: 17.4042 (22.1390)  lr: 0.0000 (0.0000)  time: 0.206854  data: 0.000405  max mem: 3586
I20250120 12:31:31 3545703 dinov2 helpers.py:102] Training  [ 9850/12500]  eta: 0:10:23  loss: 17.8709 (22.1370)  lr: 0.0000 (0.0000)  time: 0.206951  data: 0.000410  max mem: 3586
I20250120 12:31:33 3545703 dinov2 helpers.py:102] Training  [ 9860/12500]  eta: 0:10:20  loss: 17.4042 (22.1299)  lr: 0.0000 (0.0000)  time: 0.206938  data: 0.000404  max mem: 3586
I20250120 12:31:35 3545703 dinov2 helpers.py:102] Training  [ 9870/12500]  eta: 0:10:18  loss: 17.2868 (22.1235)  lr: 0.0000 (0.0000)  time: 0.206984  data: 0.000420  max mem: 3586
I20250120 12:31:37 3545703 dinov2 helpers.py:102] Training  [ 9880/12500]  eta: 0:10:15  loss: 17.4042 (22.1191)  lr: 0.0000 (0.0000)  time: 0.207067  data: 0.000423  max mem: 3586
I20250120 12:31:39 3545703 dinov2 helpers.py:102] Training  [ 9890/12500]  eta: 0:10:13  loss: 17.7653 (22.1151)  lr: 0.0000 (0.0000)  time: 0.206912  data: 0.000454  max mem: 3586
I20250120 12:31:41 3545703 dinov2 helpers.py:102] Training  [ 9900/12500]  eta: 0:10:10  loss: 17.8709 (22.1148)  lr: 0.0000 (0.0000)  time: 0.206843  data: 0.000466  max mem: 3586
I20250120 12:31:43 3545703 dinov2 helpers.py:102] Training  [ 9910/12500]  eta: 0:10:08  loss: 17.8709 (22.1112)  lr: 0.0000 (0.0000)  time: 0.206929  data: 0.000435  max mem: 3586
I20250120 12:31:45 3545703 dinov2 helpers.py:102] Training  [ 9920/12500]  eta: 0:10:06  loss: 17.9710 (22.1074)  lr: 0.0000 (0.0000)  time: 0.206980  data: 0.000428  max mem: 3586
I20250120 12:31:47 3545703 dinov2 helpers.py:102] Training  [ 9930/12500]  eta: 0:10:03  loss: 18.1541 (22.1040)  lr: 0.0000 (0.0000)  time: 0.206996  data: 0.000429  max mem: 3586
I20250120 12:31:49 3545703 dinov2 helpers.py:102] Training  [ 9940/12500]  eta: 0:10:01  loss: 18.3176 (22.1024)  lr: 0.0000 (0.0000)  time: 0.207022  data: 0.000431  max mem: 3586
I20250120 12:31:51 3545703 dinov2 helpers.py:102] Training  [ 9950/12500]  eta: 0:09:58  loss: 18.6287 (22.1002)  lr: 0.0000 (0.0000)  time: 0.207140  data: 0.000434  max mem: 3586
I20250120 12:31:53 3545703 dinov2 helpers.py:102] Training  [ 9960/12500]  eta: 0:09:56  loss: 18.6287 (22.0959)  lr: 0.0000 (0.0000)  time: 0.207283  data: 0.000411  max mem: 3586
I20250120 12:31:55 3545703 dinov2 helpers.py:102] Training  [ 9970/12500]  eta: 0:09:53  loss: 18.3176 (22.0914)  lr: 0.0000 (0.0000)  time: 0.207084  data: 0.000383  max mem: 3586
I20250120 12:31:57 3545703 dinov2 helpers.py:102] Training  [ 9980/12500]  eta: 0:09:51  loss: 18.3176 (22.0870)  lr: 0.0000 (0.0000)  time: 0.206927  data: 0.000458  max mem: 3586
I20250120 12:32:00 3545703 dinov2 helpers.py:102] Training  [ 9990/12500]  eta: 0:09:49  loss: 18.3176 (22.0834)  lr: 0.0000 (0.0000)  time: 0.206921  data: 0.000444  max mem: 3586
I20250120 12:32:01 3545703 dinov2 linear.py:272] running validation !
I20250120 12:32:03 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:12    time: 1.629134  data: 1.423355  max mem: 3586
I20250120 12:32:05 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:49    time: 0.342645  data: 0.131057  max mem: 3586
I20250120 12:32:07 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.211470  data: 0.001073  max mem: 3586
I20250120 12:32:09 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.208884  data: 0.000276  max mem: 3586
I20250120 12:32:11 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.208720  data: 0.000265  max mem: 3586
I20250120 12:32:14 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209029  data: 0.000284  max mem: 3586
I20250120 12:32:16 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209157  data: 0.000231  max mem: 3586
I20250120 12:32:18 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209114  data: 0.000513  max mem: 3586
I20250120 12:32:20 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.209301  data: 0.000550  max mem: 3586
I20250120 12:32:22 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209220  data: 0.000232  max mem: 3586
I20250120 12:32:24 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208914  data: 0.000219  max mem: 3586
I20250120 12:32:26 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.208988  data: 0.000200  max mem: 3586
I20250120 12:32:28 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209137  data: 0.000206  max mem: 3586
I20250120 12:32:30 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209343  data: 0.000242  max mem: 3586
I20250120 12:32:32 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209771  data: 0.000244  max mem: 3586
I20250120 12:32:34 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208898  data: 0.000185  max mem: 3586
I20250120 12:32:35 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204390  data: 0.000145  max mem: 3586
I20250120 12:32:35 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218911 s / it)
I20250120 12:32:35 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:32:35 3545703 dinov2 linear.py:287] 
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8567, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8658, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8685, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8724, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8741, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8751, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8752, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8789, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8804, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8780, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8573, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8647, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8711, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8748, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8772, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8797, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8808, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8839, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8853, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8862, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8877, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8889, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8642, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8709, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8766, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8776, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8815, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8813, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8832, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8838, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8834, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8847, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8784, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8670, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8737, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8768, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8794, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8812, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8841, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8853, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8882, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8890, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8876, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8904, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8853, device='cuda:0')}
I20250120 12:32:35 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_02500', 'accuracy': 0.8903597593307495}
I20250120 12:32:36 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:32:36 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:32:36 3545703 dinov2 helpers.py:102] Training  [10000/12500]  eta: 0:09:55  loss: 18.3176 (22.0794)  lr: 0.0000 (0.0000)  time: 1.907875  data: 0.000433  max mem: 3586
I20250120 12:32:38 3545703 dinov2 helpers.py:102] Training  [10010/12500]  eta: 0:09:52  loss: 18.1541 (22.0737)  lr: 0.0000 (0.0000)  time: 1.906818  data: 0.000462  max mem: 3586
I20250120 12:32:40 3545703 dinov2 helpers.py:102] Training  [10020/12500]  eta: 0:09:50  loss: 18.1541 (22.0705)  lr: 0.0000 (0.0000)  time: 0.205128  data: 0.000414  max mem: 3586
I20250120 12:32:42 3545703 dinov2 helpers.py:102] Training  [10030/12500]  eta: 0:09:47  loss: 18.0825 (22.0633)  lr: 0.0000 (0.0000)  time: 0.205783  data: 0.000439  max mem: 3586
I20250120 12:32:44 3545703 dinov2 helpers.py:102] Training  [10040/12500]  eta: 0:09:45  loss: 18.1541 (22.0596)  lr: 0.0000 (0.0000)  time: 0.205776  data: 0.000472  max mem: 3586
I20250120 12:32:46 3545703 dinov2 helpers.py:102] Training  [10050/12500]  eta: 0:09:42  loss: 18.0825 (22.0548)  lr: 0.0000 (0.0000)  time: 0.205583  data: 0.000479  max mem: 3586
I20250120 12:32:48 3545703 dinov2 helpers.py:102] Training  [10060/12500]  eta: 0:09:40  loss: 18.1541 (22.0524)  lr: 0.0000 (0.0000)  time: 0.205809  data: 0.000436  max mem: 3586
I20250120 12:32:50 3545703 dinov2 helpers.py:102] Training  [10070/12500]  eta: 0:09:37  loss: 18.3176 (22.0507)  lr: 0.0000 (0.0000)  time: 0.205553  data: 0.000375  max mem: 3586
I20250120 12:32:52 3545703 dinov2 helpers.py:102] Training  [10080/12500]  eta: 0:09:35  loss: 18.3543 (22.0470)  lr: 0.0000 (0.0000)  time: 0.205488  data: 0.000422  max mem: 3586
I20250120 12:32:54 3545703 dinov2 helpers.py:102] Training  [10090/12500]  eta: 0:09:33  loss: 18.3543 (22.0425)  lr: 0.0000 (0.0000)  time: 0.205846  data: 0.000440  max mem: 3586
I20250120 12:32:56 3545703 dinov2 helpers.py:102] Training  [10100/12500]  eta: 0:09:30  loss: 18.3176 (22.0357)  lr: 0.0000 (0.0000)  time: 0.205897  data: 0.000401  max mem: 3586
I20250120 12:32:58 3545703 dinov2 helpers.py:102] Training  [10110/12500]  eta: 0:09:28  loss: 18.0825 (22.0283)  lr: 0.0000 (0.0000)  time: 0.205762  data: 0.000425  max mem: 3586
I20250120 12:33:01 3545703 dinov2 helpers.py:102] Training  [10120/12500]  eta: 0:09:25  loss: 18.0825 (22.0275)  lr: 0.0000 (0.0000)  time: 0.229668  data: 0.027746  max mem: 3586
I20250120 12:33:03 3545703 dinov2 helpers.py:102] Training  [10130/12500]  eta: 0:09:23  loss: 17.7615 (22.0219)  lr: 0.0000 (0.0000)  time: 0.229548  data: 0.027708  max mem: 3586
I20250120 12:33:05 3545703 dinov2 helpers.py:102] Training  [10140/12500]  eta: 0:09:20  loss: 17.6977 (22.0172)  lr: 0.0000 (0.0000)  time: 0.205385  data: 0.000396  max mem: 3586
I20250120 12:33:07 3545703 dinov2 helpers.py:102] Training  [10150/12500]  eta: 0:09:18  loss: 17.6365 (22.0122)  lr: 0.0000 (0.0000)  time: 0.205339  data: 0.000424  max mem: 3586
I20250120 12:33:09 3545703 dinov2 helpers.py:102] Training  [10160/12500]  eta: 0:09:16  loss: 17.6365 (22.0086)  lr: 0.0000 (0.0000)  time: 0.205436  data: 0.000444  max mem: 3586
I20250120 12:33:11 3545703 dinov2 helpers.py:102] Training  [10170/12500]  eta: 0:09:13  loss: 17.6977 (22.0052)  lr: 0.0000 (0.0000)  time: 0.205546  data: 0.000438  max mem: 3586
I20250120 12:33:13 3545703 dinov2 helpers.py:102] Training  [10180/12500]  eta: 0:09:11  loss: 17.4633 (21.9990)  lr: 0.0000 (0.0000)  time: 0.205510  data: 0.000402  max mem: 3586
I20250120 12:33:15 3545703 dinov2 helpers.py:102] Training  [10190/12500]  eta: 0:09:08  loss: 17.2501 (21.9937)  lr: 0.0000 (0.0000)  time: 0.205562  data: 0.000382  max mem: 3586
I20250120 12:33:17 3545703 dinov2 helpers.py:102] Training  [10200/12500]  eta: 0:09:06  loss: 17.1955 (21.9861)  lr: 0.0000 (0.0000)  time: 0.205570  data: 0.000409  max mem: 3586
I20250120 12:33:19 3545703 dinov2 helpers.py:102] Training  [10210/12500]  eta: 0:09:03  loss: 17.2501 (21.9831)  lr: 0.0000 (0.0000)  time: 0.205743  data: 0.000461  max mem: 3586
I20250120 12:33:21 3545703 dinov2 helpers.py:102] Training  [10220/12500]  eta: 0:09:01  loss: 17.1955 (21.9775)  lr: 0.0000 (0.0000)  time: 0.205859  data: 0.000417  max mem: 3586
I20250120 12:33:23 3545703 dinov2 helpers.py:102] Training  [10230/12500]  eta: 0:08:58  loss: 17.1955 (21.9722)  lr: 0.0000 (0.0000)  time: 0.205738  data: 0.000417  max mem: 3586
I20250120 12:33:25 3545703 dinov2 helpers.py:102] Training  [10240/12500]  eta: 0:08:56  loss: 17.1955 (21.9698)  lr: 0.0000 (0.0000)  time: 0.205685  data: 0.000450  max mem: 3586
I20250120 12:33:28 3545703 dinov2 helpers.py:102] Training  [10250/12500]  eta: 0:08:53  loss: 17.2501 (21.9661)  lr: 0.0000 (0.0000)  time: 0.205610  data: 0.000425  max mem: 3586
I20250120 12:33:30 3545703 dinov2 helpers.py:102] Training  [10260/12500]  eta: 0:08:51  loss: 17.2501 (21.9623)  lr: 0.0000 (0.0000)  time: 0.205769  data: 0.000413  max mem: 3586
I20250120 12:33:32 3545703 dinov2 helpers.py:102] Training  [10270/12500]  eta: 0:08:49  loss: 17.2501 (21.9589)  lr: 0.0000 (0.0000)  time: 0.206067  data: 0.000458  max mem: 3586
I20250120 12:33:34 3545703 dinov2 helpers.py:102] Training  [10280/12500]  eta: 0:08:46  loss: 16.9195 (21.9537)  lr: 0.0000 (0.0000)  time: 0.205853  data: 0.000449  max mem: 3586
I20250120 12:33:36 3545703 dinov2 helpers.py:102] Training  [10290/12500]  eta: 0:08:44  loss: 16.6067 (21.9482)  lr: 0.0000 (0.0000)  time: 0.205591  data: 0.000412  max mem: 3586
I20250120 12:33:38 3545703 dinov2 helpers.py:102] Training  [10300/12500]  eta: 0:08:41  loss: 16.9195 (21.9459)  lr: 0.0000 (0.0000)  time: 0.205589  data: 0.000436  max mem: 3586
I20250120 12:33:40 3545703 dinov2 helpers.py:102] Training  [10310/12500]  eta: 0:08:39  loss: 16.9195 (21.9410)  lr: 0.0000 (0.0000)  time: 0.205649  data: 0.000440  max mem: 3586
I20250120 12:33:42 3545703 dinov2 helpers.py:102] Training  [10320/12500]  eta: 0:08:36  loss: 16.9195 (21.9378)  lr: 0.0000 (0.0000)  time: 0.205834  data: 0.000432  max mem: 3586
I20250120 12:33:44 3545703 dinov2 helpers.py:102] Training  [10330/12500]  eta: 0:08:34  loss: 17.2501 (21.9338)  lr: 0.0000 (0.0000)  time: 0.205789  data: 0.000415  max mem: 3586
I20250120 12:33:46 3545703 dinov2 helpers.py:102] Training  [10340/12500]  eta: 0:08:32  loss: 16.9195 (21.9287)  lr: 0.0000 (0.0000)  time: 0.205647  data: 0.000427  max mem: 3586
I20250120 12:33:48 3545703 dinov2 helpers.py:102] Training  [10350/12500]  eta: 0:08:29  loss: 17.8264 (21.9261)  lr: 0.0000 (0.0000)  time: 0.205672  data: 0.000455  max mem: 3586
I20250120 12:33:50 3545703 dinov2 helpers.py:102] Training  [10360/12500]  eta: 0:08:27  loss: 16.9083 (21.9200)  lr: 0.0000 (0.0000)  time: 0.205803  data: 0.000472  max mem: 3586
I20250120 12:33:52 3545703 dinov2 helpers.py:102] Training  [10370/12500]  eta: 0:08:24  loss: 16.6067 (21.9137)  lr: 0.0000 (0.0000)  time: 0.205911  data: 0.000438  max mem: 3586
I20250120 12:33:54 3545703 dinov2 helpers.py:102] Training  [10380/12500]  eta: 0:08:22  loss: 16.9083 (21.9119)  lr: 0.0000 (0.0000)  time: 0.205856  data: 0.000463  max mem: 3586
I20250120 12:33:56 3545703 dinov2 helpers.py:102] Training  [10390/12500]  eta: 0:08:19  loss: 16.9083 (21.9069)  lr: 0.0000 (0.0000)  time: 0.205911  data: 0.000528  max mem: 3586
I20250120 12:33:58 3545703 dinov2 helpers.py:102] Training  [10400/12500]  eta: 0:08:17  loss: 17.8264 (21.9067)  lr: 0.0000 (0.0000)  time: 0.205929  data: 0.000508  max mem: 3586
I20250120 12:34:00 3545703 dinov2 helpers.py:102] Training  [10410/12500]  eta: 0:08:15  loss: 17.8264 (21.9042)  lr: 0.0000 (0.0000)  time: 0.205810  data: 0.000477  max mem: 3586
I20250120 12:34:03 3545703 dinov2 helpers.py:102] Training  [10420/12500]  eta: 0:08:12  loss: 17.8264 (21.8978)  lr: 0.0000 (0.0000)  time: 0.205765  data: 0.000455  max mem: 3586
I20250120 12:34:05 3545703 dinov2 helpers.py:102] Training  [10430/12500]  eta: 0:08:10  loss: 17.8264 (21.8929)  lr: 0.0000 (0.0000)  time: 0.205817  data: 0.000442  max mem: 3586
I20250120 12:34:07 3545703 dinov2 helpers.py:102] Training  [10440/12500]  eta: 0:08:07  loss: 16.9083 (21.8865)  lr: 0.0000 (0.0000)  time: 0.205827  data: 0.000489  max mem: 3586
I20250120 12:34:09 3545703 dinov2 helpers.py:102] Training  [10450/12500]  eta: 0:08:05  loss: 16.9083 (21.8819)  lr: 0.0000 (0.0000)  time: 0.205702  data: 0.000479  max mem: 3586
I20250120 12:34:11 3545703 dinov2 helpers.py:102] Training  [10460/12500]  eta: 0:08:02  loss: 16.7235 (21.8728)  lr: 0.0000 (0.0000)  time: 0.205809  data: 0.000375  max mem: 3586
I20250120 12:34:13 3545703 dinov2 helpers.py:102] Training  [10470/12500]  eta: 0:08:00  loss: 16.7127 (21.8665)  lr: 0.0000 (0.0000)  time: 0.205799  data: 0.000345  max mem: 3586
I20250120 12:34:15 3545703 dinov2 helpers.py:102] Training  [10480/12500]  eta: 0:07:58  loss: 16.7235 (21.8661)  lr: 0.0000 (0.0000)  time: 0.205687  data: 0.000403  max mem: 3586
I20250120 12:34:17 3545703 dinov2 helpers.py:102] Training  [10490/12500]  eta: 0:07:55  loss: 16.7235 (21.8611)  lr: 0.0000 (0.0000)  time: 0.205968  data: 0.000446  max mem: 3586
I20250120 12:34:19 3545703 dinov2 helpers.py:102] Training  [10500/12500]  eta: 0:07:53  loss: 16.7235 (21.8565)  lr: 0.0000 (0.0000)  time: 0.206002  data: 0.000469  max mem: 3586
I20250120 12:34:21 3545703 dinov2 helpers.py:102] Training  [10510/12500]  eta: 0:07:50  loss: 16.7235 (21.8564)  lr: 0.0000 (0.0000)  time: 0.205796  data: 0.000499  max mem: 3586
I20250120 12:34:26 3545703 dinov2 helpers.py:102] Training  [10520/12500]  eta: 0:07:48  loss: 16.7127 (21.8513)  lr: 0.0000 (0.0000)  time: 0.349663  data: 0.147942  max mem: 3586
I20250120 12:34:29 3545703 dinov2 helpers.py:102] Training  [10530/12500]  eta: 0:07:46  loss: 16.7127 (21.8476)  lr: 0.0000 (0.0000)  time: 0.417836  data: 0.229141  max mem: 3586
I20250120 12:34:31 3545703 dinov2 helpers.py:102] Training  [10540/12500]  eta: 0:07:44  loss: 16.7235 (21.8481)  lr: 0.0000 (0.0000)  time: 0.273048  data: 0.082056  max mem: 3586
I20250120 12:34:33 3545703 dinov2 helpers.py:102] Training  [10550/12500]  eta: 0:07:41  loss: 16.7235 (21.8472)  lr: 0.0000 (0.0000)  time: 0.203684  data: 0.000868  max mem: 3586
I20250120 12:34:36 3545703 dinov2 helpers.py:102] Training  [10560/12500]  eta: 0:07:39  loss: 17.0035 (21.8444)  lr: 0.0000 (0.0000)  time: 0.203715  data: 0.000464  max mem: 3586
I20250120 12:34:38 3545703 dinov2 helpers.py:102] Training  [10570/12500]  eta: 0:07:36  loss: 17.0964 (21.8428)  lr: 0.0000 (0.0000)  time: 0.204026  data: 0.000437  max mem: 3586
I20250120 12:34:40 3545703 dinov2 helpers.py:102] Training  [10580/12500]  eta: 0:07:34  loss: 17.0964 (21.8389)  lr: 0.0000 (0.0000)  time: 0.204185  data: 0.000469  max mem: 3586
I20250120 12:34:42 3545703 dinov2 helpers.py:102] Training  [10590/12500]  eta: 0:07:32  loss: 17.0964 (21.8334)  lr: 0.0000 (0.0000)  time: 0.204314  data: 0.000463  max mem: 3586
I20250120 12:34:44 3545703 dinov2 helpers.py:102] Training  [10600/12500]  eta: 0:07:29  loss: 17.0035 (21.8280)  lr: 0.0000 (0.0000)  time: 0.204392  data: 0.000421  max mem: 3586
I20250120 12:34:46 3545703 dinov2 helpers.py:102] Training  [10610/12500]  eta: 0:07:27  loss: 16.7235 (21.8222)  lr: 0.0000 (0.0000)  time: 0.204817  data: 0.000417  max mem: 3586
I20250120 12:34:48 3545703 dinov2 helpers.py:102] Training  [10620/12500]  eta: 0:07:24  loss: 17.0035 (21.8177)  lr: 0.0000 (0.0000)  time: 0.205207  data: 0.000433  max mem: 3586
I20250120 12:34:50 3545703 dinov2 helpers.py:102] Training  [10630/12500]  eta: 0:07:22  loss: 17.0144 (21.8165)  lr: 0.0000 (0.0000)  time: 0.205212  data: 0.000422  max mem: 3586
I20250120 12:34:52 3545703 dinov2 helpers.py:102] Training  [10640/12500]  eta: 0:07:20  loss: 17.0964 (21.8140)  lr: 0.0000 (0.0000)  time: 0.205129  data: 0.000380  max mem: 3586
I20250120 12:34:54 3545703 dinov2 helpers.py:102] Training  [10650/12500]  eta: 0:07:17  loss: 17.7190 (21.8110)  lr: 0.0000 (0.0000)  time: 0.205315  data: 0.000424  max mem: 3586
I20250120 12:34:56 3545703 dinov2 helpers.py:102] Training  [10660/12500]  eta: 0:07:15  loss: 17.8841 (21.8076)  lr: 0.0000 (0.0000)  time: 0.205387  data: 0.000450  max mem: 3586
I20250120 12:34:58 3545703 dinov2 helpers.py:102] Training  [10670/12500]  eta: 0:07:12  loss: 18.2542 (21.8049)  lr: 0.0000 (0.0000)  time: 0.205242  data: 0.000417  max mem: 3586
I20250120 12:35:00 3545703 dinov2 helpers.py:102] Training  [10680/12500]  eta: 0:07:10  loss: 18.2542 (21.8037)  lr: 0.0000 (0.0000)  time: 0.205468  data: 0.000434  max mem: 3586
I20250120 12:35:02 3545703 dinov2 helpers.py:102] Training  [10690/12500]  eta: 0:07:07  loss: 18.2542 (21.7967)  lr: 0.0000 (0.0000)  time: 0.205675  data: 0.000442  max mem: 3586
I20250120 12:35:04 3545703 dinov2 helpers.py:102] Training  [10700/12500]  eta: 0:07:05  loss: 18.2542 (21.7929)  lr: 0.0000 (0.0000)  time: 0.205647  data: 0.000444  max mem: 3586
I20250120 12:35:06 3545703 dinov2 helpers.py:102] Training  [10710/12500]  eta: 0:07:03  loss: 18.2542 (21.7903)  lr: 0.0000 (0.0000)  time: 0.205580  data: 0.000415  max mem: 3586
I20250120 12:35:08 3545703 dinov2 helpers.py:102] Training  [10720/12500]  eta: 0:07:00  loss: 18.2542 (21.7849)  lr: 0.0000 (0.0000)  time: 0.205739  data: 0.000401  max mem: 3586
I20250120 12:35:10 3545703 dinov2 helpers.py:102] Training  [10730/12500]  eta: 0:06:58  loss: 18.2542 (21.7784)  lr: 0.0000 (0.0000)  time: 0.205992  data: 0.000416  max mem: 3586
I20250120 12:35:12 3545703 dinov2 helpers.py:102] Training  [10740/12500]  eta: 0:06:55  loss: 17.7312 (21.7736)  lr: 0.0000 (0.0000)  time: 0.205886  data: 0.000416  max mem: 3586
I20250120 12:35:15 3545703 dinov2 helpers.py:102] Training  [10750/12500]  eta: 0:06:53  loss: 17.7312 (21.7705)  lr: 0.0000 (0.0000)  time: 0.205794  data: 0.000420  max mem: 3586
I20250120 12:35:17 3545703 dinov2 helpers.py:102] Training  [10760/12500]  eta: 0:06:51  loss: 17.7190 (21.7636)  lr: 0.0000 (0.0000)  time: 0.205839  data: 0.000444  max mem: 3586
I20250120 12:35:19 3545703 dinov2 helpers.py:102] Training  [10770/12500]  eta: 0:06:48  loss: 17.7190 (21.7605)  lr: 0.0000 (0.0000)  time: 0.205846  data: 0.000403  max mem: 3586
I20250120 12:35:21 3545703 dinov2 helpers.py:102] Training  [10780/12500]  eta: 0:06:46  loss: 17.5386 (21.7566)  lr: 0.0000 (0.0000)  time: 0.205841  data: 0.000367  max mem: 3586
I20250120 12:35:23 3545703 dinov2 helpers.py:102] Training  [10790/12500]  eta: 0:06:43  loss: 17.5386 (21.7504)  lr: 0.0000 (0.0000)  time: 0.205871  data: 0.000425  max mem: 3586
I20250120 12:35:25 3545703 dinov2 helpers.py:102] Training  [10800/12500]  eta: 0:06:41  loss: 17.5386 (21.7437)  lr: 0.0000 (0.0000)  time: 0.206063  data: 0.000487  max mem: 3586
I20250120 12:35:27 3545703 dinov2 helpers.py:102] Training  [10810/12500]  eta: 0:06:38  loss: 17.5386 (21.7388)  lr: 0.0000 (0.0000)  time: 0.206062  data: 0.000470  max mem: 3586
I20250120 12:35:29 3545703 dinov2 helpers.py:102] Training  [10820/12500]  eta: 0:06:36  loss: 17.5386 (21.7345)  lr: 0.0000 (0.0000)  time: 0.206037  data: 0.000454  max mem: 3586
I20250120 12:35:31 3545703 dinov2 helpers.py:102] Training  [10830/12500]  eta: 0:06:34  loss: 17.0812 (21.7279)  lr: 0.0000 (0.0000)  time: 0.206180  data: 0.000479  max mem: 3586
I20250120 12:35:33 3545703 dinov2 helpers.py:102] Training  [10840/12500]  eta: 0:06:31  loss: 16.6204 (21.7214)  lr: 0.0000 (0.0000)  time: 0.206066  data: 0.000417  max mem: 3586
I20250120 12:35:35 3545703 dinov2 helpers.py:102] Training  [10850/12500]  eta: 0:06:29  loss: 16.6204 (21.7171)  lr: 0.0000 (0.0000)  time: 0.206174  data: 0.000420  max mem: 3586
I20250120 12:35:37 3545703 dinov2 helpers.py:102] Training  [10860/12500]  eta: 0:06:26  loss: 16.6204 (21.7143)  lr: 0.0000 (0.0000)  time: 0.206552  data: 0.000510  max mem: 3586
I20250120 12:35:39 3545703 dinov2 helpers.py:102] Training  [10870/12500]  eta: 0:06:24  loss: 16.4693 (21.7089)  lr: 0.0000 (0.0000)  time: 0.206484  data: 0.000496  max mem: 3586
I20250120 12:35:41 3545703 dinov2 helpers.py:102] Training  [10880/12500]  eta: 0:06:22  loss: 16.4693 (21.7070)  lr: 0.0000 (0.0000)  time: 0.206568  data: 0.000469  max mem: 3586
I20250120 12:35:43 3545703 dinov2 helpers.py:102] Training  [10890/12500]  eta: 0:06:19  loss: 16.4693 (21.6985)  lr: 0.0000 (0.0000)  time: 0.206508  data: 0.000452  max mem: 3586
I20250120 12:35:45 3545703 dinov2 helpers.py:102] Training  [10900/12500]  eta: 0:06:17  loss: 15.9947 (21.6931)  lr: 0.0000 (0.0000)  time: 0.205835  data: 0.000443  max mem: 3586
I20250120 12:35:48 3545703 dinov2 helpers.py:102] Training  [10910/12500]  eta: 0:06:14  loss: 15.8219 (21.6867)  lr: 0.0000 (0.0000)  time: 0.205911  data: 0.000422  max mem: 3586
I20250120 12:35:50 3545703 dinov2 helpers.py:102] Training  [10920/12500]  eta: 0:06:12  loss: 15.8219 (21.6829)  lr: 0.0000 (0.0000)  time: 0.206246  data: 0.000446  max mem: 3586
I20250120 12:35:52 3545703 dinov2 helpers.py:102] Training  [10930/12500]  eta: 0:06:10  loss: 16.4693 (21.6799)  lr: 0.0000 (0.0000)  time: 0.206215  data: 0.000463  max mem: 3586
I20250120 12:35:54 3545703 dinov2 helpers.py:102] Training  [10940/12500]  eta: 0:06:07  loss: 16.4693 (21.6760)  lr: 0.0000 (0.0000)  time: 0.206225  data: 0.000406  max mem: 3586
I20250120 12:35:56 3545703 dinov2 helpers.py:102] Training  [10950/12500]  eta: 0:06:05  loss: 16.4004 (21.6712)  lr: 0.0000 (0.0000)  time: 0.206335  data: 0.000396  max mem: 3586
I20250120 12:35:58 3545703 dinov2 helpers.py:102] Training  [10960/12500]  eta: 0:06:02  loss: 16.4693 (21.6716)  lr: 0.0000 (0.0000)  time: 0.206345  data: 0.000436  max mem: 3586
I20250120 12:36:00 3545703 dinov2 helpers.py:102] Training  [10970/12500]  eta: 0:06:00  loss: 16.4693 (21.6678)  lr: 0.0000 (0.0000)  time: 0.206198  data: 0.000378  max mem: 3586
I20250120 12:36:02 3545703 dinov2 helpers.py:102] Training  [10980/12500]  eta: 0:05:58  loss: 16.4693 (21.6675)  lr: 0.0000 (0.0000)  time: 0.206091  data: 0.000384  max mem: 3586
I20250120 12:36:04 3545703 dinov2 helpers.py:102] Training  [10990/12500]  eta: 0:05:55  loss: 17.0037 (21.6639)  lr: 0.0000 (0.0000)  time: 0.206091  data: 0.000499  max mem: 3586
I20250120 12:36:06 3545703 dinov2 helpers.py:102] Training  [11000/12500]  eta: 0:05:53  loss: 17.0037 (21.6580)  lr: 0.0000 (0.0000)  time: 0.206241  data: 0.000488  max mem: 3586
I20250120 12:36:08 3545703 dinov2 helpers.py:102] Training  [11010/12500]  eta: 0:05:50  loss: 17.0812 (21.6549)  lr: 0.0000 (0.0000)  time: 0.206461  data: 0.000426  max mem: 3586
I20250120 12:36:10 3545703 dinov2 helpers.py:102] Training  [11020/12500]  eta: 0:05:48  loss: 17.1857 (21.6509)  lr: 0.0000 (0.0000)  time: 0.206497  data: 0.000441  max mem: 3586
I20250120 12:36:12 3545703 dinov2 helpers.py:102] Training  [11030/12500]  eta: 0:05:46  loss: 17.4474 (21.6512)  lr: 0.0000 (0.0000)  time: 0.206428  data: 0.000435  max mem: 3586
I20250120 12:36:14 3545703 dinov2 helpers.py:102] Training  [11040/12500]  eta: 0:05:43  loss: 17.5176 (21.6483)  lr: 0.0000 (0.0000)  time: 0.206526  data: 0.000434  max mem: 3586
I20250120 12:36:16 3545703 dinov2 helpers.py:102] Training  [11050/12500]  eta: 0:05:41  loss: 17.5176 (21.6443)  lr: 0.0000 (0.0000)  time: 0.206550  data: 0.000458  max mem: 3586
I20250120 12:36:18 3545703 dinov2 helpers.py:102] Training  [11060/12500]  eta: 0:05:38  loss: 17.5176 (21.6435)  lr: 0.0000 (0.0000)  time: 0.206483  data: 0.000473  max mem: 3586
I20250120 12:36:21 3545703 dinov2 helpers.py:102] Training  [11070/12500]  eta: 0:05:36  loss: 17.5857 (21.6420)  lr: 0.0000 (0.0000)  time: 0.206294  data: 0.000441  max mem: 3586
I20250120 12:36:23 3545703 dinov2 helpers.py:102] Training  [11080/12500]  eta: 0:05:34  loss: 17.5176 (21.6360)  lr: 0.0000 (0.0000)  time: 0.206349  data: 0.000386  max mem: 3586
I20250120 12:36:25 3545703 dinov2 helpers.py:102] Training  [11090/12500]  eta: 0:05:31  loss: 17.5176 (21.6309)  lr: 0.0000 (0.0000)  time: 0.206353  data: 0.000489  max mem: 3586
I20250120 12:36:27 3545703 dinov2 helpers.py:102] Training  [11100/12500]  eta: 0:05:29  loss: 17.5176 (21.6271)  lr: 0.0000 (0.0000)  time: 0.206230  data: 0.000517  max mem: 3586
I20250120 12:36:29 3545703 dinov2 helpers.py:102] Training  [11110/12500]  eta: 0:05:27  loss: 17.5857 (21.6236)  lr: 0.0000 (0.0000)  time: 0.206207  data: 0.000431  max mem: 3586
I20250120 12:36:31 3545703 dinov2 helpers.py:102] Training  [11120/12500]  eta: 0:05:24  loss: 17.5176 (21.6196)  lr: 0.0000 (0.0000)  time: 0.206238  data: 0.000411  max mem: 3586
I20250120 12:36:33 3545703 dinov2 helpers.py:102] Training  [11130/12500]  eta: 0:05:22  loss: 17.4474 (21.6154)  lr: 0.0000 (0.0000)  time: 0.206453  data: 0.000426  max mem: 3586
I20250120 12:36:35 3545703 dinov2 helpers.py:102] Training  [11140/12500]  eta: 0:05:19  loss: 17.3776 (21.6098)  lr: 0.0000 (0.0000)  time: 0.206344  data: 0.000439  max mem: 3586
I20250120 12:36:37 3545703 dinov2 helpers.py:102] Training  [11150/12500]  eta: 0:05:17  loss: 17.3776 (21.6045)  lr: 0.0000 (0.0000)  time: 0.206165  data: 0.000446  max mem: 3586
I20250120 12:36:39 3545703 dinov2 helpers.py:102] Training  [11160/12500]  eta: 0:05:15  loss: 17.2534 (21.5986)  lr: 0.0000 (0.0000)  time: 0.206332  data: 0.000464  max mem: 3586
I20250120 12:36:41 3545703 dinov2 helpers.py:102] Training  [11170/12500]  eta: 0:05:12  loss: 17.2534 (21.6013)  lr: 0.0000 (0.0000)  time: 0.206360  data: 0.000459  max mem: 3586
I20250120 12:36:43 3545703 dinov2 helpers.py:102] Training  [11180/12500]  eta: 0:05:10  loss: 17.2534 (21.5988)  lr: 0.0000 (0.0000)  time: 0.206138  data: 0.000426  max mem: 3586
I20250120 12:36:45 3545703 dinov2 helpers.py:102] Training  [11190/12500]  eta: 0:05:07  loss: 17.1857 (21.5934)  lr: 0.0000 (0.0000)  time: 0.206312  data: 0.000441  max mem: 3586
I20250120 12:36:47 3545703 dinov2 helpers.py:102] Training  [11200/12500]  eta: 0:05:05  loss: 17.2534 (21.5920)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000422  max mem: 3586
I20250120 12:36:49 3545703 dinov2 helpers.py:102] Training  [11210/12500]  eta: 0:05:03  loss: 17.2534 (21.5911)  lr: 0.0000 (0.0000)  time: 0.206353  data: 0.000412  max mem: 3586
I20250120 12:36:52 3545703 dinov2 helpers.py:102] Training  [11220/12500]  eta: 0:05:00  loss: 17.3776 (21.5886)  lr: 0.0000 (0.0000)  time: 0.206544  data: 0.000405  max mem: 3586
I20250120 12:36:54 3545703 dinov2 helpers.py:102] Training  [11230/12500]  eta: 0:04:58  loss: 17.2534 (21.5815)  lr: 0.0000 (0.0000)  time: 0.206477  data: 0.000396  max mem: 3586
I20250120 12:36:56 3545703 dinov2 helpers.py:102] Training  [11240/12500]  eta: 0:04:56  loss: 17.2534 (21.5782)  lr: 0.0000 (0.0000)  time: 0.206342  data: 0.000448  max mem: 3586
I20250120 12:36:57 3545703 dinov2 linear.py:272] running validation !
I20250120 12:36:59 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:54    time: 1.512449  data: 1.305832  max mem: 3586
I20250120 12:37:01 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.330188  data: 0.118989  max mem: 3586
I20250120 12:37:03 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.211373  data: 0.000495  max mem: 3586
I20250120 12:37:05 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.210199  data: 0.000448  max mem: 3586
I20250120 12:37:07 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209286  data: 0.000225  max mem: 3586
I20250120 12:37:10 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209034  data: 0.000233  max mem: 3586
I20250120 12:37:12 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.209031  data: 0.000222  max mem: 3586
I20250120 12:37:14 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209473  data: 0.000226  max mem: 3586
I20250120 12:37:16 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.209408  data: 0.000225  max mem: 3586
I20250120 12:37:18 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209435  data: 0.000214  max mem: 3586
I20250120 12:37:20 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.209530  data: 0.000224  max mem: 3586
I20250120 12:37:22 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.209065  data: 0.000234  max mem: 3586
I20250120 12:37:24 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209165  data: 0.000226  max mem: 3586
I20250120 12:37:26 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209085  data: 0.000206  max mem: 3586
I20250120 12:37:28 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209190  data: 0.000217  max mem: 3586
I20250120 12:37:30 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208633  data: 0.000177  max mem: 3586
I20250120 12:37:31 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204497  data: 0.000159  max mem: 3586
I20250120 12:37:31 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218319 s / it)
I20250120 12:37:31 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:37:31 3545703 dinov2 linear.py:287] 
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8568, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8659, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8685, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8722, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8751, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8759, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8779, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8788, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8804, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8806, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8573, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8649, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8713, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8743, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8774, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8799, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8810, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8838, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8860, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8885, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8909, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8902, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8642, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8710, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8772, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8777, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8790, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8811, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8825, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8840, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8858, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8868, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8859, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8670, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8740, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8767, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8787, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8813, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8840, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8861, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8903, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8916, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8930, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8916, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8859, device='cuda:0')}
I20250120 12:37:31 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_01000', 'accuracy': 0.8930376172065735}
I20250120 12:37:32 3545703 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 12:37:32 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 12:37:32 3545703 dinov2 helpers.py:102] Training  [11250/12500]  eta: 0:04:57  loss: 17.1506 (21.5736)  lr: 0.0000 (0.0000)  time: 1.903643  data: 0.000447  max mem: 3586
I20250120 12:37:34 3545703 dinov2 helpers.py:102] Training  [11260/12500]  eta: 0:04:54  loss: 17.1506 (21.5720)  lr: 0.0000 (0.0000)  time: 1.902781  data: 0.000409  max mem: 3586
I20250120 12:37:36 3545703 dinov2 helpers.py:102] Training  [11270/12500]  eta: 0:04:52  loss: 17.1506 (21.5693)  lr: 0.0000 (0.0000)  time: 0.205134  data: 0.000411  max mem: 3586
I20250120 12:37:38 3545703 dinov2 helpers.py:102] Training  [11280/12500]  eta: 0:04:50  loss: 17.3776 (21.5691)  lr: 0.0000 (0.0000)  time: 0.205779  data: 0.000438  max mem: 3586
I20250120 12:37:40 3545703 dinov2 helpers.py:102] Training  [11290/12500]  eta: 0:04:47  loss: 17.7310 (21.5669)  lr: 0.0000 (0.0000)  time: 0.206016  data: 0.000409  max mem: 3586
I20250120 12:37:42 3545703 dinov2 helpers.py:102] Training  [11300/12500]  eta: 0:04:45  loss: 17.7310 (21.5621)  lr: 0.0000 (0.0000)  time: 0.206042  data: 0.000405  max mem: 3586
I20250120 12:37:44 3545703 dinov2 helpers.py:102] Training  [11310/12500]  eta: 0:04:42  loss: 17.9079 (21.5590)  lr: 0.0000 (0.0000)  time: 0.206077  data: 0.000421  max mem: 3586
I20250120 12:37:46 3545703 dinov2 helpers.py:102] Training  [11320/12500]  eta: 0:04:40  loss: 17.9079 (21.5537)  lr: 0.0000 (0.0000)  time: 0.206190  data: 0.000390  max mem: 3586
I20250120 12:37:48 3545703 dinov2 helpers.py:102] Training  [11330/12500]  eta: 0:04:38  loss: 17.9079 (21.5494)  lr: 0.0000 (0.0000)  time: 0.206183  data: 0.000366  max mem: 3586
I20250120 12:37:50 3545703 dinov2 helpers.py:102] Training  [11340/12500]  eta: 0:04:35  loss: 18.0277 (21.5463)  lr: 0.0000 (0.0000)  time: 0.206014  data: 0.000403  max mem: 3586
I20250120 12:37:52 3545703 dinov2 helpers.py:102] Training  [11350/12500]  eta: 0:04:33  loss: 18.0882 (21.5449)  lr: 0.0000 (0.0000)  time: 0.205859  data: 0.000426  max mem: 3586
I20250120 12:37:54 3545703 dinov2 helpers.py:102] Training  [11360/12500]  eta: 0:04:30  loss: 18.5840 (21.5436)  lr: 0.0000 (0.0000)  time: 0.206074  data: 0.000462  max mem: 3586
I20250120 12:37:56 3545703 dinov2 helpers.py:102] Training  [11370/12500]  eta: 0:04:28  loss: 18.0882 (21.5405)  lr: 0.0000 (0.0000)  time: 0.206083  data: 0.000507  max mem: 3586
I20250120 12:37:58 3545703 dinov2 helpers.py:102] Training  [11380/12500]  eta: 0:04:26  loss: 18.0277 (21.5374)  lr: 0.0000 (0.0000)  time: 0.205907  data: 0.000481  max mem: 3586
I20250120 12:38:01 3545703 dinov2 helpers.py:102] Training  [11390/12500]  eta: 0:04:23  loss: 18.0882 (21.5357)  lr: 0.0000 (0.0000)  time: 0.229254  data: 0.027497  max mem: 3586
I20250120 12:38:03 3545703 dinov2 helpers.py:102] Training  [11400/12500]  eta: 0:04:21  loss: 18.0882 (21.5339)  lr: 0.0000 (0.0000)  time: 0.229110  data: 0.027471  max mem: 3586
I20250120 12:38:05 3545703 dinov2 helpers.py:102] Training  [11410/12500]  eta: 0:04:18  loss: 18.0277 (21.5269)  lr: 0.0000 (0.0000)  time: 0.205974  data: 0.000433  max mem: 3586
I20250120 12:38:07 3545703 dinov2 helpers.py:102] Training  [11420/12500]  eta: 0:04:16  loss: 18.0051 (21.5230)  lr: 0.0000 (0.0000)  time: 0.206248  data: 0.000478  max mem: 3586
I20250120 12:38:09 3545703 dinov2 helpers.py:102] Training  [11430/12500]  eta: 0:04:14  loss: 18.0051 (21.5197)  lr: 0.0000 (0.0000)  time: 0.206035  data: 0.000461  max mem: 3586
I20250120 12:38:11 3545703 dinov2 helpers.py:102] Training  [11440/12500]  eta: 0:04:11  loss: 18.0277 (21.5171)  lr: 0.0000 (0.0000)  time: 0.205975  data: 0.000418  max mem: 3586
I20250120 12:38:13 3545703 dinov2 helpers.py:102] Training  [11450/12500]  eta: 0:04:09  loss: 18.0277 (21.5124)  lr: 0.0000 (0.0000)  time: 0.206051  data: 0.000454  max mem: 3586
I20250120 12:38:15 3545703 dinov2 helpers.py:102] Training  [11460/12500]  eta: 0:04:06  loss: 18.0277 (21.5115)  lr: 0.0000 (0.0000)  time: 0.206006  data: 0.000472  max mem: 3586
I20250120 12:38:17 3545703 dinov2 helpers.py:102] Training  [11470/12500]  eta: 0:04:04  loss: 18.0051 (21.5069)  lr: 0.0000 (0.0000)  time: 0.205954  data: 0.000456  max mem: 3586
I20250120 12:38:19 3545703 dinov2 helpers.py:102] Training  [11480/12500]  eta: 0:04:02  loss: 18.0051 (21.5046)  lr: 0.0000 (0.0000)  time: 0.205972  data: 0.000429  max mem: 3586
I20250120 12:38:22 3545703 dinov2 helpers.py:102] Training  [11490/12500]  eta: 0:03:59  loss: 17.9820 (21.4996)  lr: 0.0000 (0.0000)  time: 0.205986  data: 0.000393  max mem: 3586
I20250120 12:38:24 3545703 dinov2 helpers.py:102] Training  [11500/12500]  eta: 0:03:57  loss: 18.0051 (21.4977)  lr: 0.0000 (0.0000)  time: 0.205865  data: 0.000351  max mem: 3586
I20250120 12:38:26 3545703 dinov2 helpers.py:102] Training  [11510/12500]  eta: 0:03:54  loss: 17.9820 (21.4941)  lr: 0.0000 (0.0000)  time: 0.205845  data: 0.000400  max mem: 3586
I20250120 12:38:28 3545703 dinov2 helpers.py:102] Training  [11520/12500]  eta: 0:03:52  loss: 18.0051 (21.4929)  lr: 0.0000 (0.0000)  time: 0.205918  data: 0.000436  max mem: 3586
I20250120 12:38:30 3545703 dinov2 helpers.py:102] Training  [11530/12500]  eta: 0:03:50  loss: 18.0051 (21.4877)  lr: 0.0000 (0.0000)  time: 0.205779  data: 0.000428  max mem: 3586
I20250120 12:38:32 3545703 dinov2 helpers.py:102] Training  [11540/12500]  eta: 0:03:47  loss: 18.0051 (21.4864)  lr: 0.0000 (0.0000)  time: 0.205843  data: 0.000453  max mem: 3586
I20250120 12:38:34 3545703 dinov2 helpers.py:102] Training  [11550/12500]  eta: 0:03:45  loss: 18.0051 (21.4849)  lr: 0.0000 (0.0000)  time: 0.206073  data: 0.000412  max mem: 3586
I20250120 12:38:36 3545703 dinov2 helpers.py:102] Training  [11560/12500]  eta: 0:03:42  loss: 18.0051 (21.4830)  lr: 0.0000 (0.0000)  time: 0.205992  data: 0.000367  max mem: 3586
I20250120 12:38:38 3545703 dinov2 helpers.py:102] Training  [11570/12500]  eta: 0:03:40  loss: 17.9820 (21.4798)  lr: 0.0000 (0.0000)  time: 0.205955  data: 0.000396  max mem: 3586
I20250120 12:38:40 3545703 dinov2 helpers.py:102] Training  [11580/12500]  eta: 0:03:38  loss: 17.8007 (21.4728)  lr: 0.0000 (0.0000)  time: 0.206125  data: 0.000447  max mem: 3586
I20250120 12:38:42 3545703 dinov2 helpers.py:102] Training  [11590/12500]  eta: 0:03:35  loss: 17.7297 (21.4665)  lr: 0.0000 (0.0000)  time: 0.206223  data: 0.000467  max mem: 3586
I20250120 12:38:44 3545703 dinov2 helpers.py:102] Training  [11600/12500]  eta: 0:03:33  loss: 17.3689 (21.4596)  lr: 0.0000 (0.0000)  time: 0.206386  data: 0.000468  max mem: 3586
I20250120 12:38:46 3545703 dinov2 helpers.py:102] Training  [11610/12500]  eta: 0:03:30  loss: 17.7297 (21.4596)  lr: 0.0000 (0.0000)  time: 0.206558  data: 0.000418  max mem: 3586
I20250120 12:38:48 3545703 dinov2 helpers.py:102] Training  [11620/12500]  eta: 0:03:28  loss: 17.7297 (21.4560)  lr: 0.0000 (0.0000)  time: 0.206366  data: 0.000427  max mem: 3586
I20250120 12:38:50 3545703 dinov2 helpers.py:102] Training  [11630/12500]  eta: 0:03:26  loss: 17.3689 (21.4502)  lr: 0.0000 (0.0000)  time: 0.206353  data: 0.000421  max mem: 3586
I20250120 12:38:52 3545703 dinov2 helpers.py:102] Training  [11640/12500]  eta: 0:03:23  loss: 17.2036 (21.4454)  lr: 0.0000 (0.0000)  time: 0.206696  data: 0.000393  max mem: 3586
I20250120 12:38:55 3545703 dinov2 helpers.py:102] Training  [11650/12500]  eta: 0:03:21  loss: 17.3689 (21.4432)  lr: 0.0000 (0.0000)  time: 0.206542  data: 0.000447  max mem: 3586
I20250120 12:38:57 3545703 dinov2 helpers.py:102] Training  [11660/12500]  eta: 0:03:18  loss: 17.2036 (21.4382)  lr: 0.0000 (0.0000)  time: 0.206288  data: 0.000460  max mem: 3586
I20250120 12:38:59 3545703 dinov2 helpers.py:102] Training  [11670/12500]  eta: 0:03:16  loss: 17.2036 (21.4345)  lr: 0.0000 (0.0000)  time: 0.206434  data: 0.000428  max mem: 3586
I20250120 12:39:01 3545703 dinov2 helpers.py:102] Training  [11680/12500]  eta: 0:03:14  loss: 17.1621 (21.4290)  lr: 0.0000 (0.0000)  time: 0.206328  data: 0.000371  max mem: 3586
I20250120 12:39:03 3545703 dinov2 helpers.py:102] Training  [11690/12500]  eta: 0:03:11  loss: 17.1621 (21.4236)  lr: 0.0000 (0.0000)  time: 0.206200  data: 0.000417  max mem: 3586
I20250120 12:39:05 3545703 dinov2 helpers.py:102] Training  [11700/12500]  eta: 0:03:09  loss: 15.7900 (21.4171)  lr: 0.0000 (0.0000)  time: 0.206396  data: 0.000436  max mem: 3586
I20250120 12:39:07 3545703 dinov2 helpers.py:102] Training  [11710/12500]  eta: 0:03:07  loss: 15.7900 (21.4124)  lr: 0.0000 (0.0000)  time: 0.206429  data: 0.000364  max mem: 3586
I20250120 12:39:09 3545703 dinov2 helpers.py:102] Training  [11720/12500]  eta: 0:03:04  loss: 15.5718 (21.4069)  lr: 0.0000 (0.0000)  time: 0.206403  data: 0.000421  max mem: 3586
I20250120 12:39:11 3545703 dinov2 helpers.py:102] Training  [11730/12500]  eta: 0:03:02  loss: 15.7900 (21.4034)  lr: 0.0000 (0.0000)  time: 0.206577  data: 0.000428  max mem: 3586
I20250120 12:39:13 3545703 dinov2 helpers.py:102] Training  [11740/12500]  eta: 0:02:59  loss: 15.5718 (21.3979)  lr: 0.0000 (0.0000)  time: 0.206670  data: 0.000384  max mem: 3586
I20250120 12:39:15 3545703 dinov2 helpers.py:102] Training  [11750/12500]  eta: 0:02:57  loss: 15.5718 (21.3946)  lr: 0.0000 (0.0000)  time: 0.206576  data: 0.000426  max mem: 3586
I20250120 12:39:17 3545703 dinov2 helpers.py:102] Training  [11760/12500]  eta: 0:02:55  loss: 15.5718 (21.3927)  lr: 0.0000 (0.0000)  time: 0.206639  data: 0.000462  max mem: 3586
I20250120 12:39:19 3545703 dinov2 helpers.py:102] Training  [11770/12500]  eta: 0:02:52  loss: 15.5718 (21.3888)  lr: 0.0000 (0.0000)  time: 0.206785  data: 0.000412  max mem: 3586
I20250120 12:39:21 3545703 dinov2 helpers.py:102] Training  [11780/12500]  eta: 0:02:50  loss: 15.7900 (21.3854)  lr: 0.0000 (0.0000)  time: 0.206698  data: 0.000380  max mem: 3586
I20250120 12:39:23 3545703 dinov2 helpers.py:102] Training  [11790/12500]  eta: 0:02:47  loss: 15.8433 (21.3807)  lr: 0.0000 (0.0000)  time: 0.206838  data: 0.000418  max mem: 3586
I20250120 12:39:26 3545703 dinov2 helpers.py:102] Training  [11800/12500]  eta: 0:02:45  loss: 15.8840 (21.3776)  lr: 0.0000 (0.0000)  time: 0.206735  data: 0.000432  max mem: 3586
I20250120 12:39:28 3545703 dinov2 helpers.py:102] Training  [11810/12500]  eta: 0:02:43  loss: 15.8433 (21.3719)  lr: 0.0000 (0.0000)  time: 0.206578  data: 0.000430  max mem: 3586
I20250120 12:39:30 3545703 dinov2 helpers.py:102] Training  [11820/12500]  eta: 0:02:40  loss: 15.7900 (21.3666)  lr: 0.0000 (0.0000)  time: 0.206831  data: 0.000453  max mem: 3586
I20250120 12:39:32 3545703 dinov2 helpers.py:102] Training  [11830/12500]  eta: 0:02:38  loss: 15.8433 (21.3626)  lr: 0.0000 (0.0000)  time: 0.206915  data: 0.000480  max mem: 3586
I20250120 12:39:34 3545703 dinov2 helpers.py:102] Training  [11840/12500]  eta: 0:02:36  loss: 15.8433 (21.3580)  lr: 0.0000 (0.0000)  time: 0.206794  data: 0.000471  max mem: 3586
I20250120 12:39:36 3545703 dinov2 helpers.py:102] Training  [11850/12500]  eta: 0:02:33  loss: 15.8007 (21.3526)  lr: 0.0000 (0.0000)  time: 0.206678  data: 0.000427  max mem: 3586
I20250120 12:39:38 3545703 dinov2 helpers.py:102] Training  [11860/12500]  eta: 0:02:31  loss: 15.8433 (21.3497)  lr: 0.0000 (0.0000)  time: 0.206897  data: 0.000408  max mem: 3586
I20250120 12:39:40 3545703 dinov2 helpers.py:102] Training  [11870/12500]  eta: 0:02:28  loss: 15.8433 (21.3477)  lr: 0.0000 (0.0000)  time: 0.207131  data: 0.000434  max mem: 3586
I20250120 12:39:42 3545703 dinov2 helpers.py:102] Training  [11880/12500]  eta: 0:02:26  loss: 15.8840 (21.3439)  lr: 0.0000 (0.0000)  time: 0.207015  data: 0.000410  max mem: 3586
I20250120 12:39:44 3545703 dinov2 helpers.py:102] Training  [11890/12500]  eta: 0:02:24  loss: 16.6678 (21.3422)  lr: 0.0000 (0.0000)  time: 0.206839  data: 0.000402  max mem: 3586
I20250120 12:39:46 3545703 dinov2 helpers.py:102] Training  [11900/12500]  eta: 0:02:21  loss: 16.7531 (21.3385)  lr: 0.0000 (0.0000)  time: 0.206805  data: 0.000420  max mem: 3586
I20250120 12:39:48 3545703 dinov2 helpers.py:102] Training  [11910/12500]  eta: 0:02:19  loss: 16.8008 (21.3364)  lr: 0.0000 (0.0000)  time: 0.207003  data: 0.000384  max mem: 3586
I20250120 12:39:50 3545703 dinov2 helpers.py:102] Training  [11920/12500]  eta: 0:02:16  loss: 16.8008 (21.3299)  lr: 0.0000 (0.0000)  time: 0.206945  data: 0.000373  max mem: 3586
I20250120 12:39:52 3545703 dinov2 helpers.py:102] Training  [11930/12500]  eta: 0:02:14  loss: 16.8008 (21.3297)  lr: 0.0000 (0.0000)  time: 0.206883  data: 0.000380  max mem: 3586
I20250120 12:39:55 3545703 dinov2 helpers.py:102] Training  [11940/12500]  eta: 0:02:12  loss: 16.9395 (21.3264)  lr: 0.0000 (0.0000)  time: 0.206904  data: 0.000410  max mem: 3586
I20250120 12:39:57 3545703 dinov2 helpers.py:102] Training  [11950/12500]  eta: 0:02:09  loss: 16.9395 (21.3244)  lr: 0.0000 (0.0000)  time: 0.206808  data: 0.000447  max mem: 3586
I20250120 12:39:59 3545703 dinov2 helpers.py:102] Training  [11960/12500]  eta: 0:02:07  loss: 16.9395 (21.3224)  lr: 0.0000 (0.0000)  time: 0.207011  data: 0.000445  max mem: 3586
I20250120 12:40:01 3545703 dinov2 helpers.py:102] Training  [11970/12500]  eta: 0:02:05  loss: 17.3057 (21.3251)  lr: 0.0000 (0.0000)  time: 0.206913  data: 0.000433  max mem: 3586
I20250120 12:40:03 3545703 dinov2 helpers.py:102] Training  [11980/12500]  eta: 0:02:02  loss: 16.9395 (21.3213)  lr: 0.0000 (0.0000)  time: 0.206752  data: 0.000420  max mem: 3586
I20250120 12:40:05 3545703 dinov2 helpers.py:102] Training  [11990/12500]  eta: 0:02:00  loss: 17.3057 (21.3188)  lr: 0.0000 (0.0000)  time: 0.206931  data: 0.000408  max mem: 3586
I20250120 12:40:07 3545703 dinov2 helpers.py:102] Training  [12000/12500]  eta: 0:01:57  loss: 17.3057 (21.3155)  lr: 0.0000 (0.0000)  time: 0.206913  data: 0.000425  max mem: 3586
I20250120 12:40:09 3545703 dinov2 helpers.py:102] Training  [12010/12500]  eta: 0:01:55  loss: 17.3057 (21.3113)  lr: 0.0000 (0.0000)  time: 0.206828  data: 0.000415  max mem: 3586
I20250120 12:40:11 3545703 dinov2 helpers.py:102] Training  [12020/12500]  eta: 0:01:53  loss: 17.3384 (21.3085)  lr: 0.0000 (0.0000)  time: 0.206872  data: 0.000362  max mem: 3586
I20250120 12:40:13 3545703 dinov2 helpers.py:102] Training  [12030/12500]  eta: 0:01:50  loss: 17.8524 (21.3078)  lr: 0.0000 (0.0000)  time: 0.206852  data: 0.000374  max mem: 3586
I20250120 12:40:15 3545703 dinov2 helpers.py:102] Training  [12040/12500]  eta: 0:01:48  loss: 17.8524 (21.3031)  lr: 0.0000 (0.0000)  time: 0.206761  data: 0.000474  max mem: 3586
I20250120 12:40:17 3545703 dinov2 helpers.py:102] Training  [12050/12500]  eta: 0:01:46  loss: 17.8990 (21.3011)  lr: 0.0000 (0.0000)  time: 0.206882  data: 0.000493  max mem: 3586
I20250120 12:40:19 3545703 dinov2 helpers.py:102] Training  [12060/12500]  eta: 0:01:43  loss: 18.2963 (21.3003)  lr: 0.0000 (0.0000)  time: 0.206910  data: 0.000405  max mem: 3586
I20250120 12:40:21 3545703 dinov2 helpers.py:102] Training  [12070/12500]  eta: 0:01:41  loss: 17.8990 (21.2962)  lr: 0.0000 (0.0000)  time: 0.206950  data: 0.000402  max mem: 3586
I20250120 12:40:23 3545703 dinov2 helpers.py:102] Training  [12080/12500]  eta: 0:01:39  loss: 18.2963 (21.2940)  lr: 0.0000 (0.0000)  time: 0.207087  data: 0.000428  max mem: 3586
I20250120 12:40:26 3545703 dinov2 helpers.py:102] Training  [12090/12500]  eta: 0:01:36  loss: 17.8990 (21.2897)  lr: 0.0000 (0.0000)  time: 0.206741  data: 0.000400  max mem: 3586
I20250120 12:40:28 3545703 dinov2 helpers.py:102] Training  [12100/12500]  eta: 0:01:34  loss: 17.8990 (21.2825)  lr: 0.0000 (0.0000)  time: 0.206653  data: 0.000382  max mem: 3586
I20250120 12:40:30 3545703 dinov2 helpers.py:102] Training  [12110/12500]  eta: 0:01:31  loss: 17.8990 (21.2814)  lr: 0.0000 (0.0000)  time: 0.206855  data: 0.000412  max mem: 3586
I20250120 12:40:32 3545703 dinov2 helpers.py:102] Training  [12120/12500]  eta: 0:01:29  loss: 17.8990 (21.2776)  lr: 0.0000 (0.0000)  time: 0.206732  data: 0.000435  max mem: 3586
I20250120 12:40:34 3545703 dinov2 helpers.py:102] Training  [12130/12500]  eta: 0:01:27  loss: 17.3384 (21.2721)  lr: 0.0000 (0.0000)  time: 0.206875  data: 0.000458  max mem: 3586
I20250120 12:40:36 3545703 dinov2 helpers.py:102] Training  [12140/12500]  eta: 0:01:24  loss: 17.6692 (21.2691)  lr: 0.0000 (0.0000)  time: 0.206928  data: 0.000440  max mem: 3586
I20250120 12:40:38 3545703 dinov2 helpers.py:102] Training  [12150/12500]  eta: 0:01:22  loss: 17.3384 (21.2635)  lr: 0.0000 (0.0000)  time: 0.206841  data: 0.000393  max mem: 3586
I20250120 12:40:40 3545703 dinov2 helpers.py:102] Training  [12160/12500]  eta: 0:01:20  loss: 16.7902 (21.2594)  lr: 0.0000 (0.0000)  time: 0.207042  data: 0.000427  max mem: 3586
I20250120 12:40:42 3545703 dinov2 helpers.py:102] Training  [12170/12500]  eta: 0:01:17  loss: 16.7902 (21.2569)  lr: 0.0000 (0.0000)  time: 0.207038  data: 0.000475  max mem: 3586
I20250120 12:40:44 3545703 dinov2 helpers.py:102] Training  [12180/12500]  eta: 0:01:15  loss: 17.3384 (21.2539)  lr: 0.0000 (0.0000)  time: 0.206984  data: 0.000484  max mem: 3586
I20250120 12:40:46 3545703 dinov2 helpers.py:102] Training  [12190/12500]  eta: 0:01:13  loss: 16.7662 (21.2502)  lr: 0.0000 (0.0000)  time: 0.206937  data: 0.000473  max mem: 3586
I20250120 12:40:48 3545703 dinov2 helpers.py:102] Training  [12200/12500]  eta: 0:01:10  loss: 16.7662 (21.2480)  lr: 0.0000 (0.0000)  time: 0.206938  data: 0.000488  max mem: 3586
I20250120 12:40:50 3545703 dinov2 helpers.py:102] Training  [12210/12500]  eta: 0:01:08  loss: 17.0701 (21.2446)  lr: 0.0000 (0.0000)  time: 0.206996  data: 0.000460  max mem: 3586
I20250120 12:40:52 3545703 dinov2 helpers.py:102] Training  [12220/12500]  eta: 0:01:05  loss: 16.7662 (21.2400)  lr: 0.0000 (0.0000)  time: 0.207076  data: 0.000409  max mem: 3586
I20250120 12:40:55 3545703 dinov2 helpers.py:102] Training  [12230/12500]  eta: 0:01:03  loss: 16.7127 (21.2363)  lr: 0.0000 (0.0000)  time: 0.207091  data: 0.000365  max mem: 3586
I20250120 12:40:57 3545703 dinov2 helpers.py:102] Training  [12240/12500]  eta: 0:01:01  loss: 16.7662 (21.2338)  lr: 0.0000 (0.0000)  time: 0.207074  data: 0.000359  max mem: 3586
I20250120 12:40:59 3545703 dinov2 helpers.py:102] Training  [12250/12500]  eta: 0:00:58  loss: 16.7662 (21.2309)  lr: 0.0000 (0.0000)  time: 0.206973  data: 0.000412  max mem: 3586
I20250120 12:41:01 3545703 dinov2 helpers.py:102] Training  [12260/12500]  eta: 0:00:56  loss: 16.7127 (21.2269)  lr: 0.0000 (0.0000)  time: 0.206674  data: 0.000436  max mem: 3586
I20250120 12:41:03 3545703 dinov2 helpers.py:102] Training  [12270/12500]  eta: 0:00:54  loss: 16.7127 (21.2210)  lr: 0.0000 (0.0000)  time: 0.206585  data: 0.000452  max mem: 3586
I20250120 12:41:05 3545703 dinov2 helpers.py:102] Training  [12280/12500]  eta: 0:00:51  loss: 16.7112 (21.2169)  lr: 0.0000 (0.0000)  time: 0.206623  data: 0.000479  max mem: 3586
I20250120 12:41:07 3545703 dinov2 helpers.py:102] Training  [12290/12500]  eta: 0:00:49  loss: 16.7127 (21.2134)  lr: 0.0000 (0.0000)  time: 0.206687  data: 0.000486  max mem: 3586
I20250120 12:41:09 3545703 dinov2 helpers.py:102] Training  [12300/12500]  eta: 0:00:47  loss: 16.7127 (21.2069)  lr: 0.0000 (0.0000)  time: 0.206980  data: 0.000480  max mem: 3586
I20250120 12:41:11 3545703 dinov2 helpers.py:102] Training  [12310/12500]  eta: 0:00:44  loss: 16.7112 (21.2021)  lr: 0.0000 (0.0000)  time: 0.207042  data: 0.000488  max mem: 3586
I20250120 12:41:13 3545703 dinov2 helpers.py:102] Training  [12320/12500]  eta: 0:00:42  loss: 16.7127 (21.1997)  lr: 0.0000 (0.0000)  time: 0.207038  data: 0.000510  max mem: 3586
I20250120 12:41:15 3545703 dinov2 helpers.py:102] Training  [12330/12500]  eta: 0:00:39  loss: 16.7662 (21.1982)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000469  max mem: 3586
I20250120 12:41:17 3545703 dinov2 helpers.py:102] Training  [12340/12500]  eta: 0:00:37  loss: 16.7662 (21.1957)  lr: 0.0000 (0.0000)  time: 0.206855  data: 0.000421  max mem: 3586
I20250120 12:41:19 3545703 dinov2 helpers.py:102] Training  [12350/12500]  eta: 0:00:35  loss: 16.9326 (21.1941)  lr: 0.0000 (0.0000)  time: 0.206831  data: 0.000464  max mem: 3586
I20250120 12:41:21 3545703 dinov2 helpers.py:102] Training  [12360/12500]  eta: 0:00:32  loss: 17.0701 (21.1955)  lr: 0.0000 (0.0000)  time: 0.207107  data: 0.000481  max mem: 3586
I20250120 12:41:24 3545703 dinov2 helpers.py:102] Training  [12370/12500]  eta: 0:00:30  loss: 16.9326 (21.1912)  lr: 0.0000 (0.0000)  time: 0.207126  data: 0.000461  max mem: 3586
I20250120 12:41:26 3545703 dinov2 helpers.py:102] Training  [12380/12500]  eta: 0:00:28  loss: 16.8441 (21.1877)  lr: 0.0000 (0.0000)  time: 0.207119  data: 0.000393  max mem: 3586
I20250120 12:41:28 3545703 dinov2 helpers.py:102] Training  [12390/12500]  eta: 0:00:25  loss: 16.8441 (21.1831)  lr: 0.0000 (0.0000)  time: 0.207006  data: 0.000349  max mem: 3586
I20250120 12:41:30 3545703 dinov2 helpers.py:102] Training  [12400/12500]  eta: 0:00:23  loss: 16.7127 (21.1786)  lr: 0.0000 (0.0000)  time: 0.206784  data: 0.000419  max mem: 3586
I20250120 12:41:32 3545703 dinov2 helpers.py:102] Training  [12410/12500]  eta: 0:00:21  loss: 16.7127 (21.1769)  lr: 0.0000 (0.0000)  time: 0.206716  data: 0.000422  max mem: 3586
I20250120 12:41:34 3545703 dinov2 helpers.py:102] Training  [12420/12500]  eta: 0:00:18  loss: 16.8441 (21.1743)  lr: 0.0000 (0.0000)  time: 0.206811  data: 0.000402  max mem: 3586
I20250120 12:41:36 3545703 dinov2 helpers.py:102] Training  [12430/12500]  eta: 0:00:16  loss: 16.9326 (21.1716)  lr: 0.0000 (0.0000)  time: 0.206883  data: 0.000465  max mem: 3586
I20250120 12:41:38 3545703 dinov2 helpers.py:102] Training  [12440/12500]  eta: 0:00:14  loss: 16.9326 (21.1683)  lr: 0.0000 (0.0000)  time: 0.206870  data: 0.000463  max mem: 3586
I20250120 12:41:40 3545703 dinov2 helpers.py:102] Training  [12450/12500]  eta: 0:00:11  loss: 16.8441 (21.1640)  lr: 0.0000 (0.0000)  time: 0.206841  data: 0.000441  max mem: 3586
I20250120 12:41:42 3545703 dinov2 helpers.py:102] Training  [12460/12500]  eta: 0:00:09  loss: 16.8441 (21.1591)  lr: 0.0000 (0.0000)  time: 0.206789  data: 0.000470  max mem: 3586
I20250120 12:41:44 3545703 dinov2 helpers.py:102] Training  [12470/12500]  eta: 0:00:07  loss: 16.9326 (21.1563)  lr: 0.0000 (0.0000)  time: 0.206708  data: 0.000446  max mem: 3586
I20250120 12:41:46 3545703 dinov2 helpers.py:102] Training  [12480/12500]  eta: 0:00:04  loss: 16.9326 (21.1514)  lr: 0.0000 (0.0000)  time: 0.206736  data: 0.000442  max mem: 3586
I20250120 12:41:48 3545703 dinov2 helpers.py:102] Training  [12490/12500]  eta: 0:00:02  loss: 17.0801 (21.1538)  lr: 0.0000 (0.0000)  time: 0.206668  data: 0.000423  max mem: 3586
I20250120 12:41:50 3545703 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_pixelated_A/eval/training_124999/linear_gender_with_pixelated_train_and_val_dataset/model_final.pth
I20250120 12:41:50 3545703 dinov2 helpers.py:102] Training  [12499/12500]  eta: 0:00:00  loss: 17.0801 (21.1538)  lr: 0.0000 (0.0000)  time: 0.210938  data: 0.000404  max mem: 3586
I20250120 12:41:50 3545703 dinov2 helpers.py:130] Training Total time: 0:48:56 (0.234909 s / it)
I20250120 12:41:50 3545703 dinov2 linear.py:272] running validation !
I20250120 12:41:52 3545703 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:37    time: 1.402249  data: 1.190755  max mem: 3586
I20250120 12:41:54 3545703 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:46    time: 0.322554  data: 0.109915  max mem: 3586
I20250120 12:41:56 3545703 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.211783  data: 0.001199  max mem: 3586
I20250120 12:41:58 3545703 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.209021  data: 0.000422  max mem: 3586
I20250120 12:42:00 3545703 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209237  data: 0.000244  max mem: 3586
I20250120 12:42:02 3545703 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.208941  data: 0.000218  max mem: 3586
I20250120 12:42:04 3545703 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.208654  data: 0.000230  max mem: 3586
I20250120 12:42:06 3545703 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.208649  data: 0.000219  max mem: 3586
I20250120 12:42:08 3545703 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.208897  data: 0.000208  max mem: 3586
I20250120 12:42:11 3545703 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209137  data: 0.000232  max mem: 3586
I20250120 12:42:13 3545703 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208874  data: 0.000251  max mem: 3586
I20250120 12:42:15 3545703 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.208834  data: 0.000226  max mem: 3586
I20250120 12:42:17 3545703 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.208951  data: 0.000210  max mem: 3586
I20250120 12:42:19 3545703 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209012  data: 0.000213  max mem: 3586
I20250120 12:42:21 3545703 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.208937  data: 0.000240  max mem: 3586
I20250120 12:42:23 3545703 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208419  data: 0.000190  max mem: 3586
I20250120 12:42:24 3545703 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204355  data: 0.000147  max mem: 3586
I20250120 12:42:24 3545703 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.217321 s / it)
I20250120 12:42:24 3545703 dinov2 utils.py:79] Averaged stats: 
I20250120 12:42:24 3545703 dinov2 linear.py:287] 
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8568, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8659, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8684, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8723, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8742, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8749, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8761, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8778, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8792, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8795, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8804, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8814, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8574, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8649, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8714, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8743, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8772, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8797, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8809, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8844, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8857, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8885, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8904, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8928, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.8642, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.8711, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.8770, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.8774, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.8793, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.8811, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.8827, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.8834, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.8846, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.8864, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.8870, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.8817, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.8671, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.8739, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.8768, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.8786, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.8814, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.8841, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.8859, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.8889, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.8910, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.8916, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.8937, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.8884, device='cuda:0')}
I20250120 12:42:24 3545703 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_02500', 'accuracy': 0.893744945526123}
I20250120 12:42:24 3545703 dinov2 linear.py:590] Test Results Dict {'best_classifier': 'classifier_4_blocks_avgpool_True_lr_0_02500', 'CelebAPixelatedVal_accuracy': 89.3744945526123}

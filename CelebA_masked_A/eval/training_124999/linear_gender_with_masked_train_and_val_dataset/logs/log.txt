I20250120 11:03:18 3528121 dinov2 config.py:59] git:
  sha: 3ded4e34eb54a7264c5d718f22ec7b24d73ba04c, status: has uncommitted changes, branch: main

I20250120 11:03:18 3528121 dinov2 config.py:60] batch_size: 128
classifier_fpath: None
config_file: CelebA_masked_A/config.yaml
epoch_length: 1250
epochs: 10
eval_period_iterations: 1250
learning_rates: [1e-05, 2e-05, 5e-05, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
no_resume: False
num_workers: 8
opts: ['train.output_dir=/home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset']
output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset
pretrained_weights: CelebA_masked_A/eval/training_124999/teacher_checkpoint.pth
save_checkpoint_frequency: 20
test_class_mapping_fpaths: [None]
test_dataset_strs: None
test_metric_types: None
train_dataset_str: CelebAMaskedTrain
val_class_mapping_fpath: None
val_dataset_str: CelebAMaskedVal
val_metric_type: mean_accuracy
I20250120 11:03:18 3528121 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0004330127018922193
I20250120 11:03:18 3528121 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 12
  dataset_path: CelebAMaskedABTrain
  output_dir: /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 1250
  cache_dataset: true
  centering: centering
  a_b_training: A
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
  in_chans: 3
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0004330127018922193
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20250120 11:03:18 3528121 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20250120 11:03:21 3528121 dinov2 utils.py:26] Take key teacher in provided checkpoint dict
I20250120 11:03:21 3528121 dinov2 utils.py:33] Pretrained weights found at CelebA_masked_A/eval/training_124999/teacher_checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v'])
I20250120 11:03:21 3528121 dinov2 loaders.py:116] using dataset: "CelebAMaskedTrain"
I20250120 11:03:23 3528121 dinov2 loaders.py:121] # of dataset samples: 162,127
I20250120 11:03:24 3528121 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:03:24 3528121 dinov2 loaders.py:154] sampler: sharded infinite
I20250120 11:03:24 3528121 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:03:24 3528121 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:03:24 3528121 dinov2 loaders.py:253] infinite data loader
I20250120 11:03:24 3528121 dinov2 loaders.py:116] using dataset: "CelebAMaskedVal"
I20250120 11:03:25 3528121 dinov2 loaders.py:121] # of dataset samples: 19,792
I20250120 11:03:25 3528121 dinov2 loaders.py:179] sampler: distributed
I20250120 11:03:25 3528121 dinov2 loaders.py:238] using PyTorch data loader
W20250120 11:03:25 3528121 py.warnings warnings.py:109] /home/stud/m/mc085/mounted_home/dinov2_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

I20250120 11:03:25 3528121 dinov2 loaders.py:251] # of batches: 155
I20250120 11:03:25 3528121 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20250120 11:03:25 3528121 dinov2 linear.py:338] Starting training from iteration 0
I20250120 11:03:29 3528121 dinov2 helpers.py:102] Training  [    0/12500]  eta: 14:54:09  loss: 35.6438 (35.6438)  lr: 0.0000 (0.0000)  time: 4.291995  data: 3.819683  max mem: 2706
I20250120 11:03:29 3528121 torch.nn.parallel.distributed distributed.py:1140] Reducer buckets have been rebuilt in this iteration.
I20250120 11:03:31 3528121 dinov2 helpers.py:102] Training  [   10/12500]  eta: 1:55:39  loss: 35.6438 (36.0555)  lr: 0.0000 (0.0000)  time: 0.555579  data: 0.347681  max mem: 3115
I20250120 11:03:33 3528121 dinov2 helpers.py:102] Training  [   20/12500]  eta: 1:18:32  loss: 36.4673 (37.4044)  lr: 0.0000 (0.0000)  time: 0.181897  data: 0.000481  max mem: 3115
I20250120 11:03:34 3528121 dinov2 helpers.py:102] Training  [   30/12500]  eta: 1:05:22  loss: 36.4673 (39.2246)  lr: 0.0000 (0.0000)  time: 0.181952  data: 0.000457  max mem: 3115
I20250120 11:03:36 3528121 dinov2 helpers.py:102] Training  [   40/12500]  eta: 0:58:39  loss: 40.1021 (40.5924)  lr: 0.0000 (0.0000)  time: 0.182578  data: 0.000487  max mem: 3115
I20250120 11:03:38 3528121 dinov2 helpers.py:102] Training  [   50/12500]  eta: 0:54:35  loss: 40.1021 (42.4568)  lr: 0.0000 (0.0000)  time: 0.183423  data: 0.000472  max mem: 3115
I20250120 11:03:40 3528121 dinov2 helpers.py:102] Training  [   60/12500]  eta: 0:51:52  loss: 43.6478 (42.6270)  lr: 0.0000 (0.0000)  time: 0.184035  data: 0.000422  max mem: 3115
I20250120 11:03:42 3528121 dinov2 helpers.py:102] Training  [   70/12500]  eta: 0:49:56  loss: 41.2222 (42.4514)  lr: 0.0000 (0.0000)  time: 0.184725  data: 0.000459  max mem: 3115
I20250120 11:03:44 3528121 dinov2 helpers.py:102] Training  [   80/12500]  eta: 0:48:27  loss: 41.7621 (42.3748)  lr: 0.0000 (0.0000)  time: 0.185128  data: 0.000449  max mem: 3115
I20250120 11:03:45 3528121 dinov2 helpers.py:102] Training  [   90/12500]  eta: 0:47:19  loss: 41.7621 (42.6652)  lr: 0.0000 (0.0000)  time: 0.185540  data: 0.000450  max mem: 3115
I20250120 11:03:47 3528121 dinov2 helpers.py:102] Training  [  100/12500]  eta: 0:46:25  loss: 41.7621 (42.1929)  lr: 0.0000 (0.0000)  time: 0.186289  data: 0.000450  max mem: 3115
I20250120 11:03:49 3528121 dinov2 helpers.py:102] Training  [  110/12500]  eta: 0:45:41  loss: 41.2222 (42.0769)  lr: 0.0000 (0.0000)  time: 0.186832  data: 0.000445  max mem: 3115
I20250120 11:03:51 3528121 dinov2 helpers.py:102] Training  [  120/12500]  eta: 0:45:04  loss: 41.7621 (42.2253)  lr: 0.0000 (0.0000)  time: 0.187380  data: 0.000438  max mem: 3115
I20250120 11:03:53 3528121 dinov2 helpers.py:102] Training  [  130/12500]  eta: 0:44:34  loss: 41.7621 (42.3550)  lr: 0.0000 (0.0000)  time: 0.188128  data: 0.000426  max mem: 3115
I20250120 11:03:55 3528121 dinov2 helpers.py:102] Training  [  140/12500]  eta: 0:44:08  loss: 41.7621 (42.2262)  lr: 0.0000 (0.0000)  time: 0.188745  data: 0.000460  max mem: 3115
I20250120 11:03:57 3528121 dinov2 helpers.py:102] Training  [  150/12500]  eta: 0:43:46  loss: 41.7621 (42.6115)  lr: 0.0000 (0.0000)  time: 0.189203  data: 0.000445  max mem: 3115
I20250120 11:03:59 3528121 dinov2 helpers.py:102] Training  [  160/12500]  eta: 0:43:26  loss: 43.6478 (42.8903)  lr: 0.0000 (0.0000)  time: 0.189643  data: 0.000401  max mem: 3115
I20250120 11:04:01 3528121 dinov2 helpers.py:102] Training  [  170/12500]  eta: 0:43:09  loss: 43.6478 (43.0059)  lr: 0.0000 (0.0000)  time: 0.190133  data: 0.000400  max mem: 3115
I20250120 11:04:02 3528121 dinov2 helpers.py:102] Training  [  180/12500]  eta: 0:42:54  loss: 44.0062 (43.2480)  lr: 0.0000 (0.0000)  time: 0.190626  data: 0.000446  max mem: 3115
I20250120 11:04:04 3528121 dinov2 helpers.py:102] Training  [  190/12500]  eta: 0:42:40  loss: 44.0062 (43.3165)  lr: 0.0000 (0.0000)  time: 0.190960  data: 0.000455  max mem: 3115
I20250120 11:04:06 3528121 dinov2 helpers.py:102] Training  [  200/12500]  eta: 0:42:28  loss: 44.0062 (42.9182)  lr: 0.0000 (0.0000)  time: 0.190983  data: 0.000411  max mem: 3115
I20250120 11:04:08 3528121 dinov2 helpers.py:102] Training  [  210/12500]  eta: 0:42:17  loss: 44.0062 (42.6804)  lr: 0.0000 (0.0000)  time: 0.191531  data: 0.000387  max mem: 3115
I20250120 11:04:10 3528121 dinov2 helpers.py:102] Training  [  220/12500]  eta: 0:42:07  loss: 44.0062 (42.6055)  lr: 0.0000 (0.0000)  time: 0.192330  data: 0.000399  max mem: 3115
I20250120 11:04:12 3528121 dinov2 helpers.py:102] Training  [  230/12500]  eta: 0:41:58  loss: 43.6478 (42.4681)  lr: 0.0000 (0.0000)  time: 0.192591  data: 0.000418  max mem: 3115
I20250120 11:04:14 3528121 dinov2 helpers.py:102] Training  [  240/12500]  eta: 0:41:50  loss: 41.7621 (42.4272)  lr: 0.0000 (0.0000)  time: 0.192860  data: 0.000439  max mem: 3115
I20250120 11:04:16 3528121 dinov2 helpers.py:102] Training  [  250/12500]  eta: 0:41:42  loss: 41.4457 (42.2410)  lr: 0.0000 (0.0000)  time: 0.193293  data: 0.000429  max mem: 3115
I20250120 11:04:18 3528121 dinov2 helpers.py:102] Training  [  260/12500]  eta: 0:41:35  loss: 41.4457 (42.2172)  lr: 0.0000 (0.0000)  time: 0.193665  data: 0.000422  max mem: 3115
I20250120 11:04:20 3528121 dinov2 helpers.py:102] Training  [  270/12500]  eta: 0:41:29  loss: 41.4970 (42.1914)  lr: 0.0000 (0.0000)  time: 0.193885  data: 0.000428  max mem: 3115
I20250120 11:04:22 3528121 dinov2 helpers.py:102] Training  [  280/12500]  eta: 0:41:23  loss: 41.4457 (42.1598)  lr: 0.0000 (0.0000)  time: 0.194303  data: 0.000396  max mem: 3115
I20250120 11:04:24 3528121 dinov2 helpers.py:102] Training  [  290/12500]  eta: 0:41:17  loss: 41.2743 (42.0911)  lr: 0.0000 (0.0000)  time: 0.194985  data: 0.000385  max mem: 3115
I20250120 11:04:26 3528121 dinov2 helpers.py:102] Training  [  300/12500]  eta: 0:41:12  loss: 41.2743 (42.0008)  lr: 0.0000 (0.0000)  time: 0.195461  data: 0.000406  max mem: 3115
I20250120 11:04:28 3528121 dinov2 helpers.py:102] Training  [  310/12500]  eta: 0:41:08  loss: 41.4457 (42.0085)  lr: 0.0000 (0.0000)  time: 0.195866  data: 0.000392  max mem: 3115
I20250120 11:04:30 3528121 dinov2 helpers.py:102] Training  [  320/12500]  eta: 0:41:03  loss: 41.2743 (41.8375)  lr: 0.0000 (0.0000)  time: 0.196282  data: 0.000344  max mem: 3115
I20250120 11:04:32 3528121 dinov2 helpers.py:102] Training  [  330/12500]  eta: 0:40:59  loss: 40.9583 (41.7409)  lr: 0.0000 (0.0000)  time: 0.196505  data: 0.000376  max mem: 3115
I20250120 11:04:33 3528121 dinov2 helpers.py:102] Training  [  340/12500]  eta: 0:40:56  loss: 40.9583 (41.6616)  lr: 0.0000 (0.0000)  time: 0.196934  data: 0.000400  max mem: 3115
I20250120 11:04:35 3528121 dinov2 helpers.py:102] Training  [  350/12500]  eta: 0:40:52  loss: 40.0972 (41.5550)  lr: 0.0000 (0.0000)  time: 0.197434  data: 0.000416  max mem: 3115
I20250120 11:04:37 3528121 dinov2 helpers.py:102] Training  [  360/12500]  eta: 0:40:49  loss: 39.4602 (41.4984)  lr: 0.0000 (0.0000)  time: 0.197774  data: 0.000450  max mem: 3115
I20250120 11:04:39 3528121 dinov2 helpers.py:102] Training  [  370/12500]  eta: 0:40:46  loss: 39.4602 (41.5104)  lr: 0.0000 (0.0000)  time: 0.198041  data: 0.000424  max mem: 3115
I20250120 11:04:41 3528121 dinov2 helpers.py:102] Training  [  380/12500]  eta: 0:40:43  loss: 39.4602 (41.4917)  lr: 0.0000 (0.0000)  time: 0.198407  data: 0.000400  max mem: 3115
I20250120 11:04:43 3528121 dinov2 helpers.py:102] Training  [  390/12500]  eta: 0:40:40  loss: 39.3074 (41.3590)  lr: 0.0000 (0.0000)  time: 0.198771  data: 0.000382  max mem: 3115
I20250120 11:04:45 3528121 dinov2 helpers.py:102] Training  [  400/12500]  eta: 0:40:37  loss: 39.4602 (41.4344)  lr: 0.0000 (0.0000)  time: 0.198811  data: 0.000346  max mem: 3115
I20250120 11:04:47 3528121 dinov2 helpers.py:102] Training  [  410/12500]  eta: 0:40:34  loss: 39.4602 (41.3673)  lr: 0.0000 (0.0000)  time: 0.198882  data: 0.000344  max mem: 3115
I20250120 11:04:49 3528121 dinov2 helpers.py:102] Training  [  420/12500]  eta: 0:40:31  loss: 39.3074 (41.2279)  lr: 0.0000 (0.0000)  time: 0.198954  data: 0.000394  max mem: 3115
I20250120 11:04:51 3528121 dinov2 helpers.py:102] Training  [  430/12500]  eta: 0:40:29  loss: 39.2925 (41.1084)  lr: 0.0000 (0.0000)  time: 0.199155  data: 0.000415  max mem: 3115
I20250120 11:04:53 3528121 dinov2 helpers.py:102] Training  [  440/12500]  eta: 0:40:26  loss: 39.2925 (41.1961)  lr: 0.0000 (0.0000)  time: 0.199623  data: 0.000392  max mem: 3115
I20250120 11:04:55 3528121 dinov2 helpers.py:102] Training  [  450/12500]  eta: 0:40:24  loss: 39.4602 (41.2125)  lr: 0.0000 (0.0000)  time: 0.199842  data: 0.000366  max mem: 3115
I20250120 11:04:57 3528121 dinov2 helpers.py:102] Training  [  460/12500]  eta: 0:40:22  loss: 39.4602 (41.2067)  lr: 0.0000 (0.0000)  time: 0.200031  data: 0.000373  max mem: 3115
I20250120 11:04:59 3528121 dinov2 helpers.py:102] Training  [  470/12500]  eta: 0:40:20  loss: 39.4602 (41.2734)  lr: 0.0000 (0.0000)  time: 0.200308  data: 0.000385  max mem: 3115
I20250120 11:05:01 3528121 dinov2 helpers.py:102] Training  [  480/12500]  eta: 0:40:17  loss: 39.4602 (41.2682)  lr: 0.0000 (0.0000)  time: 0.200548  data: 0.000368  max mem: 3115
I20250120 11:05:03 3528121 dinov2 helpers.py:102] Training  [  490/12500]  eta: 0:40:15  loss: 39.4602 (41.4465)  lr: 0.0000 (0.0000)  time: 0.200704  data: 0.000368  max mem: 3115
I20250120 11:05:05 3528121 dinov2 helpers.py:102] Training  [  500/12500]  eta: 0:40:13  loss: 39.4602 (41.3886)  lr: 0.0000 (0.0000)  time: 0.200745  data: 0.000425  max mem: 3115
I20250120 11:05:07 3528121 dinov2 helpers.py:102] Training  [  510/12500]  eta: 0:40:11  loss: 39.4602 (41.4176)  lr: 0.0000 (0.0000)  time: 0.201190  data: 0.000436  max mem: 3115
I20250120 11:05:09 3528121 dinov2 helpers.py:102] Training  [  520/12500]  eta: 0:40:09  loss: 40.7823 (41.4701)  lr: 0.0000 (0.0000)  time: 0.201686  data: 0.000393  max mem: 3115
I20250120 11:05:11 3528121 dinov2 helpers.py:102] Training  [  530/12500]  eta: 0:40:08  loss: 40.9408 (41.4747)  lr: 0.0000 (0.0000)  time: 0.201792  data: 0.000401  max mem: 3115
I20250120 11:05:13 3528121 dinov2 helpers.py:102] Training  [  540/12500]  eta: 0:40:06  loss: 40.9408 (41.4271)  lr: 0.0000 (0.0000)  time: 0.201757  data: 0.000378  max mem: 3115
I20250120 11:05:15 3528121 dinov2 helpers.py:102] Training  [  550/12500]  eta: 0:40:04  loss: 40.9408 (41.3690)  lr: 0.0000 (0.0000)  time: 0.201625  data: 0.000357  max mem: 3115
I20250120 11:05:18 3528121 dinov2 helpers.py:102] Training  [  560/12500]  eta: 0:40:02  loss: 40.9408 (41.3319)  lr: 0.0000 (0.0000)  time: 0.201899  data: 0.000361  max mem: 3115
I20250120 11:05:20 3528121 dinov2 helpers.py:102] Training  [  570/12500]  eta: 0:40:00  loss: 40.9408 (41.3332)  lr: 0.0000 (0.0000)  time: 0.202222  data: 0.000330  max mem: 3115
I20250120 11:05:22 3528121 dinov2 helpers.py:102] Training  [  580/12500]  eta: 0:39:58  loss: 41.0162 (41.3811)  lr: 0.0000 (0.0000)  time: 0.202449  data: 0.000401  max mem: 3115
I20250120 11:05:24 3528121 dinov2 helpers.py:102] Training  [  590/12500]  eta: 0:39:57  loss: 41.0162 (41.2987)  lr: 0.0000 (0.0000)  time: 0.202393  data: 0.000440  max mem: 3115
I20250120 11:05:26 3528121 dinov2 helpers.py:102] Training  [  600/12500]  eta: 0:39:55  loss: 41.0162 (41.2995)  lr: 0.0000 (0.0000)  time: 0.202630  data: 0.000408  max mem: 3115
I20250120 11:05:28 3528121 dinov2 helpers.py:102] Training  [  610/12500]  eta: 0:39:53  loss: 41.0162 (41.2492)  lr: 0.0000 (0.0000)  time: 0.203055  data: 0.000406  max mem: 3115
I20250120 11:05:30 3528121 dinov2 helpers.py:102] Training  [  620/12500]  eta: 0:39:52  loss: 41.0162 (41.2246)  lr: 0.0000 (0.0000)  time: 0.203012  data: 0.000365  max mem: 3115
I20250120 11:05:32 3528121 dinov2 helpers.py:102] Training  [  630/12500]  eta: 0:39:50  loss: 41.0162 (41.1883)  lr: 0.0000 (0.0000)  time: 0.202968  data: 0.000331  max mem: 3115
I20250120 11:05:34 3528121 dinov2 helpers.py:102] Training  [  640/12500]  eta: 0:39:48  loss: 41.0162 (41.3177)  lr: 0.0000 (0.0000)  time: 0.203135  data: 0.000368  max mem: 3115
I20250120 11:05:36 3528121 dinov2 helpers.py:102] Training  [  650/12500]  eta: 0:39:46  loss: 41.0162 (41.3527)  lr: 0.0000 (0.0000)  time: 0.203172  data: 0.000434  max mem: 3115
I20250120 11:05:38 3528121 dinov2 helpers.py:102] Training  [  660/12500]  eta: 0:39:45  loss: 41.0162 (41.3107)  lr: 0.0000 (0.0000)  time: 0.203176  data: 0.000406  max mem: 3115
I20250120 11:05:40 3528121 dinov2 helpers.py:102] Training  [  670/12500]  eta: 0:39:43  loss: 40.9831 (41.3058)  lr: 0.0000 (0.0000)  time: 0.203328  data: 0.000360  max mem: 3115
I20250120 11:05:42 3528121 dinov2 helpers.py:102] Training  [  680/12500]  eta: 0:39:41  loss: 39.6948 (41.2256)  lr: 0.0000 (0.0000)  time: 0.203217  data: 0.000384  max mem: 3115
I20250120 11:05:44 3528121 dinov2 helpers.py:102] Training  [  690/12500]  eta: 0:39:40  loss: 39.2544 (41.1903)  lr: 0.0000 (0.0000)  time: 0.203151  data: 0.000413  max mem: 3115
I20250120 11:05:46 3528121 dinov2 helpers.py:102] Training  [  700/12500]  eta: 0:39:38  loss: 39.6948 (41.1901)  lr: 0.0000 (0.0000)  time: 0.203352  data: 0.000376  max mem: 3115
I20250120 11:05:48 3528121 dinov2 helpers.py:102] Training  [  710/12500]  eta: 0:39:36  loss: 39.6948 (41.1746)  lr: 0.0000 (0.0000)  time: 0.203594  data: 0.000359  max mem: 3115
I20250120 11:05:50 3528121 dinov2 helpers.py:102] Training  [  720/12500]  eta: 0:39:35  loss: 39.4804 (41.1513)  lr: 0.0000 (0.0000)  time: 0.203769  data: 0.000369  max mem: 3115
I20250120 11:05:52 3528121 dinov2 helpers.py:102] Training  [  730/12500]  eta: 0:39:33  loss: 39.2544 (41.1011)  lr: 0.0000 (0.0000)  time: 0.203878  data: 0.000335  max mem: 3115
I20250120 11:05:54 3528121 dinov2 helpers.py:102] Training  [  740/12500]  eta: 0:39:31  loss: 39.4804 (41.1403)  lr: 0.0000 (0.0000)  time: 0.203877  data: 0.000342  max mem: 3115
I20250120 11:05:56 3528121 dinov2 helpers.py:102] Training  [  750/12500]  eta: 0:39:30  loss: 39.4804 (41.1035)  lr: 0.0000 (0.0000)  time: 0.203991  data: 0.000352  max mem: 3115
I20250120 11:05:58 3528121 dinov2 helpers.py:102] Training  [  760/12500]  eta: 0:39:28  loss: 39.4804 (41.0539)  lr: 0.0000 (0.0000)  time: 0.204030  data: 0.000403  max mem: 3115
I20250120 11:06:00 3528121 dinov2 helpers.py:102] Training  [  770/12500]  eta: 0:39:26  loss: 39.4804 (41.0663)  lr: 0.0000 (0.0000)  time: 0.204124  data: 0.000426  max mem: 3115
I20250120 11:06:02 3528121 dinov2 helpers.py:102] Training  [  780/12500]  eta: 0:39:25  loss: 39.2380 (41.0431)  lr: 0.0000 (0.0000)  time: 0.204244  data: 0.000338  max mem: 3115
I20250120 11:06:04 3528121 dinov2 helpers.py:102] Training  [  790/12500]  eta: 0:39:23  loss: 39.4804 (41.0541)  lr: 0.0000 (0.0000)  time: 0.204526  data: 0.000345  max mem: 3115
I20250120 11:06:06 3528121 dinov2 helpers.py:102] Training  [  800/12500]  eta: 0:39:22  loss: 39.4804 (41.0447)  lr: 0.0000 (0.0000)  time: 0.204785  data: 0.000370  max mem: 3115
I20250120 11:06:08 3528121 dinov2 helpers.py:102] Training  [  810/12500]  eta: 0:39:20  loss: 39.6948 (41.0498)  lr: 0.0000 (0.0000)  time: 0.204907  data: 0.000375  max mem: 3115
I20250120 11:06:10 3528121 dinov2 helpers.py:102] Training  [  820/12500]  eta: 0:39:18  loss: 39.7917 (41.0346)  lr: 0.0000 (0.0000)  time: 0.204717  data: 0.000389  max mem: 3115
I20250120 11:06:12 3528121 dinov2 helpers.py:102] Training  [  830/12500]  eta: 0:39:17  loss: 40.0727 (41.0514)  lr: 0.0000 (0.0000)  time: 0.204590  data: 0.000349  max mem: 3115
I20250120 11:06:15 3528121 dinov2 helpers.py:102] Training  [  840/12500]  eta: 0:39:15  loss: 40.0727 (41.1260)  lr: 0.0000 (0.0000)  time: 0.204793  data: 0.000321  max mem: 3115
I20250120 11:06:17 3528121 dinov2 helpers.py:102] Training  [  850/12500]  eta: 0:39:14  loss: 39.7917 (41.0800)  lr: 0.0000 (0.0000)  time: 0.204917  data: 0.000354  max mem: 3115
I20250120 11:06:19 3528121 dinov2 helpers.py:102] Training  [  860/12500]  eta: 0:39:12  loss: 40.0727 (41.1021)  lr: 0.0000 (0.0000)  time: 0.204895  data: 0.000382  max mem: 3115
I20250120 11:06:21 3528121 dinov2 helpers.py:102] Training  [  870/12500]  eta: 0:39:10  loss: 40.0727 (41.0945)  lr: 0.0000 (0.0000)  time: 0.204780  data: 0.000390  max mem: 3115
I20250120 11:06:23 3528121 dinov2 helpers.py:102] Training  [  880/12500]  eta: 0:39:09  loss: 40.1440 (41.0838)  lr: 0.0000 (0.0000)  time: 0.204787  data: 0.000415  max mem: 3115
I20250120 11:06:25 3528121 dinov2 helpers.py:102] Training  [  890/12500]  eta: 0:39:07  loss: 40.1440 (41.0261)  lr: 0.0000 (0.0000)  time: 0.204746  data: 0.000436  max mem: 3115
I20250120 11:06:27 3528121 dinov2 helpers.py:102] Training  [  900/12500]  eta: 0:39:05  loss: 40.1440 (41.0371)  lr: 0.0000 (0.0000)  time: 0.204883  data: 0.000397  max mem: 3115
I20250120 11:06:29 3528121 dinov2 helpers.py:102] Training  [  910/12500]  eta: 0:39:04  loss: 40.2881 (41.0665)  lr: 0.0000 (0.0000)  time: 0.205021  data: 0.000336  max mem: 3115
I20250120 11:06:31 3528121 dinov2 helpers.py:102] Training  [  920/12500]  eta: 0:39:02  loss: 40.4319 (41.0894)  lr: 0.0000 (0.0000)  time: 0.205004  data: 0.000335  max mem: 3115
I20250120 11:06:33 3528121 dinov2 helpers.py:102] Training  [  930/12500]  eta: 0:39:00  loss: 40.4319 (41.0385)  lr: 0.0000 (0.0000)  time: 0.205119  data: 0.000347  max mem: 3115
I20250120 11:06:35 3528121 dinov2 helpers.py:102] Training  [  940/12500]  eta: 0:38:59  loss: 40.2881 (41.0068)  lr: 0.0000 (0.0000)  time: 0.205208  data: 0.000353  max mem: 3115
I20250120 11:06:37 3528121 dinov2 helpers.py:102] Training  [  950/12500]  eta: 0:38:57  loss: 40.2881 (40.9946)  lr: 0.0000 (0.0000)  time: 0.204965  data: 0.000363  max mem: 3115
I20250120 11:06:39 3528121 dinov2 helpers.py:102] Training  [  960/12500]  eta: 0:38:55  loss: 40.4319 (41.0652)  lr: 0.0000 (0.0000)  time: 0.204698  data: 0.000399  max mem: 3115
I20250120 11:06:41 3528121 dinov2 helpers.py:102] Training  [  970/12500]  eta: 0:38:53  loss: 40.4319 (41.1448)  lr: 0.0000 (0.0000)  time: 0.204861  data: 0.000408  max mem: 3115
I20250120 11:06:43 3528121 dinov2 helpers.py:102] Training  [  980/12500]  eta: 0:38:52  loss: 41.4649 (41.1797)  lr: 0.0000 (0.0000)  time: 0.205039  data: 0.000358  max mem: 3115
I20250120 11:06:45 3528121 dinov2 helpers.py:102] Training  [  990/12500]  eta: 0:38:50  loss: 40.5326 (41.1732)  lr: 0.0000 (0.0000)  time: 0.205133  data: 0.000316  max mem: 3115
I20250120 11:06:47 3528121 dinov2 helpers.py:102] Training  [ 1000/12500]  eta: 0:38:48  loss: 40.5326 (41.1346)  lr: 0.0000 (0.0000)  time: 0.205240  data: 0.000333  max mem: 3115
I20250120 11:06:49 3528121 dinov2 helpers.py:102] Training  [ 1010/12500]  eta: 0:38:47  loss: 40.4319 (41.0957)  lr: 0.0000 (0.0000)  time: 0.205332  data: 0.000338  max mem: 3115
I20250120 11:06:51 3528121 dinov2 helpers.py:102] Training  [ 1020/12500]  eta: 0:38:45  loss: 40.5326 (41.0999)  lr: 0.0000 (0.0000)  time: 0.205225  data: 0.000363  max mem: 3115
I20250120 11:06:54 3528121 dinov2 helpers.py:102] Training  [ 1030/12500]  eta: 0:38:43  loss: 40.4319 (41.0517)  lr: 0.0000 (0.0000)  time: 0.205078  data: 0.000384  max mem: 3115
I20250120 11:06:56 3528121 dinov2 helpers.py:102] Training  [ 1040/12500]  eta: 0:38:41  loss: 40.1440 (41.0064)  lr: 0.0000 (0.0000)  time: 0.204993  data: 0.000373  max mem: 3115
I20250120 11:06:58 3528121 dinov2 helpers.py:102] Training  [ 1050/12500]  eta: 0:38:40  loss: 40.1440 (40.9948)  lr: 0.0000 (0.0000)  time: 0.205214  data: 0.000347  max mem: 3115
I20250120 11:07:00 3528121 dinov2 helpers.py:102] Training  [ 1060/12500]  eta: 0:38:38  loss: 40.1440 (40.9932)  lr: 0.0000 (0.0000)  time: 0.205460  data: 0.000332  max mem: 3115
I20250120 11:07:02 3528121 dinov2 helpers.py:102] Training  [ 1070/12500]  eta: 0:38:36  loss: 40.0756 (40.9847)  lr: 0.0000 (0.0000)  time: 0.205141  data: 0.000341  max mem: 3115
I20250120 11:07:04 3528121 dinov2 helpers.py:102] Training  [ 1080/12500]  eta: 0:38:34  loss: 39.8314 (40.9570)  lr: 0.0000 (0.0000)  time: 0.205038  data: 0.000333  max mem: 3115
I20250120 11:07:06 3528121 dinov2 helpers.py:102] Training  [ 1090/12500]  eta: 0:38:33  loss: 40.0756 (40.9745)  lr: 0.0000 (0.0000)  time: 0.205199  data: 0.000355  max mem: 3115
I20250120 11:07:08 3528121 dinov2 helpers.py:102] Training  [ 1100/12500]  eta: 0:38:31  loss: 39.8314 (40.9609)  lr: 0.0000 (0.0000)  time: 0.205297  data: 0.000404  max mem: 3115
I20250120 11:07:10 3528121 dinov2 helpers.py:102] Training  [ 1110/12500]  eta: 0:38:29  loss: 39.8314 (40.9574)  lr: 0.0000 (0.0000)  time: 0.205353  data: 0.000424  max mem: 3115
I20250120 11:07:12 3528121 dinov2 helpers.py:102] Training  [ 1120/12500]  eta: 0:38:27  loss: 39.7780 (40.9102)  lr: 0.0000 (0.0000)  time: 0.205235  data: 0.000409  max mem: 3115
I20250120 11:07:14 3528121 dinov2 helpers.py:102] Training  [ 1130/12500]  eta: 0:38:25  loss: 39.7780 (40.8842)  lr: 0.0000 (0.0000)  time: 0.205014  data: 0.000363  max mem: 3115
I20250120 11:07:16 3528121 dinov2 helpers.py:102] Training  [ 1140/12500]  eta: 0:38:24  loss: 39.7780 (40.8541)  lr: 0.0000 (0.0000)  time: 0.205124  data: 0.000344  max mem: 3115
I20250120 11:07:18 3528121 dinov2 helpers.py:102] Training  [ 1150/12500]  eta: 0:38:22  loss: 39.4651 (40.8369)  lr: 0.0000 (0.0000)  time: 0.205192  data: 0.000338  max mem: 3115
I20250120 11:07:20 3528121 dinov2 helpers.py:102] Training  [ 1160/12500]  eta: 0:38:20  loss: 39.4651 (40.8266)  lr: 0.0000 (0.0000)  time: 0.205144  data: 0.000303  max mem: 3115
I20250120 11:07:22 3528121 dinov2 helpers.py:102] Training  [ 1170/12500]  eta: 0:38:18  loss: 39.4651 (40.8521)  lr: 0.0000 (0.0000)  time: 0.205297  data: 0.000317  max mem: 3115
I20250120 11:07:24 3528121 dinov2 helpers.py:102] Training  [ 1180/12500]  eta: 0:38:16  loss: 39.4651 (40.8419)  lr: 0.0000 (0.0000)  time: 0.205329  data: 0.000338  max mem: 3115
I20250120 11:07:26 3528121 dinov2 helpers.py:102] Training  [ 1190/12500]  eta: 0:38:15  loss: 39.4651 (40.8399)  lr: 0.0000 (0.0000)  time: 0.205205  data: 0.000318  max mem: 3115
I20250120 11:07:28 3528121 dinov2 helpers.py:102] Training  [ 1200/12500]  eta: 0:38:13  loss: 39.6230 (40.8634)  lr: 0.0000 (0.0000)  time: 0.205481  data: 0.000310  max mem: 3115
I20250120 11:07:30 3528121 dinov2 helpers.py:102] Training  [ 1210/12500]  eta: 0:38:11  loss: 39.6396 (40.8919)  lr: 0.0000 (0.0000)  time: 0.205368  data: 0.000343  max mem: 3115
I20250120 11:07:33 3528121 dinov2 helpers.py:102] Training  [ 1220/12500]  eta: 0:38:09  loss: 39.6230 (40.8649)  lr: 0.0000 (0.0000)  time: 0.205125  data: 0.000382  max mem: 3115
I20250120 11:07:35 3528121 dinov2 helpers.py:102] Training  [ 1230/12500]  eta: 0:38:07  loss: 39.6396 (40.8759)  lr: 0.0000 (0.0000)  time: 0.205553  data: 0.000384  max mem: 3115
I20250120 11:07:37 3528121 dinov2 helpers.py:102] Training  [ 1240/12500]  eta: 0:38:06  loss: 39.7780 (40.9128)  lr: 0.0000 (0.0000)  time: 0.205593  data: 0.000371  max mem: 3115
I20250120 11:07:38 3528121 dinov2 linear.py:272] running validation !
I20250120 11:07:40 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:05:06    time: 1.977233  data: 1.721895  max mem: 3190
I20250120 11:07:43 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:56    time: 0.390851  data: 0.156909  max mem: 3586
I20250120 11:07:45 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:41    time: 0.222249  data: 0.000330  max mem: 3586
I20250120 11:07:47 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:34    time: 0.210064  data: 0.000225  max mem: 3586
I20250120 11:07:49 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:29    time: 0.207767  data: 0.000197  max mem: 3586
I20250120 11:07:51 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:26    time: 0.207373  data: 0.000218  max mem: 3586
I20250120 11:07:53 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.207472  data: 0.000208  max mem: 3586
I20250120 11:07:55 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:20    time: 0.207943  data: 0.000212  max mem: 3586
I20250120 11:07:57 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.208336  data: 0.000248  max mem: 3586
I20250120 11:07:59 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.208427  data: 0.000238  max mem: 3586
I20250120 11:08:02 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208077  data: 0.000221  max mem: 3586
I20250120 11:08:04 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.207888  data: 0.000224  max mem: 3586
I20250120 11:08:06 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.207930  data: 0.000236  max mem: 3586
I20250120 11:08:08 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.207793  data: 0.000271  max mem: 3586
I20250120 11:08:10 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.207747  data: 0.000264  max mem: 3586
I20250120 11:08:12 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.207620  data: 0.000176  max mem: 3586
I20250120 11:08:13 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.207926  data: 0.000160  max mem: 3586
I20250120 11:08:13 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:34 (0.222091 s / it)
I20250120 11:08:13 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:08:13 3528121 dinov2 linear.py:287] 
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6191, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.6607, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.6944, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7071, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7225, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7302, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7357, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7309, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7138, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7073, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7106, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6679, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.6601, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.6909, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7071, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7206, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7293, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7327, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7394, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7412, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7409, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7262, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.6725, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6604, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6750, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7060, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7195, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7262, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7285, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7253, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7219, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7284, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7173, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.6618, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.6419, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6662, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.6829, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7104, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7259, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7340, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7359, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7255, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7304, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7302, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.6769, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.6527, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.6737, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:292] ITER: 1249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6173, device='cuda:0')}
I20250120 11:08:13 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.7411580681800842}
I20250120 11:08:14 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:08:14 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:08:14 3528121 dinov2 helpers.py:102] Training  [ 1250/12500]  eta: 0:43:19  loss: 40.0756 (40.9517)  lr: 0.0000 (0.0000)  time: 1.957992  data: 0.026925  max mem: 3586
I20250120 11:08:16 3528121 dinov2 helpers.py:102] Training  [ 1260/12500]  eta: 0:43:14  loss: 40.0756 (40.9594)  lr: 0.0000 (0.0000)  time: 1.956927  data: 0.026915  max mem: 3586
I20250120 11:08:18 3528121 dinov2 helpers.py:102] Training  [ 1270/12500]  eta: 0:43:10  loss: 40.3326 (40.9545)  lr: 0.0000 (0.0000)  time: 0.203724  data: 0.000442  max mem: 3586
I20250120 11:08:20 3528121 dinov2 helpers.py:102] Training  [ 1280/12500]  eta: 0:43:05  loss: 40.3326 (40.9080)  lr: 0.0000 (0.0000)  time: 0.204321  data: 0.000480  max mem: 3586
I20250120 11:08:22 3528121 dinov2 helpers.py:102] Training  [ 1290/12500]  eta: 0:43:00  loss: 39.6396 (40.8583)  lr: 0.0000 (0.0000)  time: 0.204616  data: 0.000448  max mem: 3586
I20250120 11:08:24 3528121 dinov2 helpers.py:102] Training  [ 1300/12500]  eta: 0:42:56  loss: 40.3326 (40.8780)  lr: 0.0000 (0.0000)  time: 0.204737  data: 0.000430  max mem: 3586
I20250120 11:08:26 3528121 dinov2 helpers.py:102] Training  [ 1310/12500]  eta: 0:42:51  loss: 39.6396 (40.8400)  lr: 0.0000 (0.0000)  time: 0.204772  data: 0.000429  max mem: 3586
I20250120 11:08:28 3528121 dinov2 helpers.py:102] Training  [ 1320/12500]  eta: 0:42:47  loss: 40.3326 (40.8460)  lr: 0.0000 (0.0000)  time: 0.204861  data: 0.000419  max mem: 3586
I20250120 11:08:30 3528121 dinov2 helpers.py:102] Training  [ 1330/12500]  eta: 0:42:43  loss: 40.3326 (40.8150)  lr: 0.0000 (0.0000)  time: 0.205049  data: 0.000371  max mem: 3586
I20250120 11:08:32 3528121 dinov2 helpers.py:102] Training  [ 1340/12500]  eta: 0:42:38  loss: 40.3326 (40.8022)  lr: 0.0000 (0.0000)  time: 0.205292  data: 0.000387  max mem: 3586
I20250120 11:08:34 3528121 dinov2 helpers.py:102] Training  [ 1350/12500]  eta: 0:42:34  loss: 40.6106 (40.8302)  lr: 0.0000 (0.0000)  time: 0.205308  data: 0.000422  max mem: 3586
I20250120 11:08:36 3528121 dinov2 helpers.py:102] Training  [ 1360/12500]  eta: 0:42:30  loss: 40.6106 (40.8185)  lr: 0.0000 (0.0000)  time: 0.205244  data: 0.000418  max mem: 3586
I20250120 11:08:38 3528121 dinov2 helpers.py:102] Training  [ 1370/12500]  eta: 0:42:26  loss: 40.3326 (40.8008)  lr: 0.0000 (0.0000)  time: 0.205154  data: 0.000349  max mem: 3586
I20250120 11:08:40 3528121 dinov2 helpers.py:102] Training  [ 1380/12500]  eta: 0:42:21  loss: 40.3326 (40.7802)  lr: 0.0000 (0.0000)  time: 0.205277  data: 0.000378  max mem: 3586
I20250120 11:08:42 3528121 dinov2 helpers.py:102] Training  [ 1390/12500]  eta: 0:42:17  loss: 39.2334 (40.7668)  lr: 0.0000 (0.0000)  time: 0.205390  data: 0.000409  max mem: 3586
I20250120 11:08:44 3528121 dinov2 helpers.py:102] Training  [ 1400/12500]  eta: 0:42:13  loss: 39.0816 (40.7122)  lr: 0.0000 (0.0000)  time: 0.205396  data: 0.000412  max mem: 3586
I20250120 11:08:47 3528121 dinov2 helpers.py:102] Training  [ 1410/12500]  eta: 0:42:09  loss: 38.9028 (40.6945)  lr: 0.0000 (0.0000)  time: 0.205359  data: 0.000451  max mem: 3586
I20250120 11:08:49 3528121 dinov2 helpers.py:102] Training  [ 1420/12500]  eta: 0:42:05  loss: 38.9028 (40.6794)  lr: 0.0000 (0.0000)  time: 0.205147  data: 0.000443  max mem: 3586
I20250120 11:08:51 3528121 dinov2 helpers.py:102] Training  [ 1430/12500]  eta: 0:42:01  loss: 38.5360 (40.6355)  lr: 0.0000 (0.0000)  time: 0.205083  data: 0.000427  max mem: 3586
I20250120 11:08:53 3528121 dinov2 helpers.py:102] Training  [ 1440/12500]  eta: 0:41:57  loss: 38.3762 (40.6061)  lr: 0.0000 (0.0000)  time: 0.205183  data: 0.000422  max mem: 3586
I20250120 11:08:55 3528121 dinov2 helpers.py:102] Training  [ 1450/12500]  eta: 0:41:53  loss: 38.1956 (40.5630)  lr: 0.0000 (0.0000)  time: 0.205341  data: 0.000459  max mem: 3586
I20250120 11:08:57 3528121 dinov2 helpers.py:102] Training  [ 1460/12500]  eta: 0:41:49  loss: 37.9344 (40.5185)  lr: 0.0000 (0.0000)  time: 0.205288  data: 0.000471  max mem: 3586
I20250120 11:08:59 3528121 dinov2 helpers.py:102] Training  [ 1470/12500]  eta: 0:41:45  loss: 36.6935 (40.4917)  lr: 0.0000 (0.0000)  time: 0.205405  data: 0.000433  max mem: 3586
I20250120 11:09:01 3528121 dinov2 helpers.py:102] Training  [ 1480/12500]  eta: 0:41:41  loss: 37.9344 (40.4805)  lr: 0.0000 (0.0000)  time: 0.205470  data: 0.000405  max mem: 3586
I20250120 11:09:03 3528121 dinov2 helpers.py:102] Training  [ 1490/12500]  eta: 0:41:37  loss: 37.9344 (40.4254)  lr: 0.0000 (0.0000)  time: 0.205353  data: 0.000424  max mem: 3586
I20250120 11:09:05 3528121 dinov2 helpers.py:102] Training  [ 1500/12500]  eta: 0:41:34  loss: 37.9344 (40.4635)  lr: 0.0000 (0.0000)  time: 0.205571  data: 0.000401  max mem: 3586
I20250120 11:09:07 3528121 dinov2 helpers.py:102] Training  [ 1510/12500]  eta: 0:41:30  loss: 37.9344 (40.4325)  lr: 0.0000 (0.0000)  time: 0.205776  data: 0.000388  max mem: 3586
I20250120 11:09:09 3528121 dinov2 helpers.py:102] Training  [ 1520/12500]  eta: 0:41:26  loss: 37.9344 (40.4191)  lr: 0.0000 (0.0000)  time: 0.205718  data: 0.000375  max mem: 3586
I20250120 11:09:11 3528121 dinov2 helpers.py:102] Training  [ 1530/12500]  eta: 0:41:22  loss: 38.0396 (40.4037)  lr: 0.0000 (0.0000)  time: 0.205730  data: 0.000385  max mem: 3586
I20250120 11:09:13 3528121 dinov2 helpers.py:102] Training  [ 1540/12500]  eta: 0:41:19  loss: 37.9344 (40.3783)  lr: 0.0000 (0.0000)  time: 0.205767  data: 0.000396  max mem: 3586
I20250120 11:09:15 3528121 dinov2 helpers.py:102] Training  [ 1550/12500]  eta: 0:41:15  loss: 37.9344 (40.4464)  lr: 0.0000 (0.0000)  time: 0.205587  data: 0.000368  max mem: 3586
I20250120 11:09:17 3528121 dinov2 helpers.py:102] Training  [ 1560/12500]  eta: 0:41:11  loss: 37.9344 (40.4496)  lr: 0.0000 (0.0000)  time: 0.205664  data: 0.000353  max mem: 3586
I20250120 11:09:19 3528121 dinov2 helpers.py:102] Training  [ 1570/12500]  eta: 0:41:08  loss: 37.9344 (40.4897)  lr: 0.0000 (0.0000)  time: 0.205921  data: 0.000317  max mem: 3586
I20250120 11:09:21 3528121 dinov2 helpers.py:102] Training  [ 1580/12500]  eta: 0:41:04  loss: 38.0396 (40.5310)  lr: 0.0000 (0.0000)  time: 0.206056  data: 0.000335  max mem: 3586
I20250120 11:09:24 3528121 dinov2 helpers.py:102] Training  [ 1590/12500]  eta: 0:41:00  loss: 38.0396 (40.5337)  lr: 0.0000 (0.0000)  time: 0.206214  data: 0.000373  max mem: 3586
I20250120 11:09:26 3528121 dinov2 helpers.py:102] Training  [ 1600/12500]  eta: 0:40:57  loss: 38.0396 (40.5072)  lr: 0.0000 (0.0000)  time: 0.206334  data: 0.000390  max mem: 3586
I20250120 11:09:28 3528121 dinov2 helpers.py:102] Training  [ 1610/12500]  eta: 0:40:53  loss: 38.0396 (40.5016)  lr: 0.0000 (0.0000)  time: 0.206053  data: 0.000448  max mem: 3586
I20250120 11:09:30 3528121 dinov2 helpers.py:102] Training  [ 1620/12500]  eta: 0:40:50  loss: 38.0396 (40.5146)  lr: 0.0000 (0.0000)  time: 0.206014  data: 0.000507  max mem: 3586
I20250120 11:09:32 3528121 dinov2 helpers.py:102] Training  [ 1630/12500]  eta: 0:40:46  loss: 38.0396 (40.4667)  lr: 0.0000 (0.0000)  time: 0.206151  data: 0.000458  max mem: 3586
I20250120 11:09:34 3528121 dinov2 helpers.py:102] Training  [ 1640/12500]  eta: 0:40:43  loss: 38.3876 (40.4727)  lr: 0.0000 (0.0000)  time: 0.205959  data: 0.000413  max mem: 3586
I20250120 11:09:36 3528121 dinov2 helpers.py:102] Training  [ 1650/12500]  eta: 0:40:39  loss: 38.8283 (40.5141)  lr: 0.0000 (0.0000)  time: 0.205984  data: 0.000464  max mem: 3586
I20250120 11:09:38 3528121 dinov2 helpers.py:102] Training  [ 1660/12500]  eta: 0:40:36  loss: 39.5947 (40.5615)  lr: 0.0000 (0.0000)  time: 0.206057  data: 0.000431  max mem: 3586
I20250120 11:09:40 3528121 dinov2 helpers.py:102] Training  [ 1670/12500]  eta: 0:40:32  loss: 39.5947 (40.5403)  lr: 0.0000 (0.0000)  time: 0.206109  data: 0.000380  max mem: 3586
I20250120 11:09:42 3528121 dinov2 helpers.py:102] Training  [ 1680/12500]  eta: 0:40:29  loss: 40.9398 (40.5583)  lr: 0.0000 (0.0000)  time: 0.206069  data: 0.000387  max mem: 3586
I20250120 11:09:44 3528121 dinov2 helpers.py:102] Training  [ 1690/12500]  eta: 0:40:25  loss: 40.9569 (40.5740)  lr: 0.0000 (0.0000)  time: 0.206114  data: 0.000407  max mem: 3586
I20250120 11:09:46 3528121 dinov2 helpers.py:102] Training  [ 1700/12500]  eta: 0:40:22  loss: 40.9398 (40.5575)  lr: 0.0000 (0.0000)  time: 0.206268  data: 0.000413  max mem: 3586
I20250120 11:09:48 3528121 dinov2 helpers.py:102] Training  [ 1710/12500]  eta: 0:40:19  loss: 40.9398 (40.5299)  lr: 0.0000 (0.0000)  time: 0.206317  data: 0.000431  max mem: 3586
I20250120 11:09:50 3528121 dinov2 helpers.py:102] Training  [ 1720/12500]  eta: 0:40:15  loss: 40.9398 (40.5235)  lr: 0.0000 (0.0000)  time: 0.206418  data: 0.000464  max mem: 3586
I20250120 11:09:52 3528121 dinov2 helpers.py:102] Training  [ 1730/12500]  eta: 0:40:12  loss: 40.9569 (40.5485)  lr: 0.0000 (0.0000)  time: 0.206239  data: 0.000417  max mem: 3586
I20250120 11:09:54 3528121 dinov2 helpers.py:102] Training  [ 1740/12500]  eta: 0:40:08  loss: 40.9569 (40.5496)  lr: 0.0000 (0.0000)  time: 0.206079  data: 0.000397  max mem: 3586
I20250120 11:09:57 3528121 dinov2 helpers.py:102] Training  [ 1750/12500]  eta: 0:40:05  loss: 40.9398 (40.5050)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000410  max mem: 3586
I20250120 11:09:59 3528121 dinov2 helpers.py:102] Training  [ 1760/12500]  eta: 0:40:02  loss: 40.9569 (40.5228)  lr: 0.0000 (0.0000)  time: 0.206406  data: 0.000444  max mem: 3586
I20250120 11:10:01 3528121 dinov2 helpers.py:102] Training  [ 1770/12500]  eta: 0:39:59  loss: 40.9569 (40.5296)  lr: 0.0000 (0.0000)  time: 0.205903  data: 0.000480  max mem: 3586
I20250120 11:10:03 3528121 dinov2 helpers.py:102] Training  [ 1780/12500]  eta: 0:39:55  loss: 40.7310 (40.5257)  lr: 0.0000 (0.0000)  time: 0.205985  data: 0.000415  max mem: 3586
I20250120 11:10:05 3528121 dinov2 helpers.py:102] Training  [ 1790/12500]  eta: 0:39:52  loss: 39.8330 (40.5120)  lr: 0.0000 (0.0000)  time: 0.206160  data: 0.000371  max mem: 3586
I20250120 11:10:07 3528121 dinov2 helpers.py:102] Training  [ 1800/12500]  eta: 0:39:49  loss: 39.8330 (40.4674)  lr: 0.0000 (0.0000)  time: 0.206176  data: 0.000336  max mem: 3586
I20250120 11:10:09 3528121 dinov2 helpers.py:102] Training  [ 1810/12500]  eta: 0:39:46  loss: 39.8330 (40.4275)  lr: 0.0000 (0.0000)  time: 0.206252  data: 0.000381  max mem: 3586
I20250120 11:10:11 3528121 dinov2 helpers.py:102] Training  [ 1820/12500]  eta: 0:39:42  loss: 39.4239 (40.3888)  lr: 0.0000 (0.0000)  time: 0.206391  data: 0.000493  max mem: 3586
I20250120 11:10:13 3528121 dinov2 helpers.py:102] Training  [ 1830/12500]  eta: 0:39:39  loss: 39.4239 (40.3835)  lr: 0.0000 (0.0000)  time: 0.206433  data: 0.000497  max mem: 3586
I20250120 11:10:15 3528121 dinov2 helpers.py:102] Training  [ 1840/12500]  eta: 0:39:36  loss: 39.4060 (40.3562)  lr: 0.0000 (0.0000)  time: 0.206213  data: 0.000445  max mem: 3586
I20250120 11:10:17 3528121 dinov2 helpers.py:102] Training  [ 1850/12500]  eta: 0:39:33  loss: 38.0666 (40.3299)  lr: 0.0000 (0.0000)  time: 0.206079  data: 0.000409  max mem: 3586
I20250120 11:10:19 3528121 dinov2 helpers.py:102] Training  [ 1860/12500]  eta: 0:39:30  loss: 38.0666 (40.3512)  lr: 0.0000 (0.0000)  time: 0.206265  data: 0.000432  max mem: 3586
I20250120 11:10:21 3528121 dinov2 helpers.py:102] Training  [ 1870/12500]  eta: 0:39:26  loss: 39.4060 (40.3624)  lr: 0.0000 (0.0000)  time: 0.206074  data: 0.000460  max mem: 3586
I20250120 11:10:23 3528121 dinov2 helpers.py:102] Training  [ 1880/12500]  eta: 0:39:23  loss: 39.2800 (40.3567)  lr: 0.0000 (0.0000)  time: 0.206336  data: 0.000427  max mem: 3586
I20250120 11:10:25 3528121 dinov2 helpers.py:102] Training  [ 1890/12500]  eta: 0:39:20  loss: 38.0666 (40.3285)  lr: 0.0000 (0.0000)  time: 0.206602  data: 0.000415  max mem: 3586
I20250120 11:10:27 3528121 dinov2 helpers.py:102] Training  [ 1900/12500]  eta: 0:39:17  loss: 38.0666 (40.2951)  lr: 0.0000 (0.0000)  time: 0.206378  data: 0.000434  max mem: 3586
I20250120 11:10:30 3528121 dinov2 helpers.py:102] Training  [ 1910/12500]  eta: 0:39:14  loss: 39.2800 (40.3218)  lr: 0.0000 (0.0000)  time: 0.206592  data: 0.000419  max mem: 3586
I20250120 11:10:32 3528121 dinov2 helpers.py:102] Training  [ 1920/12500]  eta: 0:39:11  loss: 39.1369 (40.3157)  lr: 0.0000 (0.0000)  time: 0.206451  data: 0.000440  max mem: 3586
I20250120 11:10:34 3528121 dinov2 helpers.py:102] Training  [ 1930/12500]  eta: 0:39:08  loss: 38.0666 (40.3026)  lr: 0.0000 (0.0000)  time: 0.206036  data: 0.000438  max mem: 3586
I20250120 11:10:36 3528121 dinov2 helpers.py:102] Training  [ 1940/12500]  eta: 0:39:05  loss: 38.0666 (40.3182)  lr: 0.0000 (0.0000)  time: 0.206305  data: 0.000392  max mem: 3586
I20250120 11:10:38 3528121 dinov2 helpers.py:102] Training  [ 1950/12500]  eta: 0:39:01  loss: 39.1369 (40.3187)  lr: 0.0000 (0.0000)  time: 0.206438  data: 0.000406  max mem: 3586
I20250120 11:10:40 3528121 dinov2 helpers.py:102] Training  [ 1960/12500]  eta: 0:38:58  loss: 39.1369 (40.3252)  lr: 0.0000 (0.0000)  time: 0.206047  data: 0.000392  max mem: 3586
I20250120 11:10:42 3528121 dinov2 helpers.py:102] Training  [ 1970/12500]  eta: 0:38:55  loss: 39.1369 (40.3352)  lr: 0.0000 (0.0000)  time: 0.206191  data: 0.000398  max mem: 3586
I20250120 11:10:44 3528121 dinov2 helpers.py:102] Training  [ 1980/12500]  eta: 0:38:52  loss: 39.1369 (40.3335)  lr: 0.0000 (0.0000)  time: 0.206255  data: 0.000486  max mem: 3586
I20250120 11:10:46 3528121 dinov2 helpers.py:102] Training  [ 1990/12500]  eta: 0:38:49  loss: 39.2800 (40.3349)  lr: 0.0000 (0.0000)  time: 0.206092  data: 0.000494  max mem: 3586
I20250120 11:10:48 3528121 dinov2 helpers.py:102] Training  [ 2000/12500]  eta: 0:38:46  loss: 39.4060 (40.3575)  lr: 0.0000 (0.0000)  time: 0.206221  data: 0.000462  max mem: 3586
I20250120 11:10:50 3528121 dinov2 helpers.py:102] Training  [ 2010/12500]  eta: 0:38:43  loss: 39.9920 (40.4027)  lr: 0.0000 (0.0000)  time: 0.206288  data: 0.000426  max mem: 3586
I20250120 11:10:52 3528121 dinov2 helpers.py:102] Training  [ 2020/12500]  eta: 0:38:40  loss: 39.9920 (40.3719)  lr: 0.0000 (0.0000)  time: 0.206324  data: 0.000438  max mem: 3586
I20250120 11:10:54 3528121 dinov2 helpers.py:102] Training  [ 2030/12500]  eta: 0:38:37  loss: 39.9920 (40.3613)  lr: 0.0000 (0.0000)  time: 0.206236  data: 0.000443  max mem: 3586
I20250120 11:10:56 3528121 dinov2 helpers.py:102] Training  [ 2040/12500]  eta: 0:38:34  loss: 40.4155 (40.3656)  lr: 0.0000 (0.0000)  time: 0.206094  data: 0.000418  max mem: 3586
I20250120 11:10:58 3528121 dinov2 helpers.py:102] Training  [ 2050/12500]  eta: 0:38:31  loss: 40.6182 (40.3869)  lr: 0.0000 (0.0000)  time: 0.206244  data: 0.000413  max mem: 3586
I20250120 11:11:01 3528121 dinov2 helpers.py:102] Training  [ 2060/12500]  eta: 0:38:28  loss: 40.4155 (40.3676)  lr: 0.0000 (0.0000)  time: 0.206255  data: 0.000371  max mem: 3586
I20250120 11:11:03 3528121 dinov2 helpers.py:102] Training  [ 2070/12500]  eta: 0:38:25  loss: 40.4155 (40.3846)  lr: 0.0000 (0.0000)  time: 0.206304  data: 0.000402  max mem: 3586
I20250120 11:11:05 3528121 dinov2 helpers.py:102] Training  [ 2080/12500]  eta: 0:38:22  loss: 40.6182 (40.4003)  lr: 0.0000 (0.0000)  time: 0.206405  data: 0.000416  max mem: 3586
I20250120 11:11:07 3528121 dinov2 helpers.py:102] Training  [ 2090/12500]  eta: 0:38:19  loss: 40.6182 (40.3665)  lr: 0.0000 (0.0000)  time: 0.206377  data: 0.000389  max mem: 3586
I20250120 11:11:09 3528121 dinov2 helpers.py:102] Training  [ 2100/12500]  eta: 0:38:17  loss: 40.6182 (40.3471)  lr: 0.0000 (0.0000)  time: 0.206342  data: 0.000418  max mem: 3586
I20250120 11:11:11 3528121 dinov2 helpers.py:102] Training  [ 2110/12500]  eta: 0:38:14  loss: 40.4155 (40.3405)  lr: 0.0000 (0.0000)  time: 0.206322  data: 0.000423  max mem: 3586
I20250120 11:11:13 3528121 dinov2 helpers.py:102] Training  [ 2120/12500]  eta: 0:38:11  loss: 40.4155 (40.3285)  lr: 0.0000 (0.0000)  time: 0.206355  data: 0.000391  max mem: 3586
I20250120 11:11:15 3528121 dinov2 helpers.py:102] Training  [ 2130/12500]  eta: 0:38:08  loss: 40.6182 (40.3498)  lr: 0.0000 (0.0000)  time: 0.206356  data: 0.000391  max mem: 3586
I20250120 11:11:17 3528121 dinov2 helpers.py:102] Training  [ 2140/12500]  eta: 0:38:05  loss: 40.6182 (40.3599)  lr: 0.0000 (0.0000)  time: 0.206514  data: 0.000409  max mem: 3586
I20250120 11:11:19 3528121 dinov2 helpers.py:102] Training  [ 2150/12500]  eta: 0:38:02  loss: 40.6182 (40.3512)  lr: 0.0000 (0.0000)  time: 0.206670  data: 0.000396  max mem: 3586
I20250120 11:11:21 3528121 dinov2 helpers.py:102] Training  [ 2160/12500]  eta: 0:37:59  loss: 39.9920 (40.3328)  lr: 0.0000 (0.0000)  time: 0.206585  data: 0.000401  max mem: 3586
I20250120 11:11:23 3528121 dinov2 helpers.py:102] Training  [ 2170/12500]  eta: 0:37:56  loss: 38.9460 (40.3244)  lr: 0.0000 (0.0000)  time: 0.206404  data: 0.000417  max mem: 3586
I20250120 11:11:25 3528121 dinov2 helpers.py:102] Training  [ 2180/12500]  eta: 0:37:53  loss: 38.4820 (40.2868)  lr: 0.0000 (0.0000)  time: 0.206514  data: 0.000424  max mem: 3586
I20250120 11:11:27 3528121 dinov2 helpers.py:102] Training  [ 2190/12500]  eta: 0:37:51  loss: 38.4820 (40.2817)  lr: 0.0000 (0.0000)  time: 0.206395  data: 0.000437  max mem: 3586
I20250120 11:11:29 3528121 dinov2 helpers.py:102] Training  [ 2200/12500]  eta: 0:37:48  loss: 38.4734 (40.2560)  lr: 0.0000 (0.0000)  time: 0.206087  data: 0.000434  max mem: 3586
I20250120 11:11:31 3528121 dinov2 helpers.py:102] Training  [ 2210/12500]  eta: 0:37:45  loss: 38.4734 (40.2866)  lr: 0.0000 (0.0000)  time: 0.206207  data: 0.000407  max mem: 3586
I20250120 11:11:34 3528121 dinov2 helpers.py:102] Training  [ 2220/12500]  eta: 0:37:42  loss: 38.4734 (40.2732)  lr: 0.0000 (0.0000)  time: 0.206380  data: 0.000406  max mem: 3586
I20250120 11:11:36 3528121 dinov2 helpers.py:102] Training  [ 2230/12500]  eta: 0:37:39  loss: 38.4734 (40.2586)  lr: 0.0000 (0.0000)  time: 0.206252  data: 0.000415  max mem: 3586
I20250120 11:11:38 3528121 dinov2 helpers.py:102] Training  [ 2240/12500]  eta: 0:37:36  loss: 37.9423 (40.2483)  lr: 0.0000 (0.0000)  time: 0.206083  data: 0.000362  max mem: 3586
I20250120 11:11:40 3528121 dinov2 helpers.py:102] Training  [ 2250/12500]  eta: 0:37:33  loss: 37.9423 (40.2469)  lr: 0.0000 (0.0000)  time: 0.206341  data: 0.000374  max mem: 3586
I20250120 11:11:42 3528121 dinov2 helpers.py:102] Training  [ 2260/12500]  eta: 0:37:31  loss: 38.4734 (40.2578)  lr: 0.0000 (0.0000)  time: 0.206404  data: 0.000432  max mem: 3586
I20250120 11:11:44 3528121 dinov2 helpers.py:102] Training  [ 2270/12500]  eta: 0:37:28  loss: 38.4734 (40.2501)  lr: 0.0000 (0.0000)  time: 0.206214  data: 0.000420  max mem: 3586
I20250120 11:11:46 3528121 dinov2 helpers.py:102] Training  [ 2280/12500]  eta: 0:37:25  loss: 38.4734 (40.2598)  lr: 0.0000 (0.0000)  time: 0.206220  data: 0.000429  max mem: 3586
I20250120 11:11:48 3528121 dinov2 helpers.py:102] Training  [ 2290/12500]  eta: 0:37:22  loss: 38.4734 (40.2273)  lr: 0.0000 (0.0000)  time: 0.206321  data: 0.000452  max mem: 3586
I20250120 11:11:52 3528121 dinov2 helpers.py:102] Training  [ 2300/12500]  eta: 0:37:27  loss: 38.4820 (40.2283)  lr: 0.0000 (0.0000)  time: 0.291941  data: 0.089986  max mem: 3586
I20250120 11:11:56 3528121 dinov2 helpers.py:102] Training  [ 2310/12500]  eta: 0:37:36  loss: 38.4820 (40.2529)  lr: 0.0000 (0.0000)  time: 0.420596  data: 0.235549  max mem: 3586
I20250120 11:11:58 3528121 dinov2 helpers.py:102] Training  [ 2320/12500]  eta: 0:37:33  loss: 38.4996 (40.2616)  lr: 0.0000 (0.0000)  time: 0.333537  data: 0.146213  max mem: 3586
I20250120 11:12:00 3528121 dinov2 helpers.py:102] Training  [ 2330/12500]  eta: 0:37:30  loss: 38.4820 (40.2303)  lr: 0.0000 (0.0000)  time: 0.203669  data: 0.000638  max mem: 3586
I20250120 11:12:03 3528121 dinov2 helpers.py:102] Training  [ 2340/12500]  eta: 0:37:27  loss: 38.4734 (40.2085)  lr: 0.0000 (0.0000)  time: 0.204010  data: 0.000437  max mem: 3586
I20250120 11:12:05 3528121 dinov2 helpers.py:102] Training  [ 2350/12500]  eta: 0:37:24  loss: 38.4820 (40.2039)  lr: 0.0000 (0.0000)  time: 0.204130  data: 0.000404  max mem: 3586
I20250120 11:12:07 3528121 dinov2 helpers.py:102] Training  [ 2360/12500]  eta: 0:37:21  loss: 38.4996 (40.2209)  lr: 0.0000 (0.0000)  time: 0.204186  data: 0.000406  max mem: 3586
I20250120 11:12:09 3528121 dinov2 helpers.py:102] Training  [ 2370/12500]  eta: 0:37:18  loss: 39.1158 (40.2212)  lr: 0.0000 (0.0000)  time: 0.204263  data: 0.000423  max mem: 3586
I20250120 11:12:11 3528121 dinov2 helpers.py:102] Training  [ 2380/12500]  eta: 0:37:15  loss: 39.1158 (40.1903)  lr: 0.0000 (0.0000)  time: 0.204505  data: 0.000412  max mem: 3586
I20250120 11:12:13 3528121 dinov2 helpers.py:102] Training  [ 2390/12500]  eta: 0:37:12  loss: 39.1158 (40.1861)  lr: 0.0000 (0.0000)  time: 0.204603  data: 0.000399  max mem: 3586
I20250120 11:12:15 3528121 dinov2 helpers.py:102] Training  [ 2400/12500]  eta: 0:37:09  loss: 39.1158 (40.1744)  lr: 0.0000 (0.0000)  time: 0.204659  data: 0.000437  max mem: 3586
I20250120 11:12:17 3528121 dinov2 helpers.py:102] Training  [ 2410/12500]  eta: 0:37:06  loss: 38.4996 (40.1600)  lr: 0.0000 (0.0000)  time: 0.204755  data: 0.000464  max mem: 3586
I20250120 11:12:19 3528121 dinov2 helpers.py:102] Training  [ 2420/12500]  eta: 0:37:03  loss: 39.1158 (40.1609)  lr: 0.0000 (0.0000)  time: 0.204969  data: 0.000443  max mem: 3586
I20250120 11:12:21 3528121 dinov2 helpers.py:102] Training  [ 2430/12500]  eta: 0:37:01  loss: 39.1917 (40.1841)  lr: 0.0000 (0.0000)  time: 0.205255  data: 0.000448  max mem: 3586
I20250120 11:12:23 3528121 dinov2 helpers.py:102] Training  [ 2440/12500]  eta: 0:36:58  loss: 39.9375 (40.2224)  lr: 0.0000 (0.0000)  time: 0.205376  data: 0.000409  max mem: 3586
I20250120 11:12:25 3528121 dinov2 helpers.py:102] Training  [ 2450/12500]  eta: 0:36:55  loss: 40.2968 (40.2676)  lr: 0.0000 (0.0000)  time: 0.205457  data: 0.000399  max mem: 3586
I20250120 11:12:27 3528121 dinov2 helpers.py:102] Training  [ 2460/12500]  eta: 0:36:52  loss: 40.2968 (40.2979)  lr: 0.0000 (0.0000)  time: 0.205577  data: 0.000422  max mem: 3586
I20250120 11:12:29 3528121 dinov2 helpers.py:102] Training  [ 2470/12500]  eta: 0:36:49  loss: 40.3875 (40.3096)  lr: 0.0000 (0.0000)  time: 0.205616  data: 0.000402  max mem: 3586
I20250120 11:12:31 3528121 dinov2 helpers.py:102] Training  [ 2480/12500]  eta: 0:36:47  loss: 40.3875 (40.3151)  lr: 0.0000 (0.0000)  time: 0.205703  data: 0.000364  max mem: 3586
I20250120 11:12:33 3528121 dinov2 helpers.py:102] Training  [ 2490/12500]  eta: 0:36:44  loss: 40.3875 (40.2881)  lr: 0.0000 (0.0000)  time: 0.205940  data: 0.000373  max mem: 3586
I20250120 11:12:35 3528121 dinov2 linear.py:272] running validation !
I20250120 11:12:37 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:21    time: 1.685264  data: 1.483127  max mem: 3586
I20250120 11:12:39 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:49    time: 0.343568  data: 0.135907  max mem: 3586
I20250120 11:12:41 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.209172  data: 0.000780  max mem: 3586
I20250120 11:12:43 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.208356  data: 0.000333  max mem: 3586
I20250120 11:12:45 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.207925  data: 0.000267  max mem: 3586
I20250120 11:12:47 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.207982  data: 0.000228  max mem: 3586
I20250120 11:12:49 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.208203  data: 0.000244  max mem: 3586
I20250120 11:12:51 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.208370  data: 0.000255  max mem: 3586
I20250120 11:12:54 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.208424  data: 0.000249  max mem: 3586
I20250120 11:12:56 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.208612  data: 0.000242  max mem: 3586
I20250120 11:12:58 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208553  data: 0.000208  max mem: 3586
I20250120 11:13:00 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.208723  data: 0.000209  max mem: 3586
I20250120 11:13:02 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.208581  data: 0.000242  max mem: 3586
I20250120 11:13:04 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.208881  data: 0.000245  max mem: 3586
I20250120 11:13:06 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209004  data: 0.000236  max mem: 3586
I20250120 11:13:08 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208369  data: 0.000181  max mem: 3586
I20250120 11:13:09 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204084  data: 0.000168  max mem: 3586
I20250120 11:13:09 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218369 s / it)
I20250120 11:13:09 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:13:09 3528121 dinov2 linear.py:287] 
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6567, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.6887, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7094, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7206, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7302, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7358, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7384, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7407, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7376, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7238, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.6994, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6860, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.6823, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7100, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7221, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7308, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7399, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7456, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7514, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7533, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7464, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7213, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7023, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6897, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6981, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7219, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7302, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7358, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7418, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7460, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7465, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7304, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7256, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.6931, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.6761, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6675, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7054, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7234, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7345, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7401, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7498, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7518, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7491, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7290, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7177, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.6986, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7096, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:292] ITER: 2499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7006, device='cuda:0')}
I20250120 11:13:09 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.7532841563224792}
I20250120 11:13:09 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:13:09 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:13:09 3528121 dinov2 helpers.py:102] Training  [ 2500/12500]  eta: 0:38:57  loss: 40.2968 (40.2807)  lr: 0.0000 (0.0000)  time: 1.903621  data: 0.000408  max mem: 3586
I20250120 11:13:11 3528121 dinov2 helpers.py:102] Training  [ 2510/12500]  eta: 0:38:53  loss: 39.1917 (40.2589)  lr: 0.0000 (0.0000)  time: 1.903241  data: 0.000393  max mem: 3586
I20250120 11:13:14 3528121 dinov2 helpers.py:102] Training  [ 2520/12500]  eta: 0:38:52  loss: 39.1917 (40.2764)  lr: 0.0000 (0.0000)  time: 0.228959  data: 0.027933  max mem: 3586
I20250120 11:13:16 3528121 dinov2 helpers.py:102] Training  [ 2530/12500]  eta: 0:38:48  loss: 39.1917 (40.2638)  lr: 0.0000 (0.0000)  time: 0.229263  data: 0.027955  max mem: 3586
I20250120 11:13:18 3528121 dinov2 helpers.py:102] Training  [ 2540/12500]  eta: 0:38:45  loss: 39.1917 (40.2380)  lr: 0.0000 (0.0000)  time: 0.205683  data: 0.000431  max mem: 3586
I20250120 11:13:20 3528121 dinov2 helpers.py:102] Training  [ 2550/12500]  eta: 0:38:41  loss: 39.1917 (40.1994)  lr: 0.0000 (0.0000)  time: 0.205327  data: 0.000448  max mem: 3586
I20250120 11:13:22 3528121 dinov2 helpers.py:102] Training  [ 2560/12500]  eta: 0:38:38  loss: 38.4224 (40.1653)  lr: 0.0000 (0.0000)  time: 0.205417  data: 0.000438  max mem: 3586
I20250120 11:13:24 3528121 dinov2 helpers.py:102] Training  [ 2570/12500]  eta: 0:38:35  loss: 37.3728 (40.1529)  lr: 0.0000 (0.0000)  time: 0.205518  data: 0.000436  max mem: 3586
I20250120 11:13:26 3528121 dinov2 helpers.py:102] Training  [ 2580/12500]  eta: 0:38:31  loss: 38.4224 (40.1721)  lr: 0.0000 (0.0000)  time: 0.205558  data: 0.000414  max mem: 3586
I20250120 11:13:28 3528121 dinov2 helpers.py:102] Training  [ 2590/12500]  eta: 0:38:28  loss: 37.3728 (40.1607)  lr: 0.0000 (0.0000)  time: 0.205732  data: 0.000415  max mem: 3586
I20250120 11:13:30 3528121 dinov2 helpers.py:102] Training  [ 2600/12500]  eta: 0:38:24  loss: 38.4224 (40.1568)  lr: 0.0000 (0.0000)  time: 0.205713  data: 0.000452  max mem: 3586
I20250120 11:13:32 3528121 dinov2 helpers.py:102] Training  [ 2610/12500]  eta: 0:38:21  loss: 38.4224 (40.1342)  lr: 0.0000 (0.0000)  time: 0.205685  data: 0.000429  max mem: 3586
I20250120 11:13:34 3528121 dinov2 helpers.py:102] Training  [ 2620/12500]  eta: 0:38:18  loss: 38.4224 (40.1358)  lr: 0.0000 (0.0000)  time: 0.205652  data: 0.000415  max mem: 3586
I20250120 11:13:37 3528121 dinov2 helpers.py:102] Training  [ 2630/12500]  eta: 0:38:14  loss: 37.2215 (40.1204)  lr: 0.0000 (0.0000)  time: 0.205851  data: 0.000466  max mem: 3586
I20250120 11:13:39 3528121 dinov2 helpers.py:102] Training  [ 2640/12500]  eta: 0:38:11  loss: 37.0784 (40.0842)  lr: 0.0000 (0.0000)  time: 0.205977  data: 0.000467  max mem: 3586
I20250120 11:13:41 3528121 dinov2 helpers.py:102] Training  [ 2650/12500]  eta: 0:38:08  loss: 36.9634 (40.0605)  lr: 0.0000 (0.0000)  time: 0.205945  data: 0.000391  max mem: 3586
I20250120 11:13:43 3528121 dinov2 helpers.py:102] Training  [ 2660/12500]  eta: 0:38:04  loss: 36.9634 (40.0674)  lr: 0.0000 (0.0000)  time: 0.206118  data: 0.000422  max mem: 3586
I20250120 11:13:45 3528121 dinov2 helpers.py:102] Training  [ 2670/12500]  eta: 0:38:01  loss: 36.0845 (40.0439)  lr: 0.0000 (0.0000)  time: 0.206099  data: 0.000477  max mem: 3586
I20250120 11:13:47 3528121 dinov2 helpers.py:102] Training  [ 2680/12500]  eta: 0:37:58  loss: 35.9370 (40.0286)  lr: 0.0000 (0.0000)  time: 0.206059  data: 0.000398  max mem: 3586
I20250120 11:13:49 3528121 dinov2 helpers.py:102] Training  [ 2690/12500]  eta: 0:37:55  loss: 36.0845 (40.0222)  lr: 0.0000 (0.0000)  time: 0.206212  data: 0.000385  max mem: 3586
I20250120 11:13:51 3528121 dinov2 helpers.py:102] Training  [ 2700/12500]  eta: 0:37:51  loss: 36.0845 (40.0118)  lr: 0.0000 (0.0000)  time: 0.206200  data: 0.000419  max mem: 3586
I20250120 11:13:53 3528121 dinov2 helpers.py:102] Training  [ 2710/12500]  eta: 0:37:48  loss: 36.9634 (40.0084)  lr: 0.0000 (0.0000)  time: 0.205944  data: 0.000412  max mem: 3586
I20250120 11:13:55 3528121 dinov2 helpers.py:102] Training  [ 2720/12500]  eta: 0:37:45  loss: 36.0845 (39.9753)  lr: 0.0000 (0.0000)  time: 0.205833  data: 0.000420  max mem: 3586
I20250120 11:13:57 3528121 dinov2 helpers.py:102] Training  [ 2730/12500]  eta: 0:37:42  loss: 36.0845 (39.9760)  lr: 0.0000 (0.0000)  time: 0.205924  data: 0.000445  max mem: 3586
I20250120 11:13:59 3528121 dinov2 helpers.py:102] Training  [ 2740/12500]  eta: 0:37:38  loss: 36.9634 (40.0024)  lr: 0.0000 (0.0000)  time: 0.206059  data: 0.000462  max mem: 3586
I20250120 11:14:01 3528121 dinov2 helpers.py:102] Training  [ 2750/12500]  eta: 0:37:35  loss: 37.2009 (39.9955)  lr: 0.0000 (0.0000)  time: 0.206177  data: 0.000417  max mem: 3586
I20250120 11:14:03 3528121 dinov2 helpers.py:102] Training  [ 2760/12500]  eta: 0:37:32  loss: 37.2009 (39.9831)  lr: 0.0000 (0.0000)  time: 0.206063  data: 0.000393  max mem: 3586
I20250120 11:14:05 3528121 dinov2 helpers.py:102] Training  [ 2770/12500]  eta: 0:37:29  loss: 37.2009 (39.9725)  lr: 0.0000 (0.0000)  time: 0.206064  data: 0.000444  max mem: 3586
I20250120 11:14:07 3528121 dinov2 helpers.py:102] Training  [ 2780/12500]  eta: 0:37:26  loss: 37.0407 (39.9581)  lr: 0.0000 (0.0000)  time: 0.206142  data: 0.000426  max mem: 3586
I20250120 11:14:09 3528121 dinov2 helpers.py:102] Training  [ 2790/12500]  eta: 0:37:22  loss: 37.0407 (39.9562)  lr: 0.0000 (0.0000)  time: 0.206147  data: 0.000369  max mem: 3586
I20250120 11:14:12 3528121 dinov2 helpers.py:102] Training  [ 2800/12500]  eta: 0:37:19  loss: 36.5402 (39.9403)  lr: 0.0000 (0.0000)  time: 0.206167  data: 0.000384  max mem: 3586
I20250120 11:14:14 3528121 dinov2 helpers.py:102] Training  [ 2810/12500]  eta: 0:37:16  loss: 36.5402 (39.9224)  lr: 0.0000 (0.0000)  time: 0.206147  data: 0.000392  max mem: 3586
I20250120 11:14:16 3528121 dinov2 helpers.py:102] Training  [ 2820/12500]  eta: 0:37:13  loss: 36.5402 (39.9412)  lr: 0.0000 (0.0000)  time: 0.206050  data: 0.000385  max mem: 3586
I20250120 11:14:18 3528121 dinov2 helpers.py:102] Training  [ 2830/12500]  eta: 0:37:10  loss: 36.5402 (39.9005)  lr: 0.0000 (0.0000)  time: 0.205887  data: 0.000408  max mem: 3586
I20250120 11:14:20 3528121 dinov2 helpers.py:102] Training  [ 2840/12500]  eta: 0:37:07  loss: 36.5402 (39.8818)  lr: 0.0000 (0.0000)  time: 0.205892  data: 0.000468  max mem: 3586
I20250120 11:14:22 3528121 dinov2 helpers.py:102] Training  [ 2850/12500]  eta: 0:37:04  loss: 37.0407 (39.8863)  lr: 0.0000 (0.0000)  time: 0.205851  data: 0.000457  max mem: 3586
I20250120 11:14:24 3528121 dinov2 helpers.py:102] Training  [ 2860/12500]  eta: 0:37:00  loss: 36.5402 (39.8670)  lr: 0.0000 (0.0000)  time: 0.205852  data: 0.000408  max mem: 3586
I20250120 11:14:26 3528121 dinov2 helpers.py:102] Training  [ 2870/12500]  eta: 0:36:57  loss: 36.7020 (39.8560)  lr: 0.0000 (0.0000)  time: 0.205792  data: 0.000397  max mem: 3586
I20250120 11:14:28 3528121 dinov2 helpers.py:102] Training  [ 2880/12500]  eta: 0:36:54  loss: 37.0407 (39.8595)  lr: 0.0000 (0.0000)  time: 0.205628  data: 0.000414  max mem: 3586
I20250120 11:14:30 3528121 dinov2 helpers.py:102] Training  [ 2890/12500]  eta: 0:36:51  loss: 36.7020 (39.8407)  lr: 0.0000 (0.0000)  time: 0.205759  data: 0.000434  max mem: 3586
I20250120 11:14:32 3528121 dinov2 helpers.py:102] Training  [ 2900/12500]  eta: 0:36:48  loss: 36.7020 (39.8363)  lr: 0.0000 (0.0000)  time: 0.205698  data: 0.000436  max mem: 3586
I20250120 11:14:34 3528121 dinov2 helpers.py:102] Training  [ 2910/12500]  eta: 0:36:45  loss: 36.7020 (39.8508)  lr: 0.0000 (0.0000)  time: 0.205687  data: 0.000403  max mem: 3586
I20250120 11:14:36 3528121 dinov2 helpers.py:102] Training  [ 2920/12500]  eta: 0:36:42  loss: 36.7020 (39.8298)  lr: 0.0000 (0.0000)  time: 0.205803  data: 0.000347  max mem: 3586
I20250120 11:14:38 3528121 dinov2 helpers.py:102] Training  [ 2930/12500]  eta: 0:36:39  loss: 36.7020 (39.8472)  lr: 0.0000 (0.0000)  time: 0.205731  data: 0.000423  max mem: 3586
I20250120 11:14:40 3528121 dinov2 helpers.py:102] Training  [ 2940/12500]  eta: 0:36:36  loss: 36.7020 (39.8381)  lr: 0.0000 (0.0000)  time: 0.205790  data: 0.000468  max mem: 3586
I20250120 11:14:42 3528121 dinov2 helpers.py:102] Training  [ 2950/12500]  eta: 0:36:33  loss: 36.7020 (39.8308)  lr: 0.0000 (0.0000)  time: 0.205919  data: 0.000424  max mem: 3586
I20250120 11:14:44 3528121 dinov2 helpers.py:102] Training  [ 2960/12500]  eta: 0:36:29  loss: 37.0407 (39.8219)  lr: 0.0000 (0.0000)  time: 0.205943  data: 0.000407  max mem: 3586
I20250120 11:14:47 3528121 dinov2 helpers.py:102] Training  [ 2970/12500]  eta: 0:36:26  loss: 36.7020 (39.7951)  lr: 0.0000 (0.0000)  time: 0.205747  data: 0.000437  max mem: 3586
I20250120 11:14:49 3528121 dinov2 helpers.py:102] Training  [ 2980/12500]  eta: 0:36:23  loss: 36.7020 (39.7725)  lr: 0.0000 (0.0000)  time: 0.205582  data: 0.000494  max mem: 3586
I20250120 11:14:51 3528121 dinov2 helpers.py:102] Training  [ 2990/12500]  eta: 0:36:20  loss: 36.7020 (39.7765)  lr: 0.0000 (0.0000)  time: 0.205846  data: 0.000460  max mem: 3586
I20250120 11:14:53 3528121 dinov2 helpers.py:102] Training  [ 3000/12500]  eta: 0:36:17  loss: 36.7020 (39.7509)  lr: 0.0000 (0.0000)  time: 0.205851  data: 0.000455  max mem: 3586
I20250120 11:14:55 3528121 dinov2 helpers.py:102] Training  [ 3010/12500]  eta: 0:36:14  loss: 37.1651 (39.7494)  lr: 0.0000 (0.0000)  time: 0.205579  data: 0.000451  max mem: 3586
I20250120 11:14:57 3528121 dinov2 helpers.py:102] Training  [ 3020/12500]  eta: 0:36:11  loss: 37.1651 (39.7539)  lr: 0.0000 (0.0000)  time: 0.205663  data: 0.000427  max mem: 3586
I20250120 11:14:59 3528121 dinov2 helpers.py:102] Training  [ 3030/12500]  eta: 0:36:08  loss: 37.1651 (39.7428)  lr: 0.0000 (0.0000)  time: 0.205608  data: 0.000384  max mem: 3586
I20250120 11:15:01 3528121 dinov2 helpers.py:102] Training  [ 3040/12500]  eta: 0:36:05  loss: 37.1651 (39.7276)  lr: 0.0000 (0.0000)  time: 0.205421  data: 0.000491  max mem: 3586
I20250120 11:15:03 3528121 dinov2 helpers.py:102] Training  [ 3050/12500]  eta: 0:36:02  loss: 36.7020 (39.7175)  lr: 0.0000 (0.0000)  time: 0.205399  data: 0.000588  max mem: 3586
I20250120 11:15:05 3528121 dinov2 helpers.py:102] Training  [ 3060/12500]  eta: 0:35:59  loss: 36.7020 (39.7034)  lr: 0.0000 (0.0000)  time: 0.205605  data: 0.000449  max mem: 3586
I20250120 11:15:07 3528121 dinov2 helpers.py:102] Training  [ 3070/12500]  eta: 0:35:56  loss: 37.1651 (39.7086)  lr: 0.0000 (0.0000)  time: 0.205670  data: 0.000423  max mem: 3586
I20250120 11:15:09 3528121 dinov2 helpers.py:102] Training  [ 3080/12500]  eta: 0:35:53  loss: 37.1651 (39.7122)  lr: 0.0000 (0.0000)  time: 0.205473  data: 0.000426  max mem: 3586
I20250120 11:15:11 3528121 dinov2 helpers.py:102] Training  [ 3090/12500]  eta: 0:35:50  loss: 37.1778 (39.7146)  lr: 0.0000 (0.0000)  time: 0.205310  data: 0.000398  max mem: 3586
I20250120 11:15:13 3528121 dinov2 helpers.py:102] Training  [ 3100/12500]  eta: 0:35:47  loss: 37.1778 (39.7168)  lr: 0.0000 (0.0000)  time: 0.205178  data: 0.000436  max mem: 3586
I20250120 11:15:15 3528121 dinov2 helpers.py:102] Training  [ 3110/12500]  eta: 0:35:44  loss: 37.1778 (39.7264)  lr: 0.0000 (0.0000)  time: 0.205338  data: 0.000430  max mem: 3586
I20250120 11:15:17 3528121 dinov2 helpers.py:102] Training  [ 3120/12500]  eta: 0:35:41  loss: 37.6772 (39.7296)  lr: 0.0000 (0.0000)  time: 0.205582  data: 0.000395  max mem: 3586
I20250120 11:15:19 3528121 dinov2 helpers.py:102] Training  [ 3130/12500]  eta: 0:35:38  loss: 37.6772 (39.7278)  lr: 0.0000 (0.0000)  time: 0.205740  data: 0.000431  max mem: 3586
I20250120 11:15:22 3528121 dinov2 helpers.py:102] Training  [ 3140/12500]  eta: 0:35:35  loss: 39.1701 (39.7406)  lr: 0.0000 (0.0000)  time: 0.205982  data: 0.000490  max mem: 3586
I20250120 11:15:24 3528121 dinov2 helpers.py:102] Training  [ 3150/12500]  eta: 0:35:32  loss: 39.1701 (39.7261)  lr: 0.0000 (0.0000)  time: 0.205848  data: 0.000478  max mem: 3586
I20250120 11:15:26 3528121 dinov2 helpers.py:102] Training  [ 3160/12500]  eta: 0:35:29  loss: 39.3110 (39.7260)  lr: 0.0000 (0.0000)  time: 0.205894  data: 0.000444  max mem: 3586
I20250120 11:15:28 3528121 dinov2 helpers.py:102] Training  [ 3170/12500]  eta: 0:35:26  loss: 39.3110 (39.7095)  lr: 0.0000 (0.0000)  time: 0.205996  data: 0.000437  max mem: 3586
I20250120 11:15:30 3528121 dinov2 helpers.py:102] Training  [ 3180/12500]  eta: 0:35:24  loss: 39.3110 (39.6939)  lr: 0.0000 (0.0000)  time: 0.205986  data: 0.000454  max mem: 3586
I20250120 11:15:32 3528121 dinov2 helpers.py:102] Training  [ 3190/12500]  eta: 0:35:21  loss: 39.1701 (39.6812)  lr: 0.0000 (0.0000)  time: 0.205957  data: 0.000460  max mem: 3586
I20250120 11:15:34 3528121 dinov2 helpers.py:102] Training  [ 3200/12500]  eta: 0:35:18  loss: 39.1701 (39.6680)  lr: 0.0000 (0.0000)  time: 0.205741  data: 0.000420  max mem: 3586
I20250120 11:15:36 3528121 dinov2 helpers.py:102] Training  [ 3210/12500]  eta: 0:35:15  loss: 39.1701 (39.6701)  lr: 0.0000 (0.0000)  time: 0.205740  data: 0.000431  max mem: 3586
I20250120 11:15:38 3528121 dinov2 helpers.py:102] Training  [ 3220/12500]  eta: 0:35:12  loss: 36.6156 (39.6544)  lr: 0.0000 (0.0000)  time: 0.205724  data: 0.000455  max mem: 3586
I20250120 11:15:40 3528121 dinov2 helpers.py:102] Training  [ 3230/12500]  eta: 0:35:09  loss: 39.1701 (39.6659)  lr: 0.0000 (0.0000)  time: 0.205807  data: 0.000386  max mem: 3586
I20250120 11:15:42 3528121 dinov2 helpers.py:102] Training  [ 3240/12500]  eta: 0:35:06  loss: 39.1701 (39.6518)  lr: 0.0000 (0.0000)  time: 0.205865  data: 0.000349  max mem: 3586
I20250120 11:15:44 3528121 dinov2 helpers.py:102] Training  [ 3250/12500]  eta: 0:35:03  loss: 39.6822 (39.6519)  lr: 0.0000 (0.0000)  time: 0.205765  data: 0.000409  max mem: 3586
I20250120 11:15:46 3528121 dinov2 helpers.py:102] Training  [ 3260/12500]  eta: 0:35:00  loss: 39.6822 (39.6382)  lr: 0.0000 (0.0000)  time: 0.205763  data: 0.000433  max mem: 3586
I20250120 11:15:48 3528121 dinov2 helpers.py:102] Training  [ 3270/12500]  eta: 0:34:57  loss: 39.1701 (39.6275)  lr: 0.0000 (0.0000)  time: 0.205738  data: 0.000391  max mem: 3586
I20250120 11:15:50 3528121 dinov2 helpers.py:102] Training  [ 3280/12500]  eta: 0:34:55  loss: 37.5703 (39.6213)  lr: 0.0000 (0.0000)  time: 0.205666  data: 0.000383  max mem: 3586
I20250120 11:15:52 3528121 dinov2 helpers.py:102] Training  [ 3290/12500]  eta: 0:34:52  loss: 37.5703 (39.6284)  lr: 0.0000 (0.0000)  time: 0.205564  data: 0.000426  max mem: 3586
I20250120 11:15:54 3528121 dinov2 helpers.py:102] Training  [ 3300/12500]  eta: 0:34:49  loss: 36.1349 (39.6124)  lr: 0.0000 (0.0000)  time: 0.205706  data: 0.000433  max mem: 3586
I20250120 11:15:57 3528121 dinov2 helpers.py:102] Training  [ 3310/12500]  eta: 0:34:46  loss: 35.6454 (39.5753)  lr: 0.0000 (0.0000)  time: 0.205784  data: 0.000416  max mem: 3586
I20250120 11:15:59 3528121 dinov2 helpers.py:102] Training  [ 3320/12500]  eta: 0:34:43  loss: 35.4204 (39.5491)  lr: 0.0000 (0.0000)  time: 0.205608  data: 0.000411  max mem: 3586
I20250120 11:16:01 3528121 dinov2 helpers.py:102] Training  [ 3330/12500]  eta: 0:34:40  loss: 35.1687 (39.5331)  lr: 0.0000 (0.0000)  time: 0.205685  data: 0.000428  max mem: 3586
I20250120 11:16:03 3528121 dinov2 helpers.py:102] Training  [ 3340/12500]  eta: 0:34:37  loss: 35.1687 (39.5205)  lr: 0.0000 (0.0000)  time: 0.205707  data: 0.000414  max mem: 3586
I20250120 11:16:05 3528121 dinov2 helpers.py:102] Training  [ 3350/12500]  eta: 0:34:34  loss: 35.3155 (39.5260)  lr: 0.0000 (0.0000)  time: 0.205666  data: 0.000399  max mem: 3586
I20250120 11:16:07 3528121 dinov2 helpers.py:102] Training  [ 3360/12500]  eta: 0:34:32  loss: 35.3155 (39.5301)  lr: 0.0000 (0.0000)  time: 0.205632  data: 0.000406  max mem: 3586
I20250120 11:16:09 3528121 dinov2 helpers.py:102] Training  [ 3370/12500]  eta: 0:34:29  loss: 35.3155 (39.5091)  lr: 0.0000 (0.0000)  time: 0.205849  data: 0.000426  max mem: 3586
I20250120 11:16:11 3528121 dinov2 helpers.py:102] Training  [ 3380/12500]  eta: 0:34:26  loss: 35.4204 (39.4971)  lr: 0.0000 (0.0000)  time: 0.205958  data: 0.000453  max mem: 3586
I20250120 11:16:13 3528121 dinov2 helpers.py:102] Training  [ 3390/12500]  eta: 0:34:23  loss: 35.3155 (39.4790)  lr: 0.0000 (0.0000)  time: 0.205770  data: 0.000400  max mem: 3586
I20250120 11:16:15 3528121 dinov2 helpers.py:102] Training  [ 3400/12500]  eta: 0:34:20  loss: 35.3155 (39.4732)  lr: 0.0000 (0.0000)  time: 0.205868  data: 0.000386  max mem: 3586
I20250120 11:16:17 3528121 dinov2 helpers.py:102] Training  [ 3410/12500]  eta: 0:34:18  loss: 35.3155 (39.4776)  lr: 0.0000 (0.0000)  time: 0.205848  data: 0.000395  max mem: 3586
I20250120 11:16:19 3528121 dinov2 helpers.py:102] Training  [ 3420/12500]  eta: 0:34:15  loss: 35.4436 (39.4744)  lr: 0.0000 (0.0000)  time: 0.205767  data: 0.000388  max mem: 3586
I20250120 11:16:21 3528121 dinov2 helpers.py:102] Training  [ 3430/12500]  eta: 0:34:12  loss: 35.4436 (39.4771)  lr: 0.0000 (0.0000)  time: 0.205826  data: 0.000374  max mem: 3586
I20250120 11:16:23 3528121 dinov2 helpers.py:102] Training  [ 3440/12500]  eta: 0:34:09  loss: 36.1349 (39.4805)  lr: 0.0000 (0.0000)  time: 0.205957  data: 0.000385  max mem: 3586
I20250120 11:16:25 3528121 dinov2 helpers.py:102] Training  [ 3450/12500]  eta: 0:34:06  loss: 35.4436 (39.4666)  lr: 0.0000 (0.0000)  time: 0.206067  data: 0.000382  max mem: 3586
I20250120 11:16:27 3528121 dinov2 helpers.py:102] Training  [ 3460/12500]  eta: 0:34:04  loss: 36.1349 (39.4621)  lr: 0.0000 (0.0000)  time: 0.205983  data: 0.000361  max mem: 3586
I20250120 11:16:29 3528121 dinov2 helpers.py:102] Training  [ 3470/12500]  eta: 0:34:01  loss: 35.4436 (39.4376)  lr: 0.0000 (0.0000)  time: 0.205958  data: 0.000405  max mem: 3586
I20250120 11:16:32 3528121 dinov2 helpers.py:102] Training  [ 3480/12500]  eta: 0:33:58  loss: 35.3155 (39.4213)  lr: 0.0000 (0.0000)  time: 0.205997  data: 0.000427  max mem: 3586
I20250120 11:16:34 3528121 dinov2 helpers.py:102] Training  [ 3490/12500]  eta: 0:33:55  loss: 35.3155 (39.4143)  lr: 0.0000 (0.0000)  time: 0.206057  data: 0.000432  max mem: 3586
I20250120 11:16:36 3528121 dinov2 helpers.py:102] Training  [ 3500/12500]  eta: 0:33:52  loss: 35.4436 (39.4098)  lr: 0.0000 (0.0000)  time: 0.206319  data: 0.000439  max mem: 3586
I20250120 11:16:38 3528121 dinov2 helpers.py:102] Training  [ 3510/12500]  eta: 0:33:50  loss: 36.9852 (39.4116)  lr: 0.0000 (0.0000)  time: 0.206413  data: 0.000428  max mem: 3586
I20250120 11:16:40 3528121 dinov2 helpers.py:102] Training  [ 3520/12500]  eta: 0:33:47  loss: 36.9852 (39.3953)  lr: 0.0000 (0.0000)  time: 0.206124  data: 0.000423  max mem: 3586
I20250120 11:16:42 3528121 dinov2 helpers.py:102] Training  [ 3530/12500]  eta: 0:33:44  loss: 37.5303 (39.3965)  lr: 0.0000 (0.0000)  time: 0.206137  data: 0.000427  max mem: 3586
I20250120 11:16:44 3528121 dinov2 helpers.py:102] Training  [ 3540/12500]  eta: 0:33:41  loss: 37.5303 (39.3892)  lr: 0.0000 (0.0000)  time: 0.206219  data: 0.000417  max mem: 3586
I20250120 11:16:46 3528121 dinov2 helpers.py:102] Training  [ 3550/12500]  eta: 0:33:39  loss: 36.9852 (39.3747)  lr: 0.0000 (0.0000)  time: 0.205881  data: 0.000385  max mem: 3586
I20250120 11:16:48 3528121 dinov2 helpers.py:102] Training  [ 3560/12500]  eta: 0:33:36  loss: 36.9758 (39.3680)  lr: 0.0000 (0.0000)  time: 0.205878  data: 0.000398  max mem: 3586
I20250120 11:16:50 3528121 dinov2 helpers.py:102] Training  [ 3570/12500]  eta: 0:33:33  loss: 36.9758 (39.3532)  lr: 0.0000 (0.0000)  time: 0.205888  data: 0.000414  max mem: 3586
I20250120 11:16:52 3528121 dinov2 helpers.py:102] Training  [ 3580/12500]  eta: 0:33:30  loss: 36.9758 (39.3250)  lr: 0.0000 (0.0000)  time: 0.205731  data: 0.000400  max mem: 3586
I20250120 11:16:54 3528121 dinov2 helpers.py:102] Training  [ 3590/12500]  eta: 0:33:28  loss: 36.9758 (39.3152)  lr: 0.0000 (0.0000)  time: 0.206003  data: 0.000422  max mem: 3586
I20250120 11:16:56 3528121 dinov2 helpers.py:102] Training  [ 3600/12500]  eta: 0:33:25  loss: 36.8318 (39.3060)  lr: 0.0000 (0.0000)  time: 0.206134  data: 0.000412  max mem: 3586
I20250120 11:16:58 3528121 dinov2 helpers.py:102] Training  [ 3610/12500]  eta: 0:33:22  loss: 36.7490 (39.2990)  lr: 0.0000 (0.0000)  time: 0.206016  data: 0.000437  max mem: 3586
I20250120 11:17:00 3528121 dinov2 helpers.py:102] Training  [ 3620/12500]  eta: 0:33:19  loss: 36.0005 (39.2839)  lr: 0.0000 (0.0000)  time: 0.205796  data: 0.000435  max mem: 3586
I20250120 11:17:02 3528121 dinov2 helpers.py:102] Training  [ 3630/12500]  eta: 0:33:17  loss: 35.7969 (39.2639)  lr: 0.0000 (0.0000)  time: 0.205812  data: 0.000405  max mem: 3586
I20250120 11:17:04 3528121 dinov2 helpers.py:102] Training  [ 3640/12500]  eta: 0:33:14  loss: 35.7969 (39.2624)  lr: 0.0000 (0.0000)  time: 0.206248  data: 0.000415  max mem: 3586
I20250120 11:17:07 3528121 dinov2 helpers.py:102] Training  [ 3650/12500]  eta: 0:33:11  loss: 35.7969 (39.2520)  lr: 0.0000 (0.0000)  time: 0.206169  data: 0.000410  max mem: 3586
I20250120 11:17:09 3528121 dinov2 helpers.py:102] Training  [ 3660/12500]  eta: 0:33:09  loss: 35.7969 (39.2441)  lr: 0.0000 (0.0000)  time: 0.206034  data: 0.000393  max mem: 3586
I20250120 11:17:11 3528121 dinov2 helpers.py:102] Training  [ 3670/12500]  eta: 0:33:06  loss: 35.7969 (39.2303)  lr: 0.0000 (0.0000)  time: 0.206074  data: 0.000423  max mem: 3586
I20250120 11:17:13 3528121 dinov2 helpers.py:102] Training  [ 3680/12500]  eta: 0:33:03  loss: 35.7969 (39.2124)  lr: 0.0000 (0.0000)  time: 0.205978  data: 0.000492  max mem: 3586
I20250120 11:17:15 3528121 dinov2 helpers.py:102] Training  [ 3690/12500]  eta: 0:33:01  loss: 35.7969 (39.2156)  lr: 0.0000 (0.0000)  time: 0.206164  data: 0.000477  max mem: 3586
I20250120 11:17:17 3528121 dinov2 helpers.py:102] Training  [ 3700/12500]  eta: 0:32:58  loss: 35.7969 (39.2091)  lr: 0.0000 (0.0000)  time: 0.206272  data: 0.000443  max mem: 3586
I20250120 11:17:19 3528121 dinov2 helpers.py:102] Training  [ 3710/12500]  eta: 0:32:55  loss: 35.7969 (39.2016)  lr: 0.0000 (0.0000)  time: 0.206219  data: 0.000461  max mem: 3586
I20250120 11:17:21 3528121 dinov2 helpers.py:102] Training  [ 3720/12500]  eta: 0:32:52  loss: 35.7969 (39.1747)  lr: 0.0000 (0.0000)  time: 0.206115  data: 0.000461  max mem: 3586
I20250120 11:17:23 3528121 dinov2 helpers.py:102] Training  [ 3730/12500]  eta: 0:32:50  loss: 35.7969 (39.1662)  lr: 0.0000 (0.0000)  time: 0.205884  data: 0.000403  max mem: 3586
I20250120 11:17:25 3528121 dinov2 helpers.py:102] Training  [ 3740/12500]  eta: 0:32:47  loss: 35.7969 (39.1589)  lr: 0.0000 (0.0000)  time: 0.205882  data: 0.000392  max mem: 3586
I20250120 11:17:27 3528121 dinov2 linear.py:272] running validation !
I20250120 11:17:29 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:15    time: 1.649395  data: 1.443247  max mem: 3586
I20250120 11:17:31 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:50    time: 0.345480  data: 0.132475  max mem: 3586
I20250120 11:17:33 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.212572  data: 0.000898  max mem: 3586
I20250120 11:17:35 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.209435  data: 0.000321  max mem: 3586
I20250120 11:17:37 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.208623  data: 0.000254  max mem: 3586
I20250120 11:17:39 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.208514  data: 0.000240  max mem: 3586
I20250120 11:17:41 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.208564  data: 0.000266  max mem: 3586
I20250120 11:17:43 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.208244  data: 0.000260  max mem: 3586
I20250120 11:17:45 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.207733  data: 0.000232  max mem: 3586
I20250120 11:17:47 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.208278  data: 0.000259  max mem: 3586
I20250120 11:17:50 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208908  data: 0.000263  max mem: 3586
I20250120 11:17:52 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.208774  data: 0.000245  max mem: 3586
I20250120 11:17:54 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.208699  data: 0.000232  max mem: 3586
I20250120 11:17:56 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.208521  data: 0.000237  max mem: 3586
I20250120 11:17:58 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.208362  data: 0.000240  max mem: 3586
I20250120 11:18:00 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.207887  data: 0.000184  max mem: 3586
I20250120 11:18:01 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.203867  data: 0.000177  max mem: 3586
I20250120 11:18:01 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218594 s / it)
I20250120 11:18:01 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:18:01 3528121 dinov2 linear.py:287] 
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6734, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.6988, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7155, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7272, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7343, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7391, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7407, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7371, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7364, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7302, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7138, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6917, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.6958, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7172, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7287, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7371, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7457, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7475, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7519, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7501, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7221, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7370, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7050, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6921, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7086, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7260, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7358, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7395, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7402, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7444, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7475, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7320, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7401, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7026, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.6843, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6600, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7154, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7305, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7410, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7438, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7479, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7550, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7435, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7492, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7422, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7010, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.6814, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:292] ITER: 3749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6704, device='cuda:0')}
I20250120 11:18:01 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00050', 'accuracy': 0.7550020217895508}
I20250120 11:18:01 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:18:01 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:18:01 3528121 dinov2 helpers.py:102] Training  [ 3750/12500]  eta: 0:34:04  loss: 35.7969 (39.1441)  lr: 0.0000 (0.0000)  time: 1.904769  data: 0.000407  max mem: 3586
I20250120 11:18:03 3528121 dinov2 helpers.py:102] Training  [ 3760/12500]  eta: 0:34:01  loss: 35.7969 (39.1459)  lr: 0.0000 (0.0000)  time: 1.903755  data: 0.000437  max mem: 3586
I20250120 11:18:05 3528121 dinov2 helpers.py:102] Training  [ 3770/12500]  eta: 0:33:58  loss: 35.7969 (39.1263)  lr: 0.0000 (0.0000)  time: 0.204414  data: 0.000439  max mem: 3586
I20250120 11:18:07 3528121 dinov2 helpers.py:102] Training  [ 3780/12500]  eta: 0:33:55  loss: 35.7969 (39.1063)  lr: 0.0000 (0.0000)  time: 0.204876  data: 0.000405  max mem: 3586
I20250120 11:18:10 3528121 dinov2 helpers.py:102] Training  [ 3790/12500]  eta: 0:33:53  loss: 35.4899 (39.0879)  lr: 0.0000 (0.0000)  time: 0.228005  data: 0.027135  max mem: 3586
I20250120 11:18:12 3528121 dinov2 helpers.py:102] Training  [ 3800/12500]  eta: 0:33:50  loss: 35.4899 (39.0785)  lr: 0.0000 (0.0000)  time: 0.227969  data: 0.027129  max mem: 3586
I20250120 11:18:14 3528121 dinov2 helpers.py:102] Training  [ 3810/12500]  eta: 0:33:47  loss: 35.1812 (39.0683)  lr: 0.0000 (0.0000)  time: 0.205038  data: 0.000393  max mem: 3586
I20250120 11:18:16 3528121 dinov2 helpers.py:102] Training  [ 3820/12500]  eta: 0:33:44  loss: 35.4899 (39.0641)  lr: 0.0000 (0.0000)  time: 0.205071  data: 0.000362  max mem: 3586
I20250120 11:18:18 3528121 dinov2 helpers.py:102] Training  [ 3830/12500]  eta: 0:33:41  loss: 35.5075 (39.0585)  lr: 0.0000 (0.0000)  time: 0.205241  data: 0.000354  max mem: 3586
I20250120 11:18:20 3528121 dinov2 helpers.py:102] Training  [ 3840/12500]  eta: 0:33:38  loss: 35.4899 (39.0473)  lr: 0.0000 (0.0000)  time: 0.205431  data: 0.000411  max mem: 3586
I20250120 11:18:22 3528121 dinov2 helpers.py:102] Training  [ 3850/12500]  eta: 0:33:35  loss: 35.1812 (39.0355)  lr: 0.0000 (0.0000)  time: 0.205434  data: 0.000411  max mem: 3586
I20250120 11:18:24 3528121 dinov2 helpers.py:102] Training  [ 3860/12500]  eta: 0:33:32  loss: 35.1812 (39.0378)  lr: 0.0000 (0.0000)  time: 0.205613  data: 0.000399  max mem: 3586
I20250120 11:18:26 3528121 dinov2 helpers.py:102] Training  [ 3870/12500]  eta: 0:33:29  loss: 35.5075 (39.0295)  lr: 0.0000 (0.0000)  time: 0.205602  data: 0.000412  max mem: 3586
I20250120 11:18:28 3528121 dinov2 helpers.py:102] Training  [ 3880/12500]  eta: 0:33:26  loss: 35.8496 (39.0233)  lr: 0.0000 (0.0000)  time: 0.205561  data: 0.000377  max mem: 3586
I20250120 11:18:30 3528121 dinov2 helpers.py:102] Training  [ 3890/12500]  eta: 0:33:23  loss: 35.5075 (39.0124)  lr: 0.0000 (0.0000)  time: 0.205550  data: 0.000375  max mem: 3586
I20250120 11:18:32 3528121 dinov2 helpers.py:102] Training  [ 3900/12500]  eta: 0:33:20  loss: 35.5075 (39.0170)  lr: 0.0000 (0.0000)  time: 0.205644  data: 0.000388  max mem: 3586
I20250120 11:18:34 3528121 dinov2 helpers.py:102] Training  [ 3910/12500]  eta: 0:33:17  loss: 35.1812 (39.0013)  lr: 0.0000 (0.0000)  time: 0.205634  data: 0.000381  max mem: 3586
I20250120 11:18:37 3528121 dinov2 helpers.py:102] Training  [ 3920/12500]  eta: 0:33:14  loss: 35.5075 (38.9973)  lr: 0.0000 (0.0000)  time: 0.205716  data: 0.000408  max mem: 3586
I20250120 11:18:39 3528121 dinov2 helpers.py:102] Training  [ 3930/12500]  eta: 0:33:11  loss: 35.1812 (38.9865)  lr: 0.0000 (0.0000)  time: 0.205747  data: 0.000406  max mem: 3586
I20250120 11:18:41 3528121 dinov2 helpers.py:102] Training  [ 3940/12500]  eta: 0:33:09  loss: 34.7755 (38.9743)  lr: 0.0000 (0.0000)  time: 0.205525  data: 0.000377  max mem: 3586
I20250120 11:18:43 3528121 dinov2 helpers.py:102] Training  [ 3950/12500]  eta: 0:33:06  loss: 35.1812 (38.9892)  lr: 0.0000 (0.0000)  time: 0.205584  data: 0.000362  max mem: 3586
I20250120 11:18:45 3528121 dinov2 helpers.py:102] Training  [ 3960/12500]  eta: 0:33:03  loss: 35.1812 (38.9929)  lr: 0.0000 (0.0000)  time: 0.205740  data: 0.000361  max mem: 3586
I20250120 11:18:47 3528121 dinov2 helpers.py:102] Training  [ 3970/12500]  eta: 0:33:00  loss: 35.5075 (39.0245)  lr: 0.0000 (0.0000)  time: 0.205926  data: 0.000418  max mem: 3586
I20250120 11:18:49 3528121 dinov2 helpers.py:102] Training  [ 3980/12500]  eta: 0:32:57  loss: 35.8496 (39.0177)  lr: 0.0000 (0.0000)  time: 0.206140  data: 0.000429  max mem: 3586
I20250120 11:18:51 3528121 dinov2 helpers.py:102] Training  [ 3990/12500]  eta: 0:32:54  loss: 36.3007 (39.0152)  lr: 0.0000 (0.0000)  time: 0.206219  data: 0.000399  max mem: 3586
I20250120 11:18:53 3528121 dinov2 helpers.py:102] Training  [ 4000/12500]  eta: 0:32:51  loss: 36.3007 (39.0009)  lr: 0.0000 (0.0000)  time: 0.206165  data: 0.000394  max mem: 3586
I20250120 11:18:55 3528121 dinov2 helpers.py:102] Training  [ 4010/12500]  eta: 0:32:48  loss: 36.6104 (38.9970)  lr: 0.0000 (0.0000)  time: 0.206128  data: 0.000409  max mem: 3586
I20250120 11:18:57 3528121 dinov2 helpers.py:102] Training  [ 4020/12500]  eta: 0:32:46  loss: 36.6104 (38.9929)  lr: 0.0000 (0.0000)  time: 0.206172  data: 0.000415  max mem: 3586
I20250120 11:18:59 3528121 dinov2 helpers.py:102] Training  [ 4030/12500]  eta: 0:32:43  loss: 36.3007 (38.9785)  lr: 0.0000 (0.0000)  time: 0.206289  data: 0.000433  max mem: 3586
I20250120 11:19:01 3528121 dinov2 helpers.py:102] Training  [ 4040/12500]  eta: 0:32:40  loss: 36.6104 (38.9776)  lr: 0.0000 (0.0000)  time: 0.206242  data: 0.000409  max mem: 3586
I20250120 11:19:03 3528121 dinov2 helpers.py:102] Training  [ 4050/12500]  eta: 0:32:37  loss: 36.6104 (38.9605)  lr: 0.0000 (0.0000)  time: 0.206062  data: 0.000358  max mem: 3586
I20250120 11:19:05 3528121 dinov2 helpers.py:102] Training  [ 4060/12500]  eta: 0:32:34  loss: 36.3007 (38.9416)  lr: 0.0000 (0.0000)  time: 0.206065  data: 0.000391  max mem: 3586
I20250120 11:19:07 3528121 dinov2 helpers.py:102] Training  [ 4070/12500]  eta: 0:32:31  loss: 36.6104 (38.9445)  lr: 0.0000 (0.0000)  time: 0.206092  data: 0.000444  max mem: 3586
I20250120 11:19:09 3528121 dinov2 helpers.py:102] Training  [ 4080/12500]  eta: 0:32:28  loss: 37.3307 (38.9432)  lr: 0.0000 (0.0000)  time: 0.206285  data: 0.000433  max mem: 3586
I20250120 11:19:12 3528121 dinov2 helpers.py:102] Training  [ 4090/12500]  eta: 0:32:26  loss: 37.4016 (38.9464)  lr: 0.0000 (0.0000)  time: 0.206470  data: 0.000391  max mem: 3586
I20250120 11:19:14 3528121 dinov2 helpers.py:102] Training  [ 4100/12500]  eta: 0:32:23  loss: 37.3307 (38.9316)  lr: 0.0000 (0.0000)  time: 0.206363  data: 0.000424  max mem: 3586
I20250120 11:19:16 3528121 dinov2 helpers.py:102] Training  [ 4110/12500]  eta: 0:32:20  loss: 37.3307 (38.9242)  lr: 0.0000 (0.0000)  time: 0.206477  data: 0.000442  max mem: 3586
I20250120 11:19:18 3528121 dinov2 helpers.py:102] Training  [ 4120/12500]  eta: 0:32:17  loss: 36.3007 (38.9140)  lr: 0.0000 (0.0000)  time: 0.206661  data: 0.000421  max mem: 3586
I20250120 11:19:20 3528121 dinov2 helpers.py:102] Training  [ 4130/12500]  eta: 0:32:14  loss: 36.3007 (38.9061)  lr: 0.0000 (0.0000)  time: 0.206568  data: 0.000377  max mem: 3586
I20250120 11:19:22 3528121 dinov2 helpers.py:102] Training  [ 4140/12500]  eta: 0:32:12  loss: 36.3007 (38.8884)  lr: 0.0000 (0.0000)  time: 0.206456  data: 0.000349  max mem: 3586
I20250120 11:19:24 3528121 dinov2 helpers.py:102] Training  [ 4150/12500]  eta: 0:32:09  loss: 35.8684 (38.8722)  lr: 0.0000 (0.0000)  time: 0.206441  data: 0.000385  max mem: 3586
I20250120 11:19:26 3528121 dinov2 helpers.py:102] Training  [ 4160/12500]  eta: 0:32:06  loss: 35.6431 (38.8600)  lr: 0.0000 (0.0000)  time: 0.206424  data: 0.000426  max mem: 3586
I20250120 11:19:28 3528121 dinov2 helpers.py:102] Training  [ 4170/12500]  eta: 0:32:03  loss: 34.7067 (38.8487)  lr: 0.0000 (0.0000)  time: 0.206280  data: 0.000408  max mem: 3586
I20250120 11:19:30 3528121 dinov2 helpers.py:102] Training  [ 4180/12500]  eta: 0:32:00  loss: 34.7067 (38.8511)  lr: 0.0000 (0.0000)  time: 0.206309  data: 0.000389  max mem: 3586
I20250120 11:19:32 3528121 dinov2 helpers.py:102] Training  [ 4190/12500]  eta: 0:31:58  loss: 34.7067 (38.8577)  lr: 0.0000 (0.0000)  time: 0.206506  data: 0.000395  max mem: 3586
I20250120 11:19:34 3528121 dinov2 helpers.py:102] Training  [ 4200/12500]  eta: 0:31:55  loss: 35.6431 (38.8580)  lr: 0.0000 (0.0000)  time: 0.206565  data: 0.000357  max mem: 3586
I20250120 11:19:36 3528121 dinov2 helpers.py:102] Training  [ 4210/12500]  eta: 0:31:52  loss: 35.1967 (38.8493)  lr: 0.0000 (0.0000)  time: 0.206527  data: 0.000388  max mem: 3586
I20250120 11:19:38 3528121 dinov2 helpers.py:102] Training  [ 4220/12500]  eta: 0:31:49  loss: 34.7067 (38.8347)  lr: 0.0000 (0.0000)  time: 0.206456  data: 0.000438  max mem: 3586
I20250120 11:19:40 3528121 dinov2 helpers.py:102] Training  [ 4230/12500]  eta: 0:31:46  loss: 35.1967 (38.8272)  lr: 0.0000 (0.0000)  time: 0.206658  data: 0.000417  max mem: 3586
I20250120 11:19:43 3528121 dinov2 helpers.py:102] Training  [ 4240/12500]  eta: 0:31:44  loss: 34.7067 (38.8121)  lr: 0.0000 (0.0000)  time: 0.206727  data: 0.000394  max mem: 3586
I20250120 11:19:45 3528121 dinov2 helpers.py:102] Training  [ 4250/12500]  eta: 0:31:41  loss: 34.7067 (38.7963)  lr: 0.0000 (0.0000)  time: 0.206612  data: 0.000399  max mem: 3586
I20250120 11:19:47 3528121 dinov2 helpers.py:102] Training  [ 4260/12500]  eta: 0:31:38  loss: 35.1967 (38.7933)  lr: 0.0000 (0.0000)  time: 0.206614  data: 0.000410  max mem: 3586
I20250120 11:19:49 3528121 dinov2 helpers.py:102] Training  [ 4270/12500]  eta: 0:31:35  loss: 34.7067 (38.7772)  lr: 0.0000 (0.0000)  time: 0.206770  data: 0.000366  max mem: 3586
I20250120 11:19:51 3528121 dinov2 helpers.py:102] Training  [ 4280/12500]  eta: 0:31:33  loss: 34.7067 (38.7693)  lr: 0.0000 (0.0000)  time: 0.207023  data: 0.000398  max mem: 3586
I20250120 11:19:53 3528121 dinov2 helpers.py:102] Training  [ 4290/12500]  eta: 0:31:30  loss: 34.7067 (38.7700)  lr: 0.0000 (0.0000)  time: 0.207080  data: 0.000456  max mem: 3586
I20250120 11:19:55 3528121 dinov2 helpers.py:102] Training  [ 4300/12500]  eta: 0:31:27  loss: 35.1967 (38.7797)  lr: 0.0000 (0.0000)  time: 0.207099  data: 0.000386  max mem: 3586
I20250120 11:19:57 3528121 dinov2 helpers.py:102] Training  [ 4310/12500]  eta: 0:31:24  loss: 35.1967 (38.7815)  lr: 0.0000 (0.0000)  time: 0.207081  data: 0.000376  max mem: 3586
I20250120 11:19:59 3528121 dinov2 helpers.py:102] Training  [ 4320/12500]  eta: 0:31:22  loss: 35.1967 (38.7731)  lr: 0.0000 (0.0000)  time: 0.206877  data: 0.000411  max mem: 3586
I20250120 11:20:01 3528121 dinov2 helpers.py:102] Training  [ 4330/12500]  eta: 0:31:19  loss: 35.1967 (38.7731)  lr: 0.0000 (0.0000)  time: 0.206923  data: 0.000353  max mem: 3586
I20250120 11:20:03 3528121 dinov2 helpers.py:102] Training  [ 4340/12500]  eta: 0:31:16  loss: 35.1967 (38.7607)  lr: 0.0000 (0.0000)  time: 0.206908  data: 0.000382  max mem: 3586
I20250120 11:20:05 3528121 dinov2 helpers.py:102] Training  [ 4350/12500]  eta: 0:31:13  loss: 35.1967 (38.7519)  lr: 0.0000 (0.0000)  time: 0.206416  data: 0.000448  max mem: 3586
I20250120 11:20:07 3528121 dinov2 helpers.py:102] Training  [ 4360/12500]  eta: 0:31:11  loss: 35.3486 (38.7472)  lr: 0.0000 (0.0000)  time: 0.206306  data: 0.000452  max mem: 3586
I20250120 11:20:09 3528121 dinov2 helpers.py:102] Training  [ 4370/12500]  eta: 0:31:08  loss: 35.6650 (38.7403)  lr: 0.0000 (0.0000)  time: 0.206213  data: 0.000418  max mem: 3586
I20250120 11:20:11 3528121 dinov2 helpers.py:102] Training  [ 4380/12500]  eta: 0:31:05  loss: 35.6650 (38.7354)  lr: 0.0000 (0.0000)  time: 0.206122  data: 0.000388  max mem: 3586
I20250120 11:20:14 3528121 dinov2 helpers.py:102] Training  [ 4390/12500]  eta: 0:31:02  loss: 35.6650 (38.7306)  lr: 0.0000 (0.0000)  time: 0.206247  data: 0.000437  max mem: 3586
I20250120 11:20:16 3528121 dinov2 helpers.py:102] Training  [ 4400/12500]  eta: 0:31:00  loss: 35.6650 (38.7237)  lr: 0.0000 (0.0000)  time: 0.206474  data: 0.000442  max mem: 3586
I20250120 11:20:18 3528121 dinov2 helpers.py:102] Training  [ 4410/12500]  eta: 0:30:57  loss: 35.6650 (38.7123)  lr: 0.0000 (0.0000)  time: 0.206424  data: 0.000398  max mem: 3586
I20250120 11:20:20 3528121 dinov2 helpers.py:102] Training  [ 4420/12500]  eta: 0:30:54  loss: 35.6650 (38.7048)  lr: 0.0000 (0.0000)  time: 0.206193  data: 0.000363  max mem: 3586
I20250120 11:20:22 3528121 dinov2 helpers.py:102] Training  [ 4430/12500]  eta: 0:30:52  loss: 35.4036 (38.6912)  lr: 0.0000 (0.0000)  time: 0.206106  data: 0.000398  max mem: 3586
I20250120 11:20:24 3528121 dinov2 helpers.py:102] Training  [ 4440/12500]  eta: 0:30:49  loss: 35.4036 (38.6740)  lr: 0.0000 (0.0000)  time: 0.206064  data: 0.000418  max mem: 3586
I20250120 11:20:26 3528121 dinov2 helpers.py:102] Training  [ 4450/12500]  eta: 0:30:46  loss: 35.7021 (38.6691)  lr: 0.0000 (0.0000)  time: 0.206205  data: 0.000364  max mem: 3586
I20250120 11:20:28 3528121 dinov2 helpers.py:102] Training  [ 4460/12500]  eta: 0:30:43  loss: 35.7021 (38.6666)  lr: 0.0000 (0.0000)  time: 0.206736  data: 0.000413  max mem: 3586
I20250120 11:20:30 3528121 dinov2 helpers.py:102] Training  [ 4470/12500]  eta: 0:30:41  loss: 35.7021 (38.6508)  lr: 0.0000 (0.0000)  time: 0.207041  data: 0.000431  max mem: 3586
I20250120 11:20:32 3528121 dinov2 helpers.py:102] Training  [ 4480/12500]  eta: 0:30:38  loss: 35.7048 (38.6442)  lr: 0.0000 (0.0000)  time: 0.206569  data: 0.000406  max mem: 3586
I20250120 11:20:34 3528121 dinov2 helpers.py:102] Training  [ 4490/12500]  eta: 0:30:35  loss: 35.7021 (38.6312)  lr: 0.0000 (0.0000)  time: 0.206163  data: 0.000374  max mem: 3586
I20250120 11:20:36 3528121 dinov2 helpers.py:102] Training  [ 4500/12500]  eta: 0:30:33  loss: 35.4036 (38.6173)  lr: 0.0000 (0.0000)  time: 0.205915  data: 0.000361  max mem: 3586
I20250120 11:20:38 3528121 dinov2 helpers.py:102] Training  [ 4510/12500]  eta: 0:30:30  loss: 35.1766 (38.6092)  lr: 0.0000 (0.0000)  time: 0.206196  data: 0.000395  max mem: 3586
I20250120 11:20:40 3528121 dinov2 helpers.py:102] Training  [ 4520/12500]  eta: 0:30:27  loss: 35.4036 (38.6039)  lr: 0.0000 (0.0000)  time: 0.206533  data: 0.000404  max mem: 3586
I20250120 11:20:42 3528121 dinov2 helpers.py:102] Training  [ 4530/12500]  eta: 0:30:25  loss: 35.4036 (38.6020)  lr: 0.0000 (0.0000)  time: 0.206427  data: 0.000400  max mem: 3586
I20250120 11:20:45 3528121 dinov2 helpers.py:102] Training  [ 4540/12500]  eta: 0:30:22  loss: 35.7021 (38.6048)  lr: 0.0000 (0.0000)  time: 0.206350  data: 0.000365  max mem: 3586
I20250120 11:20:47 3528121 dinov2 helpers.py:102] Training  [ 4550/12500]  eta: 0:30:19  loss: 35.7048 (38.5997)  lr: 0.0000 (0.0000)  time: 0.206316  data: 0.000393  max mem: 3586
I20250120 11:20:49 3528121 dinov2 helpers.py:102] Training  [ 4560/12500]  eta: 0:30:17  loss: 35.7021 (38.5875)  lr: 0.0000 (0.0000)  time: 0.206289  data: 0.000381  max mem: 3586
I20250120 11:20:51 3528121 dinov2 helpers.py:102] Training  [ 4570/12500]  eta: 0:30:14  loss: 35.4036 (38.5701)  lr: 0.0000 (0.0000)  time: 0.206579  data: 0.000368  max mem: 3586
I20250120 11:20:53 3528121 dinov2 helpers.py:102] Training  [ 4580/12500]  eta: 0:30:11  loss: 35.4036 (38.5658)  lr: 0.0000 (0.0000)  time: 0.206617  data: 0.000410  max mem: 3586
I20250120 11:20:55 3528121 dinov2 helpers.py:102] Training  [ 4590/12500]  eta: 0:30:08  loss: 34.9465 (38.5557)  lr: 0.0000 (0.0000)  time: 0.206391  data: 0.000377  max mem: 3586
I20250120 11:20:57 3528121 dinov2 helpers.py:102] Training  [ 4600/12500]  eta: 0:30:06  loss: 34.7948 (38.5475)  lr: 0.0000 (0.0000)  time: 0.206410  data: 0.000392  max mem: 3586
I20250120 11:20:59 3528121 dinov2 helpers.py:102] Training  [ 4610/12500]  eta: 0:30:03  loss: 34.9465 (38.5489)  lr: 0.0000 (0.0000)  time: 0.206564  data: 0.000409  max mem: 3586
I20250120 11:21:01 3528121 dinov2 helpers.py:102] Training  [ 4620/12500]  eta: 0:30:00  loss: 34.9465 (38.5465)  lr: 0.0000 (0.0000)  time: 0.206688  data: 0.000390  max mem: 3586
I20250120 11:21:03 3528121 dinov2 helpers.py:102] Training  [ 4630/12500]  eta: 0:29:58  loss: 35.7048 (38.5466)  lr: 0.0000 (0.0000)  time: 0.206625  data: 0.000389  max mem: 3586
I20250120 11:21:05 3528121 dinov2 helpers.py:102] Training  [ 4640/12500]  eta: 0:29:55  loss: 35.7048 (38.5367)  lr: 0.0000 (0.0000)  time: 0.206534  data: 0.000373  max mem: 3586
I20250120 11:21:07 3528121 dinov2 helpers.py:102] Training  [ 4650/12500]  eta: 0:29:53  loss: 34.9465 (38.5110)  lr: 0.0000 (0.0000)  time: 0.206260  data: 0.000376  max mem: 3586
I20250120 11:21:09 3528121 dinov2 helpers.py:102] Training  [ 4660/12500]  eta: 0:29:50  loss: 34.7948 (38.4926)  lr: 0.0000 (0.0000)  time: 0.205982  data: 0.000323  max mem: 3586
I20250120 11:21:11 3528121 dinov2 helpers.py:102] Training  [ 4670/12500]  eta: 0:29:47  loss: 34.7948 (38.4846)  lr: 0.0000 (0.0000)  time: 0.206339  data: 0.000374  max mem: 3586
I20250120 11:21:13 3528121 dinov2 helpers.py:102] Training  [ 4680/12500]  eta: 0:29:45  loss: 34.7948 (38.5019)  lr: 0.0000 (0.0000)  time: 0.206443  data: 0.000425  max mem: 3586
I20250120 11:21:15 3528121 dinov2 helpers.py:102] Training  [ 4690/12500]  eta: 0:29:42  loss: 34.9465 (38.4943)  lr: 0.0000 (0.0000)  time: 0.205810  data: 0.000369  max mem: 3586
I20250120 11:21:18 3528121 dinov2 helpers.py:102] Training  [ 4700/12500]  eta: 0:29:39  loss: 34.9465 (38.4749)  lr: 0.0000 (0.0000)  time: 0.205815  data: 0.000356  max mem: 3586
I20250120 11:21:20 3528121 dinov2 helpers.py:102] Training  [ 4710/12500]  eta: 0:29:37  loss: 34.9622 (38.4730)  lr: 0.0000 (0.0000)  time: 0.206017  data: 0.000403  max mem: 3586
I20250120 11:21:22 3528121 dinov2 helpers.py:102] Training  [ 4720/12500]  eta: 0:29:34  loss: 34.9622 (38.4703)  lr: 0.0000 (0.0000)  time: 0.205932  data: 0.000392  max mem: 3586
I20250120 11:21:24 3528121 dinov2 helpers.py:102] Training  [ 4730/12500]  eta: 0:29:31  loss: 34.7948 (38.4548)  lr: 0.0000 (0.0000)  time: 0.206055  data: 0.000343  max mem: 3586
I20250120 11:21:26 3528121 dinov2 helpers.py:102] Training  [ 4740/12500]  eta: 0:29:29  loss: 34.7948 (38.4526)  lr: 0.0000 (0.0000)  time: 0.206180  data: 0.000382  max mem: 3586
I20250120 11:21:28 3528121 dinov2 helpers.py:102] Training  [ 4750/12500]  eta: 0:29:26  loss: 34.7648 (38.4437)  lr: 0.0000 (0.0000)  time: 0.206209  data: 0.000394  max mem: 3586
I20250120 11:21:30 3528121 dinov2 helpers.py:102] Training  [ 4760/12500]  eta: 0:29:23  loss: 34.7648 (38.4359)  lr: 0.0000 (0.0000)  time: 0.206301  data: 0.000369  max mem: 3586
I20250120 11:21:32 3528121 dinov2 helpers.py:102] Training  [ 4770/12500]  eta: 0:29:21  loss: 34.7648 (38.4191)  lr: 0.0000 (0.0000)  time: 0.206342  data: 0.000385  max mem: 3586
I20250120 11:21:34 3528121 dinov2 helpers.py:102] Training  [ 4780/12500]  eta: 0:29:18  loss: 34.7364 (38.4114)  lr: 0.0000 (0.0000)  time: 0.206437  data: 0.000420  max mem: 3586
I20250120 11:21:36 3528121 dinov2 helpers.py:102] Training  [ 4790/12500]  eta: 0:29:16  loss: 34.7648 (38.4106)  lr: 0.0000 (0.0000)  time: 0.206649  data: 0.000391  max mem: 3586
I20250120 11:21:38 3528121 dinov2 helpers.py:102] Training  [ 4800/12500]  eta: 0:29:13  loss: 34.7648 (38.4250)  lr: 0.0000 (0.0000)  time: 0.206458  data: 0.000418  max mem: 3586
I20250120 11:21:40 3528121 dinov2 helpers.py:102] Training  [ 4810/12500]  eta: 0:29:10  loss: 34.7648 (38.4200)  lr: 0.0000 (0.0000)  time: 0.206372  data: 0.000474  max mem: 3586
I20250120 11:21:42 3528121 dinov2 helpers.py:102] Training  [ 4820/12500]  eta: 0:29:08  loss: 34.7648 (38.4290)  lr: 0.0000 (0.0000)  time: 0.206372  data: 0.000452  max mem: 3586
I20250120 11:21:44 3528121 dinov2 helpers.py:102] Training  [ 4830/12500]  eta: 0:29:05  loss: 34.7648 (38.4271)  lr: 0.0000 (0.0000)  time: 0.206177  data: 0.000410  max mem: 3586
I20250120 11:21:46 3528121 dinov2 helpers.py:102] Training  [ 4840/12500]  eta: 0:29:02  loss: 34.9622 (38.4247)  lr: 0.0000 (0.0000)  time: 0.206166  data: 0.000345  max mem: 3586
I20250120 11:21:48 3528121 dinov2 helpers.py:102] Training  [ 4850/12500]  eta: 0:29:00  loss: 34.9622 (38.4130)  lr: 0.0000 (0.0000)  time: 0.206119  data: 0.000379  max mem: 3586
I20250120 11:21:51 3528121 dinov2 helpers.py:102] Training  [ 4860/12500]  eta: 0:28:57  loss: 35.9791 (38.4113)  lr: 0.0000 (0.0000)  time: 0.206362  data: 0.000422  max mem: 3586
I20250120 11:21:53 3528121 dinov2 helpers.py:102] Training  [ 4870/12500]  eta: 0:28:55  loss: 35.9791 (38.3994)  lr: 0.0000 (0.0000)  time: 0.206458  data: 0.000414  max mem: 3586
I20250120 11:21:55 3528121 dinov2 helpers.py:102] Training  [ 4880/12500]  eta: 0:28:52  loss: 35.9791 (38.3981)  lr: 0.0000 (0.0000)  time: 0.206194  data: 0.000427  max mem: 3586
I20250120 11:21:57 3528121 dinov2 helpers.py:102] Training  [ 4890/12500]  eta: 0:28:49  loss: 35.9791 (38.3876)  lr: 0.0000 (0.0000)  time: 0.206365  data: 0.000393  max mem: 3586
I20250120 11:21:59 3528121 dinov2 helpers.py:102] Training  [ 4900/12500]  eta: 0:28:47  loss: 35.9791 (38.3774)  lr: 0.0000 (0.0000)  time: 0.206336  data: 0.000331  max mem: 3586
I20250120 11:22:01 3528121 dinov2 helpers.py:102] Training  [ 4910/12500]  eta: 0:28:44  loss: 34.7364 (38.3629)  lr: 0.0000 (0.0000)  time: 0.205922  data: 0.000332  max mem: 3586
I20250120 11:22:03 3528121 dinov2 helpers.py:102] Training  [ 4920/12500]  eta: 0:28:42  loss: 34.7298 (38.3520)  lr: 0.0000 (0.0000)  time: 0.206168  data: 0.000388  max mem: 3586
I20250120 11:22:05 3528121 dinov2 helpers.py:102] Training  [ 4930/12500]  eta: 0:28:39  loss: 34.7298 (38.3355)  lr: 0.0000 (0.0000)  time: 0.206460  data: 0.000418  max mem: 3586
I20250120 11:22:07 3528121 dinov2 helpers.py:102] Training  [ 4940/12500]  eta: 0:28:36  loss: 34.3021 (38.3273)  lr: 0.0000 (0.0000)  time: 0.206308  data: 0.000430  max mem: 3586
I20250120 11:22:09 3528121 dinov2 helpers.py:102] Training  [ 4950/12500]  eta: 0:28:34  loss: 34.7298 (38.3228)  lr: 0.0000 (0.0000)  time: 0.206281  data: 0.000431  max mem: 3586
I20250120 11:22:11 3528121 dinov2 helpers.py:102] Training  [ 4960/12500]  eta: 0:28:31  loss: 34.7298 (38.3199)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000378  max mem: 3586
I20250120 11:22:13 3528121 dinov2 helpers.py:102] Training  [ 4970/12500]  eta: 0:28:29  loss: 35.3293 (38.3139)  lr: 0.0000 (0.0000)  time: 0.206440  data: 0.000470  max mem: 3586
I20250120 11:22:20 3528121 dinov2 helpers.py:102] Training  [ 4980/12500]  eta: 0:28:33  loss: 35.3293 (38.3030)  lr: 0.0000 (0.0000)  time: 0.424559  data: 0.239092  max mem: 3586
I20250120 11:22:22 3528121 dinov2 helpers.py:102] Training  [ 4990/12500]  eta: 0:28:30  loss: 35.3293 (38.3006)  lr: 0.0000 (0.0000)  time: 0.423207  data: 0.239164  max mem: 3586
I20250120 11:22:23 3528121 dinov2 linear.py:272] running validation !
I20250120 11:22:25 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:58    time: 1.540237  data: 1.335801  max mem: 3586
I20250120 11:22:27 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.331983  data: 0.122311  max mem: 3586
I20250120 11:22:29 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.209547  data: 0.000676  max mem: 3586
I20250120 11:22:31 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.207441  data: 0.000322  max mem: 3586
I20250120 11:22:33 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.207094  data: 0.000259  max mem: 3586
I20250120 11:22:36 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.207249  data: 0.000275  max mem: 3586
I20250120 11:22:38 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:21    time: 0.207188  data: 0.000243  max mem: 3586
I20250120 11:22:40 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.207147  data: 0.000206  max mem: 3586
I20250120 11:22:42 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.207429  data: 0.000215  max mem: 3586
I20250120 11:22:44 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.207466  data: 0.000249  max mem: 3586
I20250120 11:22:46 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.207280  data: 0.000269  max mem: 3586
I20250120 11:22:48 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.213197  data: 0.000241  max mem: 3586
I20250120 11:22:50 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.213694  data: 0.000214  max mem: 3586
I20250120 11:22:52 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.207920  data: 0.000198  max mem: 3586
I20250120 11:22:54 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.207442  data: 0.000234  max mem: 3586
I20250120 11:22:56 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.207050  data: 0.000195  max mem: 3586
I20250120 11:22:57 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.202967  data: 0.000157  max mem: 3586
I20250120 11:22:57 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.217308 s / it)
I20250120 11:22:57 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:22:57 3528121 dinov2 linear.py:287] 
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6834, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7047, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7201, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7303, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7363, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7405, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7426, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7444, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7445, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7386, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7172, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6881, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7024, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7209, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7335, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7406, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7473, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7535, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7563, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7579, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7507, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7383, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7079, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6810, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7129, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7294, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7378, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7424, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7475, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7522, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7492, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7410, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7255, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7145, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.6905, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6722, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7214, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7348, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7440, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7470, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7561, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7613, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7582, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7427, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7276, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7041, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.6578, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:292] ITER: 4999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6768, device='cuda:0')}
I20250120 11:22:57 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00050', 'accuracy': 0.7613177299499512}
I20250120 11:22:57 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:22:57 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:22:58 3528121 dinov2 helpers.py:102] Training  [ 5000/12500]  eta: 0:29:18  loss: 34.3021 (38.2894)  lr: 0.0000 (0.0000)  time: 1.892629  data: 0.000578  max mem: 3586
I20250120 11:23:00 3528121 dinov2 helpers.py:102] Training  [ 5010/12500]  eta: 0:29:15  loss: 33.4101 (38.2710)  lr: 0.0000 (0.0000)  time: 1.892621  data: 0.000399  max mem: 3586
I20250120 11:23:02 3528121 dinov2 helpers.py:102] Training  [ 5020/12500]  eta: 0:29:12  loss: 33.4101 (38.2662)  lr: 0.0000 (0.0000)  time: 0.204364  data: 0.000406  max mem: 3586
I20250120 11:23:04 3528121 dinov2 helpers.py:102] Training  [ 5030/12500]  eta: 0:29:10  loss: 33.2599 (38.2554)  lr: 0.0000 (0.0000)  time: 0.204986  data: 0.000455  max mem: 3586
I20250120 11:23:06 3528121 dinov2 helpers.py:102] Training  [ 5040/12500]  eta: 0:29:07  loss: 33.2599 (38.2579)  lr: 0.0000 (0.0000)  time: 0.204861  data: 0.000496  max mem: 3586
I20250120 11:23:08 3528121 dinov2 helpers.py:102] Training  [ 5050/12500]  eta: 0:29:05  loss: 33.4101 (38.2556)  lr: 0.0000 (0.0000)  time: 0.227742  data: 0.027167  max mem: 3586
I20250120 11:23:10 3528121 dinov2 helpers.py:102] Training  [ 5060/12500]  eta: 0:29:02  loss: 33.4101 (38.2474)  lr: 0.0000 (0.0000)  time: 0.227874  data: 0.027151  max mem: 3586
I20250120 11:23:12 3528121 dinov2 helpers.py:102] Training  [ 5070/12500]  eta: 0:28:59  loss: 34.0744 (38.2454)  lr: 0.0000 (0.0000)  time: 0.204888  data: 0.000441  max mem: 3586
I20250120 11:23:14 3528121 dinov2 helpers.py:102] Training  [ 5080/12500]  eta: 0:28:57  loss: 34.0744 (38.2477)  lr: 0.0000 (0.0000)  time: 0.204851  data: 0.000446  max mem: 3586
I20250120 11:23:16 3528121 dinov2 helpers.py:102] Training  [ 5090/12500]  eta: 0:28:54  loss: 34.0744 (38.2378)  lr: 0.0000 (0.0000)  time: 0.205182  data: 0.000452  max mem: 3586
I20250120 11:23:18 3528121 dinov2 helpers.py:102] Training  [ 5100/12500]  eta: 0:28:51  loss: 34.0744 (38.2258)  lr: 0.0000 (0.0000)  time: 0.205453  data: 0.000356  max mem: 3586
I20250120 11:23:21 3528121 dinov2 helpers.py:102] Training  [ 5110/12500]  eta: 0:28:48  loss: 34.3021 (38.2204)  lr: 0.0000 (0.0000)  time: 0.205465  data: 0.000381  max mem: 3586
I20250120 11:23:23 3528121 dinov2 helpers.py:102] Training  [ 5120/12500]  eta: 0:28:45  loss: 34.3021 (38.1999)  lr: 0.0000 (0.0000)  time: 0.205443  data: 0.000495  max mem: 3586
I20250120 11:23:25 3528121 dinov2 helpers.py:102] Training  [ 5130/12500]  eta: 0:28:43  loss: 35.3293 (38.1957)  lr: 0.0000 (0.0000)  time: 0.205424  data: 0.000467  max mem: 3586
I20250120 11:23:27 3528121 dinov2 helpers.py:102] Training  [ 5140/12500]  eta: 0:28:40  loss: 35.3293 (38.1806)  lr: 0.0000 (0.0000)  time: 0.205700  data: 0.000463  max mem: 3586
I20250120 11:23:29 3528121 dinov2 helpers.py:102] Training  [ 5150/12500]  eta: 0:28:37  loss: 34.0744 (38.1711)  lr: 0.0000 (0.0000)  time: 0.205898  data: 0.000422  max mem: 3586
I20250120 11:23:31 3528121 dinov2 helpers.py:102] Training  [ 5160/12500]  eta: 0:28:35  loss: 33.2463 (38.1605)  lr: 0.0000 (0.0000)  time: 0.205590  data: 0.000404  max mem: 3586
I20250120 11:23:33 3528121 dinov2 helpers.py:102] Training  [ 5170/12500]  eta: 0:28:32  loss: 33.2408 (38.1471)  lr: 0.0000 (0.0000)  time: 0.205427  data: 0.000439  max mem: 3586
I20250120 11:23:35 3528121 dinov2 helpers.py:102] Training  [ 5180/12500]  eta: 0:28:29  loss: 33.2408 (38.1374)  lr: 0.0000 (0.0000)  time: 0.205512  data: 0.000420  max mem: 3586
I20250120 11:23:37 3528121 dinov2 helpers.py:102] Training  [ 5190/12500]  eta: 0:28:26  loss: 33.2408 (38.1298)  lr: 0.0000 (0.0000)  time: 0.205812  data: 0.000487  max mem: 3586
I20250120 11:23:39 3528121 dinov2 helpers.py:102] Training  [ 5200/12500]  eta: 0:28:24  loss: 33.2463 (38.1270)  lr: 0.0000 (0.0000)  time: 0.206091  data: 0.000491  max mem: 3586
I20250120 11:23:41 3528121 dinov2 helpers.py:102] Training  [ 5210/12500]  eta: 0:28:21  loss: 33.2463 (38.1160)  lr: 0.0000 (0.0000)  time: 0.206187  data: 0.000449  max mem: 3586
I20250120 11:23:43 3528121 dinov2 helpers.py:102] Training  [ 5220/12500]  eta: 0:28:18  loss: 33.2463 (38.1096)  lr: 0.0000 (0.0000)  time: 0.206193  data: 0.000481  max mem: 3586
I20250120 11:23:45 3528121 dinov2 helpers.py:102] Training  [ 5230/12500]  eta: 0:28:15  loss: 34.0744 (38.1029)  lr: 0.0000 (0.0000)  time: 0.206138  data: 0.000447  max mem: 3586
I20250120 11:23:47 3528121 dinov2 helpers.py:102] Training  [ 5240/12500]  eta: 0:28:13  loss: 34.0744 (38.0975)  lr: 0.0000 (0.0000)  time: 0.206168  data: 0.000385  max mem: 3586
I20250120 11:23:49 3528121 dinov2 helpers.py:102] Training  [ 5250/12500]  eta: 0:28:10  loss: 33.2463 (38.0858)  lr: 0.0000 (0.0000)  time: 0.206207  data: 0.000396  max mem: 3586
I20250120 11:23:51 3528121 dinov2 helpers.py:102] Training  [ 5260/12500]  eta: 0:28:07  loss: 33.2408 (38.0748)  lr: 0.0000 (0.0000)  time: 0.206231  data: 0.000441  max mem: 3586
I20250120 11:23:54 3528121 dinov2 helpers.py:102] Training  [ 5270/12500]  eta: 0:28:05  loss: 33.1065 (38.0630)  lr: 0.0000 (0.0000)  time: 0.206341  data: 0.000480  max mem: 3586
I20250120 11:23:56 3528121 dinov2 helpers.py:102] Training  [ 5280/12500]  eta: 0:28:02  loss: 33.1065 (38.0620)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000471  max mem: 3586
I20250120 11:23:58 3528121 dinov2 helpers.py:102] Training  [ 5290/12500]  eta: 0:27:59  loss: 33.1065 (38.0561)  lr: 0.0000 (0.0000)  time: 0.206477  data: 0.000467  max mem: 3586
I20250120 11:24:00 3528121 dinov2 helpers.py:102] Training  [ 5300/12500]  eta: 0:27:57  loss: 33.1065 (38.0416)  lr: 0.0000 (0.0000)  time: 0.206464  data: 0.000500  max mem: 3586
I20250120 11:24:02 3528121 dinov2 helpers.py:102] Training  [ 5310/12500]  eta: 0:27:54  loss: 32.6827 (38.0299)  lr: 0.0000 (0.0000)  time: 0.206427  data: 0.000455  max mem: 3586
I20250120 11:24:04 3528121 dinov2 helpers.py:102] Training  [ 5320/12500]  eta: 0:27:51  loss: 33.1065 (38.0228)  lr: 0.0000 (0.0000)  time: 0.206194  data: 0.000426  max mem: 3586
I20250120 11:24:06 3528121 dinov2 helpers.py:102] Training  [ 5330/12500]  eta: 0:27:49  loss: 32.6827 (38.0111)  lr: 0.0000 (0.0000)  time: 0.206271  data: 0.000469  max mem: 3586
I20250120 11:24:08 3528121 dinov2 helpers.py:102] Training  [ 5340/12500]  eta: 0:27:46  loss: 32.6827 (37.9925)  lr: 0.0000 (0.0000)  time: 0.206327  data: 0.000458  max mem: 3586
I20250120 11:24:10 3528121 dinov2 helpers.py:102] Training  [ 5350/12500]  eta: 0:27:43  loss: 32.3530 (37.9817)  lr: 0.0000 (0.0000)  time: 0.206287  data: 0.000440  max mem: 3586
I20250120 11:24:12 3528121 dinov2 helpers.py:102] Training  [ 5360/12500]  eta: 0:27:40  loss: 32.3530 (37.9806)  lr: 0.0000 (0.0000)  time: 0.206369  data: 0.000441  max mem: 3586
I20250120 11:24:14 3528121 dinov2 helpers.py:102] Training  [ 5370/12500]  eta: 0:27:38  loss: 32.4368 (37.9703)  lr: 0.0000 (0.0000)  time: 0.206381  data: 0.000415  max mem: 3586
I20250120 11:24:16 3528121 dinov2 helpers.py:102] Training  [ 5380/12500]  eta: 0:27:35  loss: 32.3530 (37.9576)  lr: 0.0000 (0.0000)  time: 0.206358  data: 0.000464  max mem: 3586
I20250120 11:24:18 3528121 dinov2 helpers.py:102] Training  [ 5390/12500]  eta: 0:27:32  loss: 32.2694 (37.9438)  lr: 0.0000 (0.0000)  time: 0.206363  data: 0.000489  max mem: 3586
I20250120 11:24:20 3528121 dinov2 helpers.py:102] Training  [ 5400/12500]  eta: 0:27:30  loss: 32.2330 (37.9311)  lr: 0.0000 (0.0000)  time: 0.206517  data: 0.000445  max mem: 3586
I20250120 11:24:22 3528121 dinov2 helpers.py:102] Training  [ 5410/12500]  eta: 0:27:27  loss: 31.9698 (37.9141)  lr: 0.0000 (0.0000)  time: 0.206520  data: 0.000489  max mem: 3586
I20250120 11:24:24 3528121 dinov2 helpers.py:102] Training  [ 5420/12500]  eta: 0:27:24  loss: 31.9698 (37.9066)  lr: 0.0000 (0.0000)  time: 0.206434  data: 0.000506  max mem: 3586
I20250120 11:24:27 3528121 dinov2 helpers.py:102] Training  [ 5430/12500]  eta: 0:27:22  loss: 31.8722 (37.8911)  lr: 0.0000 (0.0000)  time: 0.206513  data: 0.000452  max mem: 3586
I20250120 11:24:29 3528121 dinov2 helpers.py:102] Training  [ 5440/12500]  eta: 0:27:19  loss: 31.8722 (37.8847)  lr: 0.0000 (0.0000)  time: 0.206417  data: 0.000421  max mem: 3586
I20250120 11:24:31 3528121 dinov2 helpers.py:102] Training  [ 5450/12500]  eta: 0:27:17  loss: 31.8722 (37.8743)  lr: 0.0000 (0.0000)  time: 0.206502  data: 0.000383  max mem: 3586
I20250120 11:24:33 3528121 dinov2 helpers.py:102] Training  [ 5460/12500]  eta: 0:27:14  loss: 31.7999 (37.8630)  lr: 0.0000 (0.0000)  time: 0.206421  data: 0.000397  max mem: 3586
I20250120 11:24:35 3528121 dinov2 helpers.py:102] Training  [ 5470/12500]  eta: 0:27:11  loss: 31.7999 (37.8615)  lr: 0.0000 (0.0000)  time: 0.206161  data: 0.000427  max mem: 3586
I20250120 11:24:37 3528121 dinov2 helpers.py:102] Training  [ 5480/12500]  eta: 0:27:09  loss: 31.7999 (37.8565)  lr: 0.0000 (0.0000)  time: 0.206191  data: 0.000411  max mem: 3586
I20250120 11:24:39 3528121 dinov2 helpers.py:102] Training  [ 5490/12500]  eta: 0:27:06  loss: 31.7999 (37.8462)  lr: 0.0000 (0.0000)  time: 0.206099  data: 0.000456  max mem: 3586
I20250120 11:24:41 3528121 dinov2 helpers.py:102] Training  [ 5500/12500]  eta: 0:27:03  loss: 32.1600 (37.8399)  lr: 0.0000 (0.0000)  time: 0.205895  data: 0.000454  max mem: 3586
I20250120 11:24:43 3528121 dinov2 helpers.py:102] Training  [ 5510/12500]  eta: 0:27:01  loss: 32.1600 (37.8211)  lr: 0.0000 (0.0000)  time: 0.205867  data: 0.000407  max mem: 3586
I20250120 11:24:45 3528121 dinov2 helpers.py:102] Training  [ 5520/12500]  eta: 0:26:58  loss: 32.1600 (37.8155)  lr: 0.0000 (0.0000)  time: 0.206243  data: 0.000472  max mem: 3586
I20250120 11:24:47 3528121 dinov2 helpers.py:102] Training  [ 5530/12500]  eta: 0:26:55  loss: 32.2032 (37.8102)  lr: 0.0000 (0.0000)  time: 0.206459  data: 0.000518  max mem: 3586
I20250120 11:24:49 3528121 dinov2 helpers.py:102] Training  [ 5540/12500]  eta: 0:26:53  loss: 32.2032 (37.7976)  lr: 0.0000 (0.0000)  time: 0.206249  data: 0.000500  max mem: 3586
I20250120 11:24:51 3528121 dinov2 helpers.py:102] Training  [ 5550/12500]  eta: 0:26:50  loss: 32.2032 (37.8051)  lr: 0.0000 (0.0000)  time: 0.206112  data: 0.000482  max mem: 3586
I20250120 11:24:53 3528121 dinov2 helpers.py:102] Training  [ 5560/12500]  eta: 0:26:47  loss: 32.2032 (37.7980)  lr: 0.0000 (0.0000)  time: 0.206214  data: 0.000469  max mem: 3586
I20250120 11:24:55 3528121 dinov2 helpers.py:102] Training  [ 5570/12500]  eta: 0:26:45  loss: 32.1600 (37.7879)  lr: 0.0000 (0.0000)  time: 0.206311  data: 0.000472  max mem: 3586
I20250120 11:24:57 3528121 dinov2 helpers.py:102] Training  [ 5580/12500]  eta: 0:26:42  loss: 32.2032 (37.7867)  lr: 0.0000 (0.0000)  time: 0.206480  data: 0.000404  max mem: 3586
I20250120 11:25:00 3528121 dinov2 helpers.py:102] Training  [ 5590/12500]  eta: 0:26:40  loss: 32.2032 (37.7701)  lr: 0.0000 (0.0000)  time: 0.206616  data: 0.000402  max mem: 3586
I20250120 11:25:02 3528121 dinov2 helpers.py:102] Training  [ 5600/12500]  eta: 0:26:37  loss: 33.8570 (37.7698)  lr: 0.0000 (0.0000)  time: 0.206296  data: 0.000418  max mem: 3586
I20250120 11:25:04 3528121 dinov2 helpers.py:102] Training  [ 5610/12500]  eta: 0:26:34  loss: 33.8570 (37.7594)  lr: 0.0000 (0.0000)  time: 0.206102  data: 0.000430  max mem: 3586
I20250120 11:25:06 3528121 dinov2 helpers.py:102] Training  [ 5620/12500]  eta: 0:26:32  loss: 32.2032 (37.7486)  lr: 0.0000 (0.0000)  time: 0.205999  data: 0.000464  max mem: 3586
I20250120 11:25:08 3528121 dinov2 helpers.py:102] Training  [ 5630/12500]  eta: 0:26:29  loss: 32.2032 (37.7372)  lr: 0.0000 (0.0000)  time: 0.206074  data: 0.000484  max mem: 3586
I20250120 11:25:10 3528121 dinov2 helpers.py:102] Training  [ 5640/12500]  eta: 0:26:26  loss: 32.1600 (37.7215)  lr: 0.0000 (0.0000)  time: 0.206323  data: 0.000483  max mem: 3586
I20250120 11:25:12 3528121 dinov2 helpers.py:102] Training  [ 5650/12500]  eta: 0:26:24  loss: 32.1600 (37.7163)  lr: 0.0000 (0.0000)  time: 0.206089  data: 0.000478  max mem: 3586
I20250120 11:25:14 3528121 dinov2 helpers.py:102] Training  [ 5660/12500]  eta: 0:26:21  loss: 33.8854 (37.7096)  lr: 0.0000 (0.0000)  time: 0.205924  data: 0.000498  max mem: 3586
I20250120 11:25:16 3528121 dinov2 helpers.py:102] Training  [ 5670/12500]  eta: 0:26:19  loss: 32.1600 (37.6891)  lr: 0.0000 (0.0000)  time: 0.206121  data: 0.000459  max mem: 3586
I20250120 11:25:18 3528121 dinov2 helpers.py:102] Training  [ 5680/12500]  eta: 0:26:16  loss: 32.1600 (37.6799)  lr: 0.0000 (0.0000)  time: 0.206320  data: 0.000440  max mem: 3586
I20250120 11:25:20 3528121 dinov2 helpers.py:102] Training  [ 5690/12500]  eta: 0:26:13  loss: 32.4535 (37.6720)  lr: 0.0000 (0.0000)  time: 0.206384  data: 0.000479  max mem: 3586
I20250120 11:25:22 3528121 dinov2 helpers.py:102] Training  [ 5700/12500]  eta: 0:26:11  loss: 32.4535 (37.6717)  lr: 0.0000 (0.0000)  time: 0.206371  data: 0.000491  max mem: 3586
I20250120 11:25:24 3528121 dinov2 helpers.py:102] Training  [ 5710/12500]  eta: 0:26:08  loss: 33.1968 (37.6692)  lr: 0.0000 (0.0000)  time: 0.206267  data: 0.000474  max mem: 3586
I20250120 11:25:26 3528121 dinov2 helpers.py:102] Training  [ 5720/12500]  eta: 0:26:05  loss: 33.1968 (37.6669)  lr: 0.0000 (0.0000)  time: 0.206219  data: 0.000434  max mem: 3586
I20250120 11:25:28 3528121 dinov2 helpers.py:102] Training  [ 5730/12500]  eta: 0:26:03  loss: 33.1968 (37.6619)  lr: 0.0000 (0.0000)  time: 0.206435  data: 0.000395  max mem: 3586
I20250120 11:25:30 3528121 dinov2 helpers.py:102] Training  [ 5740/12500]  eta: 0:26:00  loss: 33.8854 (37.6562)  lr: 0.0000 (0.0000)  time: 0.206506  data: 0.000421  max mem: 3586
I20250120 11:25:33 3528121 dinov2 helpers.py:102] Training  [ 5750/12500]  eta: 0:25:58  loss: 33.1968 (37.6469)  lr: 0.0000 (0.0000)  time: 0.206422  data: 0.000453  max mem: 3586
I20250120 11:25:35 3528121 dinov2 helpers.py:102] Training  [ 5760/12500]  eta: 0:25:55  loss: 32.4535 (37.6368)  lr: 0.0000 (0.0000)  time: 0.206277  data: 0.000429  max mem: 3586
I20250120 11:25:37 3528121 dinov2 helpers.py:102] Training  [ 5770/12500]  eta: 0:25:53  loss: 32.4535 (37.6253)  lr: 0.0000 (0.0000)  time: 0.206390  data: 0.000455  max mem: 3586
I20250120 11:25:39 3528121 dinov2 helpers.py:102] Training  [ 5780/12500]  eta: 0:25:50  loss: 32.4535 (37.6196)  lr: 0.0000 (0.0000)  time: 0.206650  data: 0.000520  max mem: 3586
I20250120 11:25:41 3528121 dinov2 helpers.py:102] Training  [ 5790/12500]  eta: 0:25:47  loss: 32.4535 (37.6100)  lr: 0.0000 (0.0000)  time: 0.206576  data: 0.000480  max mem: 3586
I20250120 11:25:43 3528121 dinov2 helpers.py:102] Training  [ 5800/12500]  eta: 0:25:45  loss: 32.4535 (37.6012)  lr: 0.0000 (0.0000)  time: 0.206548  data: 0.000396  max mem: 3586
I20250120 11:25:45 3528121 dinov2 helpers.py:102] Training  [ 5810/12500]  eta: 0:25:42  loss: 32.4535 (37.5915)  lr: 0.0000 (0.0000)  time: 0.206369  data: 0.000394  max mem: 3586
I20250120 11:25:47 3528121 dinov2 helpers.py:102] Training  [ 5820/12500]  eta: 0:25:40  loss: 32.4719 (37.5861)  lr: 0.0000 (0.0000)  time: 0.206034  data: 0.000458  max mem: 3586
I20250120 11:25:49 3528121 dinov2 helpers.py:102] Training  [ 5830/12500]  eta: 0:25:37  loss: 33.1968 (37.5794)  lr: 0.0000 (0.0000)  time: 0.206192  data: 0.000481  max mem: 3586
I20250120 11:25:51 3528121 dinov2 helpers.py:102] Training  [ 5840/12500]  eta: 0:25:34  loss: 33.1968 (37.5719)  lr: 0.0000 (0.0000)  time: 0.206546  data: 0.000437  max mem: 3586
I20250120 11:25:53 3528121 dinov2 helpers.py:102] Training  [ 5850/12500]  eta: 0:25:32  loss: 33.1733 (37.5629)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000463  max mem: 3586
I20250120 11:25:55 3528121 dinov2 helpers.py:102] Training  [ 5860/12500]  eta: 0:25:29  loss: 32.4719 (37.5478)  lr: 0.0000 (0.0000)  time: 0.206453  data: 0.000481  max mem: 3586
I20250120 11:25:57 3528121 dinov2 helpers.py:102] Training  [ 5870/12500]  eta: 0:25:27  loss: 32.4719 (37.5340)  lr: 0.0000 (0.0000)  time: 0.206597  data: 0.000458  max mem: 3586
I20250120 11:25:59 3528121 dinov2 helpers.py:102] Training  [ 5880/12500]  eta: 0:25:24  loss: 33.1733 (37.5266)  lr: 0.0000 (0.0000)  time: 0.206395  data: 0.000489  max mem: 3586
I20250120 11:26:01 3528121 dinov2 helpers.py:102] Training  [ 5890/12500]  eta: 0:25:22  loss: 33.1733 (37.5194)  lr: 0.0000 (0.0000)  time: 0.206459  data: 0.000479  max mem: 3586
I20250120 11:26:04 3528121 dinov2 helpers.py:102] Training  [ 5900/12500]  eta: 0:25:19  loss: 32.4719 (37.5085)  lr: 0.0000 (0.0000)  time: 0.206749  data: 0.000479  max mem: 3586
I20250120 11:26:06 3528121 dinov2 helpers.py:102] Training  [ 5910/12500]  eta: 0:25:16  loss: 32.3231 (37.4907)  lr: 0.0000 (0.0000)  time: 0.206508  data: 0.000414  max mem: 3586
I20250120 11:26:08 3528121 dinov2 helpers.py:102] Training  [ 5920/12500]  eta: 0:25:14  loss: 32.3115 (37.4730)  lr: 0.0000 (0.0000)  time: 0.206296  data: 0.000408  max mem: 3586
I20250120 11:26:10 3528121 dinov2 helpers.py:102] Training  [ 5930/12500]  eta: 0:25:11  loss: 32.0879 (37.4614)  lr: 0.0000 (0.0000)  time: 0.206241  data: 0.000454  max mem: 3586
I20250120 11:26:12 3528121 dinov2 helpers.py:102] Training  [ 5940/12500]  eta: 0:25:09  loss: 32.0879 (37.4558)  lr: 0.0000 (0.0000)  time: 0.206058  data: 0.000439  max mem: 3586
I20250120 11:26:14 3528121 dinov2 helpers.py:102] Training  [ 5950/12500]  eta: 0:25:06  loss: 31.9344 (37.4429)  lr: 0.0000 (0.0000)  time: 0.206266  data: 0.000476  max mem: 3586
I20250120 11:26:16 3528121 dinov2 helpers.py:102] Training  [ 5960/12500]  eta: 0:25:04  loss: 31.9344 (37.4325)  lr: 0.0000 (0.0000)  time: 0.206221  data: 0.000445  max mem: 3586
I20250120 11:26:18 3528121 dinov2 helpers.py:102] Training  [ 5970/12500]  eta: 0:25:01  loss: 31.9344 (37.4159)  lr: 0.0000 (0.0000)  time: 0.205824  data: 0.000465  max mem: 3586
I20250120 11:26:20 3528121 dinov2 helpers.py:102] Training  [ 5980/12500]  eta: 0:24:58  loss: 31.9344 (37.4120)  lr: 0.0000 (0.0000)  time: 0.206026  data: 0.000450  max mem: 3586
I20250120 11:26:22 3528121 dinov2 helpers.py:102] Training  [ 5990/12500]  eta: 0:24:56  loss: 31.9344 (37.4069)  lr: 0.0000 (0.0000)  time: 0.206104  data: 0.000373  max mem: 3586
I20250120 11:26:24 3528121 dinov2 helpers.py:102] Training  [ 6000/12500]  eta: 0:24:53  loss: 31.2062 (37.3904)  lr: 0.0000 (0.0000)  time: 0.205990  data: 0.000435  max mem: 3586
I20250120 11:26:26 3528121 dinov2 helpers.py:102] Training  [ 6010/12500]  eta: 0:24:51  loss: 31.0369 (37.3777)  lr: 0.0000 (0.0000)  time: 0.206018  data: 0.000438  max mem: 3586
I20250120 11:26:28 3528121 dinov2 helpers.py:102] Training  [ 6020/12500]  eta: 0:24:48  loss: 31.0227 (37.3672)  lr: 0.0000 (0.0000)  time: 0.206192  data: 0.000434  max mem: 3586
I20250120 11:26:30 3528121 dinov2 helpers.py:102] Training  [ 6030/12500]  eta: 0:24:46  loss: 31.0227 (37.3665)  lr: 0.0000 (0.0000)  time: 0.206127  data: 0.000443  max mem: 3586
I20250120 11:26:32 3528121 dinov2 helpers.py:102] Training  [ 6040/12500]  eta: 0:24:43  loss: 31.0227 (37.3579)  lr: 0.0000 (0.0000)  time: 0.206060  data: 0.000407  max mem: 3586
I20250120 11:26:34 3528121 dinov2 helpers.py:102] Training  [ 6050/12500]  eta: 0:24:41  loss: 31.0227 (37.3532)  lr: 0.0000 (0.0000)  time: 0.206140  data: 0.000373  max mem: 3586
I20250120 11:26:37 3528121 dinov2 helpers.py:102] Training  [ 6060/12500]  eta: 0:24:38  loss: 31.0369 (37.3453)  lr: 0.0000 (0.0000)  time: 0.206126  data: 0.000357  max mem: 3586
I20250120 11:26:39 3528121 dinov2 helpers.py:102] Training  [ 6070/12500]  eta: 0:24:36  loss: 31.0369 (37.3326)  lr: 0.0000 (0.0000)  time: 0.206101  data: 0.000417  max mem: 3586
I20250120 11:26:41 3528121 dinov2 helpers.py:102] Training  [ 6080/12500]  eta: 0:24:33  loss: 31.0227 (37.3195)  lr: 0.0000 (0.0000)  time: 0.206272  data: 0.000454  max mem: 3586
I20250120 11:26:43 3528121 dinov2 helpers.py:102] Training  [ 6090/12500]  eta: 0:24:30  loss: 31.0227 (37.3167)  lr: 0.0000 (0.0000)  time: 0.206237  data: 0.000445  max mem: 3586
I20250120 11:26:45 3528121 dinov2 helpers.py:102] Training  [ 6100/12500]  eta: 0:24:28  loss: 30.5711 (37.3035)  lr: 0.0000 (0.0000)  time: 0.205870  data: 0.000457  max mem: 3586
I20250120 11:26:47 3528121 dinov2 helpers.py:102] Training  [ 6110/12500]  eta: 0:24:25  loss: 30.5711 (37.2883)  lr: 0.0000 (0.0000)  time: 0.205831  data: 0.000431  max mem: 3586
I20250120 11:26:49 3528121 dinov2 helpers.py:102] Training  [ 6120/12500]  eta: 0:24:23  loss: 30.5711 (37.2768)  lr: 0.0000 (0.0000)  time: 0.205880  data: 0.000404  max mem: 3586
I20250120 11:26:51 3528121 dinov2 helpers.py:102] Training  [ 6130/12500]  eta: 0:24:20  loss: 31.0227 (37.2713)  lr: 0.0000 (0.0000)  time: 0.205901  data: 0.000371  max mem: 3586
I20250120 11:26:53 3528121 dinov2 helpers.py:102] Training  [ 6140/12500]  eta: 0:24:18  loss: 31.0227 (37.2627)  lr: 0.0000 (0.0000)  time: 0.205855  data: 0.000339  max mem: 3586
I20250120 11:26:55 3528121 dinov2 helpers.py:102] Training  [ 6150/12500]  eta: 0:24:15  loss: 31.2062 (37.2561)  lr: 0.0000 (0.0000)  time: 0.205965  data: 0.000395  max mem: 3586
I20250120 11:26:57 3528121 dinov2 helpers.py:102] Training  [ 6160/12500]  eta: 0:24:13  loss: 31.9544 (37.2537)  lr: 0.0000 (0.0000)  time: 0.206093  data: 0.000461  max mem: 3586
I20250120 11:26:59 3528121 dinov2 helpers.py:102] Training  [ 6170/12500]  eta: 0:24:10  loss: 31.9544 (37.2442)  lr: 0.0000 (0.0000)  time: 0.206329  data: 0.000484  max mem: 3586
I20250120 11:27:01 3528121 dinov2 helpers.py:102] Training  [ 6180/12500]  eta: 0:24:08  loss: 31.9544 (37.2436)  lr: 0.0000 (0.0000)  time: 0.206474  data: 0.000472  max mem: 3586
I20250120 11:27:03 3528121 dinov2 helpers.py:102] Training  [ 6190/12500]  eta: 0:24:05  loss: 31.9544 (37.2382)  lr: 0.0000 (0.0000)  time: 0.206239  data: 0.000471  max mem: 3586
I20250120 11:27:05 3528121 dinov2 helpers.py:102] Training  [ 6200/12500]  eta: 0:24:03  loss: 31.9544 (37.2232)  lr: 0.0000 (0.0000)  time: 0.206019  data: 0.000438  max mem: 3586
I20250120 11:27:07 3528121 dinov2 helpers.py:102] Training  [ 6210/12500]  eta: 0:24:00  loss: 31.9544 (37.2105)  lr: 0.0000 (0.0000)  time: 0.206129  data: 0.000446  max mem: 3586
I20250120 11:27:10 3528121 dinov2 helpers.py:102] Training  [ 6220/12500]  eta: 0:23:58  loss: 31.9544 (37.2015)  lr: 0.0000 (0.0000)  time: 0.206489  data: 0.000474  max mem: 3586
I20250120 11:27:12 3528121 dinov2 helpers.py:102] Training  [ 6230/12500]  eta: 0:23:55  loss: 31.9544 (37.1956)  lr: 0.0000 (0.0000)  time: 0.206499  data: 0.000432  max mem: 3586
I20250120 11:27:14 3528121 dinov2 helpers.py:102] Training  [ 6240/12500]  eta: 0:23:52  loss: 31.6317 (37.1857)  lr: 0.0000 (0.0000)  time: 0.206336  data: 0.000389  max mem: 3586
I20250120 11:27:15 3528121 dinov2 linear.py:272] running validation !
I20250120 11:27:17 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:57    time: 1.534511  data: 1.327652  max mem: 3586
I20250120 11:27:19 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.332105  data: 0.121990  max mem: 3586
I20250120 11:27:21 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.211378  data: 0.001039  max mem: 3586
I20250120 11:27:23 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.209885  data: 0.000459  max mem: 3586
I20250120 11:27:25 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209285  data: 0.000265  max mem: 3586
I20250120 11:27:28 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209567  data: 0.000260  max mem: 3586
I20250120 11:27:30 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209517  data: 0.000240  max mem: 3586
I20250120 11:27:32 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209380  data: 0.000223  max mem: 3586
I20250120 11:27:34 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.209303  data: 0.000233  max mem: 3586
I20250120 11:27:36 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209391  data: 0.000223  max mem: 3586
I20250120 11:27:38 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.209505  data: 0.000220  max mem: 3586
I20250120 11:27:40 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.209497  data: 0.000225  max mem: 3586
I20250120 11:27:42 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209163  data: 0.000237  max mem: 3586
I20250120 11:27:44 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209306  data: 0.000258  max mem: 3586
I20250120 11:27:46 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209805  data: 0.000238  max mem: 3586
I20250120 11:27:48 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209072  data: 0.000175  max mem: 3586
I20250120 11:27:49 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204671  data: 0.000156  max mem: 3586
I20250120 11:27:49 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218481 s / it)
I20250120 11:27:49 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:27:49 3528121 dinov2 linear.py:287] 
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6888, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7073, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7228, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7325, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7368, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7403, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7440, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7449, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7401, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7400, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7179, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7110, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7058, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7246, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7347, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7410, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7479, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7520, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7524, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7461, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7578, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7475, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7271, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6695, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7171, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7303, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7391, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7443, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7472, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7482, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7458, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7414, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7429, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7252, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7032, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.6864, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7237, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7350, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7455, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7519, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7549, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7529, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7558, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7244, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7507, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7291, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.6921, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:292] ITER: 6249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.6983, device='cuda:0')}
I20250120 11:27:49 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_1_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.757780909538269}
I20250120 11:27:50 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:27:50 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:27:50 3528121 dinov2 helpers.py:102] Training  [ 6250/12500]  eta: 0:24:24  loss: 31.3917 (37.1736)  lr: 0.0000 (0.0000)  time: 1.904647  data: 0.000366  max mem: 3586
I20250120 11:27:52 3528121 dinov2 helpers.py:102] Training  [ 6260/12500]  eta: 0:24:21  loss: 31.0200 (37.1626)  lr: 0.0000 (0.0000)  time: 1.904077  data: 0.000372  max mem: 3586
I20250120 11:27:54 3528121 dinov2 helpers.py:102] Training  [ 6270/12500]  eta: 0:24:19  loss: 31.2707 (37.1532)  lr: 0.0000 (0.0000)  time: 0.205521  data: 0.000403  max mem: 3586
I20250120 11:27:56 3528121 dinov2 helpers.py:102] Training  [ 6280/12500]  eta: 0:24:16  loss: 31.3917 (37.1474)  lr: 0.0000 (0.0000)  time: 0.206012  data: 0.000429  max mem: 3586
I20250120 11:27:58 3528121 dinov2 helpers.py:102] Training  [ 6290/12500]  eta: 0:24:13  loss: 31.2707 (37.1370)  lr: 0.0000 (0.0000)  time: 0.206065  data: 0.000427  max mem: 3586
I20250120 11:28:00 3528121 dinov2 helpers.py:102] Training  [ 6300/12500]  eta: 0:24:11  loss: 31.2707 (37.1226)  lr: 0.0000 (0.0000)  time: 0.205777  data: 0.000424  max mem: 3586
I20250120 11:28:02 3528121 dinov2 helpers.py:102] Training  [ 6310/12500]  eta: 0:24:08  loss: 31.2707 (37.1107)  lr: 0.0000 (0.0000)  time: 0.205727  data: 0.000409  max mem: 3586
I20250120 11:28:05 3528121 dinov2 helpers.py:102] Training  [ 6320/12500]  eta: 0:24:06  loss: 31.3917 (37.1033)  lr: 0.0000 (0.0000)  time: 0.228716  data: 0.026916  max mem: 3586
I20250120 11:28:07 3528121 dinov2 helpers.py:102] Training  [ 6330/12500]  eta: 0:24:03  loss: 31.2707 (37.0893)  lr: 0.0000 (0.0000)  time: 0.229737  data: 0.026905  max mem: 3586
I20250120 11:28:09 3528121 dinov2 helpers.py:102] Training  [ 6340/12500]  eta: 0:24:01  loss: 31.2707 (37.0834)  lr: 0.0000 (0.0000)  time: 0.207660  data: 0.000416  max mem: 3586
I20250120 11:28:11 3528121 dinov2 helpers.py:102] Training  [ 6350/12500]  eta: 0:23:58  loss: 31.2707 (37.0751)  lr: 0.0000 (0.0000)  time: 0.207434  data: 0.000429  max mem: 3586
I20250120 11:28:13 3528121 dinov2 helpers.py:102] Training  [ 6360/12500]  eta: 0:23:56  loss: 31.0200 (37.0609)  lr: 0.0000 (0.0000)  time: 0.207479  data: 0.000386  max mem: 3586
I20250120 11:28:15 3528121 dinov2 helpers.py:102] Training  [ 6370/12500]  eta: 0:23:53  loss: 30.7488 (37.0510)  lr: 0.0000 (0.0000)  time: 0.207638  data: 0.000412  max mem: 3586
I20250120 11:28:17 3528121 dinov2 helpers.py:102] Training  [ 6380/12500]  eta: 0:23:50  loss: 30.7488 (37.0412)  lr: 0.0000 (0.0000)  time: 0.207950  data: 0.000420  max mem: 3586
I20250120 11:28:19 3528121 dinov2 helpers.py:102] Training  [ 6390/12500]  eta: 0:23:48  loss: 30.7488 (37.0360)  lr: 0.0000 (0.0000)  time: 0.208121  data: 0.000423  max mem: 3586
I20250120 11:28:21 3528121 dinov2 helpers.py:102] Training  [ 6400/12500]  eta: 0:23:45  loss: 30.8288 (37.0315)  lr: 0.0000 (0.0000)  time: 0.208179  data: 0.000438  max mem: 3586
I20250120 11:28:23 3528121 dinov2 helpers.py:102] Training  [ 6410/12500]  eta: 0:23:43  loss: 31.0200 (37.0315)  lr: 0.0000 (0.0000)  time: 0.208093  data: 0.000432  max mem: 3586
I20250120 11:28:25 3528121 dinov2 helpers.py:102] Training  [ 6420/12500]  eta: 0:23:40  loss: 31.0200 (37.0316)  lr: 0.0000 (0.0000)  time: 0.207916  data: 0.000452  max mem: 3586
I20250120 11:28:27 3528121 dinov2 helpers.py:102] Training  [ 6430/12500]  eta: 0:23:38  loss: 31.0200 (37.0270)  lr: 0.0000 (0.0000)  time: 0.207882  data: 0.000462  max mem: 3586
I20250120 11:28:30 3528121 dinov2 helpers.py:102] Training  [ 6440/12500]  eta: 0:23:35  loss: 31.2707 (37.0193)  lr: 0.0000 (0.0000)  time: 0.207943  data: 0.000444  max mem: 3586
I20250120 11:28:32 3528121 dinov2 helpers.py:102] Training  [ 6450/12500]  eta: 0:23:32  loss: 31.7858 (37.0180)  lr: 0.0000 (0.0000)  time: 0.208029  data: 0.000442  max mem: 3586
I20250120 11:28:34 3528121 dinov2 helpers.py:102] Training  [ 6460/12500]  eta: 0:23:30  loss: 31.7858 (37.0088)  lr: 0.0000 (0.0000)  time: 0.208140  data: 0.000444  max mem: 3586
I20250120 11:28:36 3528121 dinov2 helpers.py:102] Training  [ 6470/12500]  eta: 0:23:27  loss: 31.7858 (36.9970)  lr: 0.0000 (0.0000)  time: 0.208294  data: 0.000426  max mem: 3586
I20250120 11:28:38 3528121 dinov2 helpers.py:102] Training  [ 6480/12500]  eta: 0:23:25  loss: 31.0757 (36.9786)  lr: 0.0000 (0.0000)  time: 0.208388  data: 0.000438  max mem: 3586
I20250120 11:28:40 3528121 dinov2 helpers.py:102] Training  [ 6490/12500]  eta: 0:23:22  loss: 31.1904 (36.9697)  lr: 0.0000 (0.0000)  time: 0.208290  data: 0.000416  max mem: 3586
I20250120 11:28:42 3528121 dinov2 helpers.py:102] Training  [ 6500/12500]  eta: 0:23:20  loss: 31.7858 (36.9621)  lr: 0.0000 (0.0000)  time: 0.208192  data: 0.000411  max mem: 3586
I20250120 11:28:44 3528121 dinov2 helpers.py:102] Training  [ 6510/12500]  eta: 0:23:17  loss: 32.0184 (36.9587)  lr: 0.0000 (0.0000)  time: 0.208081  data: 0.000424  max mem: 3586
I20250120 11:28:46 3528121 dinov2 helpers.py:102] Training  [ 6520/12500]  eta: 0:23:14  loss: 31.7858 (36.9490)  lr: 0.0000 (0.0000)  time: 0.207979  data: 0.000407  max mem: 3586
I20250120 11:28:48 3528121 dinov2 helpers.py:102] Training  [ 6530/12500]  eta: 0:23:12  loss: 31.8094 (36.9411)  lr: 0.0000 (0.0000)  time: 0.207876  data: 0.000413  max mem: 3586
I20250120 11:28:50 3528121 dinov2 helpers.py:102] Training  [ 6540/12500]  eta: 0:23:09  loss: 31.8094 (36.9333)  lr: 0.0000 (0.0000)  time: 0.207855  data: 0.000428  max mem: 3586
I20250120 11:28:52 3528121 dinov2 helpers.py:102] Training  [ 6550/12500]  eta: 0:23:07  loss: 31.8323 (36.9262)  lr: 0.0000 (0.0000)  time: 0.207982  data: 0.000382  max mem: 3586
I20250120 11:28:54 3528121 dinov2 helpers.py:102] Training  [ 6560/12500]  eta: 0:23:04  loss: 31.8323 (36.9124)  lr: 0.0000 (0.0000)  time: 0.207814  data: 0.000377  max mem: 3586
I20250120 11:28:57 3528121 dinov2 helpers.py:102] Training  [ 6570/12500]  eta: 0:23:02  loss: 32.0184 (36.9133)  lr: 0.0000 (0.0000)  time: 0.207727  data: 0.000411  max mem: 3586
I20250120 11:28:59 3528121 dinov2 helpers.py:102] Training  [ 6580/12500]  eta: 0:22:59  loss: 32.0647 (36.9127)  lr: 0.0000 (0.0000)  time: 0.207697  data: 0.000451  max mem: 3586
I20250120 11:29:01 3528121 dinov2 helpers.py:102] Training  [ 6590/12500]  eta: 0:22:57  loss: 32.0184 (36.8971)  lr: 0.0000 (0.0000)  time: 0.207580  data: 0.000451  max mem: 3586
I20250120 11:29:03 3528121 dinov2 helpers.py:102] Training  [ 6600/12500]  eta: 0:22:54  loss: 32.0184 (36.8902)  lr: 0.0000 (0.0000)  time: 0.207760  data: 0.000421  max mem: 3586
I20250120 11:29:05 3528121 dinov2 helpers.py:102] Training  [ 6610/12500]  eta: 0:22:51  loss: 31.8323 (36.8778)  lr: 0.0000 (0.0000)  time: 0.207814  data: 0.000430  max mem: 3586
I20250120 11:29:07 3528121 dinov2 helpers.py:102] Training  [ 6620/12500]  eta: 0:22:49  loss: 31.8323 (36.8707)  lr: 0.0000 (0.0000)  time: 0.207679  data: 0.000434  max mem: 3586
I20250120 11:29:09 3528121 dinov2 helpers.py:102] Training  [ 6630/12500]  eta: 0:22:46  loss: 31.8094 (36.8622)  lr: 0.0000 (0.0000)  time: 0.207777  data: 0.000421  max mem: 3586
I20250120 11:29:11 3528121 dinov2 helpers.py:102] Training  [ 6640/12500]  eta: 0:22:44  loss: 31.2049 (36.8519)  lr: 0.0000 (0.0000)  time: 0.207900  data: 0.000438  max mem: 3586
I20250120 11:29:13 3528121 dinov2 helpers.py:102] Training  [ 6650/12500]  eta: 0:22:41  loss: 31.1904 (36.8391)  lr: 0.0000 (0.0000)  time: 0.207990  data: 0.000488  max mem: 3586
I20250120 11:29:15 3528121 dinov2 helpers.py:102] Training  [ 6660/12500]  eta: 0:22:39  loss: 31.2049 (36.8333)  lr: 0.0000 (0.0000)  time: 0.207842  data: 0.000441  max mem: 3586
I20250120 11:29:17 3528121 dinov2 helpers.py:102] Training  [ 6670/12500]  eta: 0:22:36  loss: 31.8094 (36.8315)  lr: 0.0000 (0.0000)  time: 0.207600  data: 0.000409  max mem: 3586
I20250120 11:29:19 3528121 dinov2 helpers.py:102] Training  [ 6680/12500]  eta: 0:22:34  loss: 31.8094 (36.8194)  lr: 0.0000 (0.0000)  time: 0.207655  data: 0.000459  max mem: 3586
I20250120 11:29:21 3528121 dinov2 helpers.py:102] Training  [ 6690/12500]  eta: 0:22:31  loss: 31.8094 (36.8088)  lr: 0.0000 (0.0000)  time: 0.207753  data: 0.000469  max mem: 3586
I20250120 11:29:24 3528121 dinov2 helpers.py:102] Training  [ 6700/12500]  eta: 0:22:28  loss: 31.2049 (36.7995)  lr: 0.0000 (0.0000)  time: 0.207787  data: 0.000437  max mem: 3586
I20250120 11:29:26 3528121 dinov2 helpers.py:102] Training  [ 6710/12500]  eta: 0:22:26  loss: 30.6146 (36.7854)  lr: 0.0000 (0.0000)  time: 0.207809  data: 0.000424  max mem: 3586
I20250120 11:29:28 3528121 dinov2 helpers.py:102] Training  [ 6720/12500]  eta: 0:22:23  loss: 31.2049 (36.7776)  lr: 0.0000 (0.0000)  time: 0.207706  data: 0.000421  max mem: 3586
I20250120 11:29:30 3528121 dinov2 helpers.py:102] Training  [ 6730/12500]  eta: 0:22:21  loss: 31.2049 (36.7708)  lr: 0.0000 (0.0000)  time: 0.207761  data: 0.000418  max mem: 3586
I20250120 11:29:32 3528121 dinov2 helpers.py:102] Training  [ 6740/12500]  eta: 0:22:18  loss: 31.2049 (36.7646)  lr: 0.0000 (0.0000)  time: 0.207890  data: 0.000388  max mem: 3586
I20250120 11:29:34 3528121 dinov2 helpers.py:102] Training  [ 6750/12500]  eta: 0:22:16  loss: 31.2049 (36.7586)  lr: 0.0000 (0.0000)  time: 0.207896  data: 0.000402  max mem: 3586
I20250120 11:29:36 3528121 dinov2 helpers.py:102] Training  [ 6760/12500]  eta: 0:22:13  loss: 31.5071 (36.7554)  lr: 0.0000 (0.0000)  time: 0.207980  data: 0.000474  max mem: 3586
I20250120 11:29:38 3528121 dinov2 helpers.py:102] Training  [ 6770/12500]  eta: 0:22:11  loss: 31.5071 (36.7509)  lr: 0.0000 (0.0000)  time: 0.207807  data: 0.000441  max mem: 3586
I20250120 11:29:40 3528121 dinov2 helpers.py:102] Training  [ 6780/12500]  eta: 0:22:08  loss: 31.2049 (36.7349)  lr: 0.0000 (0.0000)  time: 0.207876  data: 0.000411  max mem: 3586
I20250120 11:29:42 3528121 dinov2 helpers.py:102] Training  [ 6790/12500]  eta: 0:22:06  loss: 31.2049 (36.7253)  lr: 0.0000 (0.0000)  time: 0.208135  data: 0.000446  max mem: 3586
I20250120 11:29:44 3528121 dinov2 helpers.py:102] Training  [ 6800/12500]  eta: 0:22:03  loss: 31.2049 (36.7192)  lr: 0.0000 (0.0000)  time: 0.208091  data: 0.000407  max mem: 3586
I20250120 11:29:46 3528121 dinov2 helpers.py:102] Training  [ 6810/12500]  eta: 0:22:01  loss: 31.5071 (36.7122)  lr: 0.0000 (0.0000)  time: 0.208068  data: 0.000431  max mem: 3586
I20250120 11:29:49 3528121 dinov2 helpers.py:102] Training  [ 6820/12500]  eta: 0:21:58  loss: 31.2049 (36.7010)  lr: 0.0000 (0.0000)  time: 0.208088  data: 0.000429  max mem: 3586
I20250120 11:29:51 3528121 dinov2 helpers.py:102] Training  [ 6830/12500]  eta: 0:21:56  loss: 30.6010 (36.6901)  lr: 0.0000 (0.0000)  time: 0.208063  data: 0.000407  max mem: 3586
I20250120 11:29:53 3528121 dinov2 helpers.py:102] Training  [ 6840/12500]  eta: 0:21:53  loss: 30.6010 (36.6767)  lr: 0.0000 (0.0000)  time: 0.207983  data: 0.000460  max mem: 3586
I20250120 11:29:55 3528121 dinov2 helpers.py:102] Training  [ 6850/12500]  eta: 0:21:51  loss: 30.6010 (36.6679)  lr: 0.0000 (0.0000)  time: 0.207998  data: 0.000436  max mem: 3586
I20250120 11:29:57 3528121 dinov2 helpers.py:102] Training  [ 6860/12500]  eta: 0:21:48  loss: 30.6010 (36.6599)  lr: 0.0000 (0.0000)  time: 0.207963  data: 0.000424  max mem: 3586
I20250120 11:29:59 3528121 dinov2 helpers.py:102] Training  [ 6870/12500]  eta: 0:21:46  loss: 30.5850 (36.6470)  lr: 0.0000 (0.0000)  time: 0.207969  data: 0.000438  max mem: 3586
I20250120 11:30:01 3528121 dinov2 helpers.py:102] Training  [ 6880/12500]  eta: 0:21:43  loss: 30.5850 (36.6336)  lr: 0.0000 (0.0000)  time: 0.208020  data: 0.000447  max mem: 3586
I20250120 11:30:03 3528121 dinov2 helpers.py:102] Training  [ 6890/12500]  eta: 0:21:40  loss: 30.5850 (36.6226)  lr: 0.0000 (0.0000)  time: 0.207965  data: 0.000436  max mem: 3586
I20250120 11:30:05 3528121 dinov2 helpers.py:102] Training  [ 6900/12500]  eta: 0:21:38  loss: 30.2058 (36.6107)  lr: 0.0000 (0.0000)  time: 0.207949  data: 0.000435  max mem: 3586
I20250120 11:30:07 3528121 dinov2 helpers.py:102] Training  [ 6910/12500]  eta: 0:21:35  loss: 30.2058 (36.5988)  lr: 0.0000 (0.0000)  time: 0.207892  data: 0.000460  max mem: 3586
I20250120 11:30:09 3528121 dinov2 helpers.py:102] Training  [ 6920/12500]  eta: 0:21:33  loss: 30.2058 (36.6003)  lr: 0.0000 (0.0000)  time: 0.207902  data: 0.000442  max mem: 3586
I20250120 11:30:11 3528121 dinov2 helpers.py:102] Training  [ 6930/12500]  eta: 0:21:30  loss: 30.2058 (36.5925)  lr: 0.0000 (0.0000)  time: 0.207822  data: 0.000408  max mem: 3586
I20250120 11:30:13 3528121 dinov2 helpers.py:102] Training  [ 6940/12500]  eta: 0:21:28  loss: 29.2031 (36.5791)  lr: 0.0000 (0.0000)  time: 0.207790  data: 0.000380  max mem: 3586
I20250120 11:30:16 3528121 dinov2 helpers.py:102] Training  [ 6950/12500]  eta: 0:21:25  loss: 29.2031 (36.5695)  lr: 0.0000 (0.0000)  time: 0.207933  data: 0.000428  max mem: 3586
I20250120 11:30:18 3528121 dinov2 helpers.py:102] Training  [ 6960/12500]  eta: 0:21:23  loss: 29.2031 (36.5595)  lr: 0.0000 (0.0000)  time: 0.207862  data: 0.000459  max mem: 3586
I20250120 11:30:20 3528121 dinov2 helpers.py:102] Training  [ 6970/12500]  eta: 0:21:20  loss: 29.1020 (36.5473)  lr: 0.0000 (0.0000)  time: 0.207976  data: 0.000414  max mem: 3586
I20250120 11:30:22 3528121 dinov2 helpers.py:102] Training  [ 6980/12500]  eta: 0:21:18  loss: 29.2031 (36.5378)  lr: 0.0000 (0.0000)  time: 0.208124  data: 0.000410  max mem: 3586
I20250120 11:30:24 3528121 dinov2 helpers.py:102] Training  [ 6990/12500]  eta: 0:21:15  loss: 29.2031 (36.5361)  lr: 0.0000 (0.0000)  time: 0.208012  data: 0.000435  max mem: 3586
I20250120 11:30:26 3528121 dinov2 helpers.py:102] Training  [ 7000/12500]  eta: 0:21:13  loss: 29.2031 (36.5265)  lr: 0.0000 (0.0000)  time: 0.208020  data: 0.000439  max mem: 3586
I20250120 11:30:28 3528121 dinov2 helpers.py:102] Training  [ 7010/12500]  eta: 0:21:10  loss: 29.1020 (36.5121)  lr: 0.0000 (0.0000)  time: 0.207956  data: 0.000423  max mem: 3586
I20250120 11:30:30 3528121 dinov2 helpers.py:102] Training  [ 7020/12500]  eta: 0:21:08  loss: 29.2031 (36.5065)  lr: 0.0000 (0.0000)  time: 0.208114  data: 0.000421  max mem: 3586
I20250120 11:30:32 3528121 dinov2 helpers.py:102] Training  [ 7030/12500]  eta: 0:21:05  loss: 29.5882 (36.5002)  lr: 0.0000 (0.0000)  time: 0.208209  data: 0.000429  max mem: 3586
I20250120 11:30:34 3528121 dinov2 helpers.py:102] Training  [ 7040/12500]  eta: 0:21:03  loss: 29.5882 (36.4881)  lr: 0.0000 (0.0000)  time: 0.208028  data: 0.000433  max mem: 3586
I20250120 11:30:36 3528121 dinov2 helpers.py:102] Training  [ 7050/12500]  eta: 0:21:00  loss: 29.5882 (36.4789)  lr: 0.0000 (0.0000)  time: 0.208193  data: 0.000437  max mem: 3586
I20250120 11:30:38 3528121 dinov2 helpers.py:102] Training  [ 7060/12500]  eta: 0:20:58  loss: 29.5882 (36.4727)  lr: 0.0000 (0.0000)  time: 0.208273  data: 0.000435  max mem: 3586
I20250120 11:30:41 3528121 dinov2 helpers.py:102] Training  [ 7070/12500]  eta: 0:20:55  loss: 29.7986 (36.4633)  lr: 0.0000 (0.0000)  time: 0.208250  data: 0.000408  max mem: 3586
I20250120 11:30:43 3528121 dinov2 helpers.py:102] Training  [ 7080/12500]  eta: 0:20:53  loss: 29.8015 (36.4601)  lr: 0.0000 (0.0000)  time: 0.208218  data: 0.000385  max mem: 3586
I20250120 11:30:45 3528121 dinov2 helpers.py:102] Training  [ 7090/12500]  eta: 0:20:50  loss: 29.9200 (36.4561)  lr: 0.0000 (0.0000)  time: 0.208030  data: 0.000392  max mem: 3586
I20250120 11:30:47 3528121 dinov2 helpers.py:102] Training  [ 7100/12500]  eta: 0:20:48  loss: 29.9200 (36.4438)  lr: 0.0000 (0.0000)  time: 0.207865  data: 0.000368  max mem: 3586
I20250120 11:30:49 3528121 dinov2 helpers.py:102] Training  [ 7110/12500]  eta: 0:20:45  loss: 29.9200 (36.4308)  lr: 0.0000 (0.0000)  time: 0.207953  data: 0.000356  max mem: 3586
I20250120 11:30:51 3528121 dinov2 helpers.py:102] Training  [ 7120/12500]  eta: 0:20:43  loss: 29.9200 (36.4224)  lr: 0.0000 (0.0000)  time: 0.208192  data: 0.000421  max mem: 3586
I20250120 11:30:53 3528121 dinov2 helpers.py:102] Training  [ 7130/12500]  eta: 0:20:41  loss: 29.9200 (36.4152)  lr: 0.0000 (0.0000)  time: 0.208264  data: 0.000414  max mem: 3586
I20250120 11:30:55 3528121 dinov2 helpers.py:102] Training  [ 7140/12500]  eta: 0:20:38  loss: 29.9200 (36.4054)  lr: 0.0000 (0.0000)  time: 0.208205  data: 0.000422  max mem: 3586
I20250120 11:30:57 3528121 dinov2 helpers.py:102] Training  [ 7150/12500]  eta: 0:20:36  loss: 29.8015 (36.3919)  lr: 0.0000 (0.0000)  time: 0.208124  data: 0.000467  max mem: 3586
I20250120 11:30:59 3528121 dinov2 helpers.py:102] Training  [ 7160/12500]  eta: 0:20:33  loss: 29.9457 (36.3831)  lr: 0.0000 (0.0000)  time: 0.208149  data: 0.000420  max mem: 3586
I20250120 11:31:01 3528121 dinov2 helpers.py:102] Training  [ 7170/12500]  eta: 0:20:31  loss: 29.9457 (36.3701)  lr: 0.0000 (0.0000)  time: 0.208210  data: 0.000382  max mem: 3586
I20250120 11:31:03 3528121 dinov2 helpers.py:102] Training  [ 7180/12500]  eta: 0:20:28  loss: 29.8015 (36.3576)  lr: 0.0000 (0.0000)  time: 0.208157  data: 0.000383  max mem: 3586
I20250120 11:31:06 3528121 dinov2 helpers.py:102] Training  [ 7190/12500]  eta: 0:20:26  loss: 29.7986 (36.3480)  lr: 0.0000 (0.0000)  time: 0.208039  data: 0.000455  max mem: 3586
I20250120 11:31:08 3528121 dinov2 helpers.py:102] Training  [ 7200/12500]  eta: 0:20:23  loss: 29.8015 (36.3427)  lr: 0.0000 (0.0000)  time: 0.208082  data: 0.000481  max mem: 3586
I20250120 11:31:10 3528121 dinov2 helpers.py:102] Training  [ 7210/12500]  eta: 0:20:21  loss: 29.8015 (36.3278)  lr: 0.0000 (0.0000)  time: 0.208108  data: 0.000429  max mem: 3586
I20250120 11:31:12 3528121 dinov2 helpers.py:102] Training  [ 7220/12500]  eta: 0:20:18  loss: 29.8015 (36.3197)  lr: 0.0000 (0.0000)  time: 0.208107  data: 0.000397  max mem: 3586
I20250120 11:31:14 3528121 dinov2 helpers.py:102] Training  [ 7230/12500]  eta: 0:20:16  loss: 29.4899 (36.3063)  lr: 0.0000 (0.0000)  time: 0.208104  data: 0.000447  max mem: 3586
I20250120 11:31:16 3528121 dinov2 helpers.py:102] Training  [ 7240/12500]  eta: 0:20:13  loss: 29.4899 (36.2937)  lr: 0.0000 (0.0000)  time: 0.207952  data: 0.000471  max mem: 3586
I20250120 11:31:18 3528121 dinov2 helpers.py:102] Training  [ 7250/12500]  eta: 0:20:11  loss: 29.4414 (36.2841)  lr: 0.0000 (0.0000)  time: 0.208070  data: 0.000445  max mem: 3586
I20250120 11:31:20 3528121 dinov2 helpers.py:102] Training  [ 7260/12500]  eta: 0:20:08  loss: 29.4414 (36.2748)  lr: 0.0000 (0.0000)  time: 0.208113  data: 0.000486  max mem: 3586
I20250120 11:31:22 3528121 dinov2 helpers.py:102] Training  [ 7270/12500]  eta: 0:20:06  loss: 29.4414 (36.2704)  lr: 0.0000 (0.0000)  time: 0.208088  data: 0.000454  max mem: 3586
I20250120 11:31:24 3528121 dinov2 helpers.py:102] Training  [ 7280/12500]  eta: 0:20:03  loss: 29.4414 (36.2629)  lr: 0.0000 (0.0000)  time: 0.208098  data: 0.000437  max mem: 3586
I20250120 11:31:26 3528121 dinov2 helpers.py:102] Training  [ 7290/12500]  eta: 0:20:01  loss: 29.3572 (36.2528)  lr: 0.0000 (0.0000)  time: 0.208240  data: 0.000484  max mem: 3586
I20250120 11:31:28 3528121 dinov2 helpers.py:102] Training  [ 7300/12500]  eta: 0:19:58  loss: 29.3572 (36.2421)  lr: 0.0000 (0.0000)  time: 0.208405  data: 0.000468  max mem: 3586
I20250120 11:31:31 3528121 dinov2 helpers.py:102] Training  [ 7310/12500]  eta: 0:19:56  loss: 29.4414 (36.2335)  lr: 0.0000 (0.0000)  time: 0.208333  data: 0.000470  max mem: 3586
I20250120 11:31:33 3528121 dinov2 helpers.py:102] Training  [ 7320/12500]  eta: 0:19:54  loss: 29.3572 (36.2204)  lr: 0.0000 (0.0000)  time: 0.208246  data: 0.000468  max mem: 3586
I20250120 11:31:35 3528121 dinov2 helpers.py:102] Training  [ 7330/12500]  eta: 0:19:51  loss: 29.3572 (36.2143)  lr: 0.0000 (0.0000)  time: 0.208324  data: 0.000414  max mem: 3586
I20250120 11:31:37 3528121 dinov2 helpers.py:102] Training  [ 7340/12500]  eta: 0:19:49  loss: 29.3572 (36.2066)  lr: 0.0000 (0.0000)  time: 0.208571  data: 0.000441  max mem: 3586
I20250120 11:31:39 3528121 dinov2 helpers.py:102] Training  [ 7350/12500]  eta: 0:19:46  loss: 29.3708 (36.1973)  lr: 0.0000 (0.0000)  time: 0.208523  data: 0.000467  max mem: 3586
I20250120 11:31:41 3528121 dinov2 helpers.py:102] Training  [ 7360/12500]  eta: 0:19:44  loss: 29.3708 (36.1882)  lr: 0.0000 (0.0000)  time: 0.208448  data: 0.000456  max mem: 3586
I20250120 11:31:43 3528121 dinov2 helpers.py:102] Training  [ 7370/12500]  eta: 0:19:41  loss: 29.4709 (36.1821)  lr: 0.0000 (0.0000)  time: 0.208469  data: 0.000468  max mem: 3586
I20250120 11:31:45 3528121 dinov2 helpers.py:102] Training  [ 7380/12500]  eta: 0:19:39  loss: 29.4709 (36.1712)  lr: 0.0000 (0.0000)  time: 0.208541  data: 0.000460  max mem: 3586
I20250120 11:31:47 3528121 dinov2 helpers.py:102] Training  [ 7390/12500]  eta: 0:19:36  loss: 29.4709 (36.1636)  lr: 0.0000 (0.0000)  time: 0.208432  data: 0.000459  max mem: 3586
I20250120 11:31:49 3528121 dinov2 helpers.py:102] Training  [ 7400/12500]  eta: 0:19:34  loss: 29.3708 (36.1510)  lr: 0.0000 (0.0000)  time: 0.208364  data: 0.000453  max mem: 3586
I20250120 11:31:51 3528121 dinov2 helpers.py:102] Training  [ 7410/12500]  eta: 0:19:31  loss: 29.3708 (36.1386)  lr: 0.0000 (0.0000)  time: 0.208520  data: 0.000436  max mem: 3586
I20250120 11:31:53 3528121 dinov2 helpers.py:102] Training  [ 7420/12500]  eta: 0:19:29  loss: 29.3572 (36.1240)  lr: 0.0000 (0.0000)  time: 0.208341  data: 0.000428  max mem: 3586
I20250120 11:31:56 3528121 dinov2 helpers.py:102] Training  [ 7430/12500]  eta: 0:19:26  loss: 29.3708 (36.1151)  lr: 0.0000 (0.0000)  time: 0.208238  data: 0.000421  max mem: 3586
I20250120 11:31:58 3528121 dinov2 helpers.py:102] Training  [ 7440/12500]  eta: 0:19:24  loss: 29.4709 (36.1073)  lr: 0.0000 (0.0000)  time: 0.208424  data: 0.000451  max mem: 3586
I20250120 11:32:00 3528121 dinov2 helpers.py:102] Training  [ 7450/12500]  eta: 0:19:22  loss: 29.4784 (36.1024)  lr: 0.0000 (0.0000)  time: 0.208556  data: 0.000480  max mem: 3586
I20250120 11:32:02 3528121 dinov2 helpers.py:102] Training  [ 7460/12500]  eta: 0:19:19  loss: 29.4902 (36.0958)  lr: 0.0000 (0.0000)  time: 0.208491  data: 0.000463  max mem: 3586
I20250120 11:32:04 3528121 dinov2 helpers.py:102] Training  [ 7470/12500]  eta: 0:19:17  loss: 29.4902 (36.0888)  lr: 0.0000 (0.0000)  time: 0.208353  data: 0.000450  max mem: 3586
I20250120 11:32:06 3528121 dinov2 helpers.py:102] Training  [ 7480/12500]  eta: 0:19:14  loss: 29.4902 (36.0831)  lr: 0.0000 (0.0000)  time: 0.208321  data: 0.000432  max mem: 3586
I20250120 11:32:08 3528121 dinov2 helpers.py:102] Training  [ 7490/12500]  eta: 0:19:12  loss: 29.9060 (36.0788)  lr: 0.0000 (0.0000)  time: 0.208391  data: 0.000445  max mem: 3586
I20250120 11:32:10 3528121 dinov2 linear.py:272] running validation !
I20250120 11:32:11 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:51    time: 1.494823  data: 1.289351  max mem: 3586
I20250120 11:32:14 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.330325  data: 0.118745  max mem: 3586
I20250120 11:32:16 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.212350  data: 0.001043  max mem: 3586
I20250120 11:32:18 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.210122  data: 0.000364  max mem: 3586
I20250120 11:32:20 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209598  data: 0.000261  max mem: 3586
I20250120 11:32:22 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209836  data: 0.000200  max mem: 3586
I20250120 11:32:29 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:29    time: 0.439427  data: 0.233011  max mem: 3586
I20250120 11:32:31 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:24    time: 0.437799  data: 0.233205  max mem: 3586
I20250120 11:32:33 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:21    time: 0.209203  data: 0.000720  max mem: 3586
I20250120 11:32:35 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:17    time: 0.210530  data: 0.000593  max mem: 3586
I20250120 11:32:37 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:14    time: 0.209418  data: 0.000443  max mem: 3586
I20250120 11:32:39 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:11    time: 0.209098  data: 0.000373  max mem: 3586
I20250120 11:32:41 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:09    time: 0.208784  data: 0.000213  max mem: 3586
I20250120 11:32:43 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:06    time: 0.209030  data: 0.000217  max mem: 3586
I20250120 11:32:45 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209212  data: 0.000226  max mem: 3586
I20250120 11:32:47 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208600  data: 0.000184  max mem: 3586
I20250120 11:32:48 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204435  data: 0.000166  max mem: 3586
I20250120 11:32:48 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:38 (0.247941 s / it)
I20250120 11:32:48 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:32:48 3528121 dinov2 linear.py:287] 
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6921, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7094, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7238, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7332, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7380, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7412, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7449, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7467, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7432, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7342, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7282, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7233, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7075, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7264, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7362, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7432, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7499, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7537, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7564, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7492, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7562, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7567, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7499, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7211, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7185, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7321, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7411, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7466, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7518, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7516, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7473, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7429, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7458, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7309, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7158, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7030, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7263, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7382, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7472, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7511, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7578, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7584, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7531, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7576, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7587, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7467, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7370, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:292] ITER: 7499 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7206, device='cuda:0')}
I20250120 11:32:48 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00500', 'accuracy': 0.7587409019470215}
I20250120 11:32:49 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:32:49 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:32:49 3528121 dinov2 helpers.py:102] Training  [ 7500/12500]  eta: 0:19:35  loss: 29.9060 (36.0679)  lr: 0.0000 (0.0000)  time: 2.134409  data: 0.000482  max mem: 3586
I20250120 11:32:51 3528121 dinov2 helpers.py:102] Training  [ 7510/12500]  eta: 0:19:32  loss: 29.4902 (36.0522)  lr: 0.0000 (0.0000)  time: 2.132386  data: 0.000466  max mem: 3586
I20250120 11:32:53 3528121 dinov2 helpers.py:102] Training  [ 7520/12500]  eta: 0:19:30  loss: 30.3118 (36.0476)  lr: 0.0000 (0.0000)  time: 0.204772  data: 0.000422  max mem: 3586
I20250120 11:32:55 3528121 dinov2 helpers.py:102] Training  [ 7530/12500]  eta: 0:19:27  loss: 29.4902 (36.0375)  lr: 0.0000 (0.0000)  time: 0.205394  data: 0.000421  max mem: 3586
I20250120 11:32:57 3528121 dinov2 helpers.py:102] Training  [ 7540/12500]  eta: 0:19:25  loss: 29.4709 (36.0275)  lr: 0.0000 (0.0000)  time: 0.205603  data: 0.000443  max mem: 3586
I20250120 11:32:59 3528121 dinov2 helpers.py:102] Training  [ 7550/12500]  eta: 0:19:22  loss: 29.4902 (36.0212)  lr: 0.0000 (0.0000)  time: 0.205647  data: 0.000424  max mem: 3586
I20250120 11:33:01 3528121 dinov2 helpers.py:102] Training  [ 7560/12500]  eta: 0:19:20  loss: 29.6925 (36.0129)  lr: 0.0000 (0.0000)  time: 0.205818  data: 0.000428  max mem: 3586
I20250120 11:33:03 3528121 dinov2 helpers.py:102] Training  [ 7570/12500]  eta: 0:19:17  loss: 29.6925 (36.0074)  lr: 0.0000 (0.0000)  time: 0.205968  data: 0.000485  max mem: 3586
I20250120 11:33:05 3528121 dinov2 helpers.py:102] Training  [ 7580/12500]  eta: 0:19:15  loss: 30.3118 (36.0029)  lr: 0.0000 (0.0000)  time: 0.206052  data: 0.000484  max mem: 3586
I20250120 11:33:08 3528121 dinov2 helpers.py:102] Training  [ 7590/12500]  eta: 0:19:12  loss: 29.6925 (35.9882)  lr: 0.0000 (0.0000)  time: 0.228930  data: 0.026871  max mem: 3586
I20250120 11:33:10 3528121 dinov2 helpers.py:102] Training  [ 7600/12500]  eta: 0:19:10  loss: 29.6925 (35.9784)  lr: 0.0000 (0.0000)  time: 0.228966  data: 0.026874  max mem: 3586
I20250120 11:33:12 3528121 dinov2 helpers.py:102] Training  [ 7610/12500]  eta: 0:19:07  loss: 30.3118 (35.9744)  lr: 0.0000 (0.0000)  time: 0.206014  data: 0.000432  max mem: 3586
I20250120 11:33:14 3528121 dinov2 helpers.py:102] Training  [ 7620/12500]  eta: 0:19:05  loss: 30.3118 (35.9642)  lr: 0.0000 (0.0000)  time: 0.206207  data: 0.000406  max mem: 3586
I20250120 11:33:16 3528121 dinov2 helpers.py:102] Training  [ 7630/12500]  eta: 0:19:02  loss: 30.8917 (35.9583)  lr: 0.0000 (0.0000)  time: 0.206366  data: 0.000384  max mem: 3586
I20250120 11:33:18 3528121 dinov2 helpers.py:102] Training  [ 7640/12500]  eta: 0:19:00  loss: 30.8917 (35.9504)  lr: 0.0000 (0.0000)  time: 0.206362  data: 0.000409  max mem: 3586
I20250120 11:33:20 3528121 dinov2 helpers.py:102] Training  [ 7650/12500]  eta: 0:18:57  loss: 29.9005 (35.9412)  lr: 0.0000 (0.0000)  time: 0.206732  data: 0.000459  max mem: 3586
I20250120 11:33:22 3528121 dinov2 helpers.py:102] Training  [ 7660/12500]  eta: 0:18:55  loss: 29.9005 (35.9345)  lr: 0.0000 (0.0000)  time: 0.206962  data: 0.000459  max mem: 3586
I20250120 11:33:24 3528121 dinov2 helpers.py:102] Training  [ 7670/12500]  eta: 0:18:52  loss: 29.6925 (35.9230)  lr: 0.0000 (0.0000)  time: 0.206943  data: 0.000465  max mem: 3586
I20250120 11:33:26 3528121 dinov2 helpers.py:102] Training  [ 7680/12500]  eta: 0:18:50  loss: 29.6925 (35.9173)  lr: 0.0000 (0.0000)  time: 0.206748  data: 0.000489  max mem: 3586
I20250120 11:33:28 3528121 dinov2 helpers.py:102] Training  [ 7690/12500]  eta: 0:18:47  loss: 28.8855 (35.9058)  lr: 0.0000 (0.0000)  time: 0.206783  data: 0.000498  max mem: 3586
I20250120 11:33:30 3528121 dinov2 helpers.py:102] Training  [ 7700/12500]  eta: 0:18:45  loss: 28.8855 (35.8957)  lr: 0.0000 (0.0000)  time: 0.207001  data: 0.000486  max mem: 3586
I20250120 11:33:32 3528121 dinov2 helpers.py:102] Training  [ 7710/12500]  eta: 0:18:42  loss: 28.8855 (35.8854)  lr: 0.0000 (0.0000)  time: 0.206884  data: 0.000450  max mem: 3586
I20250120 11:33:34 3528121 dinov2 helpers.py:102] Training  [ 7720/12500]  eta: 0:18:40  loss: 28.8855 (35.8792)  lr: 0.0000 (0.0000)  time: 0.206638  data: 0.000407  max mem: 3586
I20250120 11:33:37 3528121 dinov2 helpers.py:102] Training  [ 7730/12500]  eta: 0:18:37  loss: 28.8855 (35.8683)  lr: 0.0000 (0.0000)  time: 0.206558  data: 0.000444  max mem: 3586
I20250120 11:33:39 3528121 dinov2 helpers.py:102] Training  [ 7740/12500]  eta: 0:18:35  loss: 28.8855 (35.8523)  lr: 0.0000 (0.0000)  time: 0.206645  data: 0.000499  max mem: 3586
I20250120 11:33:41 3528121 dinov2 helpers.py:102] Training  [ 7750/12500]  eta: 0:18:32  loss: 28.8855 (35.8467)  lr: 0.0000 (0.0000)  time: 0.206585  data: 0.000504  max mem: 3586
I20250120 11:33:43 3528121 dinov2 helpers.py:102] Training  [ 7760/12500]  eta: 0:18:30  loss: 28.8855 (35.8423)  lr: 0.0000 (0.0000)  time: 0.206711  data: 0.000472  max mem: 3586
I20250120 11:33:45 3528121 dinov2 helpers.py:102] Training  [ 7770/12500]  eta: 0:18:27  loss: 28.8855 (35.8347)  lr: 0.0000 (0.0000)  time: 0.206828  data: 0.000422  max mem: 3586
I20250120 11:33:47 3528121 dinov2 helpers.py:102] Training  [ 7780/12500]  eta: 0:18:25  loss: 28.6714 (35.8255)  lr: 0.0000 (0.0000)  time: 0.206818  data: 0.000397  max mem: 3586
I20250120 11:33:49 3528121 dinov2 helpers.py:102] Training  [ 7790/12500]  eta: 0:18:22  loss: 28.6714 (35.8142)  lr: 0.0000 (0.0000)  time: 0.206918  data: 0.000430  max mem: 3586
I20250120 11:33:51 3528121 dinov2 helpers.py:102] Training  [ 7800/12500]  eta: 0:18:20  loss: 28.6714 (35.8048)  lr: 0.0000 (0.0000)  time: 0.206976  data: 0.000496  max mem: 3586
I20250120 11:33:53 3528121 dinov2 helpers.py:102] Training  [ 7810/12500]  eta: 0:18:17  loss: 28.6714 (35.7960)  lr: 0.0000 (0.0000)  time: 0.207171  data: 0.000509  max mem: 3586
I20250120 11:33:55 3528121 dinov2 helpers.py:102] Training  [ 7820/12500]  eta: 0:18:15  loss: 28.8654 (35.7954)  lr: 0.0000 (0.0000)  time: 0.207291  data: 0.000485  max mem: 3586
I20250120 11:33:57 3528121 dinov2 helpers.py:102] Training  [ 7830/12500]  eta: 0:18:12  loss: 28.6714 (35.7860)  lr: 0.0000 (0.0000)  time: 0.207192  data: 0.000466  max mem: 3586
I20250120 11:33:59 3528121 dinov2 helpers.py:102] Training  [ 7840/12500]  eta: 0:18:10  loss: 28.6714 (35.7771)  lr: 0.0000 (0.0000)  time: 0.207231  data: 0.000465  max mem: 3586
I20250120 11:34:01 3528121 dinov2 helpers.py:102] Training  [ 7850/12500]  eta: 0:18:07  loss: 28.4809 (35.7656)  lr: 0.0000 (0.0000)  time: 0.207178  data: 0.000471  max mem: 3586
I20250120 11:34:03 3528121 dinov2 helpers.py:102] Training  [ 7860/12500]  eta: 0:18:05  loss: 28.4809 (35.7576)  lr: 0.0000 (0.0000)  time: 0.207154  data: 0.000463  max mem: 3586
I20250120 11:34:06 3528121 dinov2 helpers.py:102] Training  [ 7870/12500]  eta: 0:18:02  loss: 28.6714 (35.7515)  lr: 0.0000 (0.0000)  time: 0.207141  data: 0.000447  max mem: 3586
I20250120 11:34:08 3528121 dinov2 helpers.py:102] Training  [ 7880/12500]  eta: 0:18:00  loss: 28.4809 (35.7420)  lr: 0.0000 (0.0000)  time: 0.207256  data: 0.000448  max mem: 3586
I20250120 11:34:10 3528121 dinov2 helpers.py:102] Training  [ 7890/12500]  eta: 0:17:57  loss: 28.4809 (35.7323)  lr: 0.0000 (0.0000)  time: 0.207512  data: 0.000445  max mem: 3586
I20250120 11:34:12 3528121 dinov2 helpers.py:102] Training  [ 7900/12500]  eta: 0:17:55  loss: 28.4809 (35.7213)  lr: 0.0000 (0.0000)  time: 0.207617  data: 0.000463  max mem: 3586
I20250120 11:34:14 3528121 dinov2 helpers.py:102] Training  [ 7910/12500]  eta: 0:17:52  loss: 28.4809 (35.7089)  lr: 0.0000 (0.0000)  time: 0.207886  data: 0.000466  max mem: 3586
I20250120 11:34:16 3528121 dinov2 helpers.py:102] Training  [ 7920/12500]  eta: 0:17:50  loss: 28.4809 (35.7048)  lr: 0.0000 (0.0000)  time: 0.207708  data: 0.000461  max mem: 3586
I20250120 11:34:18 3528121 dinov2 helpers.py:102] Training  [ 7930/12500]  eta: 0:17:47  loss: 28.4809 (35.6935)  lr: 0.0000 (0.0000)  time: 0.207509  data: 0.000441  max mem: 3586
I20250120 11:34:20 3528121 dinov2 helpers.py:102] Training  [ 7940/12500]  eta: 0:17:45  loss: 28.6714 (35.6866)  lr: 0.0000 (0.0000)  time: 0.207646  data: 0.000433  max mem: 3586
I20250120 11:34:22 3528121 dinov2 helpers.py:102] Training  [ 7950/12500]  eta: 0:17:42  loss: 28.4809 (35.6740)  lr: 0.0000 (0.0000)  time: 0.207766  data: 0.000429  max mem: 3586
I20250120 11:34:24 3528121 dinov2 helpers.py:102] Training  [ 7960/12500]  eta: 0:17:40  loss: 28.4546 (35.6649)  lr: 0.0000 (0.0000)  time: 0.207391  data: 0.000391  max mem: 3586
I20250120 11:34:26 3528121 dinov2 helpers.py:102] Training  [ 7970/12500]  eta: 0:17:37  loss: 28.4546 (35.6604)  lr: 0.0000 (0.0000)  time: 0.207356  data: 0.000415  max mem: 3586
I20250120 11:34:28 3528121 dinov2 helpers.py:102] Training  [ 7980/12500]  eta: 0:17:35  loss: 28.4546 (35.6575)  lr: 0.0000 (0.0000)  time: 0.207542  data: 0.000470  max mem: 3586
I20250120 11:34:30 3528121 dinov2 helpers.py:102] Training  [ 7990/12500]  eta: 0:17:32  loss: 28.4546 (35.6475)  lr: 0.0000 (0.0000)  time: 0.207430  data: 0.000501  max mem: 3586
I20250120 11:34:33 3528121 dinov2 helpers.py:102] Training  [ 8000/12500]  eta: 0:17:30  loss: 28.4546 (35.6410)  lr: 0.0000 (0.0000)  time: 0.207501  data: 0.000493  max mem: 3586
I20250120 11:34:35 3528121 dinov2 helpers.py:102] Training  [ 8010/12500]  eta: 0:17:27  loss: 28.3968 (35.6287)  lr: 0.0000 (0.0000)  time: 0.207376  data: 0.000475  max mem: 3586
I20250120 11:34:37 3528121 dinov2 helpers.py:102] Training  [ 8020/12500]  eta: 0:17:25  loss: 28.3015 (35.6187)  lr: 0.0000 (0.0000)  time: 0.207527  data: 0.000451  max mem: 3586
I20250120 11:34:39 3528121 dinov2 helpers.py:102] Training  [ 8030/12500]  eta: 0:17:22  loss: 28.3015 (35.6124)  lr: 0.0000 (0.0000)  time: 0.207817  data: 0.000442  max mem: 3586
I20250120 11:34:41 3528121 dinov2 helpers.py:102] Training  [ 8040/12500]  eta: 0:17:20  loss: 28.3015 (35.6057)  lr: 0.0000 (0.0000)  time: 0.207817  data: 0.000461  max mem: 3586
I20250120 11:34:43 3528121 dinov2 helpers.py:102] Training  [ 8050/12500]  eta: 0:17:17  loss: 28.4546 (35.5995)  lr: 0.0000 (0.0000)  time: 0.207512  data: 0.000467  max mem: 3586
I20250120 11:34:45 3528121 dinov2 helpers.py:102] Training  [ 8060/12500]  eta: 0:17:15  loss: 28.4546 (35.5907)  lr: 0.0000 (0.0000)  time: 0.207427  data: 0.000446  max mem: 3586
I20250120 11:34:47 3528121 dinov2 helpers.py:102] Training  [ 8070/12500]  eta: 0:17:12  loss: 28.3015 (35.5810)  lr: 0.0000 (0.0000)  time: 0.207497  data: 0.000415  max mem: 3586
I20250120 11:34:49 3528121 dinov2 helpers.py:102] Training  [ 8080/12500]  eta: 0:17:10  loss: 28.0641 (35.5715)  lr: 0.0000 (0.0000)  time: 0.207366  data: 0.000442  max mem: 3586
I20250120 11:34:51 3528121 dinov2 helpers.py:102] Training  [ 8090/12500]  eta: 0:17:08  loss: 27.9397 (35.5591)  lr: 0.0000 (0.0000)  time: 0.207224  data: 0.000461  max mem: 3586
I20250120 11:34:53 3528121 dinov2 helpers.py:102] Training  [ 8100/12500]  eta: 0:17:05  loss: 28.4546 (35.5548)  lr: 0.0000 (0.0000)  time: 0.207155  data: 0.000427  max mem: 3586
I20250120 11:34:55 3528121 dinov2 helpers.py:102] Training  [ 8110/12500]  eta: 0:17:03  loss: 28.4811 (35.5468)  lr: 0.0000 (0.0000)  time: 0.207185  data: 0.000399  max mem: 3586
I20250120 11:34:57 3528121 dinov2 helpers.py:102] Training  [ 8120/12500]  eta: 0:17:00  loss: 28.4811 (35.5394)  lr: 0.0000 (0.0000)  time: 0.207484  data: 0.000392  max mem: 3586
I20250120 11:35:00 3528121 dinov2 helpers.py:102] Training  [ 8130/12500]  eta: 0:16:58  loss: 29.0691 (35.5341)  lr: 0.0000 (0.0000)  time: 0.207526  data: 0.000378  max mem: 3586
I20250120 11:35:02 3528121 dinov2 helpers.py:102] Training  [ 8140/12500]  eta: 0:16:55  loss: 29.0691 (35.5293)  lr: 0.0000 (0.0000)  time: 0.207143  data: 0.000415  max mem: 3586
I20250120 11:35:04 3528121 dinov2 helpers.py:102] Training  [ 8150/12500]  eta: 0:16:53  loss: 29.0691 (35.5191)  lr: 0.0000 (0.0000)  time: 0.207217  data: 0.000444  max mem: 3586
I20250120 11:35:06 3528121 dinov2 helpers.py:102] Training  [ 8160/12500]  eta: 0:16:50  loss: 29.0691 (35.5106)  lr: 0.0000 (0.0000)  time: 0.207400  data: 0.000424  max mem: 3586
I20250120 11:35:08 3528121 dinov2 helpers.py:102] Training  [ 8170/12500]  eta: 0:16:48  loss: 28.5697 (35.5008)  lr: 0.0000 (0.0000)  time: 0.207333  data: 0.000415  max mem: 3586
I20250120 11:35:10 3528121 dinov2 helpers.py:102] Training  [ 8180/12500]  eta: 0:16:45  loss: 28.5697 (35.4928)  lr: 0.0000 (0.0000)  time: 0.207539  data: 0.000401  max mem: 3586
I20250120 11:35:12 3528121 dinov2 helpers.py:102] Training  [ 8190/12500]  eta: 0:16:43  loss: 28.9672 (35.4851)  lr: 0.0000 (0.0000)  time: 0.207523  data: 0.000422  max mem: 3586
I20250120 11:35:14 3528121 dinov2 helpers.py:102] Training  [ 8200/12500]  eta: 0:16:40  loss: 28.9672 (35.4786)  lr: 0.0000 (0.0000)  time: 0.207350  data: 0.000433  max mem: 3586
I20250120 11:35:16 3528121 dinov2 helpers.py:102] Training  [ 8210/12500]  eta: 0:16:38  loss: 28.9672 (35.4659)  lr: 0.0000 (0.0000)  time: 0.207441  data: 0.000456  max mem: 3586
I20250120 11:35:18 3528121 dinov2 helpers.py:102] Training  [ 8220/12500]  eta: 0:16:35  loss: 28.9672 (35.4563)  lr: 0.0000 (0.0000)  time: 0.207318  data: 0.000465  max mem: 3586
I20250120 11:35:20 3528121 dinov2 helpers.py:102] Training  [ 8230/12500]  eta: 0:16:33  loss: 28.7347 (35.4481)  lr: 0.0000 (0.0000)  time: 0.207239  data: 0.000471  max mem: 3586
I20250120 11:35:22 3528121 dinov2 helpers.py:102] Training  [ 8240/12500]  eta: 0:16:31  loss: 28.7347 (35.4431)  lr: 0.0000 (0.0000)  time: 0.207476  data: 0.000439  max mem: 3586
I20250120 11:35:24 3528121 dinov2 helpers.py:102] Training  [ 8250/12500]  eta: 0:16:28  loss: 28.7347 (35.4390)  lr: 0.0000 (0.0000)  time: 0.207521  data: 0.000439  max mem: 3586
I20250120 11:35:26 3528121 dinov2 helpers.py:102] Training  [ 8260/12500]  eta: 0:16:26  loss: 28.9672 (35.4316)  lr: 0.0000 (0.0000)  time: 0.207544  data: 0.000427  max mem: 3586
I20250120 11:35:29 3528121 dinov2 helpers.py:102] Training  [ 8270/12500]  eta: 0:16:23  loss: 28.9672 (35.4181)  lr: 0.0000 (0.0000)  time: 0.207616  data: 0.000387  max mem: 3586
I20250120 11:35:31 3528121 dinov2 helpers.py:102] Training  [ 8280/12500]  eta: 0:16:21  loss: 29.0691 (35.4143)  lr: 0.0000 (0.0000)  time: 0.207530  data: 0.000424  max mem: 3586
I20250120 11:35:33 3528121 dinov2 helpers.py:102] Training  [ 8290/12500]  eta: 0:16:18  loss: 29.1502 (35.4109)  lr: 0.0000 (0.0000)  time: 0.207408  data: 0.000484  max mem: 3586
I20250120 11:35:35 3528121 dinov2 helpers.py:102] Training  [ 8300/12500]  eta: 0:16:16  loss: 29.1502 (35.4042)  lr: 0.0000 (0.0000)  time: 0.207409  data: 0.000495  max mem: 3586
I20250120 11:35:37 3528121 dinov2 helpers.py:102] Training  [ 8310/12500]  eta: 0:16:13  loss: 29.1502 (35.3920)  lr: 0.0000 (0.0000)  time: 0.207684  data: 0.000457  max mem: 3586
I20250120 11:35:39 3528121 dinov2 helpers.py:102] Training  [ 8320/12500]  eta: 0:16:11  loss: 29.1502 (35.3859)  lr: 0.0000 (0.0000)  time: 0.207491  data: 0.000465  max mem: 3586
I20250120 11:35:41 3528121 dinov2 helpers.py:102] Training  [ 8330/12500]  eta: 0:16:08  loss: 28.9672 (35.3768)  lr: 0.0000 (0.0000)  time: 0.207244  data: 0.000487  max mem: 3586
I20250120 11:35:43 3528121 dinov2 helpers.py:102] Training  [ 8340/12500]  eta: 0:16:06  loss: 28.9672 (35.3694)  lr: 0.0000 (0.0000)  time: 0.207665  data: 0.000456  max mem: 3586
I20250120 11:35:45 3528121 dinov2 helpers.py:102] Training  [ 8350/12500]  eta: 0:16:04  loss: 28.9672 (35.3591)  lr: 0.0000 (0.0000)  time: 0.207844  data: 0.000446  max mem: 3586
I20250120 11:35:47 3528121 dinov2 helpers.py:102] Training  [ 8360/12500]  eta: 0:16:01  loss: 29.0548 (35.3516)  lr: 0.0000 (0.0000)  time: 0.207550  data: 0.000476  max mem: 3586
I20250120 11:35:49 3528121 dinov2 helpers.py:102] Training  [ 8370/12500]  eta: 0:15:59  loss: 29.1502 (35.3445)  lr: 0.0000 (0.0000)  time: 0.207522  data: 0.000474  max mem: 3586
I20250120 11:35:51 3528121 dinov2 helpers.py:102] Training  [ 8380/12500]  eta: 0:15:56  loss: 29.2057 (35.3397)  lr: 0.0000 (0.0000)  time: 0.207664  data: 0.000464  max mem: 3586
I20250120 11:35:53 3528121 dinov2 helpers.py:102] Training  [ 8390/12500]  eta: 0:15:54  loss: 29.2902 (35.3362)  lr: 0.0000 (0.0000)  time: 0.207648  data: 0.000468  max mem: 3586
I20250120 11:35:56 3528121 dinov2 helpers.py:102] Training  [ 8400/12500]  eta: 0:15:51  loss: 29.2902 (35.3324)  lr: 0.0000 (0.0000)  time: 0.207546  data: 0.000465  max mem: 3586
I20250120 11:35:58 3528121 dinov2 helpers.py:102] Training  [ 8410/12500]  eta: 0:15:49  loss: 29.2902 (35.3217)  lr: 0.0000 (0.0000)  time: 0.207507  data: 0.000453  max mem: 3586
I20250120 11:36:00 3528121 dinov2 helpers.py:102] Training  [ 8420/12500]  eta: 0:15:46  loss: 29.3854 (35.3148)  lr: 0.0000 (0.0000)  time: 0.207365  data: 0.000480  max mem: 3586
I20250120 11:36:02 3528121 dinov2 helpers.py:102] Training  [ 8430/12500]  eta: 0:15:44  loss: 29.3854 (35.3051)  lr: 0.0000 (0.0000)  time: 0.207407  data: 0.000476  max mem: 3586
I20250120 11:36:04 3528121 dinov2 helpers.py:102] Training  [ 8440/12500]  eta: 0:15:42  loss: 29.2902 (35.2935)  lr: 0.0000 (0.0000)  time: 0.207421  data: 0.000476  max mem: 3586
I20250120 11:36:06 3528121 dinov2 helpers.py:102] Training  [ 8450/12500]  eta: 0:15:39  loss: 29.2057 (35.2836)  lr: 0.0000 (0.0000)  time: 0.207529  data: 0.000462  max mem: 3586
I20250120 11:36:08 3528121 dinov2 helpers.py:102] Training  [ 8460/12500]  eta: 0:15:37  loss: 29.2057 (35.2765)  lr: 0.0000 (0.0000)  time: 0.207415  data: 0.000435  max mem: 3586
I20250120 11:36:10 3528121 dinov2 helpers.py:102] Training  [ 8470/12500]  eta: 0:15:34  loss: 29.2672 (35.2700)  lr: 0.0000 (0.0000)  time: 0.207462  data: 0.000428  max mem: 3586
I20250120 11:36:12 3528121 dinov2 helpers.py:102] Training  [ 8480/12500]  eta: 0:15:32  loss: 29.2057 (35.2608)  lr: 0.0000 (0.0000)  time: 0.208102  data: 0.000423  max mem: 3586
I20250120 11:36:14 3528121 dinov2 helpers.py:102] Training  [ 8490/12500]  eta: 0:15:29  loss: 29.2057 (35.2540)  lr: 0.0000 (0.0000)  time: 0.208114  data: 0.000449  max mem: 3586
I20250120 11:36:16 3528121 dinov2 helpers.py:102] Training  [ 8500/12500]  eta: 0:15:27  loss: 29.2057 (35.2495)  lr: 0.0000 (0.0000)  time: 0.207755  data: 0.000467  max mem: 3586
I20250120 11:36:18 3528121 dinov2 helpers.py:102] Training  [ 8510/12500]  eta: 0:15:25  loss: 29.2057 (35.2381)  lr: 0.0000 (0.0000)  time: 0.207538  data: 0.000472  max mem: 3586
I20250120 11:36:20 3528121 dinov2 helpers.py:102] Training  [ 8520/12500]  eta: 0:15:22  loss: 29.0548 (35.2270)  lr: 0.0000 (0.0000)  time: 0.207664  data: 0.000463  max mem: 3586
I20250120 11:36:23 3528121 dinov2 helpers.py:102] Training  [ 8530/12500]  eta: 0:15:20  loss: 29.0548 (35.2169)  lr: 0.0000 (0.0000)  time: 0.208124  data: 0.000448  max mem: 3586
I20250120 11:36:25 3528121 dinov2 helpers.py:102] Training  [ 8540/12500]  eta: 0:15:17  loss: 27.4620 (35.2055)  lr: 0.0000 (0.0000)  time: 0.208155  data: 0.000462  max mem: 3586
I20250120 11:36:27 3528121 dinov2 helpers.py:102] Training  [ 8550/12500]  eta: 0:15:15  loss: 27.4620 (35.1929)  lr: 0.0000 (0.0000)  time: 0.207694  data: 0.000479  max mem: 3586
I20250120 11:36:29 3528121 dinov2 helpers.py:102] Training  [ 8560/12500]  eta: 0:15:12  loss: 27.1188 (35.1834)  lr: 0.0000 (0.0000)  time: 0.207369  data: 0.000487  max mem: 3586
I20250120 11:36:31 3528121 dinov2 helpers.py:102] Training  [ 8570/12500]  eta: 0:15:10  loss: 27.0951 (35.1736)  lr: 0.0000 (0.0000)  time: 0.207402  data: 0.000456  max mem: 3586
I20250120 11:36:33 3528121 dinov2 helpers.py:102] Training  [ 8580/12500]  eta: 0:15:08  loss: 27.0951 (35.1650)  lr: 0.0000 (0.0000)  time: 0.207437  data: 0.000416  max mem: 3586
I20250120 11:36:35 3528121 dinov2 helpers.py:102] Training  [ 8590/12500]  eta: 0:15:05  loss: 26.8711 (35.1517)  lr: 0.0000 (0.0000)  time: 0.207185  data: 0.000428  max mem: 3586
I20250120 11:36:37 3528121 dinov2 helpers.py:102] Training  [ 8600/12500]  eta: 0:15:03  loss: 26.7045 (35.1416)  lr: 0.0000 (0.0000)  time: 0.207115  data: 0.000460  max mem: 3586
I20250120 11:36:39 3528121 dinov2 helpers.py:102] Training  [ 8610/12500]  eta: 0:15:00  loss: 26.7045 (35.1287)  lr: 0.0000 (0.0000)  time: 0.206944  data: 0.000452  max mem: 3586
I20250120 11:36:41 3528121 dinov2 helpers.py:102] Training  [ 8620/12500]  eta: 0:14:58  loss: 26.7045 (35.1245)  lr: 0.0000 (0.0000)  time: 0.206973  data: 0.000450  max mem: 3586
I20250120 11:36:43 3528121 dinov2 helpers.py:102] Training  [ 8630/12500]  eta: 0:14:55  loss: 26.7045 (35.1165)  lr: 0.0000 (0.0000)  time: 0.207352  data: 0.000479  max mem: 3586
I20250120 11:36:45 3528121 dinov2 helpers.py:102] Training  [ 8640/12500]  eta: 0:14:53  loss: 26.8711 (35.1101)  lr: 0.0000 (0.0000)  time: 0.207356  data: 0.000480  max mem: 3586
I20250120 11:36:47 3528121 dinov2 helpers.py:102] Training  [ 8650/12500]  eta: 0:14:51  loss: 26.9597 (35.1007)  lr: 0.0000 (0.0000)  time: 0.207140  data: 0.000473  max mem: 3586
I20250120 11:36:50 3528121 dinov2 helpers.py:102] Training  [ 8660/12500]  eta: 0:14:48  loss: 26.9597 (35.0938)  lr: 0.0000 (0.0000)  time: 0.207185  data: 0.000422  max mem: 3586
I20250120 11:36:52 3528121 dinov2 helpers.py:102] Training  [ 8670/12500]  eta: 0:14:46  loss: 26.7275 (35.0841)  lr: 0.0000 (0.0000)  time: 0.207208  data: 0.000405  max mem: 3586
I20250120 11:36:54 3528121 dinov2 helpers.py:102] Training  [ 8680/12500]  eta: 0:14:43  loss: 26.7275 (35.0754)  lr: 0.0000 (0.0000)  time: 0.207249  data: 0.000462  max mem: 3586
I20250120 11:36:56 3528121 dinov2 helpers.py:102] Training  [ 8690/12500]  eta: 0:14:41  loss: 26.7275 (35.0701)  lr: 0.0000 (0.0000)  time: 0.207275  data: 0.000436  max mem: 3586
I20250120 11:36:58 3528121 dinov2 helpers.py:102] Training  [ 8700/12500]  eta: 0:14:38  loss: 26.7045 (35.0590)  lr: 0.0000 (0.0000)  time: 0.207358  data: 0.000411  max mem: 3586
I20250120 11:37:00 3528121 dinov2 helpers.py:102] Training  [ 8710/12500]  eta: 0:14:36  loss: 26.7045 (35.0465)  lr: 0.0000 (0.0000)  time: 0.207463  data: 0.000454  max mem: 3586
I20250120 11:37:02 3528121 dinov2 helpers.py:102] Training  [ 8720/12500]  eta: 0:14:34  loss: 26.7275 (35.0398)  lr: 0.0000 (0.0000)  time: 0.207475  data: 0.000460  max mem: 3586
I20250120 11:37:04 3528121 dinov2 helpers.py:102] Training  [ 8730/12500]  eta: 0:14:31  loss: 26.7275 (35.0296)  lr: 0.0000 (0.0000)  time: 0.207923  data: 0.000440  max mem: 3586
I20250120 11:37:06 3528121 dinov2 helpers.py:102] Training  [ 8740/12500]  eta: 0:14:29  loss: 26.9398 (35.0204)  lr: 0.0000 (0.0000)  time: 0.207962  data: 0.000434  max mem: 3586
I20250120 11:37:08 3528121 dinov2 linear.py:272] running validation !
I20250120 11:37:09 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:45    time: 1.456339  data: 1.251712  max mem: 3586
I20250120 11:37:12 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:47    time: 0.324507  data: 0.114330  max mem: 3586
I20250120 11:37:14 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:36    time: 0.212155  data: 0.000497  max mem: 3586
I20250120 11:37:16 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.212203  data: 0.000347  max mem: 3586
I20250120 11:37:18 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.211303  data: 0.000262  max mem: 3586
I20250120 11:37:20 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.211099  data: 0.000234  max mem: 3586
I20250120 11:37:22 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.210763  data: 0.000228  max mem: 3586
I20250120 11:37:24 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.210546  data: 0.000226  max mem: 3586
I20250120 11:37:26 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.210640  data: 0.000216  max mem: 3586
I20250120 11:37:28 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.210703  data: 0.000221  max mem: 3586
I20250120 11:37:31 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.210435  data: 0.000243  max mem: 3586
I20250120 11:37:33 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.210493  data: 0.000248  max mem: 3586
I20250120 11:37:35 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.210354  data: 0.000228  max mem: 3586
I20250120 11:37:37 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.210851  data: 0.000209  max mem: 3586
I20250120 11:37:39 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.210968  data: 0.000219  max mem: 3586
I20250120 11:37:41 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.209851  data: 0.000173  max mem: 3586
I20250120 11:37:42 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.205683  data: 0.000149  max mem: 3586
I20250120 11:37:42 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.219268 s / it)
I20250120 11:37:42 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:37:42 3528121 dinov2 linear.py:287] 
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6939, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7104, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7247, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7333, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7382, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7419, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7459, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7459, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7453, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7435, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7351, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7249, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7087, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7274, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7362, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7424, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7480, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7516, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7558, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7619, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7600, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7527, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7454, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7360, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7201, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7322, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7413, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7450, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7496, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7542, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7554, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7564, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7445, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7493, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7219, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7112, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7279, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7377, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7457, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7498, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7566, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7622, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7638, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7639, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7552, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7512, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7367, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:292] ITER: 8749 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7094, device='cuda:0')}
I20250120 11:37:42 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.7638944983482361}
I20250120 11:37:42 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:37:42 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:37:42 3528121 dinov2 helpers.py:102] Training  [ 8750/12500]  eta: 0:14:41  loss: 26.9597 (35.0119)  lr: 0.0000 (0.0000)  time: 1.911344  data: 0.000447  max mem: 3586
I20250120 11:37:44 3528121 dinov2 helpers.py:102] Training  [ 8760/12500]  eta: 0:14:39  loss: 26.9398 (35.0018)  lr: 0.0000 (0.0000)  time: 1.910356  data: 0.000469  max mem: 3586
I20250120 11:37:46 3528121 dinov2 helpers.py:102] Training  [ 8770/12500]  eta: 0:14:36  loss: 26.9597 (34.9944)  lr: 0.0000 (0.0000)  time: 0.206102  data: 0.000490  max mem: 3586
I20250120 11:37:48 3528121 dinov2 helpers.py:102] Training  [ 8780/12500]  eta: 0:14:34  loss: 26.9398 (34.9840)  lr: 0.0000 (0.0000)  time: 0.206413  data: 0.000458  max mem: 3586
I20250120 11:37:51 3528121 dinov2 helpers.py:102] Training  [ 8790/12500]  eta: 0:14:31  loss: 26.9597 (34.9793)  lr: 0.0000 (0.0000)  time: 0.206580  data: 0.000420  max mem: 3586
I20250120 11:37:53 3528121 dinov2 helpers.py:102] Training  [ 8800/12500]  eta: 0:14:29  loss: 26.9597 (34.9669)  lr: 0.0000 (0.0000)  time: 0.206820  data: 0.000463  max mem: 3586
I20250120 11:37:55 3528121 dinov2 helpers.py:102] Training  [ 8810/12500]  eta: 0:14:26  loss: 27.5137 (34.9589)  lr: 0.0000 (0.0000)  time: 0.206789  data: 0.000514  max mem: 3586
I20250120 11:37:57 3528121 dinov2 helpers.py:102] Training  [ 8820/12500]  eta: 0:14:24  loss: 26.9597 (34.9494)  lr: 0.0000 (0.0000)  time: 0.206693  data: 0.000488  max mem: 3586
I20250120 11:37:59 3528121 dinov2 helpers.py:102] Training  [ 8830/12500]  eta: 0:14:21  loss: 26.9597 (34.9463)  lr: 0.0000 (0.0000)  time: 0.206819  data: 0.000484  max mem: 3586
I20250120 11:38:01 3528121 dinov2 helpers.py:102] Training  [ 8840/12500]  eta: 0:14:19  loss: 26.9597 (34.9378)  lr: 0.0000 (0.0000)  time: 0.206869  data: 0.000466  max mem: 3586
I20250120 11:38:03 3528121 dinov2 helpers.py:102] Training  [ 8850/12500]  eta: 0:14:17  loss: 27.4352 (34.9331)  lr: 0.0000 (0.0000)  time: 0.229658  data: 0.026884  max mem: 3586
I20250120 11:38:05 3528121 dinov2 helpers.py:102] Training  [ 8860/12500]  eta: 0:14:14  loss: 26.9398 (34.9220)  lr: 0.0000 (0.0000)  time: 0.229453  data: 0.026896  max mem: 3586
I20250120 11:38:08 3528121 dinov2 helpers.py:102] Training  [ 8870/12500]  eta: 0:14:12  loss: 27.4352 (34.9142)  lr: 0.0000 (0.0000)  time: 0.206187  data: 0.000419  max mem: 3586
I20250120 11:38:10 3528121 dinov2 helpers.py:102] Training  [ 8880/12500]  eta: 0:14:09  loss: 26.9398 (34.9036)  lr: 0.0000 (0.0000)  time: 0.206364  data: 0.000447  max mem: 3586
I20250120 11:38:12 3528121 dinov2 helpers.py:102] Training  [ 8890/12500]  eta: 0:14:07  loss: 26.5862 (34.8939)  lr: 0.0000 (0.0000)  time: 0.206613  data: 0.000464  max mem: 3586
I20250120 11:38:14 3528121 dinov2 helpers.py:102] Training  [ 8900/12500]  eta: 0:14:04  loss: 26.5862 (34.8838)  lr: 0.0000 (0.0000)  time: 0.206602  data: 0.000429  max mem: 3586
I20250120 11:38:16 3528121 dinov2 helpers.py:102] Training  [ 8910/12500]  eta: 0:14:02  loss: 26.9398 (34.8761)  lr: 0.0000 (0.0000)  time: 0.206706  data: 0.000400  max mem: 3586
I20250120 11:38:18 3528121 dinov2 helpers.py:102] Training  [ 8920/12500]  eta: 0:13:59  loss: 26.9398 (34.8723)  lr: 0.0000 (0.0000)  time: 0.206795  data: 0.000406  max mem: 3586
I20250120 11:38:20 3528121 dinov2 helpers.py:102] Training  [ 8930/12500]  eta: 0:13:57  loss: 27.4352 (34.8693)  lr: 0.0000 (0.0000)  time: 0.206832  data: 0.000477  max mem: 3586
I20250120 11:38:22 3528121 dinov2 helpers.py:102] Training  [ 8940/12500]  eta: 0:13:54  loss: 27.4352 (34.8593)  lr: 0.0000 (0.0000)  time: 0.206952  data: 0.000466  max mem: 3586
I20250120 11:38:24 3528121 dinov2 helpers.py:102] Training  [ 8950/12500]  eta: 0:13:52  loss: 27.4352 (34.8530)  lr: 0.0000 (0.0000)  time: 0.206834  data: 0.000442  max mem: 3586
I20250120 11:38:26 3528121 dinov2 helpers.py:102] Training  [ 8960/12500]  eta: 0:13:49  loss: 27.8994 (34.8465)  lr: 0.0000 (0.0000)  time: 0.206649  data: 0.000464  max mem: 3586
I20250120 11:38:28 3528121 dinov2 helpers.py:102] Training  [ 8970/12500]  eta: 0:13:47  loss: 27.4352 (34.8360)  lr: 0.0000 (0.0000)  time: 0.206758  data: 0.000461  max mem: 3586
I20250120 11:38:30 3528121 dinov2 helpers.py:102] Training  [ 8980/12500]  eta: 0:13:45  loss: 27.4352 (34.8276)  lr: 0.0000 (0.0000)  time: 0.206741  data: 0.000478  max mem: 3586
I20250120 11:38:32 3528121 dinov2 helpers.py:102] Training  [ 8990/12500]  eta: 0:13:42  loss: 27.3664 (34.8193)  lr: 0.0000 (0.0000)  time: 0.206603  data: 0.000502  max mem: 3586
I20250120 11:38:34 3528121 dinov2 helpers.py:102] Training  [ 9000/12500]  eta: 0:13:40  loss: 27.3664 (34.8093)  lr: 0.0000 (0.0000)  time: 0.206610  data: 0.000459  max mem: 3586
I20250120 11:38:36 3528121 dinov2 helpers.py:102] Training  [ 9010/12500]  eta: 0:13:37  loss: 27.3664 (34.8033)  lr: 0.0000 (0.0000)  time: 0.206608  data: 0.000454  max mem: 3586
I20250120 11:38:39 3528121 dinov2 helpers.py:102] Training  [ 9020/12500]  eta: 0:13:35  loss: 27.4352 (34.7964)  lr: 0.0000 (0.0000)  time: 0.206722  data: 0.000482  max mem: 3586
I20250120 11:38:41 3528121 dinov2 helpers.py:102] Training  [ 9030/12500]  eta: 0:13:32  loss: 27.4352 (34.7897)  lr: 0.0000 (0.0000)  time: 0.207017  data: 0.000457  max mem: 3586
I20250120 11:38:43 3528121 dinov2 helpers.py:102] Training  [ 9040/12500]  eta: 0:13:30  loss: 27.9636 (34.7838)  lr: 0.0000 (0.0000)  time: 0.206966  data: 0.000475  max mem: 3586
I20250120 11:38:45 3528121 dinov2 helpers.py:102] Training  [ 9050/12500]  eta: 0:13:27  loss: 27.9636 (34.7768)  lr: 0.0000 (0.0000)  time: 0.206769  data: 0.000449  max mem: 3586
I20250120 11:38:47 3528121 dinov2 helpers.py:102] Training  [ 9060/12500]  eta: 0:13:25  loss: 27.9636 (34.7656)  lr: 0.0000 (0.0000)  time: 0.207042  data: 0.000442  max mem: 3586
I20250120 11:38:49 3528121 dinov2 helpers.py:102] Training  [ 9070/12500]  eta: 0:13:23  loss: 27.9636 (34.7624)  lr: 0.0000 (0.0000)  time: 0.207153  data: 0.000449  max mem: 3586
I20250120 11:38:51 3528121 dinov2 helpers.py:102] Training  [ 9080/12500]  eta: 0:13:20  loss: 27.9636 (34.7537)  lr: 0.0000 (0.0000)  time: 0.207076  data: 0.000380  max mem: 3586
I20250120 11:38:53 3528121 dinov2 helpers.py:102] Training  [ 9090/12500]  eta: 0:13:18  loss: 27.9636 (34.7451)  lr: 0.0000 (0.0000)  time: 0.207209  data: 0.000411  max mem: 3586
I20250120 11:38:55 3528121 dinov2 helpers.py:102] Training  [ 9100/12500]  eta: 0:13:15  loss: 27.9636 (34.7327)  lr: 0.0000 (0.0000)  time: 0.207296  data: 0.000484  max mem: 3586
I20250120 11:38:57 3528121 dinov2 helpers.py:102] Training  [ 9110/12500]  eta: 0:13:13  loss: 27.3664 (34.7236)  lr: 0.0000 (0.0000)  time: 0.207300  data: 0.000501  max mem: 3586
I20250120 11:38:59 3528121 dinov2 helpers.py:102] Training  [ 9120/12500]  eta: 0:13:10  loss: 27.3664 (34.7183)  lr: 0.0000 (0.0000)  time: 0.207376  data: 0.000500  max mem: 3586
I20250120 11:39:01 3528121 dinov2 helpers.py:102] Training  [ 9130/12500]  eta: 0:13:08  loss: 27.2603 (34.7073)  lr: 0.0000 (0.0000)  time: 0.207311  data: 0.000474  max mem: 3586
I20250120 11:39:03 3528121 dinov2 helpers.py:102] Training  [ 9140/12500]  eta: 0:13:05  loss: 27.2603 (34.6958)  lr: 0.0000 (0.0000)  time: 0.207358  data: 0.000470  max mem: 3586
I20250120 11:39:05 3528121 dinov2 helpers.py:102] Training  [ 9150/12500]  eta: 0:13:03  loss: 26.9713 (34.6868)  lr: 0.0000 (0.0000)  time: 0.207160  data: 0.000462  max mem: 3586
I20250120 11:39:08 3528121 dinov2 helpers.py:102] Training  [ 9160/12500]  eta: 0:13:01  loss: 26.9713 (34.6802)  lr: 0.0000 (0.0000)  time: 0.206818  data: 0.000412  max mem: 3586
I20250120 11:39:10 3528121 dinov2 helpers.py:102] Training  [ 9170/12500]  eta: 0:12:58  loss: 27.2603 (34.6731)  lr: 0.0000 (0.0000)  time: 0.206928  data: 0.000435  max mem: 3586
I20250120 11:39:12 3528121 dinov2 helpers.py:102] Training  [ 9180/12500]  eta: 0:12:56  loss: 27.3664 (34.6665)  lr: 0.0000 (0.0000)  time: 0.207141  data: 0.000456  max mem: 3586
I20250120 11:39:14 3528121 dinov2 helpers.py:102] Training  [ 9190/12500]  eta: 0:12:53  loss: 28.2235 (34.6612)  lr: 0.0000 (0.0000)  time: 0.207343  data: 0.000453  max mem: 3586
I20250120 11:39:16 3528121 dinov2 helpers.py:102] Training  [ 9200/12500]  eta: 0:12:51  loss: 28.2235 (34.6504)  lr: 0.0000 (0.0000)  time: 0.207088  data: 0.000436  max mem: 3586
I20250120 11:39:18 3528121 dinov2 helpers.py:102] Training  [ 9210/12500]  eta: 0:12:48  loss: 26.9713 (34.6420)  lr: 0.0000 (0.0000)  time: 0.207075  data: 0.000403  max mem: 3586
I20250120 11:39:20 3528121 dinov2 helpers.py:102] Training  [ 9220/12500]  eta: 0:12:46  loss: 26.9713 (34.6348)  lr: 0.0000 (0.0000)  time: 0.207448  data: 0.000425  max mem: 3586
I20250120 11:39:22 3528121 dinov2 helpers.py:102] Training  [ 9230/12500]  eta: 0:12:44  loss: 26.8748 (34.6262)  lr: 0.0000 (0.0000)  time: 0.207153  data: 0.000458  max mem: 3586
I20250120 11:39:24 3528121 dinov2 helpers.py:102] Training  [ 9240/12500]  eta: 0:12:41  loss: 26.8588 (34.6165)  lr: 0.0000 (0.0000)  time: 0.206726  data: 0.000464  max mem: 3586
I20250120 11:39:26 3528121 dinov2 helpers.py:102] Training  [ 9250/12500]  eta: 0:12:39  loss: 26.7694 (34.6080)  lr: 0.0000 (0.0000)  time: 0.206963  data: 0.000444  max mem: 3586
I20250120 11:39:28 3528121 dinov2 helpers.py:102] Training  [ 9260/12500]  eta: 0:12:36  loss: 26.8588 (34.6040)  lr: 0.0000 (0.0000)  time: 0.207196  data: 0.000440  max mem: 3586
I20250120 11:39:30 3528121 dinov2 helpers.py:102] Training  [ 9270/12500]  eta: 0:12:34  loss: 26.8588 (34.5968)  lr: 0.0000 (0.0000)  time: 0.207146  data: 0.000443  max mem: 3586
I20250120 11:39:32 3528121 dinov2 helpers.py:102] Training  [ 9280/12500]  eta: 0:12:31  loss: 26.7694 (34.5882)  lr: 0.0000 (0.0000)  time: 0.207274  data: 0.000408  max mem: 3586
I20250120 11:39:34 3528121 dinov2 helpers.py:102] Training  [ 9290/12500]  eta: 0:12:29  loss: 26.7551 (34.5789)  lr: 0.0000 (0.0000)  time: 0.207268  data: 0.000443  max mem: 3586
I20250120 11:39:37 3528121 dinov2 helpers.py:102] Training  [ 9300/12500]  eta: 0:12:27  loss: 26.7551 (34.5696)  lr: 0.0000 (0.0000)  time: 0.207253  data: 0.000494  max mem: 3586
I20250120 11:39:39 3528121 dinov2 helpers.py:102] Training  [ 9310/12500]  eta: 0:12:24  loss: 26.7694 (34.5621)  lr: 0.0000 (0.0000)  time: 0.207159  data: 0.000424  max mem: 3586
I20250120 11:39:41 3528121 dinov2 helpers.py:102] Training  [ 9320/12500]  eta: 0:12:22  loss: 26.7694 (34.5577)  lr: 0.0000 (0.0000)  time: 0.206915  data: 0.000365  max mem: 3586
I20250120 11:39:43 3528121 dinov2 helpers.py:102] Training  [ 9330/12500]  eta: 0:12:19  loss: 26.8748 (34.5500)  lr: 0.0000 (0.0000)  time: 0.206996  data: 0.000414  max mem: 3586
I20250120 11:39:45 3528121 dinov2 helpers.py:102] Training  [ 9340/12500]  eta: 0:12:17  loss: 27.3804 (34.5433)  lr: 0.0000 (0.0000)  time: 0.207045  data: 0.000457  max mem: 3586
I20250120 11:39:47 3528121 dinov2 helpers.py:102] Training  [ 9350/12500]  eta: 0:12:14  loss: 27.5617 (34.5367)  lr: 0.0000 (0.0000)  time: 0.206881  data: 0.000419  max mem: 3586
I20250120 11:39:49 3528121 dinov2 helpers.py:102] Training  [ 9360/12500]  eta: 0:12:12  loss: 27.5617 (34.5322)  lr: 0.0000 (0.0000)  time: 0.207116  data: 0.000395  max mem: 3586
I20250120 11:39:51 3528121 dinov2 helpers.py:102] Training  [ 9370/12500]  eta: 0:12:10  loss: 27.3804 (34.5220)  lr: 0.0000 (0.0000)  time: 0.207127  data: 0.000455  max mem: 3586
I20250120 11:39:53 3528121 dinov2 helpers.py:102] Training  [ 9380/12500]  eta: 0:12:07  loss: 26.8748 (34.5124)  lr: 0.0000 (0.0000)  time: 0.206726  data: 0.000480  max mem: 3586
I20250120 11:39:55 3528121 dinov2 helpers.py:102] Training  [ 9390/12500]  eta: 0:12:05  loss: 26.8748 (34.5062)  lr: 0.0000 (0.0000)  time: 0.206837  data: 0.000483  max mem: 3586
I20250120 11:39:57 3528121 dinov2 helpers.py:102] Training  [ 9400/12500]  eta: 0:12:02  loss: 26.8748 (34.4980)  lr: 0.0000 (0.0000)  time: 0.206717  data: 0.000480  max mem: 3586
I20250120 11:39:59 3528121 dinov2 helpers.py:102] Training  [ 9410/12500]  eta: 0:12:00  loss: 27.3804 (34.4927)  lr: 0.0000 (0.0000)  time: 0.206468  data: 0.000426  max mem: 3586
I20250120 11:40:01 3528121 dinov2 helpers.py:102] Training  [ 9420/12500]  eta: 0:11:57  loss: 27.3804 (34.4867)  lr: 0.0000 (0.0000)  time: 0.206668  data: 0.000418  max mem: 3586
I20250120 11:40:03 3528121 dinov2 helpers.py:102] Training  [ 9430/12500]  eta: 0:11:55  loss: 27.5617 (34.4805)  lr: 0.0000 (0.0000)  time: 0.206941  data: 0.000415  max mem: 3586
I20250120 11:40:06 3528121 dinov2 helpers.py:102] Training  [ 9440/12500]  eta: 0:11:53  loss: 27.9207 (34.4746)  lr: 0.0000 (0.0000)  time: 0.206808  data: 0.000390  max mem: 3586
I20250120 11:40:08 3528121 dinov2 helpers.py:102] Training  [ 9450/12500]  eta: 0:11:50  loss: 28.3181 (34.4701)  lr: 0.0000 (0.0000)  time: 0.206757  data: 0.000373  max mem: 3586
I20250120 11:40:10 3528121 dinov2 helpers.py:102] Training  [ 9460/12500]  eta: 0:11:48  loss: 27.9207 (34.4627)  lr: 0.0000 (0.0000)  time: 0.207071  data: 0.000399  max mem: 3586
I20250120 11:40:12 3528121 dinov2 helpers.py:102] Training  [ 9470/12500]  eta: 0:11:45  loss: 28.3181 (34.4562)  lr: 0.0000 (0.0000)  time: 0.207158  data: 0.000419  max mem: 3586
I20250120 11:40:14 3528121 dinov2 helpers.py:102] Training  [ 9480/12500]  eta: 0:11:43  loss: 28.3181 (34.4491)  lr: 0.0000 (0.0000)  time: 0.206980  data: 0.000444  max mem: 3586
I20250120 11:40:16 3528121 dinov2 helpers.py:102] Training  [ 9490/12500]  eta: 0:11:41  loss: 28.3711 (34.4460)  lr: 0.0000 (0.0000)  time: 0.206888  data: 0.000460  max mem: 3586
I20250120 11:40:18 3528121 dinov2 helpers.py:102] Training  [ 9500/12500]  eta: 0:11:38  loss: 28.3711 (34.4395)  lr: 0.0000 (0.0000)  time: 0.206775  data: 0.000426  max mem: 3586
I20250120 11:40:20 3528121 dinov2 helpers.py:102] Training  [ 9510/12500]  eta: 0:11:36  loss: 28.3711 (34.4285)  lr: 0.0000 (0.0000)  time: 0.206591  data: 0.000376  max mem: 3586
I20250120 11:40:22 3528121 dinov2 helpers.py:102] Training  [ 9520/12500]  eta: 0:11:33  loss: 28.3181 (34.4169)  lr: 0.0000 (0.0000)  time: 0.206759  data: 0.000392  max mem: 3586
I20250120 11:40:24 3528121 dinov2 helpers.py:102] Training  [ 9530/12500]  eta: 0:11:31  loss: 28.3711 (34.4130)  lr: 0.0000 (0.0000)  time: 0.206914  data: 0.000420  max mem: 3586
I20250120 11:40:26 3528121 dinov2 helpers.py:102] Training  [ 9540/12500]  eta: 0:11:29  loss: 28.3711 (34.4039)  lr: 0.0000 (0.0000)  time: 0.206725  data: 0.000439  max mem: 3586
I20250120 11:40:28 3528121 dinov2 helpers.py:102] Training  [ 9550/12500]  eta: 0:11:26  loss: 28.3711 (34.3979)  lr: 0.0000 (0.0000)  time: 0.206591  data: 0.000453  max mem: 3586
I20250120 11:40:30 3528121 dinov2 helpers.py:102] Training  [ 9560/12500]  eta: 0:11:24  loss: 28.2578 (34.3907)  lr: 0.0000 (0.0000)  time: 0.206734  data: 0.000425  max mem: 3586
I20250120 11:40:32 3528121 dinov2 helpers.py:102] Training  [ 9570/12500]  eta: 0:11:21  loss: 28.2578 (34.3819)  lr: 0.0000 (0.0000)  time: 0.206707  data: 0.000455  max mem: 3586
I20250120 11:40:35 3528121 dinov2 helpers.py:102] Training  [ 9580/12500]  eta: 0:11:19  loss: 28.2578 (34.3721)  lr: 0.0000 (0.0000)  time: 0.206716  data: 0.000457  max mem: 3586
I20250120 11:40:37 3528121 dinov2 helpers.py:102] Training  [ 9590/12500]  eta: 0:11:17  loss: 27.6654 (34.3642)  lr: 0.0000 (0.0000)  time: 0.206873  data: 0.000435  max mem: 3586
I20250120 11:40:39 3528121 dinov2 helpers.py:102] Training  [ 9600/12500]  eta: 0:11:14  loss: 27.6654 (34.3569)  lr: 0.0000 (0.0000)  time: 0.207013  data: 0.000406  max mem: 3586
I20250120 11:40:41 3528121 dinov2 helpers.py:102] Training  [ 9610/12500]  eta: 0:11:12  loss: 27.6654 (34.3516)  lr: 0.0000 (0.0000)  time: 0.206777  data: 0.000396  max mem: 3586
I20250120 11:40:43 3528121 dinov2 helpers.py:102] Training  [ 9620/12500]  eta: 0:11:09  loss: 27.6654 (34.3459)  lr: 0.0000 (0.0000)  time: 0.206666  data: 0.000389  max mem: 3586
I20250120 11:40:45 3528121 dinov2 helpers.py:102] Training  [ 9630/12500]  eta: 0:11:07  loss: 27.6654 (34.3396)  lr: 0.0000 (0.0000)  time: 0.206655  data: 0.000360  max mem: 3586
I20250120 11:40:47 3528121 dinov2 helpers.py:102] Training  [ 9640/12500]  eta: 0:11:04  loss: 27.5016 (34.3324)  lr: 0.0000 (0.0000)  time: 0.206491  data: 0.000405  max mem: 3586
I20250120 11:40:49 3528121 dinov2 helpers.py:102] Training  [ 9650/12500]  eta: 0:11:02  loss: 27.3942 (34.3231)  lr: 0.0000 (0.0000)  time: 0.206903  data: 0.000469  max mem: 3586
I20250120 11:40:51 3528121 dinov2 helpers.py:102] Training  [ 9660/12500]  eta: 0:11:00  loss: 27.3412 (34.3151)  lr: 0.0000 (0.0000)  time: 0.206900  data: 0.000441  max mem: 3586
I20250120 11:40:53 3528121 dinov2 helpers.py:102] Training  [ 9670/12500]  eta: 0:10:57  loss: 27.3412 (34.3136)  lr: 0.0000 (0.0000)  time: 0.206687  data: 0.000391  max mem: 3586
I20250120 11:40:55 3528121 dinov2 helpers.py:102] Training  [ 9680/12500]  eta: 0:10:55  loss: 27.3412 (34.3076)  lr: 0.0000 (0.0000)  time: 0.206745  data: 0.000403  max mem: 3586
I20250120 11:40:57 3528121 dinov2 helpers.py:102] Training  [ 9690/12500]  eta: 0:10:52  loss: 27.3079 (34.2968)  lr: 0.0000 (0.0000)  time: 0.206782  data: 0.000407  max mem: 3586
I20250120 11:40:59 3528121 dinov2 helpers.py:102] Training  [ 9700/12500]  eta: 0:10:50  loss: 26.8499 (34.2892)  lr: 0.0000 (0.0000)  time: 0.206855  data: 0.000405  max mem: 3586
I20250120 11:41:01 3528121 dinov2 helpers.py:102] Training  [ 9710/12500]  eta: 0:10:48  loss: 26.8499 (34.2797)  lr: 0.0000 (0.0000)  time: 0.206845  data: 0.000423  max mem: 3586
I20250120 11:41:03 3528121 dinov2 helpers.py:102] Training  [ 9720/12500]  eta: 0:10:45  loss: 26.8499 (34.2696)  lr: 0.0000 (0.0000)  time: 0.206547  data: 0.000464  max mem: 3586
I20250120 11:41:06 3528121 dinov2 helpers.py:102] Training  [ 9730/12500]  eta: 0:10:43  loss: 26.8499 (34.2621)  lr: 0.0000 (0.0000)  time: 0.206323  data: 0.000462  max mem: 3586
I20250120 11:41:08 3528121 dinov2 helpers.py:102] Training  [ 9740/12500]  eta: 0:10:41  loss: 26.9039 (34.2579)  lr: 0.0000 (0.0000)  time: 0.206536  data: 0.000457  max mem: 3586
I20250120 11:41:10 3528121 dinov2 helpers.py:102] Training  [ 9750/12500]  eta: 0:10:38  loss: 26.8499 (34.2495)  lr: 0.0000 (0.0000)  time: 0.206591  data: 0.000458  max mem: 3586
I20250120 11:41:12 3528121 dinov2 helpers.py:102] Training  [ 9760/12500]  eta: 0:10:36  loss: 26.8482 (34.2419)  lr: 0.0000 (0.0000)  time: 0.206384  data: 0.000427  max mem: 3586
I20250120 11:41:14 3528121 dinov2 helpers.py:102] Training  [ 9770/12500]  eta: 0:10:33  loss: 26.8499 (34.2353)  lr: 0.0000 (0.0000)  time: 0.206467  data: 0.000415  max mem: 3586
I20250120 11:41:16 3528121 dinov2 helpers.py:102] Training  [ 9780/12500]  eta: 0:10:31  loss: 26.8499 (34.2275)  lr: 0.0000 (0.0000)  time: 0.206621  data: 0.000383  max mem: 3586
I20250120 11:41:18 3528121 dinov2 helpers.py:102] Training  [ 9790/12500]  eta: 0:10:29  loss: 26.8482 (34.2198)  lr: 0.0000 (0.0000)  time: 0.206495  data: 0.000418  max mem: 3586
I20250120 11:41:20 3528121 dinov2 helpers.py:102] Training  [ 9800/12500]  eta: 0:10:26  loss: 26.8367 (34.2118)  lr: 0.0000 (0.0000)  time: 0.206607  data: 0.000439  max mem: 3586
I20250120 11:41:22 3528121 dinov2 helpers.py:102] Training  [ 9810/12500]  eta: 0:10:24  loss: 26.6832 (34.2031)  lr: 0.0000 (0.0000)  time: 0.206760  data: 0.000411  max mem: 3586
I20250120 11:41:24 3528121 dinov2 helpers.py:102] Training  [ 9820/12500]  eta: 0:10:21  loss: 26.6832 (34.1959)  lr: 0.0000 (0.0000)  time: 0.206735  data: 0.000397  max mem: 3586
I20250120 11:41:26 3528121 dinov2 helpers.py:102] Training  [ 9830/12500]  eta: 0:10:19  loss: 26.6832 (34.1883)  lr: 0.0000 (0.0000)  time: 0.206742  data: 0.000417  max mem: 3586
I20250120 11:41:28 3528121 dinov2 helpers.py:102] Training  [ 9840/12500]  eta: 0:10:17  loss: 26.6266 (34.1778)  lr: 0.0000 (0.0000)  time: 0.206700  data: 0.000448  max mem: 3586
I20250120 11:41:30 3528121 dinov2 helpers.py:102] Training  [ 9850/12500]  eta: 0:10:14  loss: 26.6832 (34.1713)  lr: 0.0000 (0.0000)  time: 0.206715  data: 0.000440  max mem: 3586
I20250120 11:41:32 3528121 dinov2 helpers.py:102] Training  [ 9860/12500]  eta: 0:10:12  loss: 26.6832 (34.1614)  lr: 0.0000 (0.0000)  time: 0.206602  data: 0.000441  max mem: 3586
I20250120 11:41:34 3528121 dinov2 helpers.py:102] Training  [ 9870/12500]  eta: 0:10:09  loss: 26.6832 (34.1540)  lr: 0.0000 (0.0000)  time: 0.206590  data: 0.000413  max mem: 3586
I20250120 11:41:37 3528121 dinov2 helpers.py:102] Training  [ 9880/12500]  eta: 0:10:07  loss: 26.6832 (34.1473)  lr: 0.0000 (0.0000)  time: 0.206721  data: 0.000388  max mem: 3586
I20250120 11:41:39 3528121 dinov2 helpers.py:102] Training  [ 9890/12500]  eta: 0:10:05  loss: 26.6832 (34.1361)  lr: 0.0000 (0.0000)  time: 0.206520  data: 0.000461  max mem: 3586
I20250120 11:41:41 3528121 dinov2 helpers.py:102] Training  [ 9900/12500]  eta: 0:10:02  loss: 26.6832 (34.1300)  lr: 0.0000 (0.0000)  time: 0.206448  data: 0.000485  max mem: 3586
I20250120 11:41:43 3528121 dinov2 helpers.py:102] Training  [ 9910/12500]  eta: 0:10:00  loss: 26.6832 (34.1217)  lr: 0.0000 (0.0000)  time: 0.206472  data: 0.000443  max mem: 3586
I20250120 11:41:45 3528121 dinov2 helpers.py:102] Training  [ 9920/12500]  eta: 0:09:58  loss: 26.6832 (34.1124)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000456  max mem: 3586
I20250120 11:41:47 3528121 dinov2 helpers.py:102] Training  [ 9930/12500]  eta: 0:09:55  loss: 26.6266 (34.1044)  lr: 0.0000 (0.0000)  time: 0.206491  data: 0.000451  max mem: 3586
I20250120 11:41:49 3528121 dinov2 helpers.py:102] Training  [ 9940/12500]  eta: 0:09:53  loss: 26.6266 (34.0975)  lr: 0.0000 (0.0000)  time: 0.206485  data: 0.000433  max mem: 3586
I20250120 11:41:51 3528121 dinov2 helpers.py:102] Training  [ 9950/12500]  eta: 0:09:50  loss: 26.6832 (34.0926)  lr: 0.0000 (0.0000)  time: 0.206540  data: 0.000420  max mem: 3586
I20250120 11:41:53 3528121 dinov2 helpers.py:102] Training  [ 9960/12500]  eta: 0:09:48  loss: 26.6266 (34.0845)  lr: 0.0000 (0.0000)  time: 0.206400  data: 0.000473  max mem: 3586
I20250120 11:41:55 3528121 dinov2 helpers.py:102] Training  [ 9970/12500]  eta: 0:09:46  loss: 26.6266 (34.0788)  lr: 0.0000 (0.0000)  time: 0.206620  data: 0.000463  max mem: 3586
I20250120 11:41:57 3528121 dinov2 helpers.py:102] Training  [ 9980/12500]  eta: 0:09:43  loss: 26.6832 (34.0742)  lr: 0.0000 (0.0000)  time: 0.206837  data: 0.000435  max mem: 3586
I20250120 11:41:59 3528121 dinov2 helpers.py:102] Training  [ 9990/12500]  eta: 0:09:41  loss: 26.3820 (34.0650)  lr: 0.0000 (0.0000)  time: 0.206793  data: 0.000452  max mem: 3586
I20250120 11:42:01 3528121 dinov2 linear.py:272] running validation !
I20250120 11:42:03 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:41    time: 1.427879  data: 1.215856  max mem: 3586
I20250120 11:42:05 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:48    time: 0.335517  data: 0.117266  max mem: 3586
I20250120 11:42:07 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.217860  data: 0.003950  max mem: 3586
I20250120 11:42:09 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.209423  data: 0.000397  max mem: 3586
I20250120 11:42:11 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:27    time: 0.209256  data: 0.000294  max mem: 3586
I20250120 11:42:13 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209315  data: 0.000254  max mem: 3586
I20250120 11:42:15 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209340  data: 0.000246  max mem: 3586
I20250120 11:42:17 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209443  data: 0.000257  max mem: 3586
I20250120 11:42:19 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:16    time: 0.209463  data: 0.000253  max mem: 3586
I20250120 11:42:22 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209422  data: 0.000242  max mem: 3586
I20250120 11:42:24 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208924  data: 0.000247  max mem: 3586
I20250120 11:42:26 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.208864  data: 0.000244  max mem: 3586
I20250120 11:42:28 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209443  data: 0.000210  max mem: 3586
I20250120 11:42:30 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209628  data: 0.000236  max mem: 3586
I20250120 11:42:32 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209633  data: 0.000255  max mem: 3586
I20250120 11:42:34 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208818  data: 0.000180  max mem: 3586
I20250120 11:42:35 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204664  data: 0.000164  max mem: 3586
I20250120 11:42:35 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218623 s / it)
I20250120 11:42:35 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:42:35 3528121 dinov2 linear.py:287] 
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6944, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7109, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7255, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7337, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7383, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7420, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7442, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7484, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7508, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7531, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7513, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7470, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7099, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7278, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7371, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7432, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7489, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7557, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7590, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7643, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7648, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7643, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7645, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7656, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7201, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7329, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7415, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7462, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7519, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7569, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7601, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7605, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7541, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7604, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7528, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7428, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7278, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7385, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7470, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7512, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7600, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7656, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7667, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7686, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7599, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7712, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7537, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:292] ITER: 9999 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7491, device='cuda:0')}
I20250120 11:42:35 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_01000', 'accuracy': 0.7712206840515137}
I20250120 11:42:35 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:42:35 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:42:35 3528121 dinov2 helpers.py:102] Training  [10000/12500]  eta: 0:09:47  loss: 26.2153 (34.0555)  lr: 0.0000 (0.0000)  time: 1.906299  data: 0.000467  max mem: 3586
I20250120 11:42:37 3528121 dinov2 helpers.py:102] Training  [10010/12500]  eta: 0:09:45  loss: 26.2153 (34.0469)  lr: 0.0000 (0.0000)  time: 1.905344  data: 0.000478  max mem: 3586
I20250120 11:42:39 3528121 dinov2 helpers.py:102] Training  [10020/12500]  eta: 0:09:42  loss: 26.2153 (34.0421)  lr: 0.0000 (0.0000)  time: 0.205421  data: 0.000453  max mem: 3586
I20250120 11:42:41 3528121 dinov2 helpers.py:102] Training  [10030/12500]  eta: 0:09:40  loss: 26.1095 (34.0320)  lr: 0.0000 (0.0000)  time: 0.205764  data: 0.000446  max mem: 3586
I20250120 11:42:44 3528121 dinov2 helpers.py:102] Training  [10040/12500]  eta: 0:09:37  loss: 26.2153 (34.0272)  lr: 0.0000 (0.0000)  time: 0.205898  data: 0.000414  max mem: 3586
I20250120 11:42:46 3528121 dinov2 helpers.py:102] Training  [10050/12500]  eta: 0:09:35  loss: 26.1095 (34.0180)  lr: 0.0000 (0.0000)  time: 0.205975  data: 0.000379  max mem: 3586
I20250120 11:42:48 3528121 dinov2 helpers.py:102] Training  [10060/12500]  eta: 0:09:32  loss: 26.2153 (34.0105)  lr: 0.0000 (0.0000)  time: 0.205886  data: 0.000440  max mem: 3586
I20250120 11:42:50 3528121 dinov2 helpers.py:102] Training  [10070/12500]  eta: 0:09:30  loss: 26.2153 (34.0045)  lr: 0.0000 (0.0000)  time: 0.206109  data: 0.000508  max mem: 3586
I20250120 11:42:52 3528121 dinov2 helpers.py:102] Training  [10080/12500]  eta: 0:09:28  loss: 26.2153 (34.0007)  lr: 0.0000 (0.0000)  time: 0.206084  data: 0.000467  max mem: 3586
I20250120 11:42:54 3528121 dinov2 helpers.py:102] Training  [10090/12500]  eta: 0:09:25  loss: 26.5333 (33.9937)  lr: 0.0000 (0.0000)  time: 0.206012  data: 0.000448  max mem: 3586
I20250120 11:42:56 3528121 dinov2 helpers.py:102] Training  [10100/12500]  eta: 0:09:23  loss: 26.5333 (33.9870)  lr: 0.0000 (0.0000)  time: 0.206290  data: 0.000469  max mem: 3586
I20250120 11:42:58 3528121 dinov2 helpers.py:102] Training  [10110/12500]  eta: 0:09:20  loss: 26.9495 (33.9803)  lr: 0.0000 (0.0000)  time: 0.206451  data: 0.000460  max mem: 3586
I20250120 11:43:04 3528121 dinov2 helpers.py:102] Training  [10120/12500]  eta: 0:09:19  loss: 27.1910 (33.9758)  lr: 0.0000 (0.0000)  time: 0.426805  data: 0.239752  max mem: 3586
I20250120 11:43:06 3528121 dinov2 helpers.py:102] Training  [10130/12500]  eta: 0:09:17  loss: 27.2278 (33.9697)  lr: 0.0000 (0.0000)  time: 0.425086  data: 0.240545  max mem: 3586
I20250120 11:43:09 3528121 dinov2 helpers.py:102] Training  [10140/12500]  eta: 0:09:14  loss: 27.2412 (33.9637)  lr: 0.0000 (0.0000)  time: 0.203271  data: 0.001269  max mem: 3586
I20250120 11:43:11 3528121 dinov2 helpers.py:102] Training  [10150/12500]  eta: 0:09:12  loss: 27.2261 (33.9571)  lr: 0.0000 (0.0000)  time: 0.203720  data: 0.000473  max mem: 3586
I20250120 11:43:13 3528121 dinov2 helpers.py:102] Training  [10160/12500]  eta: 0:09:09  loss: 27.2261 (33.9470)  lr: 0.0000 (0.0000)  time: 0.203784  data: 0.000407  max mem: 3586
I20250120 11:43:15 3528121 dinov2 helpers.py:102] Training  [10170/12500]  eta: 0:09:07  loss: 27.2261 (33.9411)  lr: 0.0000 (0.0000)  time: 0.203721  data: 0.000417  max mem: 3586
I20250120 11:43:17 3528121 dinov2 helpers.py:102] Training  [10180/12500]  eta: 0:09:04  loss: 27.1910 (33.9332)  lr: 0.0000 (0.0000)  time: 0.203928  data: 0.000429  max mem: 3586
I20250120 11:43:19 3528121 dinov2 helpers.py:102] Training  [10190/12500]  eta: 0:09:02  loss: 27.1910 (33.9245)  lr: 0.0000 (0.0000)  time: 0.204241  data: 0.000433  max mem: 3586
I20250120 11:43:21 3528121 dinov2 helpers.py:102] Training  [10200/12500]  eta: 0:09:00  loss: 27.1910 (33.9158)  lr: 0.0000 (0.0000)  time: 0.204485  data: 0.000448  max mem: 3586
I20250120 11:43:23 3528121 dinov2 helpers.py:102] Training  [10210/12500]  eta: 0:08:57  loss: 27.2261 (33.9094)  lr: 0.0000 (0.0000)  time: 0.204609  data: 0.000413  max mem: 3586
I20250120 11:43:25 3528121 dinov2 helpers.py:102] Training  [10220/12500]  eta: 0:08:55  loss: 27.1910 (33.9001)  lr: 0.0000 (0.0000)  time: 0.204602  data: 0.000399  max mem: 3586
I20250120 11:43:27 3528121 dinov2 helpers.py:102] Training  [10230/12500]  eta: 0:08:52  loss: 27.2261 (33.8938)  lr: 0.0000 (0.0000)  time: 0.204844  data: 0.000413  max mem: 3586
I20250120 11:43:29 3528121 dinov2 helpers.py:102] Training  [10240/12500]  eta: 0:08:50  loss: 27.1910 (33.8855)  lr: 0.0000 (0.0000)  time: 0.204972  data: 0.000446  max mem: 3586
I20250120 11:43:31 3528121 dinov2 helpers.py:102] Training  [10250/12500]  eta: 0:08:48  loss: 27.1910 (33.8778)  lr: 0.0000 (0.0000)  time: 0.205094  data: 0.000463  max mem: 3586
I20250120 11:43:33 3528121 dinov2 helpers.py:102] Training  [10260/12500]  eta: 0:08:45  loss: 27.1910 (33.8684)  lr: 0.0000 (0.0000)  time: 0.205603  data: 0.000441  max mem: 3586
I20250120 11:43:35 3528121 dinov2 helpers.py:102] Training  [10270/12500]  eta: 0:08:43  loss: 27.1910 (33.8637)  lr: 0.0000 (0.0000)  time: 0.205866  data: 0.000400  max mem: 3586
I20250120 11:43:37 3528121 dinov2 helpers.py:102] Training  [10280/12500]  eta: 0:08:40  loss: 27.1910 (33.8577)  lr: 0.0000 (0.0000)  time: 0.205826  data: 0.000458  max mem: 3586
I20250120 11:43:39 3528121 dinov2 helpers.py:102] Training  [10290/12500]  eta: 0:08:38  loss: 27.2261 (33.8526)  lr: 0.0000 (0.0000)  time: 0.205606  data: 0.000500  max mem: 3586
I20250120 11:43:41 3528121 dinov2 helpers.py:102] Training  [10300/12500]  eta: 0:08:35  loss: 27.1910 (33.8461)  lr: 0.0000 (0.0000)  time: 0.205766  data: 0.000460  max mem: 3586
I20250120 11:43:43 3528121 dinov2 helpers.py:102] Training  [10310/12500]  eta: 0:08:33  loss: 27.1114 (33.8387)  lr: 0.0000 (0.0000)  time: 0.205985  data: 0.000464  max mem: 3586
I20250120 11:43:45 3528121 dinov2 helpers.py:102] Training  [10320/12500]  eta: 0:08:31  loss: 26.1852 (33.8307)  lr: 0.0000 (0.0000)  time: 0.205952  data: 0.000456  max mem: 3586
I20250120 11:43:47 3528121 dinov2 helpers.py:102] Training  [10330/12500]  eta: 0:08:28  loss: 26.1852 (33.8244)  lr: 0.0000 (0.0000)  time: 0.206028  data: 0.000434  max mem: 3586
I20250120 11:43:50 3528121 dinov2 helpers.py:102] Training  [10340/12500]  eta: 0:08:26  loss: 26.1852 (33.8188)  lr: 0.0000 (0.0000)  time: 0.206191  data: 0.000437  max mem: 3586
I20250120 11:43:52 3528121 dinov2 helpers.py:102] Training  [10350/12500]  eta: 0:08:23  loss: 26.1852 (33.8124)  lr: 0.0000 (0.0000)  time: 0.206133  data: 0.000444  max mem: 3586
I20250120 11:43:54 3528121 dinov2 helpers.py:102] Training  [10360/12500]  eta: 0:08:21  loss: 27.1114 (33.8069)  lr: 0.0000 (0.0000)  time: 0.206108  data: 0.000462  max mem: 3586
I20250120 11:43:56 3528121 dinov2 helpers.py:102] Training  [10370/12500]  eta: 0:08:19  loss: 27.1114 (33.8011)  lr: 0.0000 (0.0000)  time: 0.206280  data: 0.000394  max mem: 3586
I20250120 11:43:58 3528121 dinov2 helpers.py:102] Training  [10380/12500]  eta: 0:08:16  loss: 27.2558 (33.7957)  lr: 0.0000 (0.0000)  time: 0.206281  data: 0.000380  max mem: 3586
I20250120 11:44:00 3528121 dinov2 helpers.py:102] Training  [10390/12500]  eta: 0:08:14  loss: 27.2558 (33.7867)  lr: 0.0000 (0.0000)  time: 0.206318  data: 0.000398  max mem: 3586
I20250120 11:44:02 3528121 dinov2 helpers.py:102] Training  [10400/12500]  eta: 0:08:11  loss: 27.2558 (33.7799)  lr: 0.0000 (0.0000)  time: 0.206255  data: 0.000395  max mem: 3586
I20250120 11:44:04 3528121 dinov2 helpers.py:102] Training  [10410/12500]  eta: 0:08:09  loss: 27.1114 (33.7717)  lr: 0.0000 (0.0000)  time: 0.206230  data: 0.000443  max mem: 3586
I20250120 11:44:06 3528121 dinov2 helpers.py:102] Training  [10420/12500]  eta: 0:08:07  loss: 27.1114 (33.7641)  lr: 0.0000 (0.0000)  time: 0.206248  data: 0.000432  max mem: 3586
I20250120 11:44:08 3528121 dinov2 helpers.py:102] Training  [10430/12500]  eta: 0:08:04  loss: 27.1114 (33.7586)  lr: 0.0000 (0.0000)  time: 0.206370  data: 0.000450  max mem: 3586
I20250120 11:44:10 3528121 dinov2 helpers.py:102] Training  [10440/12500]  eta: 0:08:02  loss: 27.1114 (33.7512)  lr: 0.0000 (0.0000)  time: 0.206480  data: 0.000432  max mem: 3586
I20250120 11:44:12 3528121 dinov2 helpers.py:102] Training  [10450/12500]  eta: 0:07:59  loss: 27.1114 (33.7443)  lr: 0.0000 (0.0000)  time: 0.206346  data: 0.000396  max mem: 3586
I20250120 11:44:14 3528121 dinov2 helpers.py:102] Training  [10460/12500]  eta: 0:07:57  loss: 27.1114 (33.7365)  lr: 0.0000 (0.0000)  time: 0.206490  data: 0.000435  max mem: 3586
I20250120 11:44:16 3528121 dinov2 helpers.py:102] Training  [10470/12500]  eta: 0:07:55  loss: 26.7179 (33.7284)  lr: 0.0000 (0.0000)  time: 0.206477  data: 0.000442  max mem: 3586
I20250120 11:44:18 3528121 dinov2 helpers.py:102] Training  [10480/12500]  eta: 0:07:52  loss: 26.7179 (33.7260)  lr: 0.0000 (0.0000)  time: 0.206248  data: 0.000401  max mem: 3586
I20250120 11:44:21 3528121 dinov2 helpers.py:102] Training  [10490/12500]  eta: 0:07:50  loss: 26.5685 (33.7160)  lr: 0.0000 (0.0000)  time: 0.206391  data: 0.000405  max mem: 3586
I20250120 11:44:23 3528121 dinov2 helpers.py:102] Training  [10500/12500]  eta: 0:07:48  loss: 26.1852 (33.7082)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000420  max mem: 3586
I20250120 11:44:25 3528121 dinov2 helpers.py:102] Training  [10510/12500]  eta: 0:07:45  loss: 26.5685 (33.7016)  lr: 0.0000 (0.0000)  time: 0.206410  data: 0.000408  max mem: 3586
I20250120 11:44:27 3528121 dinov2 helpers.py:102] Training  [10520/12500]  eta: 0:07:43  loss: 26.5685 (33.6942)  lr: 0.0000 (0.0000)  time: 0.206610  data: 0.000429  max mem: 3586
I20250120 11:44:29 3528121 dinov2 helpers.py:102] Training  [10530/12500]  eta: 0:07:40  loss: 26.5685 (33.6905)  lr: 0.0000 (0.0000)  time: 0.206601  data: 0.000455  max mem: 3586
I20250120 11:44:31 3528121 dinov2 helpers.py:102] Training  [10540/12500]  eta: 0:07:38  loss: 26.5685 (33.6872)  lr: 0.0000 (0.0000)  time: 0.206306  data: 0.000444  max mem: 3586
I20250120 11:44:33 3528121 dinov2 helpers.py:102] Training  [10550/12500]  eta: 0:07:36  loss: 26.5685 (33.6806)  lr: 0.0000 (0.0000)  time: 0.206447  data: 0.000370  max mem: 3586
I20250120 11:44:35 3528121 dinov2 helpers.py:102] Training  [10560/12500]  eta: 0:07:33  loss: 26.0601 (33.6733)  lr: 0.0000 (0.0000)  time: 0.206648  data: 0.000338  max mem: 3586
I20250120 11:44:37 3528121 dinov2 helpers.py:102] Training  [10570/12500]  eta: 0:07:31  loss: 26.0601 (33.6691)  lr: 0.0000 (0.0000)  time: 0.206540  data: 0.000381  max mem: 3586
I20250120 11:44:39 3528121 dinov2 helpers.py:102] Training  [10580/12500]  eta: 0:07:28  loss: 26.0601 (33.6621)  lr: 0.0000 (0.0000)  time: 0.206676  data: 0.000390  max mem: 3586
I20250120 11:44:41 3528121 dinov2 helpers.py:102] Training  [10590/12500]  eta: 0:07:26  loss: 26.3123 (33.6553)  lr: 0.0000 (0.0000)  time: 0.206915  data: 0.000420  max mem: 3586
I20250120 11:44:43 3528121 dinov2 helpers.py:102] Training  [10600/12500]  eta: 0:07:24  loss: 26.3123 (33.6493)  lr: 0.0000 (0.0000)  time: 0.206718  data: 0.000459  max mem: 3586
I20250120 11:44:45 3528121 dinov2 helpers.py:102] Training  [10610/12500]  eta: 0:07:21  loss: 26.4096 (33.6424)  lr: 0.0000 (0.0000)  time: 0.206653  data: 0.000430  max mem: 3586
I20250120 11:44:47 3528121 dinov2 helpers.py:102] Training  [10620/12500]  eta: 0:07:19  loss: 26.4096 (33.6342)  lr: 0.0000 (0.0000)  time: 0.206725  data: 0.000413  max mem: 3586
I20250120 11:44:49 3528121 dinov2 helpers.py:102] Training  [10630/12500]  eta: 0:07:16  loss: 26.4096 (33.6319)  lr: 0.0000 (0.0000)  time: 0.206453  data: 0.000441  max mem: 3586
I20250120 11:44:52 3528121 dinov2 helpers.py:102] Training  [10640/12500]  eta: 0:07:14  loss: 26.4994 (33.6276)  lr: 0.0000 (0.0000)  time: 0.206338  data: 0.000436  max mem: 3586
I20250120 11:44:54 3528121 dinov2 helpers.py:102] Training  [10650/12500]  eta: 0:07:12  loss: 26.4994 (33.6216)  lr: 0.0000 (0.0000)  time: 0.206551  data: 0.000442  max mem: 3586
I20250120 11:44:56 3528121 dinov2 helpers.py:102] Training  [10660/12500]  eta: 0:07:09  loss: 26.6815 (33.6151)  lr: 0.0000 (0.0000)  time: 0.206764  data: 0.000409  max mem: 3586
I20250120 11:44:58 3528121 dinov2 helpers.py:102] Training  [10670/12500]  eta: 0:07:07  loss: 26.7317 (33.6100)  lr: 0.0000 (0.0000)  time: 0.206915  data: 0.000440  max mem: 3586
I20250120 11:45:00 3528121 dinov2 helpers.py:102] Training  [10680/12500]  eta: 0:07:05  loss: 26.7317 (33.6050)  lr: 0.0000 (0.0000)  time: 0.206758  data: 0.000461  max mem: 3586
I20250120 11:45:02 3528121 dinov2 helpers.py:102] Training  [10690/12500]  eta: 0:07:02  loss: 26.7317 (33.5962)  lr: 0.0000 (0.0000)  time: 0.206479  data: 0.000375  max mem: 3586
I20250120 11:45:04 3528121 dinov2 helpers.py:102] Training  [10700/12500]  eta: 0:07:00  loss: 26.7856 (33.5906)  lr: 0.0000 (0.0000)  time: 0.206287  data: 0.000391  max mem: 3586
I20250120 11:45:06 3528121 dinov2 helpers.py:102] Training  [10710/12500]  eta: 0:06:57  loss: 27.1976 (33.5855)  lr: 0.0000 (0.0000)  time: 0.206233  data: 0.000412  max mem: 3586
I20250120 11:45:08 3528121 dinov2 helpers.py:102] Training  [10720/12500]  eta: 0:06:55  loss: 27.1976 (33.5782)  lr: 0.0000 (0.0000)  time: 0.206409  data: 0.000445  max mem: 3586
I20250120 11:45:10 3528121 dinov2 helpers.py:102] Training  [10730/12500]  eta: 0:06:53  loss: 27.1976 (33.5743)  lr: 0.0000 (0.0000)  time: 0.206489  data: 0.000475  max mem: 3586
I20250120 11:45:12 3528121 dinov2 helpers.py:102] Training  [10740/12500]  eta: 0:06:50  loss: 27.1976 (33.5687)  lr: 0.0000 (0.0000)  time: 0.206382  data: 0.000453  max mem: 3586
I20250120 11:45:14 3528121 dinov2 helpers.py:102] Training  [10750/12500]  eta: 0:06:48  loss: 27.2782 (33.5628)  lr: 0.0000 (0.0000)  time: 0.206370  data: 0.000436  max mem: 3586
I20250120 11:45:16 3528121 dinov2 helpers.py:102] Training  [10760/12500]  eta: 0:06:46  loss: 27.2782 (33.5550)  lr: 0.0000 (0.0000)  time: 0.206369  data: 0.000379  max mem: 3586
I20250120 11:45:18 3528121 dinov2 helpers.py:102] Training  [10770/12500]  eta: 0:06:43  loss: 27.1976 (33.5488)  lr: 0.0000 (0.0000)  time: 0.206311  data: 0.000347  max mem: 3586
I20250120 11:45:20 3528121 dinov2 helpers.py:102] Training  [10780/12500]  eta: 0:06:41  loss: 27.2782 (33.5444)  lr: 0.0000 (0.0000)  time: 0.206163  data: 0.000408  max mem: 3586
I20250120 11:45:22 3528121 dinov2 helpers.py:102] Training  [10790/12500]  eta: 0:06:38  loss: 27.2782 (33.5363)  lr: 0.0000 (0.0000)  time: 0.206353  data: 0.000453  max mem: 3586
I20250120 11:45:25 3528121 dinov2 helpers.py:102] Training  [10800/12500]  eta: 0:06:36  loss: 27.2782 (33.5279)  lr: 0.0000 (0.0000)  time: 0.206745  data: 0.000424  max mem: 3586
I20250120 11:45:27 3528121 dinov2 helpers.py:102] Training  [10810/12500]  eta: 0:06:34  loss: 27.2782 (33.5219)  lr: 0.0000 (0.0000)  time: 0.206635  data: 0.000437  max mem: 3586
I20250120 11:45:29 3528121 dinov2 helpers.py:102] Training  [10820/12500]  eta: 0:06:31  loss: 27.2782 (33.5146)  lr: 0.0000 (0.0000)  time: 0.206457  data: 0.000455  max mem: 3586
I20250120 11:45:31 3528121 dinov2 helpers.py:102] Training  [10830/12500]  eta: 0:06:29  loss: 26.9591 (33.5079)  lr: 0.0000 (0.0000)  time: 0.206657  data: 0.000420  max mem: 3586
I20250120 11:45:33 3528121 dinov2 helpers.py:102] Training  [10840/12500]  eta: 0:06:27  loss: 26.8664 (33.4989)  lr: 0.0000 (0.0000)  time: 0.206822  data: 0.000434  max mem: 3586
I20250120 11:45:35 3528121 dinov2 helpers.py:102] Training  [10850/12500]  eta: 0:06:24  loss: 26.6815 (33.4919)  lr: 0.0000 (0.0000)  time: 0.206973  data: 0.000416  max mem: 3586
I20250120 11:45:37 3528121 dinov2 helpers.py:102] Training  [10860/12500]  eta: 0:06:22  loss: 26.2882 (33.4836)  lr: 0.0000 (0.0000)  time: 0.207022  data: 0.000376  max mem: 3586
I20250120 11:45:39 3528121 dinov2 helpers.py:102] Training  [10870/12500]  eta: 0:06:19  loss: 26.2882 (33.4779)  lr: 0.0000 (0.0000)  time: 0.206799  data: 0.000440  max mem: 3586
I20250120 11:45:41 3528121 dinov2 helpers.py:102] Training  [10880/12500]  eta: 0:06:17  loss: 26.2882 (33.4728)  lr: 0.0000 (0.0000)  time: 0.206637  data: 0.000436  max mem: 3586
I20250120 11:45:43 3528121 dinov2 helpers.py:102] Training  [10890/12500]  eta: 0:06:15  loss: 26.2882 (33.4656)  lr: 0.0000 (0.0000)  time: 0.206624  data: 0.000429  max mem: 3586
I20250120 11:45:45 3528121 dinov2 helpers.py:102] Training  [10900/12500]  eta: 0:06:12  loss: 25.9857 (33.4579)  lr: 0.0000 (0.0000)  time: 0.206579  data: 0.000441  max mem: 3586
I20250120 11:45:47 3528121 dinov2 helpers.py:102] Training  [10910/12500]  eta: 0:06:10  loss: 25.8091 (33.4497)  lr: 0.0000 (0.0000)  time: 0.206558  data: 0.000429  max mem: 3586
I20250120 11:45:49 3528121 dinov2 helpers.py:102] Training  [10920/12500]  eta: 0:06:08  loss: 25.6402 (33.4414)  lr: 0.0000 (0.0000)  time: 0.206683  data: 0.000458  max mem: 3586
I20250120 11:45:51 3528121 dinov2 helpers.py:102] Training  [10930/12500]  eta: 0:06:05  loss: 25.5434 (33.4324)  lr: 0.0000 (0.0000)  time: 0.206590  data: 0.000455  max mem: 3586
I20250120 11:45:54 3528121 dinov2 helpers.py:102] Training  [10940/12500]  eta: 0:06:03  loss: 25.5434 (33.4252)  lr: 0.0000 (0.0000)  time: 0.206832  data: 0.000455  max mem: 3586
I20250120 11:45:56 3528121 dinov2 helpers.py:102] Training  [10950/12500]  eta: 0:06:00  loss: 25.1419 (33.4174)  lr: 0.0000 (0.0000)  time: 0.207112  data: 0.000414  max mem: 3586
I20250120 11:45:58 3528121 dinov2 helpers.py:102] Training  [10960/12500]  eta: 0:05:58  loss: 25.5434 (33.4116)  lr: 0.0000 (0.0000)  time: 0.207079  data: 0.000424  max mem: 3586
I20250120 11:46:00 3528121 dinov2 helpers.py:102] Training  [10970/12500]  eta: 0:05:56  loss: 25.5434 (33.4066)  lr: 0.0000 (0.0000)  time: 0.206873  data: 0.000394  max mem: 3586
I20250120 11:46:02 3528121 dinov2 helpers.py:102] Training  [10980/12500]  eta: 0:05:53  loss: 25.5434 (33.4026)  lr: 0.0000 (0.0000)  time: 0.206802  data: 0.000320  max mem: 3586
I20250120 11:46:04 3528121 dinov2 helpers.py:102] Training  [10990/12500]  eta: 0:05:51  loss: 25.6001 (33.3974)  lr: 0.0000 (0.0000)  time: 0.207020  data: 0.000408  max mem: 3586
I20250120 11:46:06 3528121 dinov2 helpers.py:102] Training  [11000/12500]  eta: 0:05:49  loss: 25.6001 (33.3882)  lr: 0.0000 (0.0000)  time: 0.206869  data: 0.000472  max mem: 3586
I20250120 11:46:08 3528121 dinov2 helpers.py:102] Training  [11010/12500]  eta: 0:05:46  loss: 25.5434 (33.3802)  lr: 0.0000 (0.0000)  time: 0.206715  data: 0.000429  max mem: 3586
I20250120 11:46:10 3528121 dinov2 helpers.py:102] Training  [11020/12500]  eta: 0:05:44  loss: 25.1419 (33.3724)  lr: 0.0000 (0.0000)  time: 0.206926  data: 0.000405  max mem: 3586
I20250120 11:46:12 3528121 dinov2 helpers.py:102] Training  [11030/12500]  eta: 0:05:42  loss: 25.1419 (33.3672)  lr: 0.0000 (0.0000)  time: 0.206932  data: 0.000409  max mem: 3586
I20250120 11:46:14 3528121 dinov2 helpers.py:102] Training  [11040/12500]  eta: 0:05:39  loss: 25.5434 (33.3631)  lr: 0.0000 (0.0000)  time: 0.206818  data: 0.000448  max mem: 3586
I20250120 11:46:16 3528121 dinov2 helpers.py:102] Training  [11050/12500]  eta: 0:05:37  loss: 25.5434 (33.3585)  lr: 0.0000 (0.0000)  time: 0.206919  data: 0.000460  max mem: 3586
I20250120 11:46:18 3528121 dinov2 helpers.py:102] Training  [11060/12500]  eta: 0:05:34  loss: 25.6001 (33.3524)  lr: 0.0000 (0.0000)  time: 0.206784  data: 0.000431  max mem: 3586
I20250120 11:46:20 3528121 dinov2 helpers.py:102] Training  [11070/12500]  eta: 0:05:32  loss: 25.5434 (33.3449)  lr: 0.0000 (0.0000)  time: 0.206672  data: 0.000445  max mem: 3586
I20250120 11:46:22 3528121 dinov2 helpers.py:102] Training  [11080/12500]  eta: 0:05:30  loss: 25.5434 (33.3406)  lr: 0.0000 (0.0000)  time: 0.206926  data: 0.000446  max mem: 3586
I20250120 11:46:25 3528121 dinov2 helpers.py:102] Training  [11090/12500]  eta: 0:05:27  loss: 25.6001 (33.3343)  lr: 0.0000 (0.0000)  time: 0.206836  data: 0.000454  max mem: 3586
I20250120 11:46:27 3528121 dinov2 helpers.py:102] Training  [11100/12500]  eta: 0:05:25  loss: 26.3019 (33.3302)  lr: 0.0000 (0.0000)  time: 0.206588  data: 0.000464  max mem: 3586
I20250120 11:46:29 3528121 dinov2 helpers.py:102] Training  [11110/12500]  eta: 0:05:23  loss: 26.3019 (33.3232)  lr: 0.0000 (0.0000)  time: 0.206648  data: 0.000463  max mem: 3586
I20250120 11:46:31 3528121 dinov2 helpers.py:102] Training  [11120/12500]  eta: 0:05:20  loss: 26.5445 (33.3199)  lr: 0.0000 (0.0000)  time: 0.206569  data: 0.000450  max mem: 3586
I20250120 11:46:33 3528121 dinov2 helpers.py:102] Training  [11130/12500]  eta: 0:05:18  loss: 26.9942 (33.3152)  lr: 0.0000 (0.0000)  time: 0.206731  data: 0.000465  max mem: 3586
I20250120 11:46:35 3528121 dinov2 helpers.py:102] Training  [11140/12500]  eta: 0:05:16  loss: 26.9942 (33.3081)  lr: 0.0000 (0.0000)  time: 0.206823  data: 0.000452  max mem: 3586
I20250120 11:46:37 3528121 dinov2 helpers.py:102] Training  [11150/12500]  eta: 0:05:13  loss: 26.9942 (33.3018)  lr: 0.0000 (0.0000)  time: 0.206822  data: 0.000380  max mem: 3586
I20250120 11:46:39 3528121 dinov2 helpers.py:102] Training  [11160/12500]  eta: 0:05:11  loss: 26.5445 (33.2951)  lr: 0.0000 (0.0000)  time: 0.206835  data: 0.000420  max mem: 3586
I20250120 11:46:41 3528121 dinov2 helpers.py:102] Training  [11170/12500]  eta: 0:05:09  loss: 26.5445 (33.2909)  lr: 0.0000 (0.0000)  time: 0.206797  data: 0.000439  max mem: 3586
I20250120 11:46:43 3528121 dinov2 helpers.py:102] Training  [11180/12500]  eta: 0:05:06  loss: 26.5445 (33.2869)  lr: 0.0000 (0.0000)  time: 0.206626  data: 0.000429  max mem: 3586
I20250120 11:46:45 3528121 dinov2 helpers.py:102] Training  [11190/12500]  eta: 0:05:04  loss: 26.3019 (33.2789)  lr: 0.0000 (0.0000)  time: 0.206524  data: 0.000489  max mem: 3586
I20250120 11:46:47 3528121 dinov2 helpers.py:102] Training  [11200/12500]  eta: 0:05:01  loss: 26.5445 (33.2752)  lr: 0.0000 (0.0000)  time: 0.206872  data: 0.000476  max mem: 3586
I20250120 11:46:49 3528121 dinov2 helpers.py:102] Training  [11210/12500]  eta: 0:04:59  loss: 27.6625 (33.2736)  lr: 0.0000 (0.0000)  time: 0.206857  data: 0.000418  max mem: 3586
I20250120 11:46:51 3528121 dinov2 helpers.py:102] Training  [11220/12500]  eta: 0:04:57  loss: 27.6625 (33.2666)  lr: 0.0000 (0.0000)  time: 0.206872  data: 0.000415  max mem: 3586
I20250120 11:46:54 3528121 dinov2 helpers.py:102] Training  [11230/12500]  eta: 0:04:54  loss: 26.5445 (33.2593)  lr: 0.0000 (0.0000)  time: 0.207240  data: 0.000429  max mem: 3586
I20250120 11:46:56 3528121 dinov2 helpers.py:102] Training  [11240/12500]  eta: 0:04:52  loss: 26.4410 (33.2532)  lr: 0.0000 (0.0000)  time: 0.206965  data: 0.000468  max mem: 3586
I20250120 11:46:57 3528121 dinov2 linear.py:272] running validation !
I20250120 11:46:59 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:03:52    time: 1.499220  data: 1.286483  max mem: 3586
I20250120 11:47:01 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:49    time: 0.339486  data: 0.120957  max mem: 3586
I20250120 11:47:03 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:37    time: 0.216397  data: 0.002374  max mem: 3586
I20250120 11:47:05 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:31    time: 0.208957  data: 0.000273  max mem: 3586
I20250120 11:47:07 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.209112  data: 0.000207  max mem: 3586
I20250120 11:47:10 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:24    time: 0.209602  data: 0.000237  max mem: 3586
I20250120 11:47:12 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209360  data: 0.000260  max mem: 3586
I20250120 11:47:14 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209098  data: 0.000285  max mem: 3586
I20250120 11:47:16 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.209551  data: 0.000272  max mem: 3586
I20250120 11:47:18 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209749  data: 0.000243  max mem: 3586
I20250120 11:47:20 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.209356  data: 0.000284  max mem: 3586
I20250120 11:47:22 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:09    time: 0.208990  data: 0.000287  max mem: 3586
I20250120 11:47:24 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.209119  data: 0.000263  max mem: 3586
I20250120 11:47:26 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.209496  data: 0.000253  max mem: 3586
I20250120 11:47:28 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.209111  data: 0.000237  max mem: 3586
I20250120 11:47:30 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208860  data: 0.000178  max mem: 3586
I20250120 11:47:31 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204775  data: 0.000148  max mem: 3586
I20250120 11:47:31 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.218911 s / it)
I20250120 11:47:31 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:47:31 3528121 dinov2 linear.py:287] 
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6945, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7116, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7256, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7342, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7388, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7424, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7463, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7484, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7509, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7536, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7518, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7501, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7102, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7280, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7376, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7435, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7496, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7553, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7587, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7636, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7655, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7671, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7666, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7676, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7205, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7339, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7421, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7462, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7531, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7572, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7593, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7615, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7608, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7612, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7586, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7433, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7280, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7393, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7483, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7520, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7600, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7641, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7678, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7711, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7705, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7711, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7605, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:292] ITER: 11249 -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7552, device='cuda:0')}
I20250120 11:47:31 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_00250', 'accuracy': 0.7711196541786194}
I20250120 11:47:32 3528121 dinov2 linear.py:377] Checkpointing running_checkpoint
I20250120 11:47:32 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/running_checkpoint_linear_eval.pth
I20250120 11:47:32 3528121 dinov2 helpers.py:102] Training  [11250/12500]  eta: 0:04:54  loss: 26.3019 (33.2469)  lr: 0.0000 (0.0000)  time: 1.908128  data: 0.000442  max mem: 3586
I20250120 11:47:34 3528121 dinov2 helpers.py:102] Training  [11260/12500]  eta: 0:04:51  loss: 26.3019 (33.2427)  lr: 0.0000 (0.0000)  time: 1.907336  data: 0.000393  max mem: 3586
I20250120 11:47:36 3528121 dinov2 helpers.py:102] Training  [11270/12500]  eta: 0:04:49  loss: 26.4410 (33.2370)  lr: 0.0000 (0.0000)  time: 0.205208  data: 0.000448  max mem: 3586
I20250120 11:47:38 3528121 dinov2 helpers.py:102] Training  [11280/12500]  eta: 0:04:46  loss: 26.3019 (33.2296)  lr: 0.0000 (0.0000)  time: 0.205589  data: 0.000485  max mem: 3586
I20250120 11:47:40 3528121 dinov2 helpers.py:102] Training  [11290/12500]  eta: 0:04:44  loss: 26.4410 (33.2271)  lr: 0.0000 (0.0000)  time: 0.205860  data: 0.000420  max mem: 3586
I20250120 11:47:42 3528121 dinov2 helpers.py:102] Training  [11300/12500]  eta: 0:04:42  loss: 26.2113 (33.2190)  lr: 0.0000 (0.0000)  time: 0.206045  data: 0.000417  max mem: 3586
I20250120 11:47:44 3528121 dinov2 helpers.py:102] Training  [11310/12500]  eta: 0:04:39  loss: 26.2113 (33.2120)  lr: 0.0000 (0.0000)  time: 0.206180  data: 0.000466  max mem: 3586
I20250120 11:47:46 3528121 dinov2 helpers.py:102] Training  [11320/12500]  eta: 0:04:37  loss: 26.2113 (33.2075)  lr: 0.0000 (0.0000)  time: 0.206327  data: 0.000480  max mem: 3586
I20250120 11:47:48 3528121 dinov2 helpers.py:102] Training  [11330/12500]  eta: 0:04:34  loss: 26.2113 (33.2022)  lr: 0.0000 (0.0000)  time: 0.206357  data: 0.000458  max mem: 3586
I20250120 11:47:50 3528121 dinov2 helpers.py:102] Training  [11340/12500]  eta: 0:04:32  loss: 26.4410 (33.1985)  lr: 0.0000 (0.0000)  time: 0.206255  data: 0.000449  max mem: 3586
I20250120 11:47:52 3528121 dinov2 helpers.py:102] Training  [11350/12500]  eta: 0:04:30  loss: 26.4410 (33.1922)  lr: 0.0000 (0.0000)  time: 0.206184  data: 0.000466  max mem: 3586
I20250120 11:47:54 3528121 dinov2 helpers.py:102] Training  [11360/12500]  eta: 0:04:27  loss: 26.8334 (33.1877)  lr: 0.0000 (0.0000)  time: 0.206284  data: 0.000451  max mem: 3586
I20250120 11:47:56 3528121 dinov2 helpers.py:102] Training  [11370/12500]  eta: 0:04:25  loss: 26.4410 (33.1813)  lr: 0.0000 (0.0000)  time: 0.206412  data: 0.000431  max mem: 3586
I20250120 11:47:58 3528121 dinov2 helpers.py:102] Training  [11380/12500]  eta: 0:04:23  loss: 26.4410 (33.1787)  lr: 0.0000 (0.0000)  time: 0.206474  data: 0.000404  max mem: 3586
I20250120 11:48:01 3528121 dinov2 helpers.py:102] Training  [11390/12500]  eta: 0:04:20  loss: 26.8334 (33.1731)  lr: 0.0000 (0.0000)  time: 0.230932  data: 0.028261  max mem: 3586
I20250120 11:48:03 3528121 dinov2 helpers.py:102] Training  [11400/12500]  eta: 0:04:18  loss: 26.8334 (33.1694)  lr: 0.0000 (0.0000)  time: 0.230777  data: 0.028301  max mem: 3586
I20250120 11:48:05 3528121 dinov2 helpers.py:102] Training  [11410/12500]  eta: 0:04:15  loss: 26.4410 (33.1618)  lr: 0.0000 (0.0000)  time: 0.206208  data: 0.000419  max mem: 3586
I20250120 11:48:07 3528121 dinov2 helpers.py:102] Training  [11420/12500]  eta: 0:04:13  loss: 26.4410 (33.1541)  lr: 0.0000 (0.0000)  time: 0.206205  data: 0.000378  max mem: 3586
I20250120 11:48:09 3528121 dinov2 helpers.py:102] Training  [11430/12500]  eta: 0:04:11  loss: 26.8334 (33.1495)  lr: 0.0000 (0.0000)  time: 0.206260  data: 0.000450  max mem: 3586
I20250120 11:48:11 3528121 dinov2 helpers.py:102] Training  [11440/12500]  eta: 0:04:08  loss: 26.8513 (33.1445)  lr: 0.0000 (0.0000)  time: 0.206332  data: 0.000494  max mem: 3586
I20250120 11:48:13 3528121 dinov2 helpers.py:102] Training  [11450/12500]  eta: 0:04:06  loss: 26.8513 (33.1365)  lr: 0.0000 (0.0000)  time: 0.206347  data: 0.000486  max mem: 3586
I20250120 11:48:15 3528121 dinov2 helpers.py:102] Training  [11460/12500]  eta: 0:04:04  loss: 26.8513 (33.1325)  lr: 0.0000 (0.0000)  time: 0.206399  data: 0.000458  max mem: 3586
I20250120 11:48:18 3528121 dinov2 helpers.py:102] Training  [11470/12500]  eta: 0:04:01  loss: 26.8513 (33.1268)  lr: 0.0000 (0.0000)  time: 0.206270  data: 0.000444  max mem: 3586
I20250120 11:48:20 3528121 dinov2 helpers.py:102] Training  [11480/12500]  eta: 0:03:59  loss: 26.8513 (33.1187)  lr: 0.0000 (0.0000)  time: 0.206362  data: 0.000435  max mem: 3586
I20250120 11:48:22 3528121 dinov2 helpers.py:102] Training  [11490/12500]  eta: 0:03:56  loss: 26.6276 (33.1120)  lr: 0.0000 (0.0000)  time: 0.206412  data: 0.000461  max mem: 3586
I20250120 11:48:24 3528121 dinov2 helpers.py:102] Training  [11500/12500]  eta: 0:03:54  loss: 26.8513 (33.1092)  lr: 0.0000 (0.0000)  time: 0.206307  data: 0.000455  max mem: 3586
I20250120 11:48:26 3528121 dinov2 helpers.py:102] Training  [11510/12500]  eta: 0:03:52  loss: 27.0610 (33.1040)  lr: 0.0000 (0.0000)  time: 0.206338  data: 0.000399  max mem: 3586
I20250120 11:48:28 3528121 dinov2 helpers.py:102] Training  [11520/12500]  eta: 0:03:49  loss: 27.0610 (33.1005)  lr: 0.0000 (0.0000)  time: 0.206312  data: 0.000427  max mem: 3586
I20250120 11:48:30 3528121 dinov2 helpers.py:102] Training  [11530/12500]  eta: 0:03:47  loss: 26.8513 (33.0940)  lr: 0.0000 (0.0000)  time: 0.206382  data: 0.000435  max mem: 3586
I20250120 11:48:32 3528121 dinov2 helpers.py:102] Training  [11540/12500]  eta: 0:03:45  loss: 26.8513 (33.0902)  lr: 0.0000 (0.0000)  time: 0.206334  data: 0.000372  max mem: 3586
I20250120 11:48:34 3528121 dinov2 helpers.py:102] Training  [11550/12500]  eta: 0:03:42  loss: 27.0610 (33.0856)  lr: 0.0000 (0.0000)  time: 0.206241  data: 0.000385  max mem: 3586
I20250120 11:48:36 3528121 dinov2 helpers.py:102] Training  [11560/12500]  eta: 0:03:40  loss: 26.8513 (33.0790)  lr: 0.0000 (0.0000)  time: 0.206245  data: 0.000482  max mem: 3586
I20250120 11:48:38 3528121 dinov2 helpers.py:102] Training  [11570/12500]  eta: 0:03:38  loss: 27.0610 (33.0742)  lr: 0.0000 (0.0000)  time: 0.206139  data: 0.000496  max mem: 3586
I20250120 11:48:40 3528121 dinov2 helpers.py:102] Training  [11580/12500]  eta: 0:03:35  loss: 26.8513 (33.0668)  lr: 0.0000 (0.0000)  time: 0.206137  data: 0.000404  max mem: 3586
I20250120 11:48:42 3528121 dinov2 helpers.py:102] Training  [11590/12500]  eta: 0:03:33  loss: 26.6276 (33.0601)  lr: 0.0000 (0.0000)  time: 0.206181  data: 0.000385  max mem: 3586
I20250120 11:48:44 3528121 dinov2 helpers.py:102] Training  [11600/12500]  eta: 0:03:30  loss: 25.5950 (33.0533)  lr: 0.0000 (0.0000)  time: 0.206114  data: 0.000485  max mem: 3586
I20250120 11:48:46 3528121 dinov2 helpers.py:102] Training  [11610/12500]  eta: 0:03:28  loss: 26.6276 (33.0498)  lr: 0.0000 (0.0000)  time: 0.206232  data: 0.000474  max mem: 3586
I20250120 11:48:48 3528121 dinov2 helpers.py:102] Training  [11620/12500]  eta: 0:03:26  loss: 26.6276 (33.0425)  lr: 0.0000 (0.0000)  time: 0.206267  data: 0.000456  max mem: 3586
I20250120 11:48:51 3528121 dinov2 helpers.py:102] Training  [11630/12500]  eta: 0:03:23  loss: 26.1572 (33.0365)  lr: 0.0000 (0.0000)  time: 0.206368  data: 0.000496  max mem: 3586
I20250120 11:48:53 3528121 dinov2 helpers.py:102] Training  [11640/12500]  eta: 0:03:21  loss: 26.1572 (33.0308)  lr: 0.0000 (0.0000)  time: 0.206468  data: 0.000446  max mem: 3586
I20250120 11:48:55 3528121 dinov2 helpers.py:102] Training  [11650/12500]  eta: 0:03:19  loss: 26.2921 (33.0258)  lr: 0.0000 (0.0000)  time: 0.206413  data: 0.000422  max mem: 3586
I20250120 11:48:57 3528121 dinov2 helpers.py:102] Training  [11660/12500]  eta: 0:03:16  loss: 26.1572 (33.0192)  lr: 0.0000 (0.0000)  time: 0.206422  data: 0.000467  max mem: 3586
I20250120 11:48:59 3528121 dinov2 helpers.py:102] Training  [11670/12500]  eta: 0:03:14  loss: 25.5950 (33.0126)  lr: 0.0000 (0.0000)  time: 0.206473  data: 0.000480  max mem: 3586
I20250120 11:49:01 3528121 dinov2 helpers.py:102] Training  [11680/12500]  eta: 0:03:12  loss: 25.5950 (33.0062)  lr: 0.0000 (0.0000)  time: 0.206498  data: 0.000441  max mem: 3586
I20250120 11:49:03 3528121 dinov2 helpers.py:102] Training  [11690/12500]  eta: 0:03:09  loss: 25.5950 (32.9990)  lr: 0.0000 (0.0000)  time: 0.206415  data: 0.000438  max mem: 3586
I20250120 11:49:05 3528121 dinov2 helpers.py:102] Training  [11700/12500]  eta: 0:03:07  loss: 25.5950 (32.9947)  lr: 0.0000 (0.0000)  time: 0.206526  data: 0.000417  max mem: 3586
I20250120 11:49:07 3528121 dinov2 helpers.py:102] Training  [11710/12500]  eta: 0:03:04  loss: 25.5478 (32.9874)  lr: 0.0000 (0.0000)  time: 0.206580  data: 0.000429  max mem: 3586
I20250120 11:49:09 3528121 dinov2 helpers.py:102] Training  [11720/12500]  eta: 0:03:02  loss: 25.4584 (32.9804)  lr: 0.0000 (0.0000)  time: 0.206412  data: 0.000439  max mem: 3586
I20250120 11:49:11 3528121 dinov2 helpers.py:102] Training  [11730/12500]  eta: 0:03:00  loss: 25.4584 (32.9764)  lr: 0.0000 (0.0000)  time: 0.206515  data: 0.000420  max mem: 3586
I20250120 11:49:13 3528121 dinov2 helpers.py:102] Training  [11740/12500]  eta: 0:02:57  loss: 25.3846 (32.9691)  lr: 0.0000 (0.0000)  time: 0.206601  data: 0.000448  max mem: 3586
I20250120 11:49:15 3528121 dinov2 helpers.py:102] Training  [11750/12500]  eta: 0:02:55  loss: 25.2958 (32.9618)  lr: 0.0000 (0.0000)  time: 0.206505  data: 0.000437  max mem: 3586
I20250120 11:49:17 3528121 dinov2 helpers.py:102] Training  [11760/12500]  eta: 0:02:53  loss: 25.2958 (32.9563)  lr: 0.0000 (0.0000)  time: 0.206776  data: 0.000449  max mem: 3586
I20250120 11:49:19 3528121 dinov2 helpers.py:102] Training  [11770/12500]  eta: 0:02:50  loss: 25.2958 (32.9505)  lr: 0.0000 (0.0000)  time: 0.206947  data: 0.000464  max mem: 3586
I20250120 11:49:22 3528121 dinov2 helpers.py:102] Training  [11780/12500]  eta: 0:02:48  loss: 25.3846 (32.9450)  lr: 0.0000 (0.0000)  time: 0.206751  data: 0.000478  max mem: 3586
I20250120 11:49:24 3528121 dinov2 helpers.py:102] Training  [11790/12500]  eta: 0:02:46  loss: 25.3846 (32.9376)  lr: 0.0000 (0.0000)  time: 0.206714  data: 0.000467  max mem: 3586
I20250120 11:49:26 3528121 dinov2 helpers.py:102] Training  [11800/12500]  eta: 0:02:43  loss: 25.4584 (32.9319)  lr: 0.0000 (0.0000)  time: 0.206935  data: 0.000454  max mem: 3586
I20250120 11:49:28 3528121 dinov2 helpers.py:102] Training  [11810/12500]  eta: 0:02:41  loss: 25.3846 (32.9238)  lr: 0.0000 (0.0000)  time: 0.206847  data: 0.000443  max mem: 3586
I20250120 11:49:30 3528121 dinov2 helpers.py:102] Training  [11820/12500]  eta: 0:02:39  loss: 25.3846 (32.9158)  lr: 0.0000 (0.0000)  time: 0.207002  data: 0.000421  max mem: 3586
I20250120 11:49:32 3528121 dinov2 helpers.py:102] Training  [11830/12500]  eta: 0:02:36  loss: 25.3846 (32.9095)  lr: 0.0000 (0.0000)  time: 0.206991  data: 0.000423  max mem: 3586
I20250120 11:49:34 3528121 dinov2 helpers.py:102] Training  [11840/12500]  eta: 0:02:34  loss: 25.2900 (32.9020)  lr: 0.0000 (0.0000)  time: 0.206542  data: 0.000448  max mem: 3586
I20250120 11:49:36 3528121 dinov2 helpers.py:102] Training  [11850/12500]  eta: 0:02:31  loss: 25.2763 (32.8956)  lr: 0.0000 (0.0000)  time: 0.206787  data: 0.000473  max mem: 3586
I20250120 11:49:38 3528121 dinov2 helpers.py:102] Training  [11860/12500]  eta: 0:02:29  loss: 25.2763 (32.8895)  lr: 0.0000 (0.0000)  time: 0.206793  data: 0.000453  max mem: 3586
I20250120 11:49:40 3528121 dinov2 helpers.py:102] Training  [11870/12500]  eta: 0:02:27  loss: 25.2763 (32.8854)  lr: 0.0000 (0.0000)  time: 0.206616  data: 0.000421  max mem: 3586
I20250120 11:49:42 3528121 dinov2 helpers.py:102] Training  [11880/12500]  eta: 0:02:24  loss: 25.2763 (32.8803)  lr: 0.0000 (0.0000)  time: 0.206577  data: 0.000427  max mem: 3586
I20250120 11:49:44 3528121 dinov2 helpers.py:102] Training  [11890/12500]  eta: 0:02:22  loss: 25.4413 (32.8758)  lr: 0.0000 (0.0000)  time: 0.206661  data: 0.000451  max mem: 3586
I20250120 11:49:46 3528121 dinov2 helpers.py:102] Training  [11900/12500]  eta: 0:02:20  loss: 25.4413 (32.8698)  lr: 0.0000 (0.0000)  time: 0.206856  data: 0.000466  max mem: 3586
I20250120 11:49:48 3528121 dinov2 helpers.py:102] Training  [11910/12500]  eta: 0:02:17  loss: 25.7003 (32.8646)  lr: 0.0000 (0.0000)  time: 0.206942  data: 0.000452  max mem: 3586
I20250120 11:49:51 3528121 dinov2 helpers.py:102] Training  [11920/12500]  eta: 0:02:15  loss: 25.7003 (32.8575)  lr: 0.0000 (0.0000)  time: 0.206729  data: 0.000424  max mem: 3586
I20250120 11:49:53 3528121 dinov2 helpers.py:102] Training  [11930/12500]  eta: 0:02:13  loss: 25.7003 (32.8527)  lr: 0.0000 (0.0000)  time: 0.206701  data: 0.000425  max mem: 3586
I20250120 11:49:55 3528121 dinov2 helpers.py:102] Training  [11940/12500]  eta: 0:02:10  loss: 25.7733 (32.8497)  lr: 0.0000 (0.0000)  time: 0.206859  data: 0.000391  max mem: 3586
I20250120 11:49:57 3528121 dinov2 helpers.py:102] Training  [11950/12500]  eta: 0:02:08  loss: 26.0206 (32.8454)  lr: 0.0000 (0.0000)  time: 0.206882  data: 0.000390  max mem: 3586
I20250120 11:49:59 3528121 dinov2 helpers.py:102] Training  [11960/12500]  eta: 0:02:06  loss: 26.0206 (32.8407)  lr: 0.0000 (0.0000)  time: 0.206905  data: 0.000441  max mem: 3586
I20250120 11:50:01 3528121 dinov2 helpers.py:102] Training  [11970/12500]  eta: 0:02:03  loss: 26.2367 (32.8386)  lr: 0.0000 (0.0000)  time: 0.206760  data: 0.000433  max mem: 3586
I20250120 11:50:03 3528121 dinov2 helpers.py:102] Training  [11980/12500]  eta: 0:02:01  loss: 26.2367 (32.8343)  lr: 0.0000 (0.0000)  time: 0.206776  data: 0.000432  max mem: 3586
I20250120 11:50:05 3528121 dinov2 helpers.py:102] Training  [11990/12500]  eta: 0:01:59  loss: 26.6211 (32.8291)  lr: 0.0000 (0.0000)  time: 0.206997  data: 0.000436  max mem: 3586
I20250120 11:50:07 3528121 dinov2 helpers.py:102] Training  [12000/12500]  eta: 0:01:56  loss: 26.6649 (32.8251)  lr: 0.0000 (0.0000)  time: 0.206899  data: 0.000422  max mem: 3586
I20250120 11:50:09 3528121 dinov2 helpers.py:102] Training  [12010/12500]  eta: 0:01:54  loss: 26.6649 (32.8198)  lr: 0.0000 (0.0000)  time: 0.206572  data: 0.000414  max mem: 3586
I20250120 11:50:11 3528121 dinov2 helpers.py:102] Training  [12020/12500]  eta: 0:01:52  loss: 26.7948 (32.8153)  lr: 0.0000 (0.0000)  time: 0.206604  data: 0.000430  max mem: 3586
I20250120 11:50:13 3528121 dinov2 helpers.py:102] Training  [12030/12500]  eta: 0:01:49  loss: 27.1452 (32.8120)  lr: 0.0000 (0.0000)  time: 0.206555  data: 0.000443  max mem: 3586
I20250120 11:50:15 3528121 dinov2 helpers.py:102] Training  [12040/12500]  eta: 0:01:47  loss: 27.1452 (32.8054)  lr: 0.0000 (0.0000)  time: 0.206412  data: 0.000446  max mem: 3586
I20250120 11:50:17 3528121 dinov2 helpers.py:102] Training  [12050/12500]  eta: 0:01:45  loss: 27.1452 (32.7994)  lr: 0.0000 (0.0000)  time: 0.206580  data: 0.000466  max mem: 3586
I20250120 11:50:19 3528121 dinov2 helpers.py:102] Training  [12060/12500]  eta: 0:01:42  loss: 27.1452 (32.7941)  lr: 0.0000 (0.0000)  time: 0.206686  data: 0.000440  max mem: 3586
I20250120 11:50:22 3528121 dinov2 helpers.py:102] Training  [12070/12500]  eta: 0:01:40  loss: 26.7948 (32.7884)  lr: 0.0000 (0.0000)  time: 0.206535  data: 0.000443  max mem: 3586
I20250120 11:50:24 3528121 dinov2 helpers.py:102] Training  [12080/12500]  eta: 0:01:37  loss: 27.1452 (32.7838)  lr: 0.0000 (0.0000)  time: 0.206457  data: 0.000443  max mem: 3586
I20250120 11:50:26 3528121 dinov2 helpers.py:102] Training  [12090/12500]  eta: 0:01:35  loss: 26.6649 (32.7773)  lr: 0.0000 (0.0000)  time: 0.206454  data: 0.000421  max mem: 3586
I20250120 11:50:28 3528121 dinov2 helpers.py:102] Training  [12100/12500]  eta: 0:01:33  loss: 26.6649 (32.7711)  lr: 0.0000 (0.0000)  time: 0.206410  data: 0.000463  max mem: 3586
I20250120 11:50:30 3528121 dinov2 helpers.py:102] Training  [12110/12500]  eta: 0:01:30  loss: 26.6299 (32.7660)  lr: 0.0000 (0.0000)  time: 0.206322  data: 0.000484  max mem: 3586
I20250120 11:50:32 3528121 dinov2 helpers.py:102] Training  [12120/12500]  eta: 0:01:28  loss: 26.6299 (32.7603)  lr: 0.0000 (0.0000)  time: 0.206220  data: 0.000458  max mem: 3586
I20250120 11:50:34 3528121 dinov2 helpers.py:102] Training  [12130/12500]  eta: 0:01:26  loss: 26.6211 (32.7545)  lr: 0.0000 (0.0000)  time: 0.206401  data: 0.000448  max mem: 3586
I20250120 11:50:36 3528121 dinov2 helpers.py:102] Training  [12140/12500]  eta: 0:01:23  loss: 26.5343 (32.7490)  lr: 0.0000 (0.0000)  time: 0.206677  data: 0.000437  max mem: 3586
I20250120 11:50:38 3528121 dinov2 helpers.py:102] Training  [12150/12500]  eta: 0:01:21  loss: 26.3654 (32.7417)  lr: 0.0000 (0.0000)  time: 0.206760  data: 0.000432  max mem: 3586
I20250120 11:50:40 3528121 dinov2 helpers.py:102] Training  [12160/12500]  eta: 0:01:19  loss: 26.3654 (32.7379)  lr: 0.0000 (0.0000)  time: 0.207023  data: 0.000432  max mem: 3586
I20250120 11:50:42 3528121 dinov2 helpers.py:102] Training  [12170/12500]  eta: 0:01:16  loss: 26.3654 (32.7340)  lr: 0.0000 (0.0000)  time: 0.207059  data: 0.000457  max mem: 3586
I20250120 11:50:44 3528121 dinov2 helpers.py:102] Training  [12180/12500]  eta: 0:01:14  loss: 26.3654 (32.7306)  lr: 0.0000 (0.0000)  time: 0.206954  data: 0.000417  max mem: 3586
I20250120 11:50:46 3528121 dinov2 helpers.py:102] Training  [12190/12500]  eta: 0:01:12  loss: 26.3654 (32.7261)  lr: 0.0000 (0.0000)  time: 0.206736  data: 0.000397  max mem: 3586
I20250120 11:50:48 3528121 dinov2 helpers.py:102] Training  [12200/12500]  eta: 0:01:09  loss: 26.2519 (32.7208)  lr: 0.0000 (0.0000)  time: 0.206675  data: 0.000425  max mem: 3586
I20250120 11:50:50 3528121 dinov2 helpers.py:102] Training  [12210/12500]  eta: 0:01:07  loss: 26.0620 (32.7147)  lr: 0.0000 (0.0000)  time: 0.206752  data: 0.000393  max mem: 3586
I20250120 11:50:53 3528121 dinov2 helpers.py:102] Training  [12220/12500]  eta: 0:01:05  loss: 26.0620 (32.7106)  lr: 0.0000 (0.0000)  time: 0.206677  data: 0.000419  max mem: 3586
I20250120 11:50:55 3528121 dinov2 helpers.py:102] Training  [12230/12500]  eta: 0:01:02  loss: 26.0620 (32.7076)  lr: 0.0000 (0.0000)  time: 0.207068  data: 0.000450  max mem: 3586
I20250120 11:50:57 3528121 dinov2 helpers.py:102] Training  [12240/12500]  eta: 0:01:00  loss: 26.2485 (32.7023)  lr: 0.0000 (0.0000)  time: 0.207074  data: 0.000441  max mem: 3586
I20250120 11:50:59 3528121 dinov2 helpers.py:102] Training  [12250/12500]  eta: 0:00:58  loss: 26.2519 (32.6982)  lr: 0.0000 (0.0000)  time: 0.206545  data: 0.000471  max mem: 3586
I20250120 11:51:01 3528121 dinov2 helpers.py:102] Training  [12260/12500]  eta: 0:00:55  loss: 26.2485 (32.6929)  lr: 0.0000 (0.0000)  time: 0.206574  data: 0.000500  max mem: 3586
I20250120 11:51:03 3528121 dinov2 helpers.py:102] Training  [12270/12500]  eta: 0:00:53  loss: 26.2485 (32.6876)  lr: 0.0000 (0.0000)  time: 0.206856  data: 0.000428  max mem: 3586
I20250120 11:51:05 3528121 dinov2 helpers.py:102] Training  [12280/12500]  eta: 0:00:51  loss: 26.2035 (32.6800)  lr: 0.0000 (0.0000)  time: 0.206834  data: 0.000419  max mem: 3586
I20250120 11:51:07 3528121 dinov2 helpers.py:102] Training  [12290/12500]  eta: 0:00:48  loss: 26.2485 (32.6750)  lr: 0.0000 (0.0000)  time: 0.206899  data: 0.000500  max mem: 3586
I20250120 11:51:09 3528121 dinov2 helpers.py:102] Training  [12300/12500]  eta: 0:00:46  loss: 26.2519 (32.6707)  lr: 0.0000 (0.0000)  time: 0.206883  data: 0.000515  max mem: 3586
I20250120 11:51:11 3528121 dinov2 helpers.py:102] Training  [12310/12500]  eta: 0:00:44  loss: 26.2485 (32.6647)  lr: 0.0000 (0.0000)  time: 0.206916  data: 0.000426  max mem: 3586
I20250120 11:51:13 3528121 dinov2 helpers.py:102] Training  [12320/12500]  eta: 0:00:41  loss: 26.2519 (32.6600)  lr: 0.0000 (0.0000)  time: 0.207076  data: 0.000390  max mem: 3586
I20250120 11:51:15 3528121 dinov2 helpers.py:102] Training  [12330/12500]  eta: 0:00:39  loss: 26.5288 (32.6564)  lr: 0.0000 (0.0000)  time: 0.207186  data: 0.000443  max mem: 3586
I20250120 11:51:17 3528121 dinov2 helpers.py:102] Training  [12340/12500]  eta: 0:00:37  loss: 26.5288 (32.6507)  lr: 0.0000 (0.0000)  time: 0.207095  data: 0.000456  max mem: 3586
I20250120 11:51:19 3528121 dinov2 helpers.py:102] Training  [12350/12500]  eta: 0:00:34  loss: 26.5288 (32.6437)  lr: 0.0000 (0.0000)  time: 0.206881  data: 0.000442  max mem: 3586
I20250120 11:51:22 3528121 dinov2 helpers.py:102] Training  [12360/12500]  eta: 0:00:32  loss: 26.5288 (32.6403)  lr: 0.0000 (0.0000)  time: 0.206908  data: 0.000467  max mem: 3586
I20250120 11:51:24 3528121 dinov2 helpers.py:102] Training  [12370/12500]  eta: 0:00:30  loss: 26.2519 (32.6333)  lr: 0.0000 (0.0000)  time: 0.206931  data: 0.000502  max mem: 3586
I20250120 11:51:26 3528121 dinov2 helpers.py:102] Training  [12380/12500]  eta: 0:00:27  loss: 26.2485 (32.6273)  lr: 0.0000 (0.0000)  time: 0.206910  data: 0.000480  max mem: 3586
I20250120 11:51:28 3528121 dinov2 helpers.py:102] Training  [12390/12500]  eta: 0:00:25  loss: 26.2035 (32.6221)  lr: 0.0000 (0.0000)  time: 0.206915  data: 0.000466  max mem: 3586
I20250120 11:51:30 3528121 dinov2 helpers.py:102] Training  [12400/12500]  eta: 0:00:23  loss: 26.1477 (32.6165)  lr: 0.0000 (0.0000)  time: 0.207063  data: 0.000474  max mem: 3586
I20250120 11:51:32 3528121 dinov2 helpers.py:102] Training  [12410/12500]  eta: 0:00:20  loss: 26.2035 (32.6119)  lr: 0.0000 (0.0000)  time: 0.207088  data: 0.000488  max mem: 3586
I20250120 11:51:34 3528121 dinov2 helpers.py:102] Training  [12420/12500]  eta: 0:00:18  loss: 26.1477 (32.6064)  lr: 0.0000 (0.0000)  time: 0.206972  data: 0.000474  max mem: 3586
I20250120 11:51:36 3528121 dinov2 helpers.py:102] Training  [12430/12500]  eta: 0:00:16  loss: 26.1461 (32.6007)  lr: 0.0000 (0.0000)  time: 0.206957  data: 0.000439  max mem: 3586
I20250120 11:51:38 3528121 dinov2 helpers.py:102] Training  [12440/12500]  eta: 0:00:13  loss: 26.1461 (32.5959)  lr: 0.0000 (0.0000)  time: 0.206825  data: 0.000445  max mem: 3586
I20250120 11:51:40 3528121 dinov2 helpers.py:102] Training  [12450/12500]  eta: 0:00:11  loss: 26.1461 (32.5913)  lr: 0.0000 (0.0000)  time: 0.206689  data: 0.000461  max mem: 3586
I20250120 11:51:42 3528121 dinov2 helpers.py:102] Training  [12460/12500]  eta: 0:00:09  loss: 25.7465 (32.5833)  lr: 0.0000 (0.0000)  time: 0.206756  data: 0.000502  max mem: 3586
I20250120 11:51:44 3528121 dinov2 helpers.py:102] Training  [12470/12500]  eta: 0:00:06  loss: 25.7465 (32.5795)  lr: 0.0000 (0.0000)  time: 0.206572  data: 0.000475  max mem: 3586
I20250120 11:51:46 3528121 dinov2 helpers.py:102] Training  [12480/12500]  eta: 0:00:04  loss: 25.9305 (32.5742)  lr: 0.0000 (0.0000)  time: 0.206514  data: 0.000419  max mem: 3586
I20250120 11:51:48 3528121 dinov2 helpers.py:102] Training  [12490/12500]  eta: 0:00:02  loss: 25.9305 (32.5707)  lr: 0.0000 (0.0000)  time: 0.206695  data: 0.000405  max mem: 3586
I20250120 11:51:50 3528121 fvcore.common.checkpoint checkpoint.py:124] Saving checkpoint to /home/stud/m/mc085/mounted_home/dinov2/CelebA_masked_A/eval/training_124999/linear_gender_with_masked_train_and_val_dataset/model_final.pth
I20250120 11:51:50 3528121 dinov2 helpers.py:102] Training  [12499/12500]  eta: 0:00:00  loss: 25.9305 (32.5707)  lr: 0.0000 (0.0000)  time: 0.211010  data: 0.000405  max mem: 3586
I20250120 11:51:50 3528121 dinov2 helpers.py:130] Training Total time: 0:48:25 (0.232457 s / it)
I20250120 11:51:50 3528121 dinov2 linear.py:272] running validation !
I20250120 11:51:52 3528121 dinov2 helpers.py:102] Test:  [  0/155]  eta: 0:04:11    time: 1.625241  data: 1.386437  max mem: 3586
I20250120 11:51:54 3528121 dinov2 helpers.py:102] Test:  [ 10/155]  eta: 0:00:50    time: 0.349234  data: 0.133031  max mem: 3586
I20250120 11:51:56 3528121 dinov2 helpers.py:102] Test:  [ 20/155]  eta: 0:00:38    time: 0.215386  data: 0.003969  max mem: 3586
I20250120 11:51:58 3528121 dinov2 helpers.py:102] Test:  [ 30/155]  eta: 0:00:32    time: 0.209480  data: 0.000221  max mem: 3586
I20250120 11:52:00 3528121 dinov2 helpers.py:102] Test:  [ 40/155]  eta: 0:00:28    time: 0.208768  data: 0.000206  max mem: 3586
I20250120 11:52:03 3528121 dinov2 helpers.py:102] Test:  [ 50/155]  eta: 0:00:25    time: 0.208393  data: 0.000261  max mem: 3586
I20250120 11:52:05 3528121 dinov2 helpers.py:102] Test:  [ 60/155]  eta: 0:00:22    time: 0.209148  data: 0.000265  max mem: 3586
I20250120 11:52:07 3528121 dinov2 helpers.py:102] Test:  [ 70/155]  eta: 0:00:19    time: 0.209097  data: 0.000236  max mem: 3586
I20250120 11:52:09 3528121 dinov2 helpers.py:102] Test:  [ 80/155]  eta: 0:00:17    time: 0.209509  data: 0.000246  max mem: 3586
I20250120 11:52:11 3528121 dinov2 helpers.py:102] Test:  [ 90/155]  eta: 0:00:14    time: 0.209312  data: 0.000242  max mem: 3586
I20250120 11:52:13 3528121 dinov2 helpers.py:102] Test:  [100/155]  eta: 0:00:12    time: 0.208790  data: 0.000228  max mem: 3586
I20250120 11:52:15 3528121 dinov2 helpers.py:102] Test:  [110/155]  eta: 0:00:10    time: 0.208647  data: 0.000219  max mem: 3586
I20250120 11:52:17 3528121 dinov2 helpers.py:102] Test:  [120/155]  eta: 0:00:07    time: 0.208471  data: 0.000233  max mem: 3586
I20250120 11:52:19 3528121 dinov2 helpers.py:102] Test:  [130/155]  eta: 0:00:05    time: 0.208906  data: 0.000240  max mem: 3586
I20250120 11:52:21 3528121 dinov2 helpers.py:102] Test:  [140/155]  eta: 0:00:03    time: 0.208877  data: 0.000244  max mem: 3586
I20250120 11:52:23 3528121 dinov2 helpers.py:102] Test:  [150/155]  eta: 0:00:01    time: 0.208359  data: 0.000193  max mem: 3586
I20250120 11:52:24 3528121 dinov2 helpers.py:102] Test:  [154/155]  eta: 0:00:00    time: 0.204333  data: 0.000173  max mem: 3586
I20250120 11:52:24 3528121 dinov2 helpers.py:130] Test: Total time: 0:00:33 (0.219260 s / it)
I20250120 11:52:24 3528121 dinov2 utils.py:79] Averaged stats: 
I20250120 11:52:24 3528121 dinov2 linear.py:287] 
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.6946, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7116, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7257, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7343, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7384, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7423, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7462, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7488, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7508, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7524, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7524, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7544, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7103, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7281, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7375, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7433, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7490, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7546, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7582, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7632, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7649, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7655, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7674, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_1_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7689, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00001 * {'top-1': tensor(0.7205, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00003 * {'top-1': tensor(0.7339, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00005 * {'top-1': tensor(0.7426, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00010 * {'top-1': tensor(0.7464, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00025 * {'top-1': tensor(0.7520, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00050 * {'top-1': tensor(0.7563, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00100 * {'top-1': tensor(0.7600, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00250 * {'top-1': tensor(0.7626, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_00500 * {'top-1': tensor(0.7625, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_01000 * {'top-1': tensor(0.7639, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_02500 * {'top-1': tensor(0.7654, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_False_lr_0_05000 * {'top-1': tensor(0.7598, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00001 * {'top-1': tensor(0.7282, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00003 * {'top-1': tensor(0.7392, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00005 * {'top-1': tensor(0.7478, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00010 * {'top-1': tensor(0.7518, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00025 * {'top-1': tensor(0.7604, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00050 * {'top-1': tensor(0.7645, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00100 * {'top-1': tensor(0.7679, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00250 * {'top-1': tensor(0.7701, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_00500 * {'top-1': tensor(0.7704, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_01000 * {'top-1': tensor(0.7728, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_02500 * {'top-1': tensor(0.7726, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:292]  -- Classifier: classifier_4_blocks_avgpool_True_lr_0_05000 * {'top-1': tensor(0.7623, device='cuda:0')}
I20250120 11:52:24 3528121 dinov2 linear.py:301] best classifier: {'name': 'classifier_4_blocks_avgpool_True_lr_0_01000', 'accuracy': 0.7728375196456909}
I20250120 11:52:24 3528121 dinov2 linear.py:590] Test Results Dict {'best_classifier': 'classifier_4_blocks_avgpool_True_lr_0_01000', 'CelebAMaskedVal_accuracy': 77.28375196456909}
